# Model-based clustering {#sec-mclust}

\index{cluster analysis!model-based} 

## Overview

Model-based clustering @FR02 fits a multivariate normal mixture model to the data. It uses the EM algorithm to fit the parameters for the mean, variance--covariance of each population, and the mixing proportion. The variance-covariance matrix is re-parametrized using an eigen-decomposition

$$
\Sigma_k = \lambda_kD_kA_kD_k', ~~~k=1, \dots, g ~~\mbox{(number of clusters)}
$$

\noindent resulting in several model choices, ranging from simple to complex, as shown in @tbl-covariances.

```{r}
#| label: mc-libraries
#| message: FALSE
library(dplyr)
library(kableExtra)
library(ggplot2)
library(mclust)
library(mulgar)
library(patchwork)
library(colorspace)
library(tourr)
```

```{r}
#| label: tbl-covariances
#| tbl-cap: "Parameterizations of the covariance matrix."
#| echo: FALSE
#| message: FALSE
readr::read_csv('misc/mclust-covariances.csv') %>%
  knitr::kable(align = c('c', 'c', 'c', 'c', 'c', 'c')) %>%
  kableExtra::kable_styling(full_width = FALSE)
```

\noindent Note the distribution descriptions "spherical" and "ellipsoidal". These are descriptions of the shape of the variance-covariance for a multivariate normal distribution. A standard multivariate normal distribution has a variance-covariance matrix with zeros in the off-diagonal elements, which corresponds to spherically
shaped data. When the variances (diagonals) are different or the variables are correlated, then the shape of data from a multivariate normal is ellipsoidal.

\index{Bayes Information Criterion (BIC)}

The models are typically scored using the Bayes Information Criterion (BIC), which is based on the log likelihood, number of variables, and number of mixture components. They should also be assessed using graphical methods, as we demonstrate using the \Data{penguins} data. 

## Two variables

We start with two of the four real-valued variables (`bl`, `fl`) and the three `species`. The goal is to determine whether model-based methods can discover clusters that closely correspond to the three species. Based on the scatterplot in @fig-penguins-bl-fl we would expect it to do well, and suggest an elliptical variance-covariance of roughly equal sizes as the model.

```{r}
#| label: fig-penguins-bl-fl
#| fig-cap: "Scatterplot of flipper length by bill length of the penguins data."
#| fig-width: 5
#| fig-height: 5
load("data/penguins_sub.rda")
ggplot(penguins_sub, aes(x=bl, 
                         y=fl)) + #, 
                         #colour=species)) +
  geom_point() +
  geom_density2d() +
  #scale_color_discrete_qualitative("Dark 3") +
  theme(aspect.ratio = 1)
```

```{r}
#| label: fig-penguins-bl-fl-mc
#| message: FALSE
#| fig-width: 8
#| fig-height: 4
#| fig-cap: "Summary plots from model-based clustering: (a) BIC values for clusters 2-9 of top four models, (b) variance-covariance ellipses and cluster means (+) corresponding to the best model. The best model is three-cluster EVE, which has differently shaped variance-covariances albeit the same volume and orientation."
penguins_BIC <- mclustBIC(penguins_sub[,c(1,3)])
ggmc <- ggmcbic(penguins_BIC, cl=2:9, top=4) + ggtitle("(a)")
penguins_mc <- Mclust(penguins_sub[,c(1,3)], 
                      G=3, 
                      modelNames = "EVE")
penguins_mce <- mc_ellipse(penguins_mc)
penguins_cl <- penguins_sub[,c(1,3)]
penguins_cl$cl <- factor(penguins_mc$classification)
ggell <- ggplot() +
   geom_point(data=penguins_cl, aes(x=bl, y=fl,
                                    colour=cl),
              alpha=0.3) +
   geom_point(data=penguins_mce$ell, aes(x=bl, y=fl,
                                         colour=cl),
              shape=16) +
   geom_point(data=penguins_mce$mn, aes(x=bl, y=fl,
                                        colour=cl),
              shape=3, size=2) +
  scale_color_discrete_qualitative(palette = "Dark 3") +
   theme(aspect.ratio=1, legend.position="none") +
  ggtitle("(b)")
ggmc + ggell + plot_layout(ncol=2)
```

@fig-penguins-bl-fl-mc summarises the results. All models agree that three clusters is the best. The different variance-covariance models for three clusters have similar BIC values with EVE (different shape, same volume and orientation) being slightly higher. These plots are made from the `mclust` package output using the `ggmcbic` and `mc_ellipse` functions fro the `mulgar` package.

## High-dimensions

Now we will examine how model-based clustering will group the penguins data using all four variables. 

```{r}
#| label: fig-penguins-bic
#| fig-cap: "BIC values for the top models for 2-9 clusters on the penguins data. The interpretation is mixed: if one were to choose three clusters any of the variance-covariance models would be equally as good, but the very best model is the four-cluster VEE."
#| fig-width: 6
#| fig-height: 4
#| fig-align: "center"
penguins_BIC <- mclustBIC(penguins_sub[,1:4])
ggmc <- ggmcbic(penguins_BIC, cl=2:9, top=7) 
ggmc
```

```{r}
#| eval: FALSE
#| label: best-mclust
penguins_mc <- Mclust(penguins_sub[,1:4], 
                      G=4, 
                      modelNames = "VEE")
penguins_mce <- mc_ellipse(penguins_mc)
penguins_cl <- penguins_sub
penguins_cl$cl <- factor(penguins_mc$classification)

penguins_mc_data <- penguins_cl %>%
  select(bl:bm, cl) %>%
  mutate(type = "data") %>%
  bind_rows(bind_cols(penguins_mce$ell,
                      type=rep("ellipse",
                               nrow(penguins_mce$ell)))) %>%
  mutate(type = factor(type))

animate_xy(penguins_mc_data[,1:4],
           col=penguins_mc_data$cl,
           pch=c(4, 20)[as.numeric(penguins_mc_data$type)], 
           axes="off")

# Save the animated gif
load("data/penguins_tour_path.rda")
render_gif(penguins_mc_data[,1:4], 
           planned_tour(pt1), 
           display_xy(col=penguins_mc_data$cl,
               pch=c(4, 20)[
                 as.numeric(penguins_mc_data$type)], 
                      axes="off"),
           gif_file="gifs/penguins_best_mc.gif",
           frames=500,
           loop=FALSE)
```

```{r}
#| eval: FALSE
#| label: simpler-mclust
penguins_mc <- Mclust(penguins_sub[,1:4], 
                      G=3, 
                      modelNames = "EEE")
penguins_mce <- mc_ellipse(penguins_mc)
penguins_cl <- penguins_sub
penguins_cl$cl <- factor(penguins_mc$classification)

penguins_mc_data <- penguins_cl %>%
  select(bl:bm, cl) %>%
  mutate(type = "data") %>%
  bind_rows(bind_cols(penguins_mce$ell,
                      type=rep("ellipse",
                               nrow(penguins_mce$ell)))) %>%
  mutate(type = factor(type))

animate_xy(penguins_mc_data[,1:4],
           col=penguins_mc_data$cl,
           pch=c(4, 20)[as.numeric(penguins_mc_data$type)], 
           axes="off")

# Save the animated gif
load("data/penguins_tour_path.rda")
render_gif(penguins_mc_data[,1:4], 
           planned_tour(pt1), 
           display_xy(col=penguins_mc_data$cl,
               pch=c(4, 20)[
                 as.numeric(penguins_mc_data$type)], 
                      axes="off"),
           gif_file="gifs/penguins_simpler_mc.gif",
           frames=500,
           loop=FALSE)
```
::: {#fig-penguins-mc layout-ncol=2}

![Best model: four-cluster VEE](gifs/penguins_best_mc.gif){#fig-penguins-best_mc fig-alt="FIX ME" fig.align="center"}

![Three-cluster EEE](gifs/penguins_simpler_mc.gif){#fig-penguins-simpler_mc fig-alt="FIX ME" fig.align="center"}

Examining the model-based clustering results for the penguins data: (a) best model according to BIC value, (b) simpler three-cluster model. Dots are ellipse points, and "x" are data points. It is important to note that the three cluster solution fits the data better, even though it has a lower BIC. 
:::


```{r}
#| eval: FALSE
#| echo: FALSE
# Its surprising that the four cluster solution didn't 
# pick up the sexes of the Chinstraps, where there is 
# some bimodality. Instead it splits the well-separated 
# group into two! Something to raise in the recap chapter.
penguins_cl %>% 
  count(species, cl) %>%
  pivot_wider(names_from=cl, 
              values_from=n, 
              values_fill=0)
```

<!--
@fig-model-based1 contains the plots we will use to examine the results of model-based clustering on this reduced dataset. The top leftmost plot shows the data, with male and female crabs distinguished by color and
glyph. The two sexes correspond to long cigar-shaped objects that overlap a bit, particularly for smaller crabs. The "cigars" are not perfectly regular: The variance of the data is smaller at small values
for both sexes, so that our cigars are somewhat wedge-shaped. The orientation of the longest direction of variance differs slightly between groups too: The association has a steeper slope for female crabs
than for males, because female crabs have relatively larger `rear width` than male crabs. With the heterogeneity in variance-covariance, this
data does not strictly adhere to the multivariate normal mixture model underlying model-based methods, but we hope that the departure from regularity is not so extreme that it prevents the model from working.

The top right plot shows the BIC results for a full range of models,
EEE, EEV, and VVV variance-covariance parametrization for one to nine
clusters:

    > blue.crabBIC <- mclustBIC(subset(d.blue.crabs,
        select=c(FL,RW)), modelNames=c("EEE","EEV","VVV"))
    > blue.crabBIC
     BIC:
            EEE       EEV       VVV
    1 -810.3289 -810.3289 -810.3289
    2 -820.7272 -778.6450 -783.7705
    3 -832.7712 -792.5937 -821.8645
    4 -824.8927 -835.5631 -835.7799
    5 -805.8402 -805.9425 -853.1395
    6 -807.8380 -821.1586 -879.3500
    7 -827.1099 -860.7258 -878.0679
    8 -833.8051 -861.1460 -891.9757
    9 -835.6620 -854.6120 -904.6108
    > plot(blue.crabBIC)
    EEE EEV VVV 
     15  12   0 

\noindent  The best model, EEV-2, used the equal volume, equal shape,
and different orientation variance--covariance parametrization and
divided the data into two clusters. This solution seems to be perfect!
We can imagine that this result corresponds to two equally shaped
ellipses that intersect near the lowest values of the data and angle
toward higher values. We will check by drawing ellipses representing the
variance--covariance parametrization on the data plots. The parameter
estimates are used to scale and center the ellipses:

    > mclst1 <- mclustBIC(subset(d.blue.crabs,
        select=c(FL,RW)), G=2, modelNames="EEV")
    > mclst1
     BIC:
           EEV
    2 -778.645
    > smry1 <- mclustModel(subset(d.blue.crabs,
        select=c(FL,RW)), mclst1, G=2, modelNames="EEV")
    > vc <- smry1$parameters$variance$sigma[,,1]
    > xm <- smry1$parameters$mean[,1]
    > y1 <- f.vc.ellipse(vc,xm,500)
    > ...

\noindent yielding the plots in the middle and bottom rows of
@fig-model-based1. In the plot of the data alone, cluster id is used for
the color and glyph of points. (Compare this plot with the one directly
above it, in which the classes are known.) Cluster 1 mostly corresponds
to the female crabs, and cluster 2 to the males, except that all the
small crabs, both male and female, have been assigned to cluster 1. In
the rightmost plot, we have added ellipses representing the estimated
variance--covariances. The ellipses are the same shape, as specified by
the model, but the ellipse for cluster 2 is shifted toward the large
values.

The next two best models, according to the BIC values, are EEV-3 and
VVV-2. The plots in the bottom row display representations of the
variance--covariances for these models. EEV-3 organizes the crabs into
three clusters according to the size, not the sex, of the crabs. The
VVV-2 solution is similar to EEV-2.

What solution is the best for this data? If the EEV-3 model had done
what we intuitively expected, it would have been ideal: The sexes of
smaller crabs are indistinguishable, so they should be afforded their
own cluster, whereas larger crabs could be clustered into males and
females. However, the cluster that includes the small crabs also
includes a fair number of middle-sized female crabs.

Finally, model-based clustering did not discover the true gender
clusters. Still, it produced a useful and interpretable clustering of
the crabs.

Plots are indispensable for choosing an appropriate cluster model. It is
easy to visualize the models when there are only two variables but
increasingly difficult as the number of variables grows. Tour methods
save us from producing page upon page of plots. They allow us to look at
many projections of the data, which enables us to conceptualize the
shapes and relationships between clusters in more than two dimensions.


@fig-model-based2 displays the graphics for the corresponding
high-dimensional investigation using all five variables and four classes
(two species, two sexes) of the \Data{Australian Crabs}. The cluster
analysis is much more difficult now. Can model-based clustering uncover
these four groups?

In the top row of plots, we display the raw data, before modeling. Each
plot is a tour projection of the data, colored according to the four
true classes. The blue and purple points are the male and female crabs
of the blue species, and the yellow and orange points are the male and
female crabs of the orange species. This table will help you keep track:

```{=html}
\begin{center}
\begin{tabular}{l@{\hspace{.1in}}l@{\hspace{.1in}}l} \hline
\T \B & Male & Female \\ \hline
\T Blue Species & blue rectangles & purple circles \\ 
\B Orange Species & yellow circles & orange rectangles \\\hline
\end{tabular}
\end{center}
```

The clusters corresponding to the classes are long thin wedges in five
dimensions (5D), with more separation and more variability at larger
values, as we saw in the subset just discussed. The rightmost plot shows
the looking down the barrel'' view of the wedges. At small values
the points corresponding to the sexes are mixed (leftmost plot). The
species are reasonably well separated even for small crabs (middle
plot). The variance--covariance is wedge-shaped rather than elliptical,
but again we hope that modeling based on the normal distribution that
has elliptical variance--covariance will be adequate.

```{=html}
% Figure 7
\begin{figure*}[htbp]
\centerline{{\includegraphics[width=1.5in]{chap-clust/crabs7.pdf}}
 {\includegraphics[width=1.5in]{chap-clust/crabs9.pdf}}
 {\includegraphics[width=1.5in]{chap-clust/crabs11.pdf}}}
\smallskip
\centerline{{\includegraphics[width=1.5in]{chap-clust/crabs8.pdf}}
 {\includegraphics[width=1.5in]{chap-clust/crabs10.pdf}}
 {\includegraphics[width=1.5in]{chap-clust/crabs12.pdf}}}
\caption[Comparing the \Data{Australian Crabs} data with results of
model-based clustering]{Comparing the \Data{Australian Crabs} data
with results of model-based clustering using all variables.  Compare
the tour projections of the 5D data {\bf (top row)} with the 5D ellipses
corresponding to the variance--covariance in the four-cluster model
{\bf (bottom row)}. The ellipses of the four clusters do not match the four
known groups in the data.}
\label{model-based2}
\end{figure*}
```

In the results from model-based clustering, there is very little
difference in BIC value for variance--covariance models EEE, EEV, VEV,
and VVV, with a number of clusters from three to eight. The best model
is EEV-3, and EEV-4 is second best. We know that three clusters is
insufficient to capture the four classes we have in mind, so we examine
the four-cluster solution.

    > mclst4 <- mclustBIC(subset(d.blue.crabs,select=c(FL:BD)),
        G=1:8, modelNames=c("EEE","EEV","VVV"))
    > plot(mclst4)
    EEE EEV VVV 
     15  12   0 
    > mclst5 <- mclustBIC(subset(d.blue.crabs,select=c(FL:BD)), 
       G=4, modelNames="EEV")
    > smry5 <- mclustModel(subset(d.blue.crabs,select=c(FL:BD)), 
       mclst5, G=4, modelNames="EEV")

The bottom row of plots in @fig-model-based2 illustrates the
four-cluster model in three different projections, matching the
projections in the top row showing the data.

    > vc <- smry5$parameters$variance$sigma[,,1]
    > mn <- smry5$parameters$mean[,1]
    > y1 <- f.vc.ellipse(vc, mn)
    > ...
    > mclst5.model <- cbind(matrix(NA,500*4,3),
        rbind(y1,y2,y3,y4))
    > colnames(mclst5.model) <-
        c("Species","Sex","Index","FL","RW","CL","CW","BD")
    > d.crabs.model <- rbind(d.crabs, mclst5.model)
    > gd <- ggobi(d.crabs.model)[1]
    > glyph_color(gd) <- c(rep(4,50), rep(1,50), rep(9,50), 
        rep(6,50), rep(8,2000))

\noindent In each view, the ellipsoids representing the
variance--covariance estimates for the four clusters are shown in four
shades of gray, because none of these match any actual cluster in the
data. Remember that these are 2D projections of 5D ellipsoids. The
resulting clusters from the model do not match the true classes very
well. The result roughly captures the two species, as we see in the
plots in the first column, where the species are separated both in the
data and in the ellipses. On the other hand, the grouping corresponding
to \Vbl{sex} is completely missed: See the plots in the middle and
right-hand columns, where sexes are separated in the actual data but the
ellipses are not separated. Just as in the smaller subset (two
variables, one species) discussed earlier, there is a cluster for the
smaller crabs of both species and sexes. The results of model-based
clustering on the full 5D data are very unsatisfactory.

In summary, plots of the data and parameter estimates for model-based
cluster analysis are very useful for understanding the solution, and
choosing an appropriate model. Tours are very helpful for examining the
results in higher dimensions, for arbitrary numbers of variables.

-->
