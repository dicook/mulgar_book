{
  "hash": "900ab0bbca0a73b00f694c58c0581051",
  "result": {
    "markdown": "# Overview {#sec-dimension-overview}\n\nThis chapter will focus on methods for reducing dimension, and how the tour can be used to assist with the common methods such as principal component analysis (PCA), multidimensional scaling (MDS), t-stochastic neighbour embedding (t-SNE), and factor analysis.\n\nDimension is perceived in a tour using the spread of points. When the points are spread far apart, then the data is filling the space. Conversely when the points \"collapse\" into a sub-region then the data is only partially filling the space, and some dimension reduction to reduce to this smaller dimensional space may be worthwhile. \n\n::: info\nWhen points do not fill the plotting canvas fully, it means that it lives in a lower dimension. This low-dimensional space might be linear or non-linear, with the latter being much harder to define and capture.\n:::\n\nLet's start with some 2D examples. You need at least two variables to be able to talk about association between variables. @fig-2D shows three plots of two variables. Plot (a) shows two variables that are strongly linearly associated[^5], because when `x1` is low, `x2` is low also, and conversely when `x1` is high, `x2` is also high. This can also be seen by the reducton in spread of points (or \"collapse\") in one direction making the data fill less than the full square of the plot. *So from this we can conclude that the data is not fully 2D.* The second step is to infer which variables contribute to this reduction in dimension. The axes for `x1` and `x2` are drawn extending from $(0,0)$ and because they both extend out of the cloud of points, in the direction away from the collapse of points we can say that they are jointly responsible for the dimension reduction. \n\n@fig-2D-2 shows a pair of variables that are **not** linearly associated. Variable `x1` is more varied than `x3` but knowing the value on `x1` tells us nothing about possible values on `x3`. Before running a tour all variables are typically scaled to have equal spread. The purpose of the tour is to capture association and relationships between the variables, so any univariate differences should be removed ahead of time. @fig-2D-3 shows what this would look like when `x3` is scaled - the points are fully spread in the full square of the plot. \n\n[^5]: It is generally better to use *associated*  than *correlated*. Correlated is a statistical quantity, measuring linear association. The term *associated* can be prefaced with the type of association, such as *linear* or *non-linear*. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to produce 2D data examples\"}\nlibrary(ggplot2)\nlibrary(tibble)\nset.seed(6045)\nx1 <- runif(123)\nx2 <- x1 + rnorm(123, sd=0.1)\nx3 <- rnorm(123, sd=0.2)\ndf <- tibble(x1 = (x1-mean(x1))/sd(x1), \n             x2 = (x2-mean(x2))/sd(x2),\n             x3, \n             x3scaled = (x3-mean(x3))/sd(x3))\ndp1 <- ggplot(df) + \n  geom_point(aes(x=x1, y=x2)) +\n  xlim(-2.5, 2.5) + ylim(-2.5, 2.5) +\n  annotate(\"segment\", x=0, xend=2, y=0, yend=0) +\n  annotate(\"segment\", x=0, xend=0, y=0, yend=2) +\n  annotate(\"text\", x=2.1, y=0, label=\"x1\") +\n  annotate(\"text\", x=0, y=2.1, label=\"x2\") +\n  theme_minimal() +\n  theme(aspect.ratio=1)\ndp2 <- ggplot(df) + \n  geom_point(aes(x=x1, y=x3)) +\n  xlim(-2.5, 2.5) + ylim(-2.5, 2.5) +\n  annotate(\"segment\", x=0, xend=2, y=0, yend=0) +\n  annotate(\"segment\", x=0, xend=0, y=0, yend=2) +\n  annotate(\"text\", x=2.1, y=0, label=\"x1\") +\n  annotate(\"text\", x=0, y=2.1, label=\"x3\") +\n  theme_minimal() +\n  theme(aspect.ratio=1)\ndp3 <- ggplot(df) + \n  geom_point(aes(x=x1, y=x3scaled)) +\n  xlim(-2.5, 2.5) + ylim(-2.5, 2.5) +\n  annotate(\"segment\", x=0, xend=2, y=0, yend=0) +\n  annotate(\"segment\", x=0, xend=0, y=0, yend=2) +\n  annotate(\"text\", x=2.1, y=0, label=\"x1\") +\n  annotate(\"text\", x=0, y=2.1, label=\"x3\") +\n  theme_minimal() +\n  theme(aspect.ratio=1)\n```\n:::\n\n\n::: {#fig-2D  fig-align=\"center\" layout-ncol=3}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Reduced dimension](dimension-overview_files/figure-html/fig-2D-1-1.png){#fig-2D-1 width=288}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Reduced variance](dimension-overview_files/figure-html/fig-2D-2-1.png){#fig-2D-2 width=288}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![No reduced dimension](dimension-overview_files/figure-html/fig-2D-3-1.png){#fig-2D-3 width=288}\n:::\n:::\n\n\nExplanation of how dimension reduction is perceived in 2D, relative to variables: (a) Two variables with strong linear association. Both variables contribute to the association, as indicated by their axes extending out from the \"collapsed\" direction of the points; (b) Two variables with no linear association. But x3 has less variation, so points collapse in this direction; (c) The situation in plot (b) does not arise in a tour because all variables are (usually) scaled.  When an axes extends out of a direction where the points are collapsed, it means that this variable is partially responsible for the reduced dimension.\n:::\n\nNow let's think about what this looks like with five variables. @fig-dimension shows a grand tour on five variables, with (a) showing data that is primarily 2D, (b) has data that is primarily 3D and (c) is fully 5D.  You can see that both (a) and (b) the spread of points collapse in some projections, with it happening more in (a). In (c) the data is always spread out in the square, although it does seem to concentrate or pile in the centre. This piling is typical when projecting from high dimensions to low dimensions. The sage tour [@sagetour] makes a correction for this. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to make animated gifs\"}\nlibrary(mulgar)\ndata(plane)\ndata(box)\nrender_gif(plane,\n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/plane.gif\",\n           frames=500,\n           width=200,\n           height=200)\nrender_gif(box,\n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/box.gif\",\n           frames=500,\n           width=200,\n           height=200)\n# Simulate full cube\nlibrary(geozoo)\ncube5d <- data.frame(cube.solid.random(p=5, n=300)$points)\ncolnames(cube5d) <- paste0(\"x\", 1:5)\ncube5d <- data.frame(apply(cube5d, 2, function(x) (x-mean(x))/sd(x)))\nrender_gif(cube5d,\n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/cube5d.gif\",\n           frames=500,\n           width=200,\n           height=200)\n```\n:::\n\n\n\n::: {#fig-dimension fig-align=\"center\" layout-ncol=3}\n\n::: {.content-hidden when-format=\"pdf\"}\n\n![2D plane in 5D](gifs/plane.gif){width=180}\n:::\n\n::: {.content-hidden when-format=\"pdf\"}\n\n![3D plane in 5D](gifs/box.gif){width=180}\n:::\n\n::: {.content-hidden when-format=\"pdf\"}\n\n![5D plane in 5D](gifs/cube5d.gif){width=180}\n:::\n\nDifferent dimensional planes - 2D, 3D, 5D - displayed in a grand tour projecting into 2D. Notice that the 5D in 5D always fills out the box (although it does concentrate some in the middle which is typical when projecting from high to low dimensions). Also you can see that the 2D in 5D, concentrates into a line more than the 3D in 5D. This suggests that it is lower dimensional. \n:::\n\nThe next step is to determine which variables contribute. In the examples just provided, all variables are linearly associated in the 2D and 2D data. You can check this by making a scatterplot matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code for scatterplot matrix\"}\nlibrary(GGally)\nlibrary(mulgar)\ndata(plane)\nggscatmat(plane)\n```\n\n::: {.cell-output-display}\n![Scatterplot matrix of plane data. You can see that x1-x3 are strongly linearly associated, and also x4 and x5. When you watch the tour of this data, any time the data collapses into a line you should see only (x1, x2, x3) or (x4, x5). When combinations of x1 and x4 or x5 show, the data should be spread out.](dimension-overview_files/figure-html/fig-plane-scatma-1.png){#fig-plane-scatma width=672}\n:::\n:::\n\n\nTo make an example where not all variables contribute, we have added two additional variables to the `plane` data set, which are purely noise.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# Add two pure noise dimensions to the plane\nplane_noise <- plane\nplane_noise$x6 <- rnorm(100)\nplane_noise$x7 <- rnorm(100)\nplane_noise <- data.frame(apply(plane_noise, 2, function(x) (x-mean(x))/sd(x)))\nggduo(plane_noise, columnsX = 1:5, columnsY = 6:7, \n      types = list(continuous = \"points\")) +\n  theme(aspect.ratio=1, axis.text = element_blank())\n```\n\n::: {.cell-output-display}\n![Additional noise variables are not associated with any of the first five variables.](dimension-overview_files/figure-html/fig-plane-noise-scatter-1.png){#fig-plane-noise-scatter width=768}\n:::\n:::\n\n\nNow we have 2D structure in 7D, but only five of the variables contribute to the 2D structure, that is, five of the variables are linearly related with each other. The other two variables (x6, x7) are not linearly related to any of the others. \n\nWe can still see the concentration of points along a line in some dimensions, which tells us that the data is not fully 7D. Then if you look closely at the variable axes you will see that the collapsing to a line only occurs when any of x1-x5 contribute strongly in the direction orthogonal to this. This does not happen when x6 or x7 contribute strongly to a projection - the data is always expanded to fill much of the space. That tells us that x6 and x7 don't substantially contribute to the dimension reduction, that is, they are not linearly related to the other variables.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Code to generate animation\"}\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(htmlwidgets)\n\nset.seed(78)\nb <- basis_random(7, 2)\npn_t <- tourr::save_history(plane_noise, \n                    tour_path = grand_tour(),\n                    start = b,\n                    max_bases = 8)\npn_t <- interpolate(pn_t, 0.1)\npn_anim <- render_anim(plane_noise,\n                         frames=pn_t)\n\npn_gp <- ggplot() +\n     geom_path(data=pn_anim$circle, \n               aes(x=c1, y=c2,\n                   frame=frame), linewidth=0.1) +\n     geom_segment(data=pn_anim$axes, \n                  aes(x=x1, y=y1, \n                      xend=x2, yend=y2, \n                      frame=frame), \n                  linewidth=0.1) +\n     geom_text(data=pn_anim$axes, \n               aes(x=x2, y=y2, \n                   frame=frame, \n                   label=axis_labels), \n               size=5) +\n     geom_point(data=pn_anim$frames, \n                aes(x=P1, y=P2, \n                    frame=frame), \n                alpha=0.8) +\n     xlim(-1,1) + ylim(-1,1) +\n     coord_equal() +\n     theme_bw() +\n     theme(axis.text=element_blank(),\n         axis.title=element_blank(),\n         axis.ticks=element_blank(),\n         panel.grid=element_blank())\npn_tour <- ggplotly(pn_gp,\n                        width=500,\n                        height=550) %>%\n       animation_button(label=\"Go\") %>%\n       animation_slider(len=0.8, x=0.5,\n                        xanchor=\"center\") %>%\n       animation_opts(easing=\"linear\", \n                      transition = 0)\n\nhtmlwidgets::saveWidget(pn_tour,\n          file=\"html/plane_noise.html\",\n          selfcontained = TRUE)\n```\n:::\n\n\n::: {#fig-plane-noise}\n\n<iframe width=\"750\" height=\"550\" src=\"html/plane_noise.html\" title=\"Grand tour of the plane with two additional dimensions of pure noise. \"></iframe>\n\nGrand tour of the plane with two additional dimensions of pure noise. The collapsing of the points indicates that this is not fully 7D. This only happens when any of x1-x5 are contributing strongly (frame 49 x4, x5; frame 79 x1; frame 115 x2, x3). If x6 or x7 are contributing strongly the data is spread out fully. This tells us that x6 and x7 are not linearly associated, but other variables are.\n:::\n\n::: info\nTo determine which variables are responsible for the reduced dimension look for the axes that extend out of the point cloud. These contribute to smaller variation in the observations, and thus indicate dimension reduction.\n:::\n\nThe simulated data here is very simple, and what we have learned from the tour could also be learned from principal component analysis. However, if there are small complications, such as outliers or nonlinear relationships, that might not be visible from principal component analysis, the tour can help you to see them.\n\n@fig-plane-noise-outlier and @fig-outlier show example data with an outlier and @fig-nonlinear shows data with non-linear relationships. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code for scatterplot matrix\"}\n# Add several outliers to the plane_noise data\nplane_noise_outliers <- plane_noise\nplane_noise_outliers[101,] <- c(2, 2, -2, 0, 0, 0, 0)\nplane_noise_outliers[102,] <- c(0, 0, 0,-2, -2, 0, 0)\n\nggscatmat(plane_noise_outliers, columns = 1:5) +\n  theme(aspect.ratio=1, axis.text = element_blank())\n```\n\n::: {.cell-output-display}\n![Outliers added to the plane with noise data.](dimension-overview_files/figure-html/fig-plane-noise-outlier-1.png){#fig-plane-noise-outlier width=768}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to generate animated gif\"}\nrender_gif(plane_noise_outliers,          \n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/pn_outliers.gif\",\n           frames=500,\n           width=200,\n           height=200)\n\ndata(plane_nonlin)\nrender_gif(plane_nonlin,          \n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/plane_nonlin.gif\",\n           frames=500,\n           width=200,\n           height=200)\n```\n:::\n\n\n::: {#fig-outlier-nonlin fig-align=\"center\" layout-ncol=2}\n\n::: {.content-hidden when-format=\"pdf\"}\n\n![Outliers](gifs/pn_outliers.gif){#fig-outlier width=180}\n:::\n\n::: {.content-hidden when-format=\"pdf\"}\n\n![Non-linear relationship](gifs/plane_nonlin.gif){#fig-nonlinear width=180}\n:::\n\nExamples of different types of dimensionality issues: outliers (a) and non-linearity (b). In (a) you can see two points far from the others in some projections. Also the two can be seen with different movement patterns, moving faster that other points during the tour. Outliers will affect detection of reduced dimension, but it is easy to ignore with the tour. In (b) there is a non-linear relationship between several variables, primarily with x3. Non-linear relationships may not be captured by other techniques but are visible with the tour.\n:::\n\n\n::: {.cell}\n\n:::\n\n\n## Exercises {-}\n\n1. Multicollinearity is when the predictors for a model are strongly linearly associated. It can adversely affect the fitting of most models, because many possible models may be equally as good. Variable importance might be masked by correlated variables, and confidence intervals generated for linear models might be too wide. Check the for multicollinearity or other associations between the predictors in:\na. 2001 Australian election data\nb. 2016 Australian election data\n2. Examine 5D multivariate normal samples drawn from populations with a range of variance-covariance matrices.  (You can use the `mvtnorm` package to do the sampling, for example.) Examine the data using a grand tour. What changes when you change the correlation from close to zero to close to 1?  Can you see a difference between strong positive correlation and strong negative correlation?\n",
    "supporting": [
      "dimension-overview_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}