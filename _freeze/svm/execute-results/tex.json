{
  "hash": "40cdba008c9b53034b1de07466433cc8",
  "result": {
    "markdown": "# Support vector machines\n\\index{classification methods!support vector machines (SVM)}\n\nA support vector machine (SVM) [@Va99] looks for gaps between clusters in the data, based on the extreme observations in each class. In this sense it mirrors the graphical approach described @sec-clust-graphics, in which we searched for gaps between groups. It can be viewed as similar to LDA, in that the boundary between classes is a hyperplane.  The difference between LDA and SVM is the placement of the boundary. LDA uses the means and covariance matrices of the classes to place the boundary, but SVM uses extreme observations.\n\n::: info\nThe key elements of the SVM model to examine are:\n\n- support vectors\n- separating hyperplane.\n\n:::\n\n## Components of the SVM model\n\nTo illustrate the approach, we use two simple simulated data examples. Both have only two variables, and two classes. Explaining SVM is easier when there are just two groups. In the first data set the two classes have different covariances matrices, which will cause trouble for LDA, but SVM should see the gap between the two clusters and place the separating hyperplane in the middle of the gap. In the second data set the two groups are concentric circles, with the inner one solid. A non-linear SVM should be fitted to this data, which should see circular gap between the two classes. \n\nNote that the `svm` function in the `e1071` package will automatically scale observations into the range $[0,1]$. To make it easier to examine the fitted model, it is best to scale your data first, and then fit the model.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to simulate data examples\"}\n# Toy examples\nlibrary(mulgar)\nlibrary(ggplot2)\nlibrary(geozoo)\nlibrary(tourr)\n\nset.seed(1071)\nn1 <- 162\nvc1 <- matrix(c(1, -0.7, -0.7, 1), ncol=2, byrow=TRUE)\nc1 <- rmvn(n=n1, p=2, mn=c(-2, -2), vc=vc1)\nvc2 <- matrix(c(1, -0.4, -0.4, 1)*2, ncol=2, byrow=TRUE)\nn2 <- 138\nc2 <- rmvn(n=n2, p=2, mn=c(2, 2), vc=vc2)\ndf1 <- data.frame(x1=mulgar:::scale2(c(c1[,1], c2[,1])), \n                 x2=mulgar:::scale2(c(c1[,2], c2[,2])), \n                 cl = factor(c(rep(\"A\", n1), \n                               rep(\"B\", n2))))\nc1 <- sphere.hollow(p=2, n=n1)$points*3 + \n  c(rnorm(n1, sd=0.3), rnorm(n1, sd=0.3))\nc2 <- sphere.solid.random(p=2, n=n2)$points\ndf2 <- data.frame(x1=mulgar:::scale2(c(c1[,1], c2[,1])), \n                  x2=mulgar:::scale2(c(c1[,2], c2[,2])), \n                  cl = factor(c(rep(\"A\", n1), \n                               rep(\"B\", n2))))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(classifly)\nlibrary(e1071)\ndf1_svm <- svm(cl~., data=df1, \n                     probability=TRUE, \n                     kernel=\"linear\", \n               scale=FALSE)\ndf1_svm_e <- explore(df1_svm, df1)\n\ndf2_svm <- svm(cl~., data=df2,  \n                     probability=TRUE, \n                     kernel=\"radial\")\ndf2_svm_e <- explore(df2_svm, df2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to make plots\"}\nlibrary(patchwork)\nlibrary(colorspace)\ns1 <- ggplot() + \n  geom_point(data=df1, aes(x=x1, y=x2, colour=cl),\n             shape=20) +\n  scale_colour_discrete_divergingx(palette=\"Zissou 1\") +\n  geom_point(data=df1_svm_e[(!df1_svm_e$.BOUNDARY)&(df1_svm_e$.TYPE==\"simulated\"),], \n             aes(x=x1, y=x2, colour=cl), shape=3) +\n  geom_point(data=df1[df1_svm$index,], \n             aes(x=x1, y=x2, colour=cl), \n             shape=4, size=4) +\n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position = \"none\") +\n  ggtitle(\"(a)\")\n\ns2 <- ggplot() + \n  geom_point(data=df2, aes(x=x1, y=x2, colour=cl), shape=20) +\n  scale_colour_discrete_divergingx(palette=\"Zissou 1\") +\n  geom_point(data=df2_svm_e[(!df2_svm_e$.BOUNDARY)&(df2_svm_e$.TYPE==\"simulated\"),], \n             aes(x=x1, y=x2, colour=cl), \n             shape=3) +\n  geom_point(data=df2[df2_svm$index,], \n             aes(x=x1, y=x2, colour=cl), \n             shape=4, size=4) +\n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position = \"none\") +\n  ggtitle(\"(b)\")\n\ns1+s2\n```\n\n::: {.cell-output-display}\n![SVM classifier fit overlaid on two simulated data examples: (a) groups with different variance-covariance, fitted using a linear kernel, (b) groups with non-linear separation, fitted using a radial kernel. The band of points shown as '+' mark the SVM boundary, and points marked by 'x' are the support vectors used to define the boundary. ](svm_files/figure-pdf/fig-svm-toy-1.pdf){#fig-svm-toy fig-pos='H'}\n:::\n:::\n\n\n@fig-svm-toy shows the two data sets and the important aspects of the fitted SVM model for each. The observations are represented by dots, the separating hyperplane (just a line for 2D) is represented by '+'. Where the two colours merge is the actual location of the boundary between classes. It can be seen that this is located right down the middle of the gap, for both data sets. Even though the boundary is circular for the second data set, in a transformed high-dimensional space it would be linear.\n\nSVMs use a subset of the observations to define the boundary, and these are called the support vectors. For each of the data sets these are marked with 'x'. For the linear boundary, there are nine support vectors, five in one group and four in the other. There is one interesting observation in the red group, which falls on the other side of the boundary. It is marked as a support vector, but its contribution to the fitted hyperplane is limited by a control parameter in the model fitting process. \n\nLinear SVMs can be assessed similarly to regression models. The components of the model are:\n\n1. The points that are the support vectors:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndf1_svm$index\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  15  45 123 135 155 180 202 239 292\n```\n:::\n:::\n\n\n2. Their coefficients:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndf1_svm$coefs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            [,1]\n [1,]  0.3771240\n [2,]  0.1487726\n [3,]  1.0000000\n [4,]  1.0000000\n [5,]  1.0000000\n [6,] -0.5258966\n [7,] -1.0000000\n [8,] -1.0000000\n [9,] -1.0000000\n```\n:::\n:::\n\n\nwhich indicate that all but 15, 45 and 180 are actually bounded support vectors (their coefficients are bounded to magnitude 1). \n\n3. that when used with the intercept:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndf1_svm$rho\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3520001\n```\n:::\n:::\n\n\ncan be used to compute the equation of the fitted hyperplane. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nw = t(df1_svm$SV) %*% df1_svm$coefs\nw\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        [,1]\nx1 -1.501086\nx2 -1.356237\n```\n:::\n:::\n\n\nGiving the equation to be -1.5 $x_1 +$ -1.36 $x_2 +$ -0.35 $=0$, or alternatively, $x_2 =$ -1.11 $x_1 +$ -0.26.\n\nwhich can be used to generate a line to show the boundary with the data. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ns1 + geom_abline(intercept=df1_svm$rho/w[2],\n                 slope=-w[1]/w[2])\n```\n:::\n\n\n**Note that** care in scaling of data is important to get the intercept calculated exactly. We have standardised the data, and set the `scale=FALSE` parameter in the `svm` function. The slope calculation is quite robust to the data scaling.\n\n## Examining the model components in high-dimensions\n\nFor higher dimensions, the procedures are similar, with the hyperplane and support vectors being examined using a tour. Here we examine the model for differentiating male and female Chinstrap penguins. The Chinstrap penguins have a noticeable difference in size of the sexes, unlike the other two species. Working with a two-class problem is easier for explaining SVM, but multi-class calculations can also follow this approach.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(dplyr)\nload(\"data/penguins_sub.rda\")\nchinstrap <- penguins_sub %>%\n  filter(species == \"Chinstrap\") %>%\n  select(-species) %>%\n  mutate_if(is.numeric, mulgar:::scale2)\nchinstrap_svm <- svm(sex~., data=chinstrap, \n                     kernel=\"linear\",\n                     probability=TRUE, \n                     scale=FALSE)\nchinstrap_svm_e <- explore(chinstrap_svm, chinstrap)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to make the tours\"}\n# Tour raw data\nanimate_xy(chinstrap[,1:4], col=chinstrap$sex)\n# Add all SVs, including bounded\nc_pch <- rep(20, nrow(chinstrap))\nc_pch[chinstrap_svm$index] <- 4\nanimate_xy(chinstrap[,1:4], col=chinstrap$sex, pch=c_pch)\n# Only show the SVs with |coefs| < 1\nc_pch <- rep(20, nrow(chinstrap))\nc_pch[chinstrap_svm$index[abs(chinstrap_svm$coefs)<1]] <- 4\nc_cex <- rep(1, nrow(chinstrap))\nc_cex[chinstrap_svm$index[abs(chinstrap_svm$coefs)<1]] <- 2\nanimate_xy(chinstrap[,1:4], col=chinstrap$sex, \n           pch=c_pch, cex=c_cex)\nrender_gif(chinstrap[,1:4],\n           grand_tour(),\n           display_xy(col=chinstrap$sex, pch=c_pch, cex=c_cex),\n           gif_file=\"gifs/chinstrap_svs.gif\",\n           width=400,\n           height=400,\n           frames=500)\n\n# Tour the separating hyperplane also\nsymbols <- c(3, 20)\nc_pch <- symbols[as.numeric(chinstrap_svm_e$.TYPE[!chinstrap_svm_e$.BOUNDARY])]\nanimate_xy(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4], \n           col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY],\n           pch=c_pch)\nrender_gif(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4],\n           grand_tour(),\n           display_xy(col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY], pch=c_pch),\n           gif_file=\"gifs/chinstrap_svm.gif\",\n           width=400,\n           height=400,\n           frames=500)\n```\n:::\n\n\n::: {#fig-p-svm layout-ncol=2}\n\n::: {.content-hidden when-format=\"pdf\"}\n\n![Exploring which points are support vectors.](gifs/chinstrap_svs.gif){#fig-chinstrap_svs fig-alt=\"FIX ME\" width=300}\n\n![Exploring SVM boundary.](gifs/chinstrap_svm.gif){#fig-chinstrap_svm fig-alt=\"FIX ME\" width=300}\n:::\n\nSVM model for distinguishing the sexes of the Chinstrap penguins. The separating hyperplane is 3D, and separates primarily on variables `bl` and `bd`, as seen because these two axes extend out from the plane when it is seen on its side, separating the two groups.\n:::\n\nWe can check this interpretation using the radial tour. Using the components from the model, the coefficients of the hyperplane are: \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nt(chinstrap_svm$SV) %*% chinstrap_svm$coefs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         [,1]\nbl -0.9102439\nbd -1.1073475\nfl -0.5223364\nbm -0.2846370\n```\n:::\n:::\n\n\nThis supports the observation that `bl` and `bd` are most important, because they have the largest magnitudes. We can use this vector to set the starting point for radial tour. It needs to be normalised. A randomly generated second vector orthonormal to this one can be added to make a 2D projection from which to see the boundary.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nset.seed(1022)\nprj1 <- mulgar::norm_vec(t(chinstrap_svm$SV) %*% chinstrap_svm$coefs)\nprj2 <- basis_random(4, 1)\nprj <- orthonormalise(cbind(prj1, prj2))\nprj\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         [,1]        [,2]\nbl -0.5865081 -0.06412875\nbd -0.7135101  0.51192498\nfl -0.3365631 -0.77713899\nbm -0.1834035 -0.36038216\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to conduct the radial tours\"}\nanimate_xy(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4], \n           tour_path = radial_tour(start=prj, mvar = 2),\n           col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY],\n           pch=c_pch)\nrender_gif(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4],\n           radial_tour(start=prj, mvar = 2),\n           display_xy(col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY], pch=c_pch),\n           gif_file=\"gifs/chinstrap_rad_bd.gif\",\n           apf = 1/30,\n           width=400,\n           height=400,\n           frames=500)\nrender_gif(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4],\n           radial_tour(start=prj, mvar = 1),\n           display_xy(col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY], pch=c_pch),\n           gif_file=\"gifs/chinstrap_rad_bl.gif\",\n           apf = 1/30,\n           width=400,\n           height=400,\n           frames=500)\nrender_gif(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4],\n           radial_tour(start=prj, mvar = 3),\n           display_xy(col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY], pch=c_pch),\n           gif_file=\"gifs/chinstrap_rad_fl.gif\",\n           apf = 1/30,\n           width=400,\n           height=400,\n           frames=500)\nrender_gif(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4],\n           radial_tour(start=prj, mvar = 4),\n           display_xy(col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY], pch=c_pch),\n           gif_file=\"gifs/chinstrap_rad_bm.gif\",\n           apf = 1/30,\n           width=400,\n           height=400,\n           frames=500)\n```\n:::\n\n\n::: {#fig-chinstrap-radial layout-ncol=2}\n\n::: {.content-hidden when-format=\"pdf\"}\n\n![bl](gifs/chinstrap_rad_bl.gif){#fig-chinstrap-radial-bl}\n\n![bd](gifs/chinstrap_rad_bd.gif){#fig-chinstrap-radial-bd}\n\n![fl](gifs/chinstrap_rad_fl.gif){#fig-chinstrap-radial-fl}\n\n![bm](gifs/chinstrap_rad_bm.gif){#fig-chinstrap-radial-bm}\n\n:::\n\nExploring the importance of the four variables to the separating hyperplane using a radial tour where the contribution of each variable is reduced to 0, and then increased to it's original value. You can see that `bl` and `bd` contribute most to the plane, because when they are removed the plane is no longer on it side marking the boundary. Variables `fl` and `bm` contribute a small amount to the separating hyperplane, but it is possible that these two could be removed without affecting the strength of the separation between the sexes. \n:::\n\n<!-- include Distance-weighted discrimination, eg kerndwd -->\n",
    "supporting": [
      "svm_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}