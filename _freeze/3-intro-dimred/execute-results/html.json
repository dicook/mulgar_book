{
  "hash": "192aa5b9bf8ae34282b9e927dc0ffec2",
  "result": {
    "engine": "knitr",
    "markdown": "# Dimension reduction overview {#sec-dimension-overview}\n\nThis chapter sets up the concepts related to methods for reducing dimension such as principal component analysis (PCA) and t-stochastic neighbour embedding (t-SNE), and how the tour can be used to assist with these methods. \n\n## The meaning of dimension\n\nThe number of variables, $p$, is considered to be the dimension of the data. However, the observed data may live in a lower dimensional sub-space and then not fill out the full $p$-dimensions. This implicit dimensionality is perceived in a tour using the spread of points. When the points are spread far apart, then the data is filling the space. Conversely, when the points \"collapse\" into a sub-region then the data is only partially filling the space, and some dimension reduction to reduce to this smaller dimensional space may be worthwhile. \n\\index{dimensionality!implicit}\n\n::: {.content-visible when-format=\"html\"}\n::: info\nWhen exploring the implicit dimensionality of multivariate data we are looking for projections where the points do not fill the plotting canvas fully. This would indicate that the observed values do not fully populate high dimensions. \n:::\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\\infobox{When exploring the implicit dimensionality of multivariate data we are looking for projections where the points do not fill the plotting canvas fully. This would indicate that the observed values do not fully populate high dimensions. }\n:::\n\nLet's start with some 2D examples. @fig-2D shows three plots of two variables. Plot (a) shows two variables that are strongly linearly associated[^correlation], because when `x1` is low, `x2` is low also, and conversely when `x1` is high, `x2` is also high. This can also be seen by the reduction in spread of points (or \"collapse\") in one direction making the data fill less than the full square of the plot. *So from this we can conclude that the data is not fully 2D.* The second step is to infer which variables contribute to this reduction in dimension. The axes for `x1` and `x2` are drawn extending from $(0,0)$ and because they both extend out of the cloud of points, in the direction away from the collapse of points we can say that they are jointly responsible for the dimension reduction. \n\n::: {.content-visible when-format=\"html\"}\n::: info\nThe way variables are scaled can affect the appearance of dimensionality. If the variables are scaled together, using global values, some variables may have smaller variance than others. Scaling variables individually shifts the focus to association between variables, as the predominant reason for reduced dimension.\n:::\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\\infobox{The way variables are scaled can affect the appearance of dimensionity. If the variables are scaled together, using global values, some variables may have smaller variance than others. Scaling variables individually shifts the focus to association between variables, as the predominant reason for reduced dimension.}\n:::\n\n@fig-2D (b) shows a pair of variables that are **not** linearly associated. Variable `x1` is more varied than `x3` but knowing the value on `x1` tells us nothing about possible values on `x3`. Before running a tour all variables are typically scaled to have equal spread. The purpose of the tour is to capture association and relationships between the variables, so any univariate differences should be removed ahead of time. @fig-2D (c) shows what this would look like when `x3` is scaled - the points are fully spread in the full square of the plot. \n\n[^correlation]: It is generally better to use *associated*  than *correlated*. Correlation is a statistical quantity, measuring linear association. The term *associated* can be prefaced with the type of association, such as *linear* or *non-linear*. \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to produce 2D data examples\"}\nlibrary(tibble)\nset.seed(6045)\nx1 <- runif(123)\nx2 <- x1 + rnorm(123, sd=0.1)\nx3 <- rnorm(123, sd=0.2)\ndf <- tibble(x1 = (x1-mean(x1))/sd(x1), \n             x2 = (x2-mean(x2))/sd(x2),\n             x3, \n             x3scaled = (x3-mean(x3))/sd(x3))\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Explanation of how dimension reduction is perceived in 2D, relative to variables: (a) Two variables with strong linear association. Both variables contribute to the association, as indicated by their axes extending out from the 'collapsed' direction of the points; (b) Two variables with no linear association. But x3 has less variation, so points collapse in this direction; (c) The situation in plot (b) does not arise in a tour because all variables are (usually) scaled.  When an axis extends out of a direction where the points are collapsed, it means that this variable is partially responsible for the reduced dimension.](3-intro-dimred_files/figure-html/fig-2D-1.png){#fig-2D fig-alt='Three scatterplots: (a) points lie close to a straight line in the x=y direction, (b) points lie close to a horizontal line, (c) points spread out in the full plot region. There are no axis labels or scales.' width=100%}\n:::\n:::\n\n\n\n\n\n\n@fig-nonlin-2D illustrates other types of association that could indicate reduced dimensionality. Plot (a) shows a strong nonlinear association. Plots (b) and (c) show substantial regions of the data space that have no observations, which may mean there is some barrier or gap in the data generating process. The L-shape in plot (d) is a pattern where one variable only shows variability if the other variable is essentially all the same, say close to zero. It could be described as if one variable has a non-zero value then the other variable is zero. This is a very strong association pattern, but not one that is captured by correlation. Plots (e) and (f) show other types of association, one with heterogeneous variance depending on the subspace, and clustering of observations, respectively. While we might detect these visually, using dimension reduction methods with these structures can be tricky. \n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Other types of association: (a) nonlinear, (b) gap between subspaces, (c) barrier beyond which no values are observed, perhaps a limiting inequality constraint, (d) L-shape where is one variable is observed the other is not, (e) skewness or heterogeneous variance, (f) clustering.](3-intro-dimred_files/figure-html/fig-nonlin-2D-1.png){#fig-nonlin-2D width=100%}\n:::\n:::\n\n\n\n\n\n\n## How to perceive the dimensionality using a tour\n\nNow let's think about what this looks like with five variables. @fig-dimension-html shows a grand tour on five variables, with (a) data that is primarily 2D, (b) data that is primarily 3D and (c) fully 5D data.  You can see that both (a) and (b) the spread of points collapse in some projections, with it happening more in (a). In (c) the data is always spread out in the square, although it does seem to concentrate or pile in the centre. This piling is typical when projecting from high dimensions to low dimensions. The sage tour [@sagetour] makes a correction for this. \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to make animated gifs\"}\nlibrary(mulgar)\ndata(plane)\ndata(box)\nrender_gif(plane,\n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/plane.gif\",\n           frames=500,\n           width=200,\n           height=200)\nrender_gif(box,\n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/box.gif\",\n           frames=500,\n           width=200,\n           height=200)\n# Simulate full cube\nlibrary(geozoo)\ncube5d <- data.frame(cube.solid.random(p=5, n=300)$points)\ncolnames(cube5d) <- paste0(\"x\", 1:5)\ncube5d <- data.frame(apply(cube5d, 2, function(x) (x-mean(x))/sd(x)))\nrender_gif(cube5d,\n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/cube5d.gif\",\n           frames=500,\n           width=200,\n           height=200)\n```\n:::\n\n\n\n\n\n\n::: {.content-visible when-format=\"html\"}\n\n::: {#fig-dimension-html fig-align=\"center\" layout-ncol=3}\n\n![2D plane in 5D](gifs/plane.gif){#fig-plane width=180 fig-alt=\"Animation of sequences of 2D projections shown as scatterplots. You can see points collapsing into a thick straight line in various projections. A circle with line segments indicates the projection coefficients for each variable for all projections viewed.\"}\n\n![3D plane in 5D](gifs/box.gif){#fig-box width=180 fig-alt=\"Animation of sequences of 2D projections shown as scatterplots. You can see points collapsing into a thick straight line in various projections, but not as often as in the animation in (a). A circle with line segments indicates the projection coefficients for each variable for all projections viewed.\"}\n\n![5D plane in 5D](gifs/cube5d.gif){#fig-cube5 width=180 fig-alt=\"Animation of sequences of 2D projections shown as scatterplots. You can see points are always spread out fully in the plot space, in all projections. A circle with line segments indicates the projection coefficients for each variable for all projections viewed.\"}\n\nDifferent dimensional planes - 2D, 3D, 5D - displayed in a grand tour projecting into 2D. Notice that the 5D in 5D always fills out the box (although it does concentrate some in the middle which is typical when projecting from high to low dimensions). Also you can see that the 2D in 5D, concentrates into a line more than the 3D in 5D. This suggests that it is lower dimensional. \n:::\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\n::: {#fig-dimension-pdf layout-ncol=3}\n\n![2D plane in 5D](images/plane.png){#fig-plane width=160}\n\n![3D plane in 5D](images/box.png){#fig-box width=160}\n\n![5D plane in 5D](images/cube5d.png){#fig-cube5 width=160}\n\nSingle frames from different dimensional planes - 2D, 3D, 5D - displayed in a grand tour projecting into 2D. Notice that the 5D in 5D always fills out the box (although it does concentrate some in the middle which is typical when projecting from high to low dimensions). Also you can see that the 2D in 5D, concentrates into a line more than the 3D in 5D. This suggests that it is lower dimensional. {{< fa play-circle >}}\n:::\n:::\n\nThe next step is to determine which variables contribute. In the examples just provided, all variables are linearly associated in the 2D and 3D data. You can check this by making a scatterplot matrix, @fig-plane-scatmat.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code for scatterplot matrix\"}\nlibrary(GGally)\nlibrary(mulgar)\ndata(plane)\nggscatmat(plane) +\n  theme(panel.background = \n          element_rect(colour=\"black\", fill=NA),\n    axis.text = element_blank(),\n    axis.ticks = element_blank())\n```\n\n::: {.cell-output-display}\n![Scatterplot matrix of plane data. You can see that x1-x3 are strongly linearly associated, and also x4 and x5. When you watch the tour of this data, any time the data collapses into a line you should see only (x1, x2, x3) or (x4, x5). When combinations of x1 and x4 or x5 show, the data should be spread out.](3-intro-dimred_files/figure-html/fig-plane-scatmat-1.png){#fig-plane-scatmat fig-alt='A five-by-five scatterplot matrix, with scatterplots in the lower triangle, correlaton printed in the upper triangle and density plots shown on the diagonal. Plots of x1 vs x2, x1 vs x3, x2 vs x3, and x4 vs x5 have strong positive or negative correlation. The remaining pairs of variables have no association.' width=80%}\n:::\n:::\n\n\n\n\n\n\nTo make an example where not all variables contribute, we have added two additional variables to the `plane` data set, which are purely noise.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# Add two pure noise dimensions to the plane\nplane_noise <- plane\nplane_noise$x6 <- rnorm(100)\nplane_noise$x7 <- rnorm(100)\nplane_noise <- data.frame(apply(plane_noise, 2, \n    function(x) (x-mean(x))/sd(x)))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggduo(plane_noise, columnsX = 1:5, columnsY = 6:7, \n    types = list(continuous = \"points\")) +\n  theme(aspect.ratio=1,\n    panel.background = \n          element_rect(colour=\"black\", fill=NA),\n    axis.text = element_blank(),\n    axis.ticks = element_blank())\n```\n\n::: {.cell-output-display}\n![Scatterplots showing two additional noise variables that are not associated with any of the first five variables.](3-intro-dimred_files/figure-html/fig-plane-noise-scatter-1.png){#fig-plane-noise-scatter fig-alt='Two rows of scatterplots showing x6 and x7 against x1-x5. The points are spread out in the full plotting region, although x6 has one point with an unusually low value.' width=576}\n:::\n:::\n\n\n\n\n\n\nNow we have 2D structure in 7D, but only five of the variables contribute to the 2D structure, that is, five of the variables are linearly related with each other. The other two variables (x6, x7) are not linearly related to any of the others. \n\nThe data is viewed with a grand tour in @fig-plane-noise-html. We can still see the concentration of points along a line in some dimensions, which tells us that the data is not fully 7D. Then if you look closely at the variable axes you will see that the collapsing to a line only occurs when any of x1-x5 contribute strongly in the direction orthogonal to this. This does not happen when x6 or x7 contribute strongly to a projection - the data is always expanded to fill much of the space. That tells us that x6 and x7 don't substantially contribute to the dimension reduction, that is, they are not linearly related to the other variables.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Code to generate animation\"}\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(htmlwidgets)\n\nset.seed(78)\nb <- basis_random(7, 2)\npn_t <- tourr::save_history(plane_noise, \n                    tour_path = grand_tour(),\n                    start = b,\n                    max_bases = 8)\npn_t <- interpolate(pn_t, 0.1)\npn_anim <- render_anim(plane_noise,\n                         frames=pn_t)\n\npn_gp <- ggplot() +\n     geom_path(data=pn_anim$circle, \n               aes(x=c1, y=c2,\n                   frame=frame), linewidth=0.1) +\n     geom_segment(data=pn_anim$axes, \n                  aes(x=x1, y=y1, \n                      xend=x2, yend=y2, \n                      frame=frame), \n                  linewidth=0.1) +\n     geom_text(data=pn_anim$axes, \n               aes(x=x2, y=y2, \n                   frame=frame, \n                   label=axis_labels), \n               size=5) +\n     geom_point(data=pn_anim$frames, \n                aes(x=P1, y=P2, \n                    frame=frame), \n                alpha=0.8) +\n     xlim(-1,1) + ylim(-1,1) +\n     coord_equal() +\n     theme_bw() +\n     theme(axis.text=element_blank(),\n         axis.title=element_blank(),\n         axis.ticks=element_blank(),\n         panel.grid=element_blank())\npn_tour <- ggplotly(pn_gp,\n                        width=500,\n                        height=550) |>\n       animation_button(label=\"Go\") |>\n       animation_slider(len=0.8, x=0.5,\n                        xanchor=\"center\") |>\n       animation_opts(easing=\"linear\", \n                      transition = 0)\n\nhtmlwidgets::saveWidget(pn_tour,\n          file=\"html/plane_noise.html\",\n          selfcontained = TRUE)\n```\n:::\n\n\n\n\n\n\n::: {.content-visible when-format=\"html\"}\n::: {#fig-plane-noise-html}\n\n<iframe width=\"750\" height=\"550\" src=\"html/plane_noise.html\" title=\"Grand tour of the plane with two additional dimensions of pure noise. \"> fig-alt=\"Animation with a scrollbar control to allow user to step through the sequence of projections. Scatterplots of the projections are shown. A circle with line segments indicates the projection coefficients for each variable for all projections.\" </iframe>\n\nGrand tour of the plane with two additional dimensions of pure noise. The collapsing of the points indicates that this is not fully 7D. This only happens when any of x1-x5 are contributing strongly (frame 49 x4, x5; frame 79 x1; frame 115 x2, x3). If x6 or x7 are contributing strongly the data is spread out fully (frames 27, 96). This tells us that x6 and x7 are not linearly associated, but other variables are.\n:::\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n::: {#fig-plane-noise-pdf layout-ncol=2}\n\n![](images/plane_noise1.png){width=200 fig-align=\"center\"}\n\n![](images/plane_noise2.png){width=200 fig-align=\"center\"}\n\nTwo frames from a grand tour of the plane with two additional dimensions of pure noise. The collapsing of the points indicates that this is not fully 7D. This only happens when any of x1-x5 are contributing strongly (frame 49 x4, x5; frame 79 x1; frame 115 x2, x3). If x6 or x7 are contributing strongly the data is spread out fully (frames 27, 96). This tells us that x6 and x7 are not linearly associated, but other variables are. {{< fa play-circle >}}\n:::\n:::\n\n::: {.content-visible when-format=\"html\"}\n::: info\nTo determine which variables are responsible for the reduced dimension look for the axes that extend out of the point cloud. These contribute to smaller variation in the observations, and thus indicate possible dimension reduction using these variables.\n:::\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\\infobox{To determine which variables are responsible for the reduced dimension look for the axes that extend out of the point cloud. These contribute to smaller variation in the observations, and thus indicate possible dimension reduction using these variables}\n:::\n\nThe simulated data here is very simple, and what we have learned from the tour could also be learned from principal component analysis. However, if there are small complications, such as outliers or nonlinear relationships, that might not be visible from principal component analysis, the tour can help you to see them.\n\n@fig-plane-noise-outlier and @fig-outlier-nonlin-html(a) show example data with an outlier and @fig-outlier-nonlin-html(b) shows data with non-linear relationships. \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add several outliers to the plane_noise data\nplane_noise_outliers <- plane_noise\nplane_noise_outliers[101,] <- c(2, 2, -2, 0, 0, 0, 0)\nplane_noise_outliers[102,] <- c(0, 0, 0,-2, -2, 0, 0)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code for scatterplot matrix\"}\nggscatmat(plane_noise_outliers, columns = 1:5) +\n  theme(aspect.ratio=1,\n    panel.background = \n          element_rect(colour=\"black\", fill=NA),\n    axis.text = element_blank(),\n    axis.ticks = element_blank())\n```\n\n::: {.cell-output-display}\n![Scatterplot matrix of the plane with noise data, with two added outliers in variables with strong correlation.](3-intro-dimred_files/figure-html/fig-plane-noise-outlier-1.png){#fig-plane-noise-outlier fig-alt='A five-by-five scatterplot matrix, with scatterplots in the lower triangle, correlaton printed in the upper triangle and density plots shown on the diagonal. Plots of x1 vs x2, x1 vs x3, x2 vs x3, and x4 vs x5 have strong positive or negative correlation, with an outlier in the corner of the plot. The remaining pairs of variables have no association, and thus also no outliers.' width=80%}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to generate animated gif\"}\nrender_gif(plane_noise_outliers,          \n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/pn_outliers.gif\",\n           frames=500,\n           width=200,\n           height=200)\n\ndata(plane_nonlin)\nrender_gif(plane_nonlin,          \n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/plane_nonlin.gif\",\n           frames=500,\n           width=200,\n           height=200)\n```\n:::\n\n\n\n\n\n\n\n::: {.content-visible when-format=\"html\"}\n\n::: {#fig-outlier-nonlin-html fig-align=\"center\" layout-ncol=2}\n\n![Outliers](gifs/pn_outliers.gif){#fig-outlier width=200 fig-alt=\"Animation showing scatterplots of 2D projections from 5D. The points sometimes appear to be a plane viewed from the side, with two single points futher away. A circle with line segments indicates the projection coefficients for each variable for all projections viewed.\"}\n\n![Non-linear relationship](gifs/plane_nonlin.gif){#fig-nonlinear width=200200 fig-alt=\"Animation showing scatterplots of 2D projections from 5D. The points sometimes appear to be lying on a curve in various projections. A circle with line segments indicates the projection coefficients for each variable for all projections viewed.\"}\n\nExamples of different types of dimensionality issues: outliers (a) and non-linearity (b). In (a) you can see two points far from the others in some projections. Also the two can be seen with different movement patterns -- moving faster and different directions than the other points during the tour. Outliers will affect detection of reduced dimension, but they can be ignored when assessing dimensionality with the tour. In (b) there is a non-linear relationship between several variables, primarily with x3. Non-linear relationships may not be easily captured by other techniques but are often visible with the tour.\n:::\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\n::: {#fig-outlier-nonlin-pdf fig-align=\"center\" layout-ncol=2}\n\n![Outliers](images/pn_outliers.png){#fig-outlier width=200}\n\n![Non-linear relationship](images/plane_nonlin.png){#fig-nonlinear width=200}\n\nTwo frames from tours of examples of different types of dimensionality issues: outliers (a) and non-linearity (b). In (a) you can see two points far from the others in the projection. During a tour the two can be seen with different movement patterns -- moving faster and in different directions than other points. Outliers will affect detection of reduced dimension, but they can be ignored when assessing dimensionality with the tour. In (b) there is a non-linear relationship between several variables, primarily with x3. Non-linear relationships may not be easily captured by other techniques but are often visible with the tour. {{< fa play-circle >}}\n:::\n:::\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n## Exercises {-}\n\n1. Multicollinearity is when the predictors for a model are strongly linearly associated. It can adversely affect the fitting of most models, because many possible models may be equally as good. Variable importance might be masked by correlated variables, and confidence intervals generated for linear models might be too wide. Check the for multicollinearity or other associations between the predictors in:\n    a. 2001 Australian election data\n    b. 2016 Australian election data\n2. Examine 5D multivariate normal samples drawn from populations with a range of variance-covariance matrices.  (You can use the `mvtnorm` package to do the sampling, for example.) Examine the data using a grand tour. What changes when you change the correlation from close to zero to close to 1?  Can you see a difference between strong positive correlation and strong negative correlation?\n3. The following code shows how to hide a point in a four-dimensional space, so that it is not visible in any of the plots of two variables. Generate both `d` and `d_r` and confirm that the point is visible in a scatterplot matrix of `d`, but not in the scatterplot matrix of `d_r`. Also confirm that it is visible in both data sets when you use a tour.\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tourr)\nlibrary(GGally)\nset.seed(946)\nd <- tibble(x1=runif(200, -1, 1), \n            x2=runif(200, -1, 1), \n            x3=runif(200, -1, 1))\nd <- d |>\n  mutate(x4 = x3 + runif(200, -0.1, 0.1))\n# outlier is visible in d\nd <- bind_rows(d, c(x1=0, x2=0, x3=-0.5, x4=0.5))\n\n# Point is hiding in d_r\nd_r <- d |>\n  mutate(x1 = cos(pi/6)*x1 + sin(pi/6)*x3,\n         x3 = -sin(pi/6)*x1 + cos(pi/6)*x3,\n         x2 = cos(pi/6)*x2 + sin(pi/6)*x4,\n         x4 = -sin(pi/6)*x2 + cos(pi/6)*x4)\n```\n:::\n\n\n\n\n\n\n4. Examine each of the challenge data sets `c1`, `c2`, ..., `c7` from the the `mulgar` package for signs of the observed values not filling out the full $p$ dimensions.\n\n5. The data sets `assoc1`,  `assoc2`, `assoc3` have other types of association. Can you detect what the associations are in each set?\n\n6. The data sets `anomaly1`,  `anomaly2`, `anomaly3`, `anomaly4`, `anomaly5` all have single anomalies. For there to be an anomaly in a data set, there must be some association between the variables, and the anomaly doesn't conform to this association pattern. Can you find them?\n\n7. XXX Use `covsim` package to simulate data\n",
    "supporting": [
      "3-intro-dimred_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}