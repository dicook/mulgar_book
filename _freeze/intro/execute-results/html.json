{
  "hash": "54f143cb95e81a40ab79ffe78fbd6859",
  "result": {
    "markdown": "# Picturing high dimensions {#intro}\n\nHigh-dimensional data means that we have a large number of numeric features or variables, which can be considered as dimensions in a mathematical space. The variables can be different types, such as categorical or temporal, but the handling of these variables involves different techniques. \n\n::: {#fig-shadow-puppets layout-ncol=3}\n\n![](images/shadow-puppets2.png){width=190}\n\n![](images/shadow-puppets3.png){width=190}\n\n![](images/shadow-puppets4.png){width=190}\n\nViewing high dimensions using low-dimensional displays is like playing shadow puppets, looking at the shadows to guess what the shape is.\n:::\n\n## Getting familiar with tours\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n::: {#fig-explain-1D layout=\"[[40, 60]]\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![2D data](intro_files/figure-html/fig-explain-1D-data-1.png){#fig-explain-1D-data width=384}\n:::\n:::\n\n\n::: {.content-hidden when-format=\"pdf\"}\n\n![1D grand tour of the 2D data](gifs/explain_1d.gif){#fig-explain-1D-tour fig-alt=\"\"}\n:::\n\nHow a tour can be used to explore high-dimensional data illustrated using (a) 2D data with two clusters and (b) a tour of 1D projections shown as a density plot. Imagine spinning a line around the centre of the data plot, with points projected orthogonally onto the line. With this data, when the line is at `x1=x2 (0.707, 0.707)` or `(-0.707, -0.707)` the clustering is the strongest. When it is at `x1=-x2  (0.707, -0.707)` there is no clustering.\n:::\n\n@fig-explain-1D illustrates a tour for 2D data and 1D projections. The (grand) tour will generate all possible 1D projections of the data, and display with a univariate plot like a histogram or density plot. For this data, the `simple_clusters` data, depending on the projection, the distribution might be clustered into two groups (bimodal), or there might be no clusters (unimodal). In this example, all projections are generated by rotating a line around the centre of the plot. Clustering can be seen in many of the projections, with the strongest being when the contribution of both variables is equal, and the projection is `(0.707,  0.707)` or `(-0.707, -0.707)`. (If you are curious about the number `0.707`, read the last section of this chapter.)\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n::: {#fig-explain-2D layout=\"[[57, 43]]\"}\n\n::: {.content-hidden when-format=\"pdf\"}\n![2D tour of 3D data](gifs/explain_2d.gif){#fig-explain-2D-tour fig-alt=\"\"}\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A projection revealing the hole](intro_files/figure-html/fig-explain-2D-data-1.png){#fig-explain-2D-data width=384}\n:::\n:::\n\n\nHow a tour can be used to explore high-dimensional data illustrated using a tour of 2D projections of 3D data (a). The data has a donut shape with the hole revealed in a single 2D projection (b). Data usually arrives with a given number of observations, and when we plot it like this using a scatterplot, it is like shadows of a transparent object.\n:::\n\n@fig-explain-2D illustrates a tour for 3D data using 2D projections. The data are points on the surface of a donut shape. By showing the projections using a scatterplot the donut looks transparent and we can see through the data. The donut shape can be inferred from watching many 2D projections but some are more revealing that others. The projection shown in (b) is where the hole in the donut is clearly visible.\n\n\n## What's different about space beyond 2D?\n\nThe term \"high-dimensional\" in this book refers to the  dimensionality of the Euclidean space. @fig-dimension-cubes shows a way to imagine this. It shows a sequence of cube wireframes, ranging from one-dimensional (1D) through to five-dimensional (5D), where beyond 2D is a linear projection of the cube. As the dimension increases, a new orthogonal axis is added. For cubes, this is achieved by doubling the cube: a 2D cube consists of two 1D cubes, a 3D cube consists of two 2D cubes, and so forth. This is a great way to think about the space being examined by the visual methods, and also all of the machine learning methods mentioned, in this book. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![Space can be considered to be a high-dimensional cube. Here we have pictured a sequence of increasing dimension cubes, from 1D to 5D, as wireframes, it can be seen that as the dimension increase by one, the cube doubles.](intro_files/figure-html/fig-dimension-cubes-1.png){#fig-dimension-cubes width=768}\n:::\n:::\n\n\nInterestingly, the struggle with imagining high-dimensions this way is described in a novel published in 1884 [@Ab1884] [^4]. Yes, more than 100 years ago! This is a story about characters living in a 2D world, being visited by an alien 3D character. It also is a social satire, serving the reader strong messages about gender inequity, although this provides the means to explain more intricacies in perceiving dimensions. There have been several movies made based on the book in recent decades (e.g. @Ma65, @JT07). Although purchasing the movies may be prohibitive, watching the trailers available for free online is sufficient to gain enough geometric intuition on the nature of understanding high-dimensional spaces while living in a low-dimensional world. \n\n[^4]: Thanks to Barret Schloerke for directing co-author Cook to this history when he was an undergraduate student and we were starting the [geozoo](http://schloerke.com/geozoo/) project.\n\nWhen we look at high-dimensional spaces from a low-dimensional space, we meet the \"curse of dimensionality\", a term introduced by @BellmanRichard1961 to express the difficulty of doing optimization in high dimensions because of the exponential growth in space as dimension increases. A way to imagine this is look at the cubes in @fig-dimension-cubes: As you go from 1D to 2D, 2D to 3D, the space expands a lot, and imagine how vast space might get as more dimensions are added[^5]. The volume of the space grows exponentially with dimension, which makes it infeasible to sample enough points -- any sample will be less densely covering the space as dimension increases. The effect is that most points will be far from the sample mean, on the edge of the sample space.\n\n[^5]: \"Space is big. Really big. You might think it's a long way to the pharmacy, but thatâ€™s peanuts to space.\" from Douglas Adams' [Hitchhiker's Guide to the Galaxy](https://en.wikipedia.org/wiki/The_Hitchhiker%27s_Guide_to_the_Galaxy#Stage_shows) always springs to mind when thinking about high dimensions!\n\nFor visualisation, the curse manifests in an opposite manner. Projecting from high to low dimensions creates a crowding or piling of points near the center of the distribution. This was noted by @diaconis1984. @fig-density illustrates this phenomenon. As dimension increases, the points crowd the centre, even with as few as ten dimensions. This is something that we may need to correct for when exploring high dimensions with low-dimensional projections.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Illustration of data crowding in the low-dimensional projection as dimension increases, here from 3, 10, 100. Colour shows the number of points in each hexagon bin (pink is large, navy is small). As dimension increases the points concentrate near the centre.](intro_files/figure-html/fig-density-1.png){#fig-density fig-align='center' width=95%}\n:::\n:::\n\n\n@fig-tour-intro shows 2D tours of two different 5D data sets. One has clusters (a) and the other has two outliers and a plane (b). Can you see these? One difference in the viewing of data with more than three dimensions with 2D projections is that the points seem to shrink towards the centre, and then expand out again. This the effect of dimensionality, with different variance or spread in some directions.\n\n\n::: {#fig-tour-intro layout-ncol=2}\n::: {.content-hidden when-format=\"pdf\"}\n![Clusters](gifs/clusters-intro.gif){#fig-tour-clusters}\n:::\n\n::: {.content-hidden when-format=\"pdf\"}\n![Outliers](gifs/outlier-intro.gif){#fig-tour-clusters}\n:::\n\nTwo 5D datasets shown as tours of 2D projections. Can you see clusters of points in (a) and two outliers with a plane in (b)?\n:::\n\n<!--\n-   A lot of Ursula's work like the figures in the burning sage paper could be useful here\n-->\n\n\n\n## What can you learn?\n\nThere are two ways of detecting structure in tours:\n\n- patterns in a single low-dimensional projection\n- movement patterns\n\nwith the latter being especially useful when displaying the projected data as a scatterplot. @fig-example-structure shows examples of patterns we typically look for when making a scatterplot of data. These include clustering, linear and non-linear association, outliers, barriers where there is a sharp edge beyond which no observations are seen. Not shown, but it also might be possible to observe multiple modes, or density of observations, L-shapes, discreteness or uneven spread of points. The tour is especially useful if these patterns are only visible in combinations of variables. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![Example structures that might be visible in a 2D projection that imply presence of structure in high dimensions. These include clusters, linear and non-linear association, outliers and barriers.](intro_files/figure-html/fig-example-structure-1.png){#fig-example-structure width=100%}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n@fig-trails illustrates how movement patterns of points when using scatterplots to display 2D projections indicate clustering (a, b) and outliers (c, d). \n\n::: {#fig-trails layout-ncol=2 fig-align=\"center\"}\n\n![Clustering](images/trails-clusters.png){#fig-clusters-trails-static fig-alt=\"\"}\n\n![Outliers](images/trails-outlier.png){#fig-outlier-trails-static fig-alt=\"\"}\n\nThe movement of points give further clues about the structure of the data in high-dimensions. In the data with clustering, often we can see a group of points moving differently from the others. Because there are three clusters, you should see three distinct movement patterns. It is similar with outliers, except these may be individual points moving alone, and different from all others. This can be seen in the static plot, one point (top left) has a movement pattern upwards whereas most of the other observations near it are moving down towards the right. \n:::\n\n<!--\n![Movement pattern indicates clustering as seen in a grand tour.](gifs/trails-clusters.gif){#fig-clusters-trails-tour fig-alt=\"\" width=\"300\"}\n\n![Movement pattern indicates an outlier as seen in a grand tour.](gifs/trails-outlier.gif){#fig-outlier-trails-tour fig-alt=\"\" width=\"300\"}\n\n-->\n\n\nThis type of visualisation is useful for many activities in dealing with high-dimensional data, including: \n\n- exploring high-dimensional data.\n- detecting if the data lives in a lower dimensional space than the number of variables.\n- checking assumptions required for multivariate models to be applicable.\n- check for potential problems in modeling such as multicollinearity among predictors.\n- checking assumptions required for probabilties calculated for statistical hypothesis testing to be valid.\n- diagnosing the fit of multivariate models.\n\n<!-- \nDescription and explanation of primary methods used throughout the book. Mostly focusing on tour methods.\n\nWe need a really nice friendly introduction to tour methods:\n\n- 2D to 1D projections as basic explanation\n- maybe 3D to 2D, or even 4D to 2D illustration\n-->\n\n<!-- Show examples of what can be gained from looking at combinations as opposed to pairs plots, for example. Clusters is a good situation, but also collinearity and outliers\n-->\n\n::: info\nWith a tour we slowly rotate the viewing direction, this allows us to see many individual projections and to track movement patterns. Look for interesting structures such as clusters or outlying points.\n:::\n\n\n## A little history\n\nViewing high-dimensional data based on low-dimensional projections can probably be traced back to the early work on principal component analysis by @pearson-pca and @hotelling-pca, which was extended to known classes as part of discriminant analysis by @fisher1936. \n\nWith computer graphics, the capability of animating plots to show more than a single best projection became possible. The video library [@ASA23] is the best place to experience the earliest work. Kruskal's 1962 animation of multidimensional scaling showed the process of finding a good 2D representation of high dimensional data, although the views are not projections. Chang's 1970 video shows her rotating a high dimensional point cloud along coordinate axes to find a special projection where all the numbers align. The classic video that must be watched is PRIM9 [@PRIM9-video] where a variety of interactive and dynamic tools are used together to explore high dimensional physics data, documented in @tukey. \n\nThe methods in this book primarily emerge from @As85's grand tour method. The algorithm provided the first smooth and continuous sequence of low dimensional projections, and guaranteed that all possible low dimensional projections were likely to be shown. The algorithm was refined in @BA86b (and documented in detail in @BCAH05) to make it *efficiently* show all possible projections. Since then there have been numerous varieties of tour algorithms developed to focus on specific tasks in exploring high dimensional data, and these are documented in @tours2022. \n\nThis book is an evolution from @CS07. One of the difficulties in working on interactive and dynamic graphics research has been the rapid change in technology. Programming languages have changed a little (fortran to C to java to python) but graphics toolkits and display devices have changed a lot! The tour software used in this book evolved from XGobi, which was written in C and used the X Window System, which was then rewritten in  GGobi using gtk. The video library has engaging videos of these software systems There have been several other short-lived implementations, including orca [@orca], written in java, and cranvas [@cranvas], written in R with a back-end provided by wrapper functions to qt libraries. \n\nAlthough attempts were made with these ancestor systems to connect the data plots to a statistical analysis system, these were always limited. With the emergence of R, having graphics in the data analysis workflow has been much easier, albeit at the cost of the interactivity with graphics that matches the old systems. We are mostly using the R package, `tourr` [@tourr] for examples in this book. It provides the machinery for running a tour, and has the flexibility that it can be ported, modified, and used as a regular element of data analysis.\n\n## Exercises {-}\n\n1. Randomly generate data points that are uniformly distributed in a hyper-cube of 3, 5 and 10 dimensions, with 500 points in each sample, using the `cube.solid.random` function of the `geozoo` package. What differences do we expect to see? Now visualise each set in a grand tour and describe how they differ, and whether this matched your expectations? \n2. Use the `geozoo` package to generate samples from different shapes and use them to get a better understanding of how shapes appear in a grand tour. You can start with exploring the conic spiral in 3D, a torus in 4D and points along the wire frame of a cube in 5D.\n3. For each of the challenge data sets, `c1`, ..., `c7` from the `mulgar` package, use the grand tour to view and try to identify structure (outliers, clusters, non-linear relationships). \n\n \n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::",
    "supporting": [
      "intro_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}