{
  "hash": "5c49013b3e911ce036fc42c502876871",
  "result": {
    "markdown": "# Toolbox {#toolbox}\n\n\n## Using tours in the `tourr` package\n\n### Installation\n\nYou can install the released version of `tourr` from [CRAN](https://CRAN.R-project.org) with:\n\n``` r\ninstall.packages(\"tourr\")\n```\n\nand the development version from the [GitHub repo](https://github.com/ggobi/tourr) with:\n\n``` r\n# install.packages(\"remotes\")\nremotes::install_github(\"ggobi/tourr\")\n```\n\n### Getting started\n\nTo run a tour in R, use one of the animate functions. The following code will show a 2D tour displayed as a scatterplot on a 6D data set with three labelled classes. \n\n``` r\nanimate_xy(flea[,-7], col=flea$species)\n```\n\n@tourr remains a good reference for learning more about this package. The package [website](http://ggobi.github.io/tourr/) has a list of current functionality. \n\n### Different tours\n\nThe two main components of the tour algorithm are the projection dimension which affects the choice of display to use, and the algorithm that delivers the projection sequence. The primary functions for these two parts are \n\n1. For display of different projection dimensions:\n\n- `display_dist()`: choice of density, histogram or average shifted histogram (ash) display of the 1D projections.\n- `display_xy()`, `display_density2d()`, `display_groupxy()`, `display_pca()`, `display_sage()`, `display_slice()`, `display_trails()`: choices in display of 2D projections.\n- `display_depth()`, `display_stereo()`: choices to display 3D projections. \n- `display_pcp()`, `display_scatmat()`, `display_stars()`, `display_faces()`: choices for displaying three or more variables.\n- `display_image()`: to use with multispectral images, where different combinations of spectral bands are displayed. See @WPS98 and @Symanzik2002NewAO for applications.\n- `display_andrews()`: 1D projections as Andrews curves.\n\n2. To change the way projections are delivered:\n\n- `grand_tour()`: Smooth sequence of random projections to view all possible projections as quickly as possible. Good for getting an overview of the high-dimensional data, especially when you don't know what you are looking for. \n- `guided_tour()`: Follow a projection pursuit optimisation to find projections that have particular patterns. This is used when you want to learn if the data has particular patterns, such as clustering or outliers. Use the `holes()` index to find projections with gaps that allow one to see clusters, or `lda_pp()` or `pda_pp()` when class labels are known and you want to find the projections where the clusters are separated. \n- `little_tour()`: Smoothly interpolate between pairs of variables, to show all the marginal views of the data.\n- `local_tour()`: Makes small movements around a chosen projections to explore a small neighbourhood. Very useful to learn if small distances away from a projection change the pattern substantially or not.\n- `radial_tour()`: Interpolates a chosen variable out of the projection, and then back into the projection. This is useful for assessing importance of variables to pattern in a projection. If the pattern changes a lot when the variable is rotated out, then the variable is important for producing it.\n- `dependendence_tour()`: Delivers two sequences of 1D grand tours, to examine associations between two sets of variables. This is useful for displaying two groups of variables as in multiple regression, or multivariate regression or canonical correlation analysis, as two independent 1D projections.\n- `frozen_tour()`: This is an interesting one! it allows the coefficient for some variables to be fixed, and others to vary.\n\n### The importance of scale\n\nScaling of multivariate data is really important in many ways. It affects most model fitting, and can affect the perception of patterns when data is visualised. Here we describe a few scaling issues to take control of when using tours.\n\n\n**Pre-processing data**\n\nIt is generally useful to standardise your data to have mean 0 and variance-covariance equal to the identity matrix before using the tour. We use the tour to discover associations between variables. Characteristics of single variables should be examined and understood before embarking on looking for high-dimensional structure. \n\nThe `rescale` parameter in the `animate()` function will scale all variables to range between 0 and 1, prior to starting the tour. This will force all to have the same range. It is the default, and without this data with different ranges across variable may have some strange patterns. If you have already scaled the data yourself, even if using a different scaling such as using standardised variables you should set `rescale=FALSE`.\n\nA more severe transformation that can be useful prior to starting a tour is to **sphere** the data. This is also an option in the `animate()` function, but is `FALSE` by default. Sphering is the same as conducting a principal component analysis, and using the principal components as the variables. It removes all linear association between variables! This can be especially useful if you want to focus on finding non-linear associations, including clusters, and outliers. \n\n**Scaling to fit into plot region**\n\nThe `half_range` parameter in most of the display types sets the range used to scale the data into the plot. It is estimated when a tour is started, but you may need to change it if you find that the data keeps escaping the plot window or is not fully using the space. Space expands exponentially as dimension increases, and the estimation takes this into account. However, different distributions of data points lead to different variance of observations in high-dimensional space. A skewed distribution will be more varied than a normal distribution. It is hard to estimate precisely how the data should be scaled so that it fits nicely into the plot space for all projections viewed. \n\nThe `center` parameter is used to centre each projection by setting the mean to be at the middle of the plot space. With different distributions the mean of the data can vary around the plot region, and this can be distracting. Fixing the mean of each projection to always be at the center of the plot space makes it easier to focus on other patterns.\n\n### Saving your tour\n\nThe functions `save_history()` and `planned_tour()` allow the tour path to be pre-computed, and re-played in your chosen way. The tour path is saved as a list of projection vectors, which can also be passed to external software for displaying tours easily. Only a minimal set of projections is saved, by default, and a full interpolation path of projections can always be generated from it using the `interpolate()` function.\n\nVersions and elements of tours can be saved for publication using a variety of functions:\n\n- `render_gif()`: Save a tour as an animated gif, using the `gifski` package.\n- `render_proj()`: Save an object that can be used to produce a polished rendering of a single projection, possibly with `ggplot`.\n- `render_anim()`: Creates an object containing a sequence of projections that can be used with `plotly()` to produce an HTML animation, with interactive control.\n\n### Understanding your tour path\n\n@fig-tour-paths shows tour paths on 3D data spaces. For 1D projections the space of all possible projections is a $p$-dimensional sphere [@fig-tourpaths1d]. For 2D projections the space of all possible projections is a $p\\times 2$-dimensional torus [@fig-tourpaths2d]! The geometry is elegant. \n\nIn these figures, the space is represented by the light colour, and is constructed by simulating a large number of random projections. The two darker colours indicate paths generated by a grand tour and a guided tour. The grand tour will cover the full space of all possible projections if allowed to run for some time. The guided tour will quickly converge to an optimal projection, so will cover only a small part of the overall space. \n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Load libraries\"}\nlibrary(ferrn)\nlibrary(tourr)\nlibrary(geozoo)\nlibrary(dplyr)\nlibrary(purrr)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n::: {.content-hidden when-format=\"pdf\"} \n\n::: {#fig-tour-paths layout-ncol=2}\n\n![1D tour paths](gifs/tour_paths1d.gif){#fig-tourpaths1d width=40%}\n\n![2D tour paths](gifs/tour_paths2d.gif){#fig-tourpaths2d width=40%}\n\nGrand and guided tour paths of 1D and 2D projections of 3D data. The light points represent the space of all 1D and 2D projections respectively. You can see the grand tour is more comprehensively covering the space, as expected, whereas the guided tour is more focused, and quickly moves to the best projection. \n:::\n\n:::\n\n## What not to do\n\n### Discrete and categorical data\n\nTour methods are for numerical data, particularly real-valued measurements. If your data is numerical, but discrete the data can look artificially clustered. @fig-discrete-data shows an example. The data is numeric but discrete, so it is ok to examine it in a tour. In this example, there will be overplotting of observations and the artificial clustering (plot a). It can be helpful to jitter observations, by adding a small amount of noise (plot b). This helps to remove the artificial clustering, but preserve the main pattern which is the strong linear association. Generally, jittering is a useful tool for working with discrete data, so that you can focus on examining the multivariate association. If the data is categorical, with no natural ordering of categories, the tour is not advised.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Discrete data code\"}\nset.seed(430)\ndf <- data.frame(x1 = sample(1:6, 107, replace=TRUE)) %>% \n          mutate(x2 = x1 + sample(1:2, 107, replace=TRUE),\n                 x3 = x1 - sample(1:2, 107, replace=TRUE),\n                 x4 = sample(1:3, 107, replace=TRUE))\nanimate_xy(df)\nrender_gif(df,           \n           grand_tour(),\n           display_xy(),\n           gif_file = \"gifs/discrete_data.gif\",\n           frames = 100,\n           width = 300, \n           height = 300)\n\ndfj <- df %>%\n  mutate(x1 = jitter(x1, 2), \n         x2 = jitter(x2, 2),\n         x3 = jitter(x3, 2),\n         x4 = jitter(x4, 2))\nanimate_xy(dfj)\nrender_gif(dfj,           \n           grand_tour(),\n           display_xy(),\n           gif_file = \"gifs/jittered_data.gif\",\n           frames = 100,\n           width = 300, \n           height = 300)\n```\n:::\n\n\n\n::: {#fig-discrete-data layout-ncol=2}\n\n::: {.content-hidden when-format=\"pdf\"} \n![Discrete data](gifs/discrete_data.gif){#fig-discrete width=40%}\n:::\n\n::: {.content-hidden when-format=\"pdf\"} \n![Jittered data](gifs/jittered_data.gif){#fig-jittered width=40%}\n:::\n\nDiscrete data can look like clusters, which is misleading. Adding a small amount of jitter (random number) can help. The noise is not meaningful but it could allow the viewer to focus on linear or non-linear association between variables without being distracted by artificial clustering. \n:::\n\n### Missing values\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to handle missing values\"}\nlibrary(naniar)\nlibrary(ggplot2)\nlibrary(colorspace)\ndata(\"oceanbuoys\")\nob_p <- oceanbuoys %>%\n  filter(year == 1993) %>%\n  ggplot(aes(x = air_temp_c,\n           y = humidity)) +\n     geom_miss_point() +\n  scale_color_discrete_divergingx(palette=\"Zissou 1\") +\n  theme_minimal() + \n  theme(aspect.ratio=1)\nob_nomiss_below <- oceanbuoys %>%\n  filter(year == 1993) %>%\n  rename(st = sea_temp_c,\n         at = air_temp_c,\n         hu = humidity) %>%\n  select(st, at, hu) %>%\n  rowwise() %>%\n  mutate(anymiss = factor(ifelse(naniar:::any_na(c(st, at, hu)), TRUE, FALSE))) %>%\n  add_shadow(st, at, hu) %>%\n  impute_below_if(.predicate = is.numeric) \nob_nomiss_mean <- oceanbuoys %>%\n  filter(year == 1993) %>%\n  rename(st = sea_temp_c,\n         at = air_temp_c,\n         hu = humidity) %>%\n  select(st, at, hu) %>%\n  rowwise() %>%\n  mutate(anymiss = factor(ifelse(naniar:::any_na(c(st, at, hu)), TRUE, FALSE))) %>%\n  add_shadow(st, at, hu) %>%\n  impute_mean_if(.predicate = is.numeric) \nob_p_below <- ob_nomiss_below %>%\n  ggplot(aes(x=st, y=hu, colour=anymiss)) +\n  geom_point() +\n  scale_color_discrete_divergingx(palette=\"Zissou 1\") +\n  theme_minimal() + \n  theme(aspect.ratio=1, legend.position = \"None\")\nob_p_mean <- ob_nomiss_mean %>%\n  ggplot(aes(x=st, y=hu, colour=anymiss)) +\n  geom_point() +\n  scale_color_discrete_divergingx(palette=\"Zissou 1\") +\n  theme_minimal() + \n  theme(aspect.ratio=1, legend.position = \"None\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to make animation\"}\nanimate_xy(ob_nomiss_below[,1:3], col=ob_nomiss$anymiss)\nrender_gif(ob_nomiss_below[,1:3],\n           grand_tour(),\n           display_xy(col=ob_nomiss_below$anymiss), \n           gif_file = \"gifs/missing_values1.gif\",\n           frames = 100,\n           width = 300, \n           height = 300)\nrender_gif(ob_nomiss_mean[,1:3],\n           grand_tour(),\n           display_xy(col=ob_nomiss_mean$anymiss), \n           gif_file = \"gifs/missing_values2.gif\",\n           frames = 100,\n           width = 300, \n           height = 300)\n```\n:::\n\n\nMissing values can also pose a problem for high-dimensional visualisation, but they shouldn't just be ignored or removed. Methods used in 2D to display missings as done in the `naniar` package [@naniar] like placing them below the complete data don't translate well to high dimensions. @fig-missings illustrates this. It leads to artificial clustering of observations [@fig-below-highD]. It is better to impute the values, and mark them with colour when plotting. The cases are then included in the visualisation so we can assess the multivariate relationships, and also obtain some sense of how these cases should be handled, or imputed. In the example in @fig-imputed-highD we imputed the values simply, using the mean of the complete cases. We can see this is not an ideal approach for imputation for this data because some of the imputed values are outside the domain of the complete cases. \n\n::: {#fig-missings layout-ncol=2}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Missings below in 2D](A1-toolbox_files/figure-html/fig-missings-below-2D-1.png){#fig-missings-below-2D width=288}\n:::\n:::\n\n\n::: {.content-hidden when-format=\"pdf\"} \n![Missings below in high-D](gifs/missing_values1.gif){#fig-below-highD width=40%}\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Missings imputed in 2D](A1-toolbox_files/figure-html/fig-missings-mean-2D-1.png){#fig-missings-mean-2D width=288}\n:::\n:::\n\n\n::: {.content-hidden when-format=\"pdf\"} \n![Missings imputed in high-D](gifs/missing_values2.gif){#fig-imputed-highD width=40%}\n:::\n\nWays to visualise missings for 2D don't transfer to higher dimensions. When the missings are set at 10% below the complete cases it appears to be clustered data when viewed in a tour (b). It is better to impute the value, and use colour to indicate that it is originally a missing value (d).\n:::\n\n### Context such as time and space\n\nWe occasionally hear statements like \"time is the fourth dimension\" or \"space is the fifth dimension\". This is not a useful way to think about dimensionality. \n\nIf you have data with spatial or temporal context, we recommend avoiding using the time index or the spatial coordinates along with the multiple variables in the tour. Time and space are different types of variables, and should not be combined with the multivariate measurements. \n\nFor multivariate temporal data, we recommend using a dependence tour, where one axis is reserved for the time index, and the other axis is used to tour on the multiple variables. For spatial data, we recommend using an image tour, where horizontal and vertical axes are used for spatial coordinates and colour of a tile is used for the tour of multiple variables.\n\n## Tours in other software\n\nThere are tours available in various software packages. For most examples we use the `tourr` package, but the same purpose could be achieved by using other software. We also use some of the software this book, when the `tourr` package is not up for the task. For information about these packages, their websites are the best places to start\n\n- [liminal](https://sa-lee.github.io/liminal/): to combine tours with (non-linear) dimension reduction algorithms.\n- [detourr](https://casperhart.github.io/detourr/): animations for {tourr} using `htmlwidgets` for performance and portability.\n- [langevitour](https://logarithmic.net/langevitour/): HTML widget that randomly tours projections of a high-dimensional dataset with an animated scatterplot.\n- [woylier](https://numbats.github.io/woylier/): alternative method for generating a tour path by interpolating between d-D frames in p-D space rather than d-D planes.\n- [spinifex](https://nspyrison.github.io/spinifex/): manual control of dynamic projections of numeric multivariate data.\n- [ferrn](https://huizezhang-sherry.github.io/ferrn/): extracts key components in the data object collected by the guided tour optimisation, and produces diagnostic plots.\n\n## Supporting software\n\n- [classifly](https://github.com/hadley/classifly): This package is used heavily for supervised classification. \n\nThe `explore()` function is used to explore the classification model. It will predict the class of a sample of points in the predictor space (`.TYPE=simulated`), and return this in a data frame with the observed data (`.TYPE=actual`). The variable `.BOUNDARY` indicates that a point is within a small distance of the classification boundary, when the value is `FALSE`. The variable `.ADVANTAGE` gives an indication of the confidence with which an observation is predicted, so can also be used to select simulated points near the boundary.\n\n",
    "supporting": [
      "A1-toolbox_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}