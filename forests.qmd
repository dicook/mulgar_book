# Trees and forests

<!-- Topics to include:

- trees
- forests
- boosted trees
- PP forest
-->

## Trees

The tree algorithm @BFOS84 is a simple and versatile algorithmic method for supervised classification. The basic tree algorithm generates a classification rule by sequentially splitting the data into two buckets. Splits are made between sorted data values of individual variables, with the goal of obtaining pure classes on each side of the split. The inputs for a simple tree classifier commonly include (1) an impurity measure, an indication of the relative diversity among the cases in the terminal nodes; (2) a parameter that sets the minimum number of cases in a node, or the minimum number of observations in a terminal node of the tree; and (3) a complexity measure that controls the growth of a tree, balancing the use of a simple generalizable tree against a more accurate tree
tailored to the sample.  When applying tree methods, exploring the effects of the input parameters on the tree is instructive; for example, it helps us to assess the stability of the tree model.

Although algorithmic models do not depend on distributional assumptions, that does not mean that every algorithm is suitable for all data.  For example, the tree model works best when all variables are independent within each class, because it does not take such dependencies into account.  Visualization can help us to determine whether a particular model should be applied.  In classification problems, it is useful to explore the cluster structure, comparing the clusters with the classes and looking for evidence of correlation within each class. 
The plots in @fig-lda-assumptions1 and @fig-penguins-lda-ellipses shows a strong correlation between the variables within each species, which indicates that the tree model may not give good results for the penguins data. We'll show how this is the case with two variables initially, and then extend to the four variables.

::: {#fig-p-bl-bd-tree layout-ncol=2}

```{r}
#| message: false
#| label: fig-p-bl-bd-tree1
#| fig-cap: Default tree fit
#| fig-width: 3
#| fig-height: 3
library(mulgar)
library(rpart)
library(rpart.plot)
library(colorspace)
library(classifly)
library(ggplot2)

load("data/penguins_sub.rda")
p_bl_bd_tree <- rpart(species~bl+bd, data=penguins_sub)
rpart.plot(p_bl_bd_tree, box.palette="Grays")
```

```{r}
#| message: false
#| label: fig-p-bl-bd-tree2
#| fig-cap: Boundaries of tree fit
#| fig-width: 3
#| fig-height: 3
p_bl_bd_tree_boundaries <- explore(p_bl_bd_tree, penguins_sub)
ggplot(p_bl_bd_tree_boundaries) +
  geom_point(aes(x=bl, y=bd, colour=species, shape=.TYPE)) + 
  scale_color_discrete_qualitative("Dark 3") +
  scale_shape_manual(values=c(46, 16)) +
  theme_minimal() +
  theme(aspect.ratio = 1, legend.position = "none")
```

The correlation between variables causes problems for using a tree model on the penguins data.
:::

The plots in @fig-p-bl-bd-tree show the inadequacies of the tree fit. The background color indicates the class predictions, and thus boundaries produced by the tree fit. They can be seen to be boxy, and missing the elliptical nature of the penguin clusters. This produces errors in the classification of observations which are indefensible. One could always force the tree to fit the data more closely by adjusting the parameters, but the main problem persists: that one is trying to fit elliptical data using boxes.

The boundaries for the tree model on all four variables of the penguins data can be viewed similarly using the tour. The default fitted tree is delightfully simple, with just six splits of the data. 

```{r}
#| eval: false
p_tree <- rpart(species~., data=penguins_sub)
rpart.plot(p_tree, box.palette="Grays")

p_tree_boundaries <- explore(p_tree, penguins_sub)
animate_slice(p_tree_boundaries[p_tree_boundaries$.TYPE == "simulated",1:4], col=p_tree_boundaries[p_tree_boundaries$.TYPE == "simulated",6], v_rel=0.02, axes="bottomleft")
load("data/penguins_tour_path.rda")
render_gif(p_tree_boundaries[p_tree_boundaries$.TYPE == "simulated",1:4],
           planned_tour(pt1),
           display_slice(v_rel=0.02, 
             col=p_tree_boundaries[p_tree_boundaries$.TYPE == "simulated",6], 
             axes="bottomleft"),                     gif_file="gifs/penguins_tree_boundaries.gif",
           frames=500,
           loop=FALSE
           )
```

::: {#fig-penguins-lda-tree layout-ncol=2}

![Boundaries produced by the LDA model.](gifs/penguins_lda_boundaries.gif){#fig-lda-boundary fig-alt="FIX ME" width=300}

![Boundaries produced by the tree model.](gifs/penguins_tree_boundaries.gif){#fig-tree-boundary fig-alt="FIX ME" width=300}

Comparison of the boundaries produced by the LDA model and the tree models.
:::

<!--
% Figure 2
\begin{figure*}[htbp]
\centerline{{\includegraphics[width=5in]{chap-class/missclassifications.pdf}}}
\caption[Classification of the data space for the \Data{Flea
Beetles}]{Classification of the data space for the \Data{Flea
Beetles}, as determined by LDA {\bf (left)} and a tree model {\bf
(right)}. Misclassified cases are highlighted.}
\label{misclassifications}
\end{figure*}


@HTF01 and @Bi06 include thorough discussions of
algorithms for supervised classification presented from a modeling perspective with a theoretical emphasis. @Ri96 is an early volume describing and illustrating both classical statistical methods
and algorithms for supervised classification. All three books contain some excellent examples of the use of graphics to examine two-dimensional (2D) boundaries generated by different classifiers. The discussions in these and other writings on data
mining algorithms take a less exploratory approach than that of this chapter, and they lack treatments of the use of graphics to examine the high-dimensional spaces in which the classifiers operate.
-->

<!--
### Studying the fit

\index{classification!error}
\index{classification!misclassification table}

A classifier's performance is usually assessed using its error or, conversely, its accuracy. Error is calculated by comparing the predicted class with the known true class, using a misclassification table. For example, below are the respective misclassification tables for LDA and the tree classifier applied to the \Data{Flea Beetles}:
-->

<!--
\bigskip
\begin{center}
\begin{tabular}{l@{\hspace{.15in}}r@{\hspace{.15in}}r@{\hspace{.08in}}r@{\hspace{.08in}}r@{\hspace{.3in}}rp{0.4in}
                l@{\hspace{.15in}}r@{\hspace{.15in}}r@{\hspace{.08in}}r@{\hspace{.08in}}r@{\hspace{.3in}}r} 

\multicolumn{6}{l}{LDA} & & \multicolumn{6}{l}{Tree} \\
\cline{1-6}\cline{8-13}\\

 & & \multicolumn{3}{c}{Predicted} & \multicolumn{1}{c}{Error}& &
 & & \multicolumn{3}{c}{Predicted} & \multicolumn{1}{c}{Error}\\

 & & \multicolumn{3}{c}{Class} & \multicolumn{1}{c}{}& &
 & & \multicolumn{3}{c}{Class} & \multicolumn{1}{c}{}\\

 & & 1 & 2 & 3 &  & & 
 & \B & 1 & 2 & 3 &   \\ \cline{3-6} \cline{10-13}

\T & 1 & 20 & 0 & {\bf 1} & 0.048 & & 
   & 1 & 19 & 0 & {\bf 2} & 0.095\\

Class & 2 & 0 & 22 & 0 & 0.000 & & 
Class & 2 & 0 & 22 & 0 & 0.000\\

 & 3  & {\bf 3} & 0 & 28   & 0.097 & & 
 & 3  & {\bf 3} & 0 & 28   & 0.097\\ \cline{3-6} \cline{10-13}
 & \T &         &   &      & 0.054 & &
 &    &         &   &      & 0.068\\
\end{tabular}
\end{center}
\bigskip

\noindent The total error is the number of misclassified samples divided by the total number of cases: $4/74=0.054$ for LDA and $5/74=0.068$ for the tree classifier. 

It is informative to study the misclassified cases and to see which pockets of the data space contain more error. The misclassified cases for LDA and tree classifiers are highlighted (large orange $\times$es and large green circles) in @fig-misclassifications. Some errors made by the tree classifier, such as the uppermost large green circle, seem especially egregious.  As noted earlier, they result from the
limitations of the algorithm when variables are correlated.

\index{cross-validation}

To be useful, the error estimate should predict the performance of the classifier on new samples not yet seen.  However, if the error is calculated using the same data that was used by the classifier, it is
likely to be too low.  Many methods are used to avoid double-dipping from the data, including several types of \Term{cross-validation}.  A simple example of cross-validation is to split the data into a training sample (used by the classifier) and a test sample (used for calculating error).

\index{ensemble method}
\index{classification methods!random forest}

Ensemble methods build cross-validation into the error calculations. Ensembles are constructed by using multiple classifiers and by pooling the predictions using a voting scheme.  A random forest
[@Br01,@Cu04], for example, builds in cross-validation by constructing multiple trees, each of which is generated by randomly sampling the input variables and the cases.  Because each tree is
built using a sample of the cases, there is in effect a training sample and a test sample for each tree.  (See sec-random-forests for more detail.)
-->

\index{classification methods!random forest}

## Random forests 

```{r}
#| eval: false
#| echo: false
library(mulgar)
library(tourr)
data(bushfires)

bushfires_sub <- bushfires[,c(5, 8:45, 48:55, 57:60)] %>%
  mutate(cause = factor(cause))

bushfires_pca <- prcomp(bushfires_sub[,-51],
                        scale=TRUE, retx=TRUE)
ggscree(bushfires_pca)

bushfires_pcs <- bushfires_pca$x[,1:7] %>%
  as_tibble() %>%
  mutate(cause = factor(bushfires$cause))

library(tourr)
animate_xy(bushfires_pcs[,1:7],
           guided_tour(lda_pp(bushfires_pcs$cause)),
           col=bushfires_pcs$cause)

bushfires_pca$rotation[,2]
ggplot(bushfires, aes(x=FOR_CODE)) + geom_density()
ggplot(bushfires, aes(x=COVER)) + geom_density()
ggplot(bushfires, aes(x=HEIGHT)) + geom_density()
ggplot(bushfires, aes(x=FOREST)) + geom_density()
ggplot(bushfires, aes(x=arf28)) + geom_density()

library(randomForest)
bushfires_rf <- randomForest(cause~.,
                             data=bushfires_sub,
                             importance=TRUE)
bushfires_rf_votes <- bushfires_rf$votes %>%
  as_tibble() %>%
  mutate(cause = bushfires_sub$cause)

animate_xy(bushfires_rf_votes[,1:4],
           col=bushfires_rf_votes$cause)

# Project 4D into 3D
library(geozoo)
proj <- t(geozoo::f_helmert(4)[-1,])
b_rf_v_p <- as.matrix(bushfires_rf_votes[,1:4]) %*% proj
colnames(b_rf_v_p) <- c("x1", "x2", "x3")
b_rf_v_p <- b_rf_v_p %>%
  as.data.frame() %>%
  mutate(cause = bushfires_sub$cause)
  
# Add simplex
simp <- simplex(p=3)
sp <- data.frame(simp$points)
colnames(sp) <- c("x1", "x2", "x3")
sp$cause = ""
b_rf_v_p_s <- bind_rows(sp, b_rf_v_p) %>%
  mutate(cause = factor(cause))
labels <- c("accident" , "arson", 
                "burning_off", "lightning", 
                rep("", 1021))
animate_xy(b_rf_v_p_s[,1:3], col = b_rf_v_p_s$cause, 
           axes = "off", half_range = 1.3,
           edges = as.matrix(simp$edges),
           obs_labels = labels)
render_gif(b_rf_v_p_s[,1:3],
           grand_tour(),
           display_xy(col = b_rf_v_p_s$cause, 
           axes = "off", half_range = 1.3,
           edges = as.matrix(simp$edges),
           obs_labels = labels),
           gif_file="gifs/bushfires_votes.gif",
           frames=500)  
```

A random forest [@Br01,@Cu04] is a classifier that is built from multiple trees generated by randomly sampling the cases and the variables.  The random sampling (with replacement) of cases has the fortunate effect of creating a training (``in-bag'') and a test (``out-of-bag'') sample for each tree computed.  The class of each case in the out-of-bag sample for each tree is predicted, and the predictions for all trees are combined into a vote for the class identity.  

A random forest is a computationally intensive method, a ``black box'' classifier, but it produces various diagnostics that make the outcome less mysterious.  Some diagnostics that help us to assess the model are the votes, the measures of variable importance, the error estimate, and as usual, the misclassification tables.

\index{R package!\RPackage{randomForest}}

We test the method on the \Data{Olive Oils} by building a random forest classifier of 500 trees, using the R package `randomForest` @Li06:

<!--
\begin{verbatim}
> library(randomForest)
> olive.rf <- randomForest(as.factor(region)~., 
  data=d.olive.sub, importance=TRUE, proximity=TRUE, mtry=4)
> order(olive.rf$importance[,5], decreasing=T)
[1] 8 5 4 1 7 2 6 3
> pred <- as.numeric(olive.rf$predicted)
\end{verbatim}
\newpage  % Insert page break to avoid breaking the R output.
\begin{verbatim}
> table(d.olive.sub[,1], olive.rf$predicted)
      1   2   3
  1 323   0   0
  2   0  98   0
  3   0   0 151
> margin <- olive.rf$vote
> colnames(margin) <- c("Vote1", "Vote2", "Vote3")
> d.olive.rf <- cbind(pred, margin, d.olive)
> gd <- ggobi(d.olive.rf)[1]
> glyph_color(gd) <- c(rep(6,323), rep(5,98), rep(1,151))
\end{verbatim}
-->

<!--
% Figure 11
\begin{figure*}[h]
\centerline{
  {\includegraphics[width=2.0in]{chap-class/olive-forest1.pdf}}
  {\includegraphics[width=2.0in]{chap-class/olive-forest2.pdf}}}
\smallskip
\centerline{
  {\includegraphics[width=2.0in]{chap-class/olive-forest9.pdf}}}
\caption[Examining the results of a forest classifier of \Data{Olive
Oils}]{Examining the results of a forest classifier of \Data{Olive
Oils} by `region`.  The votes assess the uncertainty associated
with each sample.  The cases classified with the greatest uncertainty
lie far from the corners of the triangles.  These points are brushed
{\bf (top left)}, and we examine their location using the linked tour
plot {\bf (top right)}.  The introduction of `linoarach` {\bf
(bottom)} eliminates the confusion between Sardinia and the North. }
\label{olive-forest}
\end{figure*}
-->

\noindent Each tree used a random sample of four of the eight variables, as well as a random sample of about a third of the 572 cases.  The votes are displayed in the left-hand plot of @fig-olive-forest, next to a projection from a
\index{tour!grand} 2D tour. Since there are three classes, the votes form a triangle, with one vertex for each region, with oils from the South at the far right, Sardinian oils at the top, and Northern oils
at the lower left. Samples that are consistently classified correctly are close to the vertices; cases that are commonly misclassified are
further from a vertex.  Although forests perfectly classify this data, the number of points falling between the Northern and the Sardinian vertices suggests some potential for error in classifying future samples.

For more understanding of the votes, we turn to another diagnostic: variable importance. Forests return two measures of variable importance, both of which give similar results. Based on the Gini measure, the most important variables, in order, are `eicosenoic`, `linoleic`, `oleic`, `palmitic`, `arachidic`, `palmitoleic`, `linolenic`, and `stearic`.  

Some of this ordering is as expected, given the initial graphical inspection of the data (@sec-class-plots).  The importance of `eicosenoic` was our first discovery, as shown in the top row of
@fig-olive-1d.  And yes, `linoleic` is next in importance: The first two plots in @fig-olive-2d make that clear.  The surprise is that the forest should consider `arachidic` to be less
important than `palmitic`.  This is not what we found, as shown in the right-hand plot in that figure.

Did we overlook something important in our earlier investigation?  We return to the use of the manual manipulation of the tour \index{tour!manual} to see whether `palmitic` does in fact perform better than `arachidic` at finding a gap between the two regions. But it does not.  By overlooking the importance of `arachidic`, the random forest never finds an adequate gap between the oils of the
Northern and the Sardinian regions, and that probably explains why there is more confusion about some Northern samples than there should be.

We rebuild the forest using a new variable constructed from a linear combination of `linoleic` and `arachidic` (`linoarach`), just as we did when applying the single tree classifier.  Since correlated variables reduce each other's importance, we need to remove `linoleic` and `oleic` when we add `linoarach`.  Once we have done this, the confusion between Northern and Sardinian oils disappears @fig-olive-forest, lower plot): The points are now
tightly clumped at each vertex, which indicates more certainty in their class predictions. The new variable becomes the second most important variable according to the importance diagnostic.

Classifying the oils by the three large `region`s is too easy a problem for forests; they are designed to tackle more challenging classification tasks. We will use them to examine the oils from the
areas in the Southern region (North and South Apulia, Calabria, and Sicily). Remember the initial graphical inspection of the data, which showed that oils from the four areas were not completely
separable. The samples from Sicily overlapped those of the three other areas.  We will use a forest classifier to see how well it can differentiate the Southern oils by `area`:

\begin{verbatim}
> d.olive.sth <- subset(d.olive, region==1, 
   select=area:eicosenoic)
> olive.rf <- randomForest(as.factor(area)~., 
   data=d.olive.sth, importance=TRUE, proximity=TRUE, 
   mtry=2, ntree=1500)
> order(olive.rf$importance[,5], decreasing=T)
[1] 5 2 4 3 1 6 7 8
> pred <- as.numeric(olive.rf$predicted)
> table(d.olive.sth[,1], olive.rf$predicted)
      1   2   3   4
  1  22   2   0   1
  2   0  53   2   1
  3   0   1 202   3
  4   3   4   5  24
> margin <- olive.rf$vote
> colnames(margin) <- c("Vote1", "Vote2", "Vote3", "Vote4")
> d.olive.rf <- cbind(pred, margin, d.olive.sth)
> gd <- ggobi(d.olive.rf)[1]
> glyph_color(gd) <- c(6,3,2,9)[d.olive.rf$area]
\end{verbatim} 

\noindent After experimenting with several input parameters, we show the results for a forest of 1,500 trees, sampling two variables at each
tree node, and yielding an error rate of 0.068.  The misclassification table is:

<!--
\bigskip
\begin{center}
\begin{tabular}{l@{\hspace{.3in}}r@{\hspace{1em}}r@{\hspace{1em}}r@{\hspace{1em}}r@{\hspace{1.5em}}r@{\hspace{2em}}r}
\B & & \multicolumn{4}{c}{Predicted `area`} & Error \\

\T & & \multicolumn{1}{c}{North}  & \multicolumn{1}{c}{Calabria} & \multicolumn{1}{c}{South}  & \multicolumn{1}{c}{Sicily} &  \\
\B & & \multicolumn{1}{c}{Apulia} &  & \multicolumn{1}{c}{Apulia} & & \\\cline{3-7}

\T         & North Apulia & 22 & {\bf 2} & 0 & {\bf 1} & 0.120 \\
`area` & Calabria & 0 & 53 & {\bf 2} & {\bf 1} & 0.054 \\
           & South Apulia & 0 & {\bf 1} & 202 & {\bf 3} & 0.019 \\
           & Sicily & {\bf 3} & {\bf 4} & {\bf 5} & 24 & 0.333 \\ \cline{3-7}
\T         &        &         &         &         &    &  0.068
\end{tabular}
\end{center}
\bigskip
-->

\noindent The error of the forest is surprisingly low, but the  error is definitely not uniform across classes. Predictions for Sicily are wrong about a third of the time. Figure~\ref{olive-forest2} shows
some more interesting aspects of the results.  For this figure, the following table describes the correspondence between area and symbol:

<!--
\begin{center}
\begin{tabular}{l@{\hspace{.3in}}l} %\hline
\T \B `area` & symbol \\\hline
\T  North Apulia   &  orange $+$ \\
  Calabria  &    red $+$ \\
  South Apulia  &    pink $\times$ \\
\B  Sicily  &    yellow $\times$ \\\hline
\end{tabular}
\end{center}
-->

\index{jittering}

\noindent Look first at the top row of the figure.  The misclassification table is represented by a jittered scatterplot, at the left.  A plot from a 2D tour \index{tour!grand} of the four voting variables is in the center.  Because there are four groups, the votes lie on a 3D tetrahedron (a simplex).  The votes from three of the areas are pretty well separated, one at each ``corner,'' but those
from Sicily overlap all of them.  Remember that when points are clumped at the vertex, class members are consistently predicted correctly.  Since this does not occur for Sicilian oils, we see that there is more uncertainty in the predictions for this area.

The plot at right confirms this observation. It is a projection from a 2D tour \index{tour!grand} of the four most important variables, showing a pattern we have seen before.  We can achieve pretty good separation of the oils from North Apulia, Calabria, and South Apulia, but the oils from Sicily overlap all three clusters.  Clearly these are tough samples to classify correctly.

<!--
% Figure 12
\begin{figure*}[htbp]
\centerline{
  {\includegraphics[width=1.5in]{chap-class/olive-sth-forest1.pdf}}
  {\includegraphics[width=1.5in]{chap-class/olive-sth-forest7.pdf}}
  {\includegraphics[width=1.5in]{chap-class/olive-sth-forest3.pdf}}}
\smallskip
\centerline{
  {\includegraphics[width=1.5in]{chap-class/olive-sth-forest4.pdf}}
  {\includegraphics[width=1.5in]{chap-class/olive-sth-forest5.pdf}}
  {\includegraphics[width=1.5in]{chap-class/olive-sth-forest6.pdf}}}
\caption[Examining the results of a random forest after classifying
the oils of the South]{Examining the results of a random forest after
classifying the oils of the South by area}.  A representation of
the misclassification table {\bf (left)} is linked to plots of the
votes {\bf (middle)} and a 2D tour {\bf (right)}.  The Sicilian oils
have been excluded from the plots in the bottom row.}
\label{olive-forest2}
\end{figure*}
-->

We remove the Sicilian oils from the plots so we can focus on the other three areas (bottom row of plots). The points representing North Apulian oils form a very tight cluster at a vertex, with three
exceptions. Two of these points are misclassified as Calabrian, and we have highlighted them as large filled circles by painting the misclassification plot.

The pattern of the votes (middle plot) suggests that there is high certainty in the predictions for North Apulian oils, with the exception of these two samples.  When we watch the votes in the tour
\index{tour!grand} for a while, we see that the votes of these two samples travel as if they were in a cluster all their own, which is distinct from the remaining North Apulian oils.

However, when we look at the data, we find the votes for these two samples a bit puzzling.  We watch the four most important variables in the tour for a while (as in the right plot), and these two points
do not behave as if they were in a distinct cluster; they travel with the rest of the samples from North Apulia.  They do seem to be outliers with respect their class, but they are not so far from their
group - it is a bit surprising that the forest has trouble classifying these cases.

Rather than exploring the other misclassifications, we leave that for the reader.

In summary, a random forest is a useful method for tackling tough classification problems.  Its diagnostics provide a rich basis for graphical exploration, which helps us to digest and evaluate the solution.

## Exercises {-}

1. For the \Data{Italian Olive Oils}:
    a. Split the samples from North Italy into $2/3$ training and
$1/3$ test samples for each area.
    b. Build a tree model to classify the oils by `area` for the
three areas of North Italy. Which are the most important
variables? Make plots of these variables. What is the accuracy of the
model for the training and test sets?
    c. Build a random forest to classify oils into the three areas of
North Italy. Compare the order of importance of variables with what
you found from a single tree. Make a parallel coordinate plot in the
order of variable importance.
