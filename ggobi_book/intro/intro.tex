\mainmatter
\chapter[Introduction]{Introduction}\label{intro}

In this technological age, we live in a sea of information.  We face
the problem of gleaning useful knowledge from masses of words and
numbers stored in computers.  Fortunately, the computing technology
that produces this deluge also gives us some tools to transform
heterogeneous information into knowledge.  We now rely on computers at
every stage of this transformation: structuring and exploring
information, developing models, and communicating knowledge.  

In this book we teach a methodology that makes visualization central
to the process of abstracting knowledge from information.  Computers
give us great power to represent information in pictures, but even
more, they give us the power to interact with these pictures.  If
these are pictures of data, then interaction gives us the feeling of
having our hands on the data itself and helps us to orient ourselves
in the sea of information.  By generating and manipulating many
pictures, we make comparisons among different views of the data, we
pose queries about the data and get immediate answers, and we
discover large patterns and small features of interest.  These are
essential facets of data exploration, and they are important for
model development and diagnosis.

In this first chapter we sketch the history of computer-aided data
visualization and the role of data visualization in the process of
data analysis.

%We also introduce methods to be used in later
%chapters, and the software used for demonstrating the methods.
% are we introducing the software in the intro?  revisit later xxxxxxxx

\section{Data visualization: beyond the third dimension}

\index{data}\index{information}\index{knowledge} So far we have used
the terms ``information,'' ``knowledge,'' and ``data'' informally.
From now on we will use the following distinction: the term {\em data}
refers to information that is structured in some schematic form such
as a table or a list, and knowledge is derived from studying
data. Data is often but not always quantitative, and it is often
derived by processing unstructured information.  It always includes
some attributes or variables such as the number of hits on web sites,
frequencies of words in text samples, weight in pounds, mileage in
gallons per mile, income per household in dollars, years of education,
acidity on the pH scale, sulfur emissions in tons per year, or scores
on standardized tests.

\index{visualization} \index{visualization!data}
\index{visualization!volume} \index{visualization!surface}
\index{visualization!flow} \index{visualization!cartographic}
\index{visualization!scientific} \index{visualization!information}
When we visualize data, we are interested in portraying abstract
relationships among such variables: for example, the degree to which
income increases with education, or whether certain astronomical
measurements indicate grouping and therefore hint at new classes of
celestial objects.  In contrast to this interest in abstract
relationships, many other areas of visualization are principally
concerned with the display of objects and phenomena in physical
three-dimensional (3D) space.  Examples are volume visualization
(e.g., for the display of human organs in medicine), surface
visualization (e.g., for manufacturing cars or animated movies), flow
visualization (e.g., for aeronautics or meteorology), and cartography
(e.g., for navigation or social studies).  In these areas one often
strives for physical realism or the display of great detail in space,
as in the visual display of a new car design or of a developing
hurricane in a meteorological simulation. The data visualization task
is obviously different from drawing physical objects.

If data visualization emphasizes abstract variables and their
relationships, then the challenge of data visualization is to create
pictures that reflect these abstract entities.  One approach to
drawing abstract variables is to create axes in space and map the
variable values to locations on the axes, and then render the axes on
a drawing surface.  In effect, one codes non-spatial information using
spatial attributes: position and distance on a page or computer
screen.  The goal of data visualization is then not realistic drawing,
which is meaningless in this context, but translating abstract
relationships to interpretable pictures.

This way of thinking about data visualization, as interpretable
spatial representation of abstract data, immediately brings up a
limitation:  Plotting surfaces such as paper or computer screens are
merely two-dimensional (2D).  We can extend this limit by simulating a third
dimension: The eye can be tricked into seeing 3D virtual
space with perspective and motion, but if we want an axis for each
variable, that's as far as we can stretch the display dimension.

This limitation to a 3D display space is not a problem if the objects
to be represented are three-dimensional, as in most other
visualization areas.  In data visualization, however, the number of
axes required to code variables can be large: Five or ten axes are
common, but these days one often encounters dozens and even hundreds.
Overcoming the 2D and 3D barriers is a key challenge for data
visualization.  To meet this challenge, we use powerful computer-aided
visualization tools.  For example, we can mimic and amplify a strategy
familiar from photography: taking pictures from multiple directions so
the shape of an object can be understood in its entirety.  This is an
example of the ``multiple views'' paradigm, \index{multiple views}
which will be a recurring theme of this book.  In our 3D world the
paradigm works superbly, because the human eye is adept at inferring
the true shape of an object from just a few directional views.
Unfortunately, the same is often not true for views of abstract data.
The chasm between different views of data, however, can be actively
bridged with additional computer technology: Unlike the passive paper
medium, computers allow us to manipulate pictures, to pull and push
their content in continuous motion like a moving video camera, or to
poke at objects in one picture and see them light up in other
pictures.  \index{plots!interactive} Motion links pictures in time;
poking links them across space.  This book features many illustrations
of the power of these linking technologies.  The diligent reader may
come away ``seeing'' high-dimensional data spaces!

\section{Statistical data visualization: goals and history}

\index{visualization!data}
\index{visualization!scientific}
\index{human--computer interaction}

% This paragraph may change as we assemble the references.

% We could start off with something like this as a way to tip our
% hats to history and to cite such books:

Visualization has been used for centuries to map our world
(cartography) and describe the animal and plant kingdoms (scientific
illustration).  Data visualization, which is more abstract, emerged
more recently.  An early innovator was William Playfair, whose
extensive charting of economic data in the 1800s \cite{WS05a,WS05b}
contributed to its emergence.  The early history of visualization
has been richly ~---~ and beautifully ~---~ documented
\cite{FrDe,Tufte83,Tufte90,Ford92,Wa00}.

%  I don't think this short paragraph adds anything.  We get
%  back to the time line on the next page, with the citations of
%  Systat and so forth ...   dfs
%Data visualization began to utilize computers in the mid-nineteenth
%century. This is the time frame for the methods described in this
%book, focusing on interactive data visualization.
% Di: The first dot plot is one by Michael H. van Langren in 1600s
% plotting guesses by people of the distance between Toledo and Rome!
% First time line chart by Joseph Priestley 1744.
% Most serious start to data graphics by William Playfair in beginning 
%  of 1800s. He plotted economic data.

Today's data visualization has homes in several disciplines, including
the natural sciences, engineering, geography, computer science, and
statistics.  There is a lot of overlap in the functionality of the
methods and tools they generate, but some differences in emphasis can
be traced to the research contexts in which they were incubated.  For
example, data visualization in the natural science and engineering
communities supports the goal of modeling physical objects and
processes, relying on scientific visualization
\cite{Hansen2004,Bonneau2006}. For the geographical community, maps
are the starting point, and other data visualization methods are used
to expand on the information displayed using cartography
\cite{LMGR05,DMK05}.  The database research community creates
visualization software that grows out of their work in data storage and
retrieval; their graphics often summarize the kinds of tables and
tabulations that are common results of database queries.  The
human--computer interface community produces software as part of their
research in human perception, human--computer interaction and
usability, and their tools are often designed to make the performance
of a complex task as straightforward as possible. These two latter
fields have been instrumental in developing the field of information
visualization \cite{CMS99,BS03,Spence07}.

% references -- HCI, database vis, ... xxxxxxxxxxxxxxxxxxxx

% possible scientific vis refs -- added 2, could add one more
% Introduction to Scientific Visualization
%   Wright, Helen
%   Springer 2007

\index{data analysis!exploratory (EDA)}
\index{inference}
\index{visualization!uncertainty}
%\index{Tukey, John}
The statistics community creates visualization systems within the
context of data analysis, so the graphics are designed to support and
enrich the statistical processes of data exploration, modeling, and
inference.
%help answer
%the questions that are raised as part of data exploration, and to be a
%part of the process of statistical modeling and inference.  
As a result, statistical data visualization has some unique features.
Statisticians are always concerned with variability in observations
and error in measurements, both of which cause uncertainty about
conclusions drawn from data.  Dealing with this uncertainty is at the
heart of classical statistics, and statisticians have developed a huge
body of inferential methods that help to quantify uncertainty.

% Cleveland's books, Buja and Tukey, 
% Cleveland and McGill, Wang 78
% Rao 93
% Latest two handbook volumes

% It's hard to think of adding SAS when graphics are mentioned ...

%This is  a bit clunky still.
Systems for data analysis included visualization as soon as they began
to emerge \cite{SPSS68,BC84,SYSTAT84}.  They could generate a wide
variety of plots, either for display on the screen or for printing,
and the more flexible systems have always allowed users considerably
leeway in plot design.  Since these systems predated the general use
of the mouse, the keyboard was their only input device, and the
displays on the screen were not themselves interactive.

As early as the 1960s, however, researchers in many disciplines were
making innovations in computer--human interaction, and statisticians
were there, too.  The seminal visualization system for exploratory
data analysis was PRIM-9, the work of Fisherkeller, Friedman, and Tukey
at the Stanford Linear Accelerator Center in 1974.  PRIM-9 was the
first stab at an interactive tool set for the visual analysis of
multivariate data.  It was followed by further pioneering systems at
the Swiss Federal Institute of Technology (PRIM-ETH), Harvard
University (PRIM-H), and Stanford University (ORION), in the late 1970s
and early 1980s.

Research picked up in the following few years in many places
\cite{Wa78,Mc77,VeVe85,CM88,BT91,Ti91,Cl93,Rao93,CWL96}.  The authors
themselves were influenced by work at Bell Laboratories, Bellcore, the
University of Washington, Rutgers University, the University of
Minnesota, MIT, CMU, Batelle Richmond WA, George Mason University,
Rice University, York University, Cornell University, Trinity College,
and the University of Augsburg, among others.
% proposed; dfs
In the past couple of years, books have begun to appear that capture
this history and continue to point the way forward
\cite{Wilkinson05,Young06,Unwin06,UHC06}.


\section{Getting down to data}

Here is a very small and seemingly simple dataset we will use to
illustrate the use of data graphics.  One waiter recorded information
about each tip he received over a period of a few months working in
one restaurant.  He collected several variables:
\newpage
\begin{itemize}
\item \Vbl{tip} (i.e., gratuity) in US dollars
\item \Vbl{bill} (the cost of the meal) in US dollars 
\item \Vbl{sex} of the bill payer
\item whether the party included \Vbl{smokers}
\item \Vbl{day} of the week
\item \Vbl{time} of day
\item \Vbl{size} of the party
\end{itemize}
In all he recorded 244 tips.  The data was reported in a collection of
case studies for business statistics \cite{BS95}. The primary
question suggested by the data is this: {\em What are the factors that affect
tipping behavior?}

\index{datasets!\Data{Tips}}
This dataset is typical (albeit small): There are seven variables,
of which two are numeric (\Vbl{tip}, \Vbl{bill}), and the others are
categorical or otherwise discrete.  In answering the question, we are
interested in exploring relationships that may involve more than three
variables, none of which corresponds to physical space.  In this sense the
data is high-dimensional and abstract.

\index{histogram}
\index{histogram!bin width}
We look first at the variable of greatest interest to the waiter:
\Vbl{tip}.  A common graph for looking at a single variable is the
histogram, where data values are binned and the count is represented
by a rectangular bar.  We choose an initial bin width of \$1 and
produce the uppermost graph of Fig.~\ref{tips1}.  The distribution
appears to be unimodal; that is, it has one peak, the bar representing
the tips greater than \$1.50 and less than or equal \$2.50.  There are
very few tips of \$1.50 or less.  The number of larger tips trails
off rapidly, which suggests that this is not a very expensive restaurant.

\begin{figure*}[htp]
%\vspace{-1in}
%\centerline{\epsfxsize=5in\epsfbox{/home/dicook/graphics/tips-hist1.ps}}
%\centerline{\epsfxsize=5in\epsfbox{/home/dicook/graphics/tips-hist2.ps}}
%\centerline{\includegraphics[width=4in]{intro/tips-hist.jpg}}
\centerline{\includegraphics[width=4in]{intro/tips-hist.pdf}}
\caption[Histograms of \Vbl{tip} with differing bin width]{Histograms
of \Vbl{tip} with differing bin width: \$1, 10{\it c}.  Bin width
can be changed interactively in interactive systems, often by
dragging a slider.
}
\label{tips1}
\end{figure*}

The conclusions drawn from a histogram are often influenced by the
choice of bin width, which is a parameter of the graph and not of the
data.  Figure~\ref{tips1} shows a histogram with a smaller bin width,
10{\it c}.  At the smaller bin width the shape is multimodal, and it is
clear that there are large peaks at the full dollars and smaller peaks
at the half dollar.  This shows that the customers tended to round the
tip to the nearest fifty cents or dollar.

This type of observation occurs frequently when studying histograms: A
large bin width smooths out the graph and shows rough or global
trends, whereas a smaller bin width highlights more local features.
Since the bin width is an example of a graph parameter, experimenting
with bin width is an example of exploring a set of related graphs.
Exploring multiple related graphs can lead to insights that would not
be apparent in any single graph.

\index{scatterplot} So far we have not addressed the primary question:
What relationships exist between \Vbl{tip} and the other variables?
Since the tip is usually calculated based on the bill, it is natural
to look first at a graph of \Vbl{tip} and \Vbl{bill}.  A common graph
for looking at a pair of continuous variables is the scatterplot, as
in Fig.~\ref{tips2}.  We see that the variables are highly correlated
($r=0.68$), which confirms that tip is calculated from the bill.  We
have added a line representing a tip rate of 18\%.  Disappointingly
for the waiter, there are many more points below the line than above
it: There are many more ``cheap tippers'' than generous tippers.
There are a couple of notable exceptions, especially one party who
gave a \${5.15} tip for a \${7.25} bill, which works out to a tip rate
of about 70\%.

%A visually striking feature of Fig.~\ref{tips2} is the horizontal
%striping, which is very clear at the full dollar amounts and somewhat
%less so at the half dollars.  The stripes have a natural explanation:
%they correspond to the peaks that were so prominent in the histogram
%with the smallest bin width.

\index{scatterplot!conditioning} We said earlier that an essential
aspect of data visualization is capturing relationships among many
variables: three, four, or even more.  This dataset, simple as it is,
illustrates the point.  Let us ask, for example, how a third variable
such as \Vbl{sex} affects the relationship between \Vbl{tip} and
\Vbl{bill}.  As \Vbl{sex} is categorical with two levels (i.e.,
binary), it is natural to divide the data into female and male payers
and to generate two scatterplots of \Vbl{tip} vs. \Vbl{bill}.  Let us
go even further by including a fourth variable, \Vbl{smoking}, which
is also binary.  We now divide the data into four parts and generate
the four scatterplots observed in Fig.~\ref{tips3}. (The 18\% tip
guideline is included in each plot, and the correlation between the
variables for each subset is in the top left of each plot.) Inspecting
these plots reveals numerous features: (1)~For smoking parties, there
is a lot less association between the size of the tip and the size of
the bill; (2)~when a female non-smoker paid the bill, the tip was a
very consistent percentage of the bill, with the exceptions of three
dining parties; and (3)~larger bills were mostly paid by men.

\begin{figure*}[htp]
%\vspace{-0.5in}
%\centerline{\epsfxsize=2.5in\epsfbox{/home/dicook/graphics/tips-scat1.ps}
%            \epsfxsize=3in\epsfbox{/home/dicook/graphics/tips-scat3.ps}}
%\centerline{\includegraphics[width=2.3in]{intro/tips-scat1.jpg}\includegraphics[width=2.3in]{intro/tips-scat2.jpg}}
\centerline{\includegraphics[width=4in]{intro/tips-scat1.pdf}}%\includegraphics[width=2.9in]{intro/tips-scat2.pdf}}
\caption[Scatterplot of \Vbl{tip} vs. \Vbl{bill}]{Scatterplot of
\Vbl{tip} vs. \Vbl{bill}. The line represents a tip of 18\%. 
The greater number of points far below the line indicates that there
are more ``cheap tippers'' than generous tippers.}
\label{tips2}
\end{figure*}

\begin{figure*}[htp]
\centerline{\includegraphics[width=5in]{intro/tips-scat2.pdf}}
\caption[Scatterplot of \Vbl{tip} vs. \Vbl{bill} conditioned by
\Vbl{sex} and \Vbl{smoker}]{Scatterplot of \Vbl{tip} vs. \Vbl{bill}
conditioned by \Vbl{sex} and \Vbl{smoker}. There is almost no
association between \Vbl{tip} and \Vbl{bill} in the smoking parties,
and with the exception of three dining parties, when a female
non-smoker paid the bill, the tip was extremely consistent.}
\label{tips3}
\end{figure*}

\vspace{1em}
\noindent{\em Taking stock}

In the above example we gained a wealth of insight in a short time.
Using nothing but graphical methods we investigated univariate,
bivariate, and multivariate relationships.  We found both global
features and local detail.  We saw that tips were rounded; then we saw
the obvious correlation between the tip and the size of the bill,
noting the scarcity of generous tippers; finally we discovered
differences in the tipping behavior of male and female smokers and
non-smokers.

%\section{Reasoning from Graphics}
% This is not the general section the title would suggest,
% because it is about nothing but conditional plots.
% It's really a story of developing multivariate insights
% using bivariate plots.

\index{drill-down}
Notice that we used very simple plots to explore some pretty complex
relationships involving as many as four variables.  We began to
explore multivariate relationships for the first time when we produced
the plots in Fig.~\ref{tips3}. Each plot shows a subset obtained by
partitioning the data according to two binary variables.  The
statistical term for partitioning based on variables is
``conditioning.''  For example, the top left plot shows the dining
parties that meet the condition that the bill payer was a male
non-smoker: \Vbl{sex} = male and \Vbl{smoking} = False.  In database
terminology this plot would be called the result of ``drill-down.''
The idea of conditioning is richer than drill-down because it involves
a structured partitioning of {\em all} data as opposed to the
extraction of a single partition.

\index{plots!conditioning}
Having generated the four plots, we arrange them in a two-by-two
layout to reflect the two variables on which we conditioned.  Although
the axes in each plot are \Vbl{tip} and \Vbl{bill}, the
axes of the overall figure are \Vbl{smoking} (vertical) and \Vbl{sex}
(horizontal).  The arrangement permits us to make several kinds of
comparisons and to make observations about the partitions.  For example,
comparing the rows shows that smokers and non-smokers differ in the
strength of the correlation between \Vbl{tip} and \Vbl{bill}, and
comparing the plots in the top row shows that male and female
non-smokers differ in that the larger bills tend to be paid by men.
In this way a few simple plots allow us to reason about relationships
among four variables.

\index{regression}
In contrast, an old-fashioned approach without graphics would be to
fit a regression model.  Without subtle regression diagnostics
(which rely on graphics!), this approach would miss many of the above
insights: the rounding of tips, the preponderance of cheap tippers,
and perhaps the multivariate relationships involving the bill payer's
sex and the group's smoking habits.


\section{Getting real: process and caveats}

% Point 1:  data analysis isn't straightforward

\index{data analysis!wisdom}
The preceding explanations may have given a somewhat misleading
impression of the process of data analysis.  In our account the data
had no problems; for example, there were no missing values and no
recording errors.  Every step was logical and necessary.  Every
question we asked had a meaningful answer.  Every plot that was
produced was useful and informative.  In actual data analysis, nothing
could be further from the truth.  Real datasets are rarely perfect;
most choices are guided by intuition, knowledge, and judgment; most
steps lead to dead ends; most plots end up in the wastebasket.  This
may sound daunting, but even though data analysis is a highly
improvisational activity, it can be given some structure nonetheless.

% Point 2:  there is somehow an overall structure

To understand data analysis, and how visualization fits in, it is
useful to talk about it as a process consisting of several stages:

\newpage
\begin{itemize}
\item The problem statement
\item Data preparation
\item Exploratory data analysis 
\item Quantitative analysis
\item Presentation
\end{itemize}

\index{data analysis!problem statement}
\noindent{\em The problem statement:} Why do you want to analyze this
data?  Underlying every dataset is a question or problem statement.
For the tipping data the question was provided to us from the data
source: ``What are the factors that affect tipping behavior?'' This
problem statement drives the process of any data analysis. Sometimes
the problem is identified prior to a data collection. Perhaps it is
realized after data becomes available because having the data
available has made it possible to imagine new issues.  It may be a
task that the boss assigns, it may be an individual's curiosity, or it
may be part of a larger scientific endeavor.  Ideally, we begin an
analysis with some sense of direction, as described by a pertinent
question.

\vspace{1em}

\index{data analysis!data preparation}
\noindent{\em Data preparation:} In the classroom, the teacher hands
the class a single data matrix with each variable clearly defined.  In
the real world, it can take a great deal of work to construct a clean
data matrix.  For example, data values may be missing or misrecorded,
data may be distributed across several sources, and the variable
definitions and data values may be inconsistent across these sources.
Analysts often have to invest considerable time in acquiring domain
knowledge and in learning computing tools before they can even ask a
meaningful question about the data.  It is therefore not uncommon for
this stage to consume most of the effort that goes into a project. And
it is also not uncommon to loop back to this stage after completing
the subsequent stages, to re-prepare and re-analyze the data.

In preparing the \Data{Tips} data, we would create a new variable called
tip rate, because when tips are discussed in restaurants, among
waiters, dining parties, and tourist guides, it is in terms of a
percentage of total bill. We may also create several new dummy
variables for the day of the week, in anticipation of fitting a
regression model. We did not talk about using visualization to verify
that we had correctly understood and prepared the tipping data.  For
example, that unusually large tip could have been the result of a
transcription error. Graphics identified the observation as unusual,
and the analyst might use this information to search the origins of
the data to check the validity of the numbers for this observation.

\vspace{1em}

\index{exploratory data analysis}
\noindent{\em Exploratory data analysis (EDA):} 
%``The primary goal of exploratory data analysis is to maximize the
%analyst's insight into a data set and into the underlying structure of
%a data set, while providing all of the specific items that an analyst
%would want to extract from a data set.'' {\tt
%http://www.itl.nist.gov/div898/handbook/} What is ``insight''?
%Dictionary (http://www.thefreedictionary.com) definition:
%``Insight. The clear (and often sudden) understanding of a complex
%situation, the power or act of seeing into a situation.'' Insight
%implies detecting and uncovering underlying structure in the data.
At this stage in the analysis, we make time to ``play in the sand'' to
allow us to find the unexpected, and come to some understanding of our
data. We like to think of this as a little like traveling. We may have
a purpose in visiting a new city, perhaps to attend a conference, but
we need to take care of our basic necessities, such as finding eating
places and gas stations.  Some of our movements will be
pre-determined, or guided by the advice of others, but some of the
time we wander around by ourselves. We may find a cafe we particularly
like or a cheaper gas station.  This is all about getting to know the
neighborhood.

By analogy, at this stage in the analysis, we relax the focus on the
problem statement and explore broadly different aspects of the
data. Modern exploratory data analysis software is designed to make
this process as fruitful as possible.  It is a highly interactive,
real-time, dynamic, and visual process, having evolved along with
computers.  It takes advantage of technology, in a way that Tukey
envisioned and experimented with on specialist hardware 40 years ago:
``Today, software and hardware together provide far more powerful
factories than most statisticians realize, factories that many of
today's most able young people find exciting and worth learning about
on their own'' \cite{Tu65}. It is characterized by direct manipulation
and dynamic graphics: plots that respond in real time to an analyst's
queries and change dynamically to re-focus, link to information from
other sources, and re-organize information. The analyst can
work rapidly and thoroughly through the data, slipping out of
dead-ends and chasing down new leads. The high level of interactivity
is enabled by bare-bones graphics, which are generally not adequate
for presentation purposes.

We gave you some flavor of this stage in the analysis of the waiter's
tips.  Although the primary question was about the factors affecting
tipping behavior, we checked the distribution of individual variables,
we looked for unusual records, we explored relationships among
multiple variables, and we found some unexpected patterns: the
rounding of tips, the prevalence of cheap tippers, and the
heterogeneity in variance between groups.

%To complete this exploration, we would also add numerical summaries to
%the visual analysis.

%[Note: Needs to be revisited.  There must be other EDA activities
%we haven't yet mentioned.]

% play in the sand, data snooping - xxxxx

\vspace{1em}

\noindent{\em Quantitative analysis (QA):} 

At this stage, we use statistical modeling and statistical
interference to answer our primary questions.  With statistical
models, we summarize complex data, decomposing it into estimates of
signal and noise.  With statistical inference, we try to assess whether a
signal is real.  Data visualization plays an important role at this
stage, although that is less well known than its key role in
exploration.  It is helpful both in better understanding a model and
in assessing its validity in relation to the data.

\index{regression} \index{modeling} For \Data{Tips}, we have not yet
answered the primary question of interest. Let's fit a regression
model using \Vbl{tiprate} as the response and the remaining variables
(except \Vbl{tip} and \Vbl{bill}) as the explanatory variables.  When
we do this, only \Vbl{size} has a significant regression coefficient,
resulting in the model $\hat{tip rate} = 0.18 -0.01\times size$.  The
model says that, starting from a baseline tip rate of 18\%, the amount
drops by 1\% for each additional diner in a party, and this is the
model answer in \citeasnoun{BS95}.  Figure~\ref{tips-reg} shows this
model and the underlying data. (The data is \Term{jittered}
horizontally to alleviate over-plotting caused by the discreteness of
\Vbl{size}; that is, a small amount of noise is added to the value
of \Vbl{size} for each case.)

Are we satisfied with this model?  We have some doubts about it,
although we know that something like it is used in practice: Most
restaurants today factor the tip into the bill automatically for
larger dining parties.  However, in this data it explains only 2\% of
the variation in tip rate.  The points are spread widely around the
regression line.  There are very few data points for parties of size
one, five, and six, which makes us question the validity of the model
in these regions.  The signal is very weak relative to the noise.

\begin{figure*}[htp]
%\vspace{-2in}
\centerline{\includegraphics[width=4in]{intro/tips-reg.pdf}}
\caption[Factors affecting tipping behavior]{Factors affecting
tipping behavior.  This scatterplot of \Vbl{tiprate} vs. \Vbl{size}
shows the best model along with the data (jittered horizontally).
There is a lot of variation around the regression line, showing very
little signal relative to noise.  In addition there are very few data
points for parties of 1, 5, or 6 diners, so the model may not be valid
at these extremes.  }
\label{tips-reg}
\end{figure*}

Most problems are more complex than the \Data{Tips} data, and the
models are often more sophisticated, so evaluating them is
correspondingly more difficult.  We evaluate a model using data
produced by the model-fitting process, such as model estimates and
diagnostics.  Other data may be derived by simulating from the model
or by calculating confidence regions.  All this data can be explored
and plotted for the pleasure of understanding the model.

\index{plots!model}
Plotting the model in relation to the original data is also important.
There is a temptation to ignore that messy raw data in favor of
the simplification provided by a model, but a lot can be learned from
what is left out of a model.  For example, we would never consider
teaching regression analysis without teaching residual plots.  A model
is a succinct explanation of the variation in the data, a
simplification. With a model we can make short descriptive statements
about the data, and pictures help us find out whether a model is {\em too}
simple.  And so we plot the model in the context of the data, as we
just did in Fig. \ref{tips-reg}, and as we will do often in the
chapters to follow.

% All very nice, but this section is getting very wordy and long.
%A graphic should be self-explanatory, but it is usually assisted by a
%detailed written or verbal description. ``A picture saves a thousand
%words!'' Or does it take a thousand words to explain? The beauty of a
%model is that the explanation is concise, and precise. But pictures
%are powerful tools in a data analysis that our visual senses embrace,
%revealing so much that a model alone cannot.

%[Draw an example from the tips data,
%using one of the conditional plots.]  
%In the classroom, it's usually easy to decide what kind of model to
%fit, and it isn't too difficult to decide which variables are
%relevant.  In the real world, these might be difficult questions.  One
%of the difficulties is deciding what assumptions to make about the
%model.  

%Fitting a model inevitably produces its own data, in the form of model
%estimates and diagnostics. One should always check the assumptions
%using model diagnostics. This new data that we should plot. We may
%plot parameter estimates and confidence intervals for the estimates in
%a model. We may plot residuals to check how much structure is left out
%of the model. How good is this model in summarizing the structure in
%the data? Graphics are an essential part of model diagnostics. Why is
%this? Models are are a simplification of the structure contained in the
%data. To assess if a model is too simple for the data we make a
%picture, because graphics can provide concise summaries of complex
%structure. Once we have a model it is tempting to forget about the
%data that gave rise to it. To understand and assess the mode it is
%important to make plots of the model in the context of the data.

%\citeasnoun{DHLZ02} see exploratory analysis as detective work,
%comprising of techniques to uncover patterns in data, and confirmatory
%analysis as judicial work, weighting evidence for and against
%hypotheses. 

%How do our observations about the data from exploratory
% analysis fit into the hypothesis testing work? xxxxx

% The tendency to plot statistics rather than the data.

% interplay of EDA and quantitative methods....

\vspace{1em}

\noindent{\em The interplay of EDA and QA: Is it data snooping?}

\index{inference} \index{data snooping} Because EDA is very graphical,
it sometimes gives rise to a suspicion that patterns in the data are
being detected and reported that are not really there.  Sometimes this
is called \Term{data snooping}.  Certainly it is important to validate
our observations about the data.  Just as we argue that models should
be validated by all means available, we are just as happy to argue
that observations made in plots should be validated using quantitative
methods, permutation tests, or cross-validation, as appropriate, and
incorporating subject matter expertise. A discussion of this topic
emerged in the comments on \citeasnoun{KS96}, and Buja's remark
\cite{BujaKS96} is particularly apt:

\begin{quotation}
In our experience, false discovery is the lesser danger when
compared to nondiscovery.  Nondiscovery is the failure to identify
meaningful structure, and it may result in false or incomplete
modeling.  In a healthy scientific enterprise, the fear of
nondiscovery should be at least as great as the fear of false
discovery.
\end{quotation}

We snooped into the \Data{Tips} data, and from a few plots we learned an
enormous amount of information about tipping: There is a scarcity of
generous tippers, the variability in tips increases extraordinarily
for smoking parties, and people tend to round their tips. These are
very different types of tipping behaviors than what we learned from
the regression model. The regression model was not compromised by what
we learned from graphics, and indeed, we have a richer and more
informative analysis. Making plots of the data is just smart.

\vspace{1em}
\noindent{\em On different sides of the pond: EDA and IDA}

\index{data analysis!initial}
Consulting statisticians, particularly in the British tradition, have
always looked at the data before formal modeling, and call it IDA
(initial data analysis) \cite{Ch95}. For example, \citeasnoun{CH90}
say: ``The first thing to do with data is to look at them.... usually
means tabulating and plotting the data in many different ways to `see
what's going on'. With the wide availability of computer packages and
graphics nowadays there is no excuse for ducking the labour of this
preliminary phase, and it may save some red faces later.''

The interactive graphics methods described in this book emerged from a
different research tradition, which started with Tukey's influential
work on EDA, focusing on discovery and finding the unexpected in
data. Like IDA, EDA has always depended heavily on graphics, even
before the term \Term{data visualization} was coined.  Our favorite
quote from John Tukey's rich legacy is that we need good pictures to
``force the unexpected upon us.''

% EDA and IDA differ: IDA focuses on data quality checking
EDA and IDA, although not entirely distinct, differ in
emphasis. Fundamental to EDA is the desire to let the data inform us,
to approach the data without pre-conceived hypotheses, so that we may
discover unexpected features. Of course, some of the unexpected
features may be errors in the data. IDA emphasizes finding these
errors by checking the quality of data prior to formal modeling. It
is much more closely tied to inference than EDA: Problems with the
data that violate the assumptions required for valid inference need to
be discovered and fixed early.

In the past, EDA and inference were sometimes seen as incompatible,
but we argue that they are not mutually exclusive.  In this book, we
present some visual methods for assessing uncertainty and performing
inference, that is, deciding whether what we see is ``really there.''

\vspace{1em}

\index{plots!presentation}
\noindent{\em Presentation:}
Once an analysis has been completed, the results must be reported,
either to clients, managers, or colleagues.  The results probably take
the form of a narrative and include quantitative summaries such as
tables, forecasts, models, and graphics.  Quite often, graphics form
the bulk of the summaries.

The graphics included in a final report may be a small fraction of the
graphics generated for exploration and diagnostics.  Indeed, they may
be different graphics altogether. They are undoubtedly carefully
prepared for their audience. The graphics generated during the
analysis are meant for the analyst only and thus need to be quickly
generated, functional but not polished. This issue is a dilemma for
authors who have much to say about exploratory graphics but need to
convey it in printed form.  The plots in this book, for example, lie
somewhere between exploratory and presentation graphics.

% Point 3:  the structure is a loose one

\vspace{2em}

%\noindent{\em Putting It Together:}
As mentioned, these broadly defined stages do not form a
rigid recipe.  Some stages overlap, and occasionally some are
skipped.  The order is often shuffled and groups of steps
reiterated.  What may look like a chaotic activity is often
improvisation on a theme loosely following the ``recipe.''

\index{data analysis!wisdom}
\index{data analysis!teaching}
%\index{Tukey, John}
Because of its improvisational nature, EDA is not easy to teach. Says
\citeasnoun{Tu65} ``Exploratory data analysis is NOT a bundle of
techniques....Confirmatory analysis is easier to teach and
compute....'' In the classroom, the teacher explains a method to the
class and demonstrates it on the single data matrix and then repeats
this process with another method.  Teaching a bundle of methods is
indeed an efficient approach to covering substantial quantities of
material, but this may be perceived by the student as a stream of
disconnected methods, applied to unrelated data fragments, and they
may not be able to apply what they have learned outside that
fragmented context for quite a while.  It takes time and experience
for students to integrate this material and to develop their own
intuition.  Students need to navigate their own way through data,
cleaning it, exploring it, choosing models; they need to make
mistakes, recover from them, and synthesize the findings into a
summary.  Learning how to perform data analysis is a process that
continues long after the student's formal training is complete.

% Point 4: what does all this have to do with visualization?


% what's missing....

\section{Interactive investigation}

\index{plots!interactive}
Thus far, all observations on the tipping data have been made
using static graphics ~---~ our purpose up to this point has been to
communicate the importance of plots in the context of data analysis.
Static plots were originally drawn by hand, and although they are now
produced by computers, they are still designed to be printed on paper,
often to be displayed or studied some time later.  However, computers
also allow us to produce plots to be viewed as they are created, and
tweaked and manipulated in real time.  This book is about such
interactive and dynamic plots, and the chapters that follow have a lot
to say about them.  Here we will say a few words about the way
interactive plots enhance the data analysis process we have just
described.

\begin{figure*}[htp]
\centerline{\includegraphics[width=4.5in]{intro/tips-brushing.pdf}}
\centerline{{\includegraphics[width=2in]{intro/tips-brushing2.pdf}}
    {\includegraphics[width=2in]{intro/tips-brushing3.pdf}}}
%\centerline{\includegraphics[width=4.5in]{intro/tips-round.pdf}}
\caption[Histogram of \Vbl{tip} linked to 2D mosaic plots of \Vbl{sex}
and \Vbl{smoker}]{Histogram of \Vbl{tip} linked to 2D mosaic plots of
\Vbl{sex} and \Vbl{smoker}.  Bars of whole and half-dollar amounts are
highlighted.  The proportion of smoking parties who round their tips
is higher than that of non-smoking parties, whereas men and women round
about equally.}
\label{tips4}
\end{figure*}

The \Data{Tips} data is simple, and most of the interesting features
can be discovered using static plots. Still, interacting with the
plots reveals more and enables the analyst to pursue follow-up
questions. For example, we could address a new question, arising from
the current analysis, such as ``Is the rounding behavior of tips
predominant in some demographic group?''  To investigate we probe the
histogram, highlight the bars corresponding to rounded tips, and
observe the pattern of highlighting in the linked plots
(Fig.~\ref{tips4}). Multiple plots are visible simultaneously, and the
highlighting action on one plot generates changes in the other plots.
The two additional plots here are \Term{mosaic plots}, \index{mosaic
plot} which are used to examine the proportions in categorical variables.
(Mosaic plots will be explained further in the next chapter; for now,
it is enough to know that the area of each rectangle is proportional
to the corresponding number of cases in the data.)  For the
highlighted subset of dining parties, the ones who rounded the tip to
the nearest dollar or half-dollar, the proportion of bill paying males
and females is roughly equal, but interestingly, the proportion of
smoking parties is higher than non-smoking parties. This might suggest
another behavioral difference between smokers and non-smokers: a
larger tendency for smokers than non-smokers to round their tips. If
we were to be skeptical about this effect we would dig deeper, making
more graphical explorations and numerical models. By pursuing this
with graphics, we would find that the proportion of smokers who round the
tip is only higher than non-smokers for full dollar amounts, and not
for half-dollar amounts.

%  Awkward sentence, but nothing better occurs to me just at the
%  moment.
%This is the approach described in this book: how interactive and
%dynamic plots are used in data analysis.

% Possible better sentence.
The remaining chapters in this book continue in this vein, describing
how interactive and dynamic plots are used in several kinds of data
analysis.

%\section{What's in this book?}

% Need a re-visit when the contents are sealed
%We have just said that visualization has a role in most stages of data
%analysis, all the way from data preparation to presentation.  In this
%book, however, we will concentrate on the use of graphics in the
%exploratory and diagnostic stages.  We concentrate on interactive
%graphics, plots that can be probed and brushed, and dynamic graphics,
%plots that can change temporally.

%The reader may note the paradoxical nature of publishing a book about
%non-static plots: Once a graphic is published, is it not by definition
%a presentation graphic?  Yes and no: As in the example of the waiter's
%tips, the graphics in this book have all been carefully selected,
%prepared, and polished, but each one is a version of a graphic that
%appeared during our analysis.

%The first chapter presents our toolbox of plot types and direct
%manipulation modes. The missing data chapter is presented next,
%because when data values are missing, that challenge must be dealt
%with as part of the data preparation stage.  The next two chapters, on
%supervised classification and cluster analysis, include both
%exploratory and diagnostic material. The final chapter introduces
%additional material, so far available only through the web site. The
%data is described at the end of the book.

