# Dimension reduction

This chapter will focus on methods for reducing dimension, and how the tour can be used to assist with the common methods such as principal component analysis (PCA), multidimensional scaling (MDS), t-stochastic neighbour embedding (t-SNE), and factor analysis.

## Principal component analysis (PCA)

This is a statistical technique used to reduce the dimensionality of a large dataset while retaining as much information as possible. PCA identifies the underlying structure of the data by finding a new set of variables, known as principal components (PCs), that are linear combinations of the original variables. The PCs can be used as a new set of variables to represent the data in a lower-dimensional space.

PCA is conducted by finding the directions where the projected data has the highest variance, that is, are most spread. Because the goal is to find a smaller number of variables that contain the similar information, the amount of variance explained by the selected PCs is examined.

PCA summarises linear relationships, and the dimension reduction is achieved by using combinations of variables that are highly correlated. However, high correlation can also occur when there are outliers, or clustering. PCA is commonly used to detect these patterns also. PCA also is not very effective when the distribution of the variables is highly skewed, so it can be helpful to transform variables before computing the PCA.

We would start by examining the data using a grand tour. The goal is to check whether there might be potential issues for PCA, such as skewness, outliers or clustering, or even non-linear dependencies.

We'll use the AFLW data as the example. This data has player statistics for all the matches in the 2021 season. We would be interested to know which variables contain similar information, and thus might be combined into single variables. We would expect that 30 statistics possibly group into a few small sets, such as offensive and defensive skills. We might also expect that some of the statistics are skewed, most players have low values and just a handful of players are stellar. It is also possible that there are some extreme values. These are interesting features, but they will distract from the main purpose of grouping the statistics. Thus the tour is used to check for potential problems with the data prior to conducting PCA.

```{r}
#| label: pca-libraries
#| eval: TRUE
#| echo: TRUE
#| message: FALSE
#| error: FALSE
#| warning: FALSE
#| code-fold: false
library(tidyverse)
library(tourr)
library(mulgar)
```

To look at all of the 30 player statistics in a grand tour use the `animate_xy()` function as follows:

```{r}
#| label: aflw-gt
#| eval: false
#| code-fold: false
animate_xy(aflw[,7:35])
```

```{r}
#| label: aflw-gif
#| eval: false
render_gif(aflw[,7:35], 
           grand_tour(), 
           display_xy(),
           gif_file="gifs/aflw_gt.gif",
           frames=500,
           loop=FALSE)
```

The gif here is the saved version of the grand tour, made using the `render_gif()` function.

![Grand tour of the AFLW player statistics](gifs/aflw_gt.gif)

The data is surprisingly good! There is a small amount of skewness, and there are no major outliers. There are no major issues that need to be addressed before PCA.

Below we have the conventional summaries of the PCA, a scree plot showing the reduction in variance to be explained when each additional PC is considered. It is also conventional to look at a table summarising the proportions of variance explained by PCs, but with 30 variables it is easier to make some decision on the number of PCs needed based on the scree plot.

```{r}
#| label: aflw-pca
aflw_pca <- prcomp(aflw[,7:35], 
               scale = TRUE, 
               retx=TRUE)

ggscree(aflw_pca)
```

From the scree plot, we see a sharp drop from one to two, two to three and then smaller drops. After four PCs the variance gradually, gradually decays. We will choose four PCs to examine more closely. This explains `r round(summary(aflw_pca)$importance[3,4]*100,1)`% of the variance.

```{r}
#| label: aflw-pcs
library(gt)
aflw_pca$rotation[,1:4] %>%
  as_tibble(rownames="Variable") %>% 
  arrange(desc(PC1), desc(PC2), desc(PC3)) %>%
  gt() %>%
  fmt_number(columns = c(PC1, PC2, PC3, PC4),
             decimals = 2)
```

When there are as many variables as this, it can be hard to digest the combinations of variables most contributing to each PC. Rearranging the table by sorting on a selected PC can help. This table has been sorted according to the PC 1 coefficients. 

PC 1 is primarily composed of `disposals`, `possessions`, `kicks`, `metres`, `uncontested`, `contested`, .... Actually almost all variables positively contribute, albeit in different amounts! It is quite common in PCA for the first PC to be a combination of all variables, although it might commonly be a closer to equal contribution, and it tells us that there is one main direction of variation in the data. For PC 1 in the AFLW data, PCA is telling us that the primary variation is through a combination of skills, and this maps to basic football playing skills, where some skills are more worthy. 

Thus the second PC might be the more interesting. PC 2 is primarily a combination of `shots`, `goals`, `marks_in50`, `accuracy`, and `behinds` contrasted against `rebounds_in50` and `intercepts`. The negative coefficients are primary offensive skills and the positive coefficients are defensive skills. This PC is reasonable measure of the offensive vs defensive skills of a player. 

We would continue to interpret each PC by examining large coefficients to help decide how many PCs are a suitable summary of the information in the data. Briefly, PC 3 is a measure of worth of the player because `time_pct` has a large coefficient, so players that are on the field longer will contribute strongly to this new variable. It also has large (an opposite) contributions from `clearances`, `tackles`, `contested_marks`. PC 4 appears to be related to aggressive play with `clangers`, `turnovers`, `bounces` and `frees_against` featuring. So all four PCs have useful information. (Note, if we had continued to examine large coefficients on PC 5 we would find that all variables already have had reasonably large coefficients on PC 1-4, which supports restricting attention to the first four.)

<!-- We might then use a PCA tour to examine the reduced dimension data, with the original variable axes. This is high-dimensional version of a 2D biplot, as shown below. -->

```{r}
#| label: aflw-plotly
#| eval: false
#| code-fold: true
library(spinifex)
library(plotly)
library(htmltools)
set.seed(20)
aflw_pct <- save_history(aflw_pca$x[,1:4], 
                    tour_path = grand_tour(),
                    max_bases = 10)
aflw_pctour <- ggtour(aflw_pct, aflw_pca$x[,1:4], 
       angle=0.05, 
       basis_label = colnames(aflw_pca$x[,1:4]),
       data_label=paste0(aflw$surname, aflw$given_name)) +
  proto_default()
animate_plotly(aflw_pctour)
save_html(animate_plotly(aflw_pctour),
          file="html/aflw_pca.html")
```

```{=html}
<iframe width="780" height="500" src="html/aflw_pca.html" title="Animation of AFLW four PCs with interactive labelling. "></iframe>
```

```{r}
#| label: aflw-pcatour
#| eval: false
#| echo: false
#| code-fold: false
# animate_pca(aflw_pca$x[,1:5], 
#             pc_coefs = aflw_pca$rotation[,1:5],
#             col = "orange",
#             pch = 16, 
#             cex = 0.5,
#             half_range=1.5)
# animate_xy(aflw_pca$x[,1:5])
```



```{=html}
<!-- Select one country. We are interested in examining the association between the scores. Because the association might be different for each country, PCA should be conducted separately for each country. All the scores are measured in the same units, so for this data we'd recommend computing PCA on the original scale, that is, the variance-covariance matrix.

Plan:

-   show data in a tour
-   compute PCs
-   explore proportion of variance
-   examine loadings
-   tour on top few PCs, using PCA tour

### Take a look at the raw data

There are 30 variables here. 30D space is huge so generally this is too many variables to watch in a tour. Here the structure is very simple so its easy to see. Trying to display the axes is a different matter, for most directions there is a small contribution from many of the 30 variables, resulting is small axis lines but over-crowded labels. -->
```
```{r}
#| eval: FALSE
#| echo: FALSE
data(pisa)
pisa_oz <- pisa %>% filter(CNT == "AUS")
```

```{r eval=FALSE}
#| eval: FALSE
#| echo: FALSE
set.seed(44)
pisa_oz_500 <- pisa_oz[sample(1:nrow(pisa_oz), 500),-1]
# Run the tour in real time
animate_xy(pisa_oz_500 , 
           axes="bottomleft", half_range = 1.5)
# Save a tour path, and select a few images to show
pisa_t1 <- interpolate(save_history(pisa_oz_500, max = 20))
pisa_tbl1 <- convert_proj_tibble(pisa_t1)
# Try animation.hook = "gifski"
```

```{r eval=FALSE}
#| eval: FALSE
#| echo: FALSE
# Show a set of 10 projections
indx <- seq(1, 101, 10)
d <- pisa_tbl1 %*% 
  dplyr::filter(frame %in% indx)
# Ok, stuck here - not filtering, and then have to work ou
# how to transform to make data and plots for a selection # of frames
```

```{r}
#| eval: FALSE
#| echo: FALSE
PISA_pca <- prcomp(pisa[,-1], scale = FALSE)
screeplot(PISA_pca, type="l")
```

```{r eval=FALSE}
#| eval: FALSE
#| echo: FALSE
options(digits=2)
summary(PISA_pca) 
```
