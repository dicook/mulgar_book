<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Interactive and dynamic graphics for high-dimensional data using R - Unsupervised learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./hierarchical-clustering.html" rel="next">
<link href="./nn.html" rel="prev">
<link href="./cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Unsupervised learning</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Interactive and dynamic graphics for high-dimensional data using R</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./dimension.html" class="sidebar-item-text sidebar-link">Dimension reduction</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pca.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Principal component analysis (PCA)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nldr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Non-linear dimension reduction</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./supervised.html" class="sidebar-item-text sidebar-link">Supervised learning</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LDA.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear discriminant analysis and MANOVA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./forests.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Trees and forests</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nn.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Neural networks and deep learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./unsupervised.html" class="sidebar-item-text sidebar-link active">Unsupervised learning</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hierarchical-clustering.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hierarchical clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./kmeans-clustering.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">k-means clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./model-based-clustering.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Model-based clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./som.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Self-organizing maps</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./unsupervised-summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Comparing methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./unsupervised-ex.html" class="sidebar-item-text sidebar-link">Exercises</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./temporal.html" class="sidebar-item-text sidebar-link">Time series</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multivariate-time-series.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Multiple time series</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Appendices</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./toolbox.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Toolbox</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Data</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-clust-bg" id="toc-sec-clust-bg" class="nav-link active" data-scroll-target="#sec-clust-bg">Background</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Unsupervised learning</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Unsupervised classification, or cluster analysis, organizes observations into similar groups. Cluster analysis is a commonly used, appealing, and conceptually intuitive statistical method. Some of its uses include market segmentation, where customers are grouped into clusters with similar attributes for targeted marketing; gene expression analysis, where genes with similar expression patterns are grouped together; and the creation of taxonomies for animals, insects, or plants. Clustering can be used as a way of reducing a massive amount of data because observations within a cluster can be summarized by its centre. Also, clustering effectively subsets the data thus simplifying analysis because observations in each cluster can be analyzed separately.</p>
<p>Organizing objects into groups is a task that comes naturally to humans, even to small children. Perhaps this is why it is an appealing method of data analysis. However, cluster analysis is more complex than it initially appears. Many people imagine that it will produce neatly separated clusters like those in the top left plot of <a href="#fig-ideal-clusters">Figure&nbsp;<span>1</span></a>, but it almost never does. Such ideal clusters are rarely encountered in real data, so we often need to modify our objective from <em>find the natural clusters in this data</em>. Instead, we need to organize the <em>cases into groups that are similar in some way</em>. Even though this may seem disappointing when compared with the ideal, it is still often an effective means of simplifying and understanding a dataset.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-ideal-clusters" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="unsupervised_files/figure-html/fig-ideal-clusters-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Different structures in data and their impact on cluster analysis. When there are well-separated groups (top left), it is simple to group similar observations. Even when there are not (top right), partitioning observations into groups may still be useful. There may be nuisance variables that do not contribute to the clustering (bottom left), and there may oddly shaped clusters (bottom right).</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>At the heart of the clustering process is the work of discovering which variables are most important for defining the groups. It is often true that we only require a subset of the variables for finding clusters, whereas another subset (called ) has no impact. In the bottom left plot of <a href="#fig-ideal-clusters">Figure&nbsp;<span>1</span></a>, it is clear that the variable plotted horizontally is important for splitting this data into two clusters, whereas the variable plotted vertically is a nuisance variable. Nuisance is an apt term for these variables, because they can radically change the interpoint distances and impair the clustering process. </p>
<p>Dynamic graphical methods help us to find and understand the cluster structure in high dimensions. With the tools in our toolbox, primarily tours, along with linked scatterplots and parallel coordinate plots, we can see clusters in high-dimensional spaces. We can detect gaps between clusters, the shape and relative positions of clusters, and the presence of nuisance variables. We can even find unusually shaped clusters, like those in the bottom right plot in <a href="#fig-ideal-clusters">Figure&nbsp;<span>1</span></a>. In simple situations we can use graphics alone to group observations into clusters, using a “spin and brush” method. In more difficult data problems, we can assess and refine numerical solutions using graphics. </p>
<p>This part of the book discusses the use of interactive and dynamic graphics in the clustering of data. <a href="#sec-clust-bg"><span>Section&nbsp;1</span></a> introduces cluster analysis, focusing on interpoint distance measures. <span class="quarto-unresolved-ref">?sec-clust-graphics</span> describes an example of a purely graphical approach to cluster analysis, the spin and brush method. In the example shown in that section, we were able to find simplifications of the data that had not been found using numerical clustering methods, and to find a variety of structures in high-dimensional space. <a href="hierarchical-clustering.html"><span>Chapter&nbsp;8</span></a> describes methods for reducing the interpoint distance matrix to an intercluster distance matrix using hierarchical algorithms, <a href="model-based-clustering.html"><span>Chapter&nbsp;10</span></a> covers model-based clustering, and <a href="som.html"><span>Chapter&nbsp;11</span></a> described clustering with self-organising maps. Each of these chapters shows how graphical tools can be used to assess the results of numerical methods. <a href="unsupervised-summary.html"><span>Chapter&nbsp;12</span></a> summarizes the chapter and revisits the data analysis strategies used in the examples. Additional references that provide good companions to the material presented in these chapters are <span class="citation" data-cites="VR02">Venables and Ripley (<a href="references.html#ref-VR02" role="doc-biblioref">2002</a>)</span>, <span class="citation" data-cites="HOML">Boehmke and Greenwell (<a href="references.html#ref-HOML" role="doc-biblioref">2019</a>)</span>, <span class="citation" data-cites="hennig">Hennig et al. (<a href="references.html#ref-hennig" role="doc-biblioref">2015</a>)</span>, <span class="citation" data-cites="giordani">Giordani, Ferraro, and Martella (<a href="references.html#ref-giordani" role="doc-biblioref">2020</a>)</span>, <span class="citation" data-cites="kassambara">Kassambara (<a href="references.html#ref-kassambara" role="doc-biblioref">2017</a>)</span>, and the CRAN Task View <span class="citation" data-cites="ctv-clustering">(<a href="references.html#ref-ctv-clustering" role="doc-biblioref">Leisch and Gruen 2023</a>)</span>. <a href="unsupervised-summary.html"><span>Chapter&nbsp;12</span></a> summarizes the chapter and revisits the data analysis strategies used in the examples.</p>
<section id="sec-clust-bg" class="level2">
<h2 class="anchored" data-anchor-id="sec-clust-bg">Background</h2>
<p>Before we can begin finding groups of cases that are similar, we need to decide on a definition of similarity. How is similarity defined? Consider a dataset with three cases <span class="math inline">\((a_1, a_2, a_3)\)</span> and four variables <span class="math inline">\((V_1, V_2, V_3, V_4)\)</span>, described in matrix format as</p>
<div class="hidden">
<p><span class="math display">\[
\require{mathtools}
\definecolor{grey}{RGB}{192, 192, 192}
\]</span></p>
</div>
<p><span class="math display">\[\begin{align*}
X = \begin{bmatrix}
&amp; {\color{grey} V_1} &amp; {\color{grey} V_2} &amp; {\color{grey} V_3} &amp; {\color{grey} V_4} \\\hline
{\color{grey} a_1} | &amp; x_{11} &amp; x_{12} &amp; x_{13} &amp; x_{14} \\
{\color{grey} a_2} | &amp; x_{21} &amp; x_{22} &amp; x_{23} &amp; x_{24} \\
{\color{grey} a_3} | &amp; x_{31} &amp; x_{32} &amp; x_{33} &amp; x_{34}    
\end{bmatrix}
=  \begin{bmatrix}
&amp; {\color{grey} V_1} &amp; {\color{grey} V_2} &amp; {\color{grey} V_3} &amp; {\color{grey} V_4} \\\hline
{\color{grey} a_1} | &amp; 7.3 &amp; 7.6 &amp; 7.7 &amp; 8.0 \\
{\color{grey} a_2} | &amp; 7.4 &amp; 7.2 &amp; 7.3 &amp; 7.2 \\
{\color{grey} a_3} | &amp; 4.1 &amp; 4.6 &amp; 4.6 &amp; 4.8
\end{bmatrix}

\end{align*}\]</span></p>
<p>which is plotted in <a href="#fig-similarity1">Figure&nbsp;<span>2</span></a>. The Euclidean distance between two cases (rows of the matrix) with <span class="math inline">\(p\)</span> elements is defined as</p>
<p><span class="math display">\[\begin{align*}
d_{\rm Euc}(a_i,a_j) &amp;=&amp; ||a_i-a_j|| %\\
% &amp;=&amp; \sqrt{(x_{i1}-x_{j1})^2+\dots + (x_{ip}-x_{jp})^2},
~~~~~~i,j=1,\dots, n,
\end{align*}\]</span></p>
<p>where <span class="math inline">\(||x_i||=\sqrt{x_{i1}^2+x_{i2}^2+\dots +x_{ip}^2}\)</span>. For example, the Euclidean distance between cases 1 and 2 in the above data, is</p>
<p><span class="math display">\[\begin{align*}
d_{\rm Euc}(a_1,a_2) &amp;= \sqrt{(7.3-7.4)^2+(7.6-7.2)^2+ (7.7-7.3)^2+(8.0-7.2)^2} \\
&amp;= 1.0
\end{align*}\]</span></p>
<p></p>
<p>For the three cases, the interpoint Euclidean distance matrix is</p>
<p><span class="math display">\[\begin{align*}
d_{\rm Euc} =
\left[ \begin{array}{ccc}
0.0  ~&amp;     &amp;   \\
1.0 ~&amp;  0.0 ~  &amp;  \\
6.3 ~&amp; 5.5 ~&amp;  0.0 ~ \\
\end{array} \right]
\begin{array}{r}
a_1 \\ a_2 \\ a_3 \\
\end{array}
\end{align*}\]</span></p>
<div id="fig-similarity1" class="quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(<span class="at">V1 =</span> <span class="fu">c</span>(<span class="fl">7.3</span>, <span class="fl">7.4</span>, <span class="fl">4.1</span>),</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>                    <span class="at">V2 =</span> <span class="fu">c</span>(<span class="fl">7.6</span>, <span class="fl">7.2</span>, <span class="fl">4.6</span>),</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">V3 =</span> <span class="fu">c</span>(<span class="fl">7.7</span>, <span class="fl">7.3</span>, <span class="fl">4.6</span>),</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">V4 =</span> <span class="fu">c</span>(<span class="fl">8.0</span>, <span class="fl">7.2</span>, <span class="fl">4.8</span>),</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">point =</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="st">"a1"</span>, <span class="st">"a2"</span>, <span class="st">"a3"</span>)))</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(colorspace)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>pscat <span class="ot">&lt;-</span> <span class="fu">ggpairs</span>(x, <span class="at">columns=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>                 <span class="at">upper=</span><span class="fu">list</span>(<span class="at">continuous=</span><span class="st">"points"</span>),</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>                 <span class="at">diag=</span><span class="fu">list</span>(<span class="at">continuous=</span><span class="st">"blankDiag"</span>),</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                 <span class="at">axisLabels=</span><span class="st">"internal"</span>,</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>                 ggplot2<span class="sc">::</span><span class="fu">aes</span>(<span class="at">colour=</span>point)) <span class="sc">+</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_colour_discrete_qualitative</span>(</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">palette =</span> <span class="st">"Dark 3"</span>) <span class="sc">+</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">aspect.ratio=</span><span class="dv">1</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>pscat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="unsupervised_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="384"></p>
</div>
</div>
<div class="cell quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>ppar <span class="ot">&lt;-</span> <span class="fu">ggparcoord</span>(x, <span class="at">columns=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">groupColumn =</span> <span class="dv">5</span>, </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">scale =</span> <span class="st">"globalminmax"</span>) <span class="sc">+</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>          <span class="fu">scale_colour_discrete_qualitative</span>(</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">palette =</span> <span class="st">"Dark 3"</span>) <span class="sc">+</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">""</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">""</span>) <span class="sc">+</span> </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>ppar</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="unsupervised_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="288"></p>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: The scatterplot matrix (left) shows that cases <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_2\)</span> have similar values. The parallel coordinate plot (right) allows a comparison of other structure, which shows the similarity in the trend of the profiles on cases <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_3\)</span>.</figcaption><p></p>
</figure>
</div>
<p>Cases <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_2\)</span> are more similar to each other than they are to case <span class="math inline">\(a_3\)</span>, because the Euclidean distance between cases <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_2\)</span> is much smaller than the distance between cases <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_3\)</span> and between cases <span class="math inline">\(a_2\)</span> and <span class="math inline">\(a_3\)</span>.</p>
<p>There are many different ways to calculate similarity. Similarity measures based on correlation distance have become common. Correlation distance is typically used where similarity of structure is more important than similarity in magnitude.</p>
<p></p>
<p>As an example, see the parallel coordinate plot of the sample data at the right of <a href="#fig-similarity1">Figure&nbsp;<span>2</span></a>. Cases <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_3\)</span> are widely separated, but their shapes are similar (low, medium, medium, high). Case <span class="math inline">\(a_2\)</span>, although overlapping with Case <span class="math inline">\(a_1\)</span>, has a very different shape (high, medium, medium, low). The correlation between two cases is defined as</p>
<p><span class="math display">\[\begin{align*}
\rho(a_i,a_j) = \frac{(a_i-c_i)'(a_j-c_j)}
{\sqrt{(a_i-c_i)'(a_i-c_i)} \sqrt{(a_j-c_j)'(a_j-c_j)}}
\label{corc}
\end{align*}\]</span></p>
<p>When <span class="math inline">\(c_i, c_j\)</span> are the sample means <span class="math inline">\(\bar{a}_i,\bar{a}_j\)</span>, then <span class="math inline">\(\rho\)</span> is the Pearson correlation coefficient. If, indeed, they are set at 0, as is commonly done, <span class="math inline">\(\rho\)</span> is a generalized correlation that describes the angle between the two data vectors. The correlation is then converted to a distance metric; one equation for doing so is as follows:</p>
<p><span class="math display">\[\begin{align*}
d_{\rm Cor}(a_i,a_j) = \sqrt{2(1-\rho(a_i,a_j))}
\end{align*}\]</span></p>
<p>The above distance metric will treat cases that are strongly negatively correlated as the most distant.</p>
<p>The interpoint distance matrix for the sample data using <span class="math inline">\(d_{\rm Cor}\)</span> and the Pearson correlation coefficient is</p>
<p><span class="math display">\[\begin{align*}
d_{\rm Cor} =
\left[ \begin{array}{rrrrrrrrr}
0.0  ~&amp;     &amp;  \\
3.6 ~ &amp; 0.0 ~ &amp;  \\
0.1 ~ &amp; 3.8 ~ &amp;  0.0 ~\\
\end{array} \right]
\begin{array}{r}
a_1 \\ a_2 \\ a_3 \\
\end{array}
\end{align*}\]</span></p>
<p>By this metric, cases <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_3\)</span> are the most similar, because the correlation distance is smaller between these two cases than the other pairs of cases. </p>
<p>Note that these interpoint distances differ dramatically from those for Euclidean distance. As a consequence, the way the cases would be clustered is also be very different. Choosing the appropriate distance measure is an important part of a cluster analysis.</p>
<p>After a distance metric has been chosen and a cluster analysis has been performed, the analyst must evaluate the results, and this is actually a difficult task. A cluster analysis does not generate <span class="math inline">\(p\)</span>-values or other numerical criteria, and the process tends to produce hypotheses rather than testing them. Even the most determined attempts to produce the “best” results using modeling and validation techniques may result in clusters that, although seemingly significant, are useless for practical purposes. As a result, cluster analysis is best thought of as an exploratory technique, and it can be quite useful despite the lack of formal validation because of its power in data simplification.</p>
<p>The context in which the data arises is the key to assessing the results. If the clusters can be characterized in a sensible manner, and they increase our knowledge of the data, then we are on the right track. To use an even more pragmatic criterion, if a company can gain an economic advantage by using a particular clustering method to carve up their customer database, then that is the method they should use.</p>
<!--
### Purely graphics {#sec-clust-graphics}

\index{brushing!persistent} \index{tour}
\index{cluster analysis!spin and brush}

A purely graphical spin and brush approach to cluster analysis works well when there are good separations between groups, even when there are marked differences in variance structures between groups or when groups have non-linear boundaries. It does not work very well when there are clusters that overlap, or when there are no distinct clusters but rather
we simply wish to partition the data. In these situations it may be better to begin with a numerical solution and to use visual tools to evaluate it, perhaps making refinements subsequently. Several examples of the spin and brush approach are documented in the literature, such as
@CBCH95 and @WWS99.


::: {.cell}

```{.r .cell-code}
library(detourr)
detour(penguins_sub, 
       tour_aes(projection = -species)) |>
       tour_path(grand_tour(2), fps = 60) |>
       show_scatter(alpha = 0.7, axes = FALSE)

# remotes::install_github("pfh/langevitour")
# remotes::install_github("plotly/plotly.R")
library(langevitour)
library(crosstalk)
shared <- SharedData$new(penguins_sub)

langevitourWidget <- langevitour(
    penguins_sub[,1:4], 
    link=shared,  
    pointSize=2,
    width=700, height=700)

library(liminal)
limn_tour(fake_trees, dim1:dim10)
```
:::



\index{datasets!\Data{PRIM7}}

This description of the spin and brush approach on \Data{PRIM7}, a
particle physics dataset, follows that in \citeasnoun{CBCH95}. The data
contains seven variables. We have no labels for the data, so when we
begin, all the points have the same color and glyph. Watch the data in a
tour for a few minutes and you will see that there are no natural
clusters, but there is clearly structure.

\index{projection pursuit!indexes}
\index{projection pursuit!indexes!holes}
\index{projection pursuit!indexes!central mass}
\index{principal component analysis}

We will use the projection pursuit guided tour to help us find that
structure. We will tour on the principal components, rather than the raw
variables, because that improves the performance of the projection
pursuit indexes. Two indexes are useful for detecting clusters: holes
and central mass. The holes index is sensitive to projections where
there are few points (i.e., a hole) in the center. The central mass
index is the opposite: It is sensitive to projections that have too many
points in the center. These indexes are explained in @chap-toolbox.

The holes index is usually the most useful for clustering, but not for
the particle physics data, because it does not have a \`\`hole'' at the
center. The central mass index is the most appropriate here. Alternate
between optimization (a guided tour) and the unguided grand tour to find
local maxima, each of which is a projection that is potentially useful
for revealing clusters. The process is illustrated in @fig-prim7-tour.

The top left plot shows the initial default projection, the second
principal component plotted against the first. The plot next to it shows
the projected data corresponding to the first local maximum found by the
guided tour. It has three strands of points stretching out from the
central clump and several outliers. We brush the points along each
strand, in red, blue, and orange, and we paint the outliers with open
circles. (See the next two plots.) We continue by choosing a new random
start for the guided tour, and then waiting until new territory in the
data is discovered. \index{brushing!persistent}

The optimization settles on a projection where there are three strands
visible, as observed in the leftmost plot in the second row. Two strands
have been previously brushed, but a new one has appeared; this is
painted yellow.

We also notice that there is another new strand hidden below the red
strand. It is barely distinguishable from the red strand in this
projection, but the two strands separate widely in other projections. It
is tricky to brush it, because it is not well separated in this
projection. We use a trick: Hide the red points, brush the new strand
green, and \`\`unhide'' the red points again (middle plot in the second
row).

Five clusters have been easily identified, and now finding new clusters
in this data is increasingly difficult. After several more alternations
between the grand tour and the guided tour, we find something new (shown
in the rightmost plot in the second row): One more strand has emerged,
and we paint it pink.

% Figure 3
\begin{figure}[htp]
\centerline{{\includegraphics[width=1.5in]{chap-clust/prim7-pp1.pdf}}
 {\includegraphics[width=1.5in]{chap-clust/prim7-pp2.pdf}}
 {\includegraphics[width=1.5in]{chap-clust/prim7-pp5.pdf}}}
\smallskip
\centerline{{\includegraphics[width=1.5in]{chap-clust/prim7-pp7.pdf}}
 {\includegraphics[width=1.5in]{chap-clust/prim7-pp8.pdf}}
 {\includegraphics[width=1.5in]{chap-clust/prim7-pp9.pdf}}}
\centerline{{\includegraphics[width=1.5in]{chap-clust/prim7-pp10.pdf}}
  {\includegraphics[width=1.5in]{chap-clust/prim7-pp11.pdf}}
  {\includegraphics[width=1.5in]{chap-clust/prim7-pp13.pdf}}}
\caption[Stages of ``spin and brush'' on \Data{PRIM7}]{Stages of spin
and brush on \Data{PRIM7}.  The high-dimensional geometry emerges as
the clusters are painted.}
\label{prim7-tour}
\end{figure}

The results at this stage are summarized by the bottom row of plots.
There is a very visible triangular component (in gray) revealed when all
of the colored points are hidden. We check the shape of this cluster by
drawing lines between outer points to contain the inner ones. Touring
after the lines are drawn helps to check how well they match the shape
of the clusters. The colored groups pair up at each vertex, and we draw
in the shape of these too --- a single line matches the structures
reasonably well.

The final step of the spin and brush clustering is to clean up this
solution, touching up the color groups by continuing to tour, and
repainting a point here and there. When we finish, we have found seven
clusters in this data that form a very strong geometric object in the
data space: a two-dimensional (2D) triangle, with two one-dimensional
(1D) strands extending in different directions from each vertex. The
lines confirm our understanding of this object's shape, because the
points stay close to the lines in all of the projections observed in a
tour.

% Figure 4
\begin{figure}
\centerline{
   \includegraphics[width=1.5in]{chap-clust/prim7-pp13-model.pdf}
   \includegraphics[width=3in]{chap-clust/prim7-par.pdf}
}
\caption[The \Data{PRIM7} model summarized]{The \Data{PRIM7} model
summarized.  The model summary {\bf (left)} was formed by adding line
segments manually.  In the parallel coordinate plot, the profiles
highlighted in dark gray correspond to the points in the 2D triangle
at the center of the model.  }
\label{prim7-model}
\end{figure}

The next stage of cluster analysis is to characterize the nature of the
clusters. To do that, we would calculate summary statistics for each
cluster, and plot the clusters (@fig-prim7-model). When we plot the
clusters of the particle physics data, we find that the 2D triangle
exists primarily in the plane defined by X3 and X5. If you do the same,
notice that the variance in measurements for the gray group is large in
variables X3 and X5, but negligible in the other variables. The linear
pieces can also be characterized by their distributions on each of the
variables. With this example, we have shown that it is possible to
uncover very unusual clusters in data without any domain knowledge.

Here are several tips about the spin and brush approach.

-   Save the dataset frequently during the exploration of a complex
    dataset, being sure to save your colors and glyphs, because it may
    take several sessions to arrive at a final clustering.\
-   Manual controls are useful for refining the optimal projection
    because another projection in the neighborhood may be more
    revealing.\
-   The holes index is usually the most successful projection pursuit
    index for finding clusters.
-   Principal component coordinates may provide a better starting point
    than the raw variables.

Finally, the spin and brush method will not work well if there are no
clear separations in the data, and the clusters are high-dimensional,
unlike the low-dimensional clusters found in this example.
-->


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-HOML" class="csl-entry" role="doc-biblioentry">
Boehmke, B., and B. M. Greenwell. 2019. <em>Hands-on Machine Learning with r (1st Ed.)</em>. Chapman; Hall/CRC. <a href="https://doi.org/10.1201/9780367816377">https://doi.org/10.1201/9780367816377</a>.
</div>
<div id="ref-giordani" class="csl-entry" role="doc-biblioentry">
Giordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. <em>An Introduction to Clustering with r</em>. Springer Singapore. <a href="https://doi.org/10.1007/978-981-13-0553-5">https://doi.org/10.1007/978-981-13-0553-5</a>.
</div>
<div id="ref-hennig" class="csl-entry" role="doc-biblioentry">
Hennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. <em>Handbook of Cluster Analysis</em>. Chapman; Hall/<span>CRC</span>. <a href="https://doi.org/10.1201/b19706">https://doi.org/10.1201/b19706</a>.
</div>
<div id="ref-kassambara" class="csl-entry" role="doc-biblioentry">
Kassambara, Alboukadel. 2017. <em>Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning</em>. STHDA.
</div>
<div id="ref-ctv-clustering" class="csl-entry" role="doc-biblioentry">
Leisch, Friedrich, and Bettina Gruen. 2023. <span>“CRAN Task View: Cluster Analysis &amp; Finite Mixture Models.”</span> https://cran.r-project.org/web/views/Cluster.html.
</div>
<div id="ref-VR02" class="csl-entry" role="doc-biblioentry">
Venables, W. N., and B. Ripley. 2002. <em>Modern <span>A</span>pplied <span>S</span>tatistics with <span>S</span></em>. New York: Springer-Verlag.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./nn.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Neural networks and deep learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./hierarchical-clustering.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hierarchical clustering</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>