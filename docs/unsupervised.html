<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Interactive and dynamic graphics for high-dimensional data using R - Unsupervised learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./hierarchical-clustering.html" rel="next">
<link href="./nn.html" rel="prev">
<link href="./cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Unsupervised learning</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Interactive and dynamic graphics for high-dimensional data using R</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./dimension.html" class="sidebar-item-text sidebar-link">Dimension reduction</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pca.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Principal component analysis (PCA)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nldr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Non-linear dimension reduction</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./supervised.html" class="sidebar-item-text sidebar-link">Supervised learning</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LDA.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear discriminant analysis and MANOVA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./forests.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Trees and forests</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nn.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Neural networks and deep learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./unsupervised.html" class="sidebar-item-text sidebar-link active">Unsupervised learning</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hierarchical-clustering.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hierarchical clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./kmeans-clustering.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">k-means clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./model-based-clustering.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Model-based clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./som.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Self-organizing maps</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./unsupervised-summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Comparing methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./unsupervised-ex.html" class="sidebar-item-text sidebar-link">Exercises</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./temporal.html" class="sidebar-item-text sidebar-link">Time series</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multivariate-time-series.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Multiple time series</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Appendices</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./toolbox.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Toolbox</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Data</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-clust-bg" id="toc-sec-clust-bg" class="nav-link active" data-scroll-target="#sec-clust-bg">Background</a></li>
  <li><a href="#sec-clust-graphics" id="toc-sec-clust-graphics" class="nav-link" data-scroll-target="#sec-clust-graphics">Purely graphics</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Unsupervised learning</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Unsupervised classification, or cluster analysis, organizes observations into similar groups. Cluster analysis is a commonly used, appealing, and conceptually intuitive statistical method. Some of its uses include market segmentation, where customers are grouped into clusters with similar attributes for targeted marketing; gene expression analysis, where genes with similar expression patterns are grouped together; and the creation of taxonomies for animals, insects, or plants. Clustering can be used as a way of reducing a massive amount of data because observations within a cluster can be summarized by its centre. Also, clustering effectively subsets the data thus simplifying analysis because observations in each cluster can be analyzed separately.</p>
<p>Organizing objects into groups is a task that comes naturally to humans, even to small children. Perhaps this is why it is an appealing method of data analysis. However, cluster analysis is more complex than it initially appears. Many people imagine that it will produce neatly separated clusters like those in the top left plot of <a href="#fig-ideal-clusters">Figure&nbsp;<span>1</span></a>, but it almost never does. Such ideal clusters are rarely encountered in real data, so we often need to modify our objective from <code>find the natural clusters in this data. Instead, we need to</code>organize the cases into groups that are similar in some way.’’ Even though this may seem disappointing when compared with the ideal, it is still often an effective means of simplifying and understanding a dataset.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-ideal-clusters" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="unsupervised_files/figure-html/fig-ideal-clusters-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Examples of clustering patterns</figcaption><p></p>
</figure>
</div>
</div>
</div>
<!--
%  Figure 1
\begin{figure}[ht]
\centerline{\includegraphics[width=4in]{chap-clust/ideal.pdf}}
\caption[Structures in data and their impact on cluster
analysis]{Different structures in data and their impact on cluster
analysis.  When there are well-separated groups {\bf (top left)}, it is
simple to group similar observations.  Even when there are not {\bf
(top right)}, grouping observations may still be useful. There may be
nuisance variables that do not contribute to the clustering {\bf
(bottom left)}, and there may oddly shaped clusters {\bf (bottom
right)}.}
\label{ideal-clusters}
\end{figure}
-->
<p>At the heart of the clustering process is the work of discovering which variables are most important for defining the groups. It is often true that we only require a subset of the variables for finding clusters, whereas another subset (called ) has no impact. In the bottom left plot of <span class="citation" data-cites="ideal-clusters">(<a href="#ref-ideal-clusters" role="doc-biblioref"><strong>ideal-clusters?</strong></a>)</span>, it is clear that the variable plotted horizontally is important for splitting this data into two clusters, whereas the variable plotted vertically is a nuisance variable. Nuisance is an apt term for these variables, because they can radically change the interpoint distances and impair the clustering process. </p>
<p>Dynamic graphical methods help us to find and understand the cluster structure in high dimensions. With the tools in our toolbox, primarily tours, along with linked scatterplots and parallel coordinate plots, we can see clusters in high-dimensional spaces. We can detect gaps between clusters, the shape and relative positions of clusters, and the presence of nuisance variables. We can even find unusually shaped clusters, like those in the bottom right plot in <a href="#fig-ideal-clusters">Figure&nbsp;<span>1</span></a>. In simple situations we can use graphics alone to group observations into clusters, using a ``spin and brush’’ method. In more difficult data problems, we can assess and refine numerical solutions using graphics. </p>
<p>This chapter discusses the use of interactive and dynamic graphics in the clustering of data. Section <span class="math inline">\(\ref{clust-bg}\)</span> introduces cluster analysis, focusing on interpoint distance measures. Section <span class="math inline">\(\ref{clust-graphics}\)</span> describes an example of a purely graphical approach to cluster analysis, the spin and brush method. In the example shown in that section, we were able to find simplifications of the data that had not been found using numerical clustering methods, and to find a variety of structures in high-dimensional space. Section <span class="math inline">\(\ref{clust-num}\)</span> describes methods for {reducing} the interpoint distance matrix to an intercluster distance matrix using hierarchical algorithms and model-based clustering, and shows how graphical tools are used to assess the results of numerical methods. Section <span class="math inline">\(\ref{clust-recap}\)</span> summarizes the chapter and revisits the data analysis strategies used in the examples. A good companion to the material presented in this chapter is , which provides data and code for practical examples of cluster analysis using R. Section <span class="math inline">\(\ref{clust-recap}\)</span> summarizes the chapter and revisits the data analysis strategies used in the examples.</p>
<section id="sec-clust-bg" class="level3">
<h3 class="anchored" data-anchor-id="sec-clust-bg">Background</h3>
<p>Before we can begin finding groups of cases that are similar, we need to decide on a definition of similarity. How is similarity defined? Consider a dataset with three cases and four variables, described in matrix format as</p>
<p><span class="math display">\[\begin{eqnarray*}
\blX = \left[ \begin{array}{c}
     \blX_1 \\ \blX_2 \\ \blX_3 \\
%\blX_4 \\
%     \blX_5 \\ \blX_6 \\ \blX_7 \\ \blX_8 \\ \blX_9
     \end{array} \right] =
     \left[ \begin{array}{rrrr}
       7.3 &amp; 7.6 &amp; 7.7 &amp; 8.0 \\
       7.4 &amp; 7.2 &amp; 7.3 &amp; 7.2 \\
       4.1 &amp; 4.6 &amp; 4.6 &amp; 4.8 \\
     \end{array} \right]
\end{eqnarray*}\]</span></p>
<p>which is plotted in <span class="citation" data-cites="similarity1">(<a href="#ref-similarity1" role="doc-biblioref"><strong>similarity1?</strong></a>)</span>. The Euclidean distance between two cases (rows of the matrix) is defined as</p>
<p><span class="math display">\[\begin{eqnarray*}
d_{\rm Euc}(\blX_i,\blX_j) &amp;=&amp; ||\blX_i-\blX_j|| %\\
% &amp;=&amp; \sqrt{(X_{i1}-X_{j1})^2+\dots + (X_{ip}-X_{jp})^2},
~~~~~~i,j=1,\dots, n,
\end{eqnarray*}\]</span></p>
<p>where <span class="math inline">\(||\blX_i||=\sqrt{X_{i1}^2+X_{i2}^2+\dots +X_{ip}^2}\)</span>. For example, the Euclidean distance between cases 1 and 2 in the above data, is</p>
<p>[ = 1.0. ]</p>
<p></p>
<p>For the three cases, the interpoint Euclidean distance matrix is</p>
<p><span class="math display">\[\begin{eqnarray*}
d_{\rm Euc} =
\left[ \begin{array}{ccc}
0.0  ~&amp;     &amp;   \\
1.0 ~&amp;  0.0 ~  &amp;  \\
6.3 ~&amp; 5.5 ~&amp;  0.0 ~ \\
\end{array} \right]
\begin{array}{r}
\blX_1 \\ \blX_2 \\ \blX_3 \\
\end{array}
\end{eqnarray*}\]</span></p>
<!--
% Figure 2
\begin{figure}[htp]
\centerline{{\includegraphics[width=3in]{chap-clust/similarity1.pdf}}
 {\includegraphics[width=2in]{chap-clust/similarity2.pdf}}}
\caption[Clustering the example data]{Clustering the example data.
The scatterplot matrix {\bf (left)} shows that cases 1 and 2 have
similar values.  The parallel coordinate plot {\bf (right)} allows a
comparison of other structure, which shows the similarity in the profiles
on cases 1 and 3.  }
\label{similarity1}
\end{figure}
-->
<p>Cases 1 and 2 are more similar to each other than they are to case 3, because the Euclidean distance between cases 1 and 2 is much smaller than the distance between cases 1 and 3 and between cases 2 and 3.</p>
<p>There are many different ways to calculate similarity. In recent years similarity measures based on correlation distance have become common. Correlation distance is typically used where similarity of structure is more important than similarity in magnitude.</p>
<p></p>
<p>As an example, see the parallel coordinate plot of the sample data at the right of <span class="citation" data-cites="similarity1">(<a href="#ref-similarity1" role="doc-biblioref"><strong>similarity1?</strong></a>)</span>. Cases 1 and 3 are widely separated, but their shapes are similar (low, medium, medium, high). Case 2, although overlapping with Case 1, has a very different shape (high, medium, medium, low). The correlation between two cases is defined as</p>
<p><span class="math display">\[\begin{eqnarray}
\rho(\blX_i,\blX_j) = \frac{(\blX_i-c_i)'(\blX_j-c_j)}
{\sqrt{(\blX_i-c_i)'(\blX_i-c_i)} \sqrt{(\blX_j-c_j)'(\blX_j-c_j)}}
\label{corc}
\end{eqnarray}\]</span></p>
<p>When <span class="math inline">\(c_i, c_j\)</span> are the sample means <span class="math inline">\(\bar{\blX}_i,\bar{\blX}_j\)</span>, then <span class="math inline">\(\rho\)</span> is the Pearson correlation coefficient. If, indeed, they are set at 0, as is commonly done, <span class="math inline">\(\rho\)</span> is a generalized correlation that describes the angle between the two data vectors. The correlation is then converted to a distance metric; one equation for doing so is as follows:</p>
<p><span class="math display">\[\begin{eqnarray*}
d_{\rm Cor}(\blX_i,\blX_j) = \sqrt{2(1-\rho(\blX_i,\blX_j))}
\end{eqnarray*}\]</span></p>
<p>The above distance metric will treat cases that are strongly negatively correlated as the most distant.</p>
<p>The interpoint distance matrix for the sample data using <span class="math inline">\(d_{\rm Cor}\)</span> and the Pearson correlation coefficient is</p>
<p><span class="math display">\[\begin{eqnarray*}
d_{\rm Cor} =
\left[ \begin{array}{rrrrrrrrr}
0.0  ~&amp;     &amp;  \\
3.6 ~ &amp; 0.0 ~ &amp;  \\
0.1 ~ &amp; 3.8 ~ &amp;  0.0 ~\\
\end{array} \right]
\end{eqnarray*}\]</span> % dist4 in R code</p>
<p>By this metric, cases 1 and 3 are the most similar, because the correlation distance is smaller between these two cases than the other pairs of cases. </p>
<p>Note that these interpoint distances differ dramatically from those for Euclidean distance. As a consequence, the way the cases would be clustered is also be very different. Choosing the appropriate distance measure is an important part of a cluster analysis.</p>
<p>After a distance metric has been chosen and a cluster analysis has been performed, the analyst must evaluate the results, and this is actually a difficult task. A cluster analysis does not generate <span class="math inline">\(p\)</span>-values or other numerical criteria, and the process tends to produce hypotheses rather than testing them. Even the most determined attempts to produce the ``best’’ results using modeling and validation techniques may result in clusters that, although seemingly significant, are useless for practical purposes. As a result, cluster analysis is best thought of as an exploratory technique, and it can be quite useful despite the lack of formal validation because of its power in data simplification.</p>
<p>The context in which the data arises is the key to assessing the results. If the clusters can be characterized in a sensible manner, and they increase our knowledge of the data, then we are on the right track. To use an even more pragmatic criterion, if a company can gain an economic advantage by using a particular clustering method to carve up their customer database, then that is the method they should use.</p>
</section>
<section id="sec-clust-graphics" class="level3">
<h3 class="anchored" data-anchor-id="sec-clust-graphics">Purely graphics</h3>
<p> </p>
<p>A purely graphical spin and brush approach to cluster analysis works well when there are good separations between groups, even when there are marked differences in variance structures between groups or when groups have non-linear boundaries. It does not work very well when there are clusters that overlap, or when there are no distinct clusters but rather we simply wish to partition the data. In these situations it may be better to begin with a numerical solution and to use visual tools to evaluate it, perhaps making refinements subsequently. Several examples of the spin and brush approach are documented in the literature, such as <span class="citation" data-cites="CBCH95">(<a href="#ref-CBCH95" role="doc-biblioref"><strong>CBCH95?</strong></a>)</span> and <span class="citation" data-cites="WWS99">(<a href="#ref-WWS99" role="doc-biblioref"><strong>WWS99?</strong></a>)</span>.</p>
<p></p>
<p>This description of the spin and brush approach on , a particle physics dataset, follows that in . The data contains seven variables. We have no labels for the data, so when we begin, all the points have the same color and glyph. Watch the data in a tour for a few minutes and you will see that there are no natural clusters, but there is clearly structure.</p>
<p> </p>
<p>We will use the projection pursuit guided tour to help us find that structure. We will tour on the principal components, rather than the raw variables, because that improves the performance of the projection pursuit indexes. Two indexes are useful for detecting clusters: holes and central mass. The holes index is sensitive to projections where there are few points (i.e., a hole) in the center. The central mass index is the opposite: It is sensitive to projections that have too many points in the center. These indexes are explained in <span class="citation" data-cites="chap-toolbox">(<a href="#ref-chap-toolbox" role="doc-biblioref"><strong>chap-toolbox?</strong></a>)</span>.</p>
<p>The holes index is usually the most useful for clustering, but not for the particle physics data, because it does not have a ``hole’’ at the center. The central mass index is the most appropriate here. Alternate between optimization (a guided tour) and the unguided grand tour to find local maxima, each of which is a projection that is potentially useful for revealing clusters. The process is illustrated in <span class="quarto-unresolved-ref">?fig-prim7-tour</span>.</p>
<p>The top left plot shows the initial default projection, the second principal component plotted against the first. The plot next to it shows the projected data corresponding to the first local maximum found by the guided tour. It has three strands of points stretching out from the central clump and several outliers. We brush the points along each strand, in red, blue, and orange, and we paint the outliers with open circles. (See the next two plots.) We continue by choosing a new random start for the guided tour, and then waiting until new territory in the data is discovered. </p>
<p>The optimization settles on a projection where there are three strands visible, as observed in the leftmost plot in the second row. Two strands have been previously brushed, but a new one has appeared; this is painted yellow.</p>
<p>We also notice that there is another new strand hidden below the red strand. It is barely distinguishable from the red strand in this projection, but the two strands separate widely in other projections. It is tricky to brush it, because it is not well separated in this projection. We use a trick: Hide the red points, brush the new strand green, and ``unhide’’ the red points again (middle plot in the second row).</p>
<p>Five clusters have been easily identified, and now finding new clusters in this data is increasingly difficult. After several more alternations between the grand tour and the guided tour, we find something new (shown in the rightmost plot in the second row): One more strand has emerged, and we paint it pink.</p>
<!-- % Figure 3
\begin{figure}[htp]
\centerline{{\includegraphics[width=1.5in]{chap-clust/prim7-pp1.pdf}}
 {\includegraphics[width=1.5in]{chap-clust/prim7-pp2.pdf}}
 {\includegraphics[width=1.5in]{chap-clust/prim7-pp5.pdf}}}
\smallskip
\centerline{{\includegraphics[width=1.5in]{chap-clust/prim7-pp7.pdf}}
 {\includegraphics[width=1.5in]{chap-clust/prim7-pp8.pdf}}
 {\includegraphics[width=1.5in]{chap-clust/prim7-pp9.pdf}}}
\centerline{{\includegraphics[width=1.5in]{chap-clust/prim7-pp10.pdf}}
  {\includegraphics[width=1.5in]{chap-clust/prim7-pp11.pdf}}
  {\includegraphics[width=1.5in]{chap-clust/prim7-pp13.pdf}}}
\caption[Stages of ``spin and brush'' on \Data{PRIM7}]{Stages of spin
and brush on \Data{PRIM7}.  The high-dimensional geometry emerges as
the clusters are painted.}
\label{prim7-tour}
\end{figure}
-->
<p>The results at this stage are summarized by the bottom row of plots. There is a very visible triangular component (in gray) revealed when all of the colored points are hidden. We check the shape of this cluster by drawing lines between outer points to contain the inner ones. Touring after the lines are drawn helps to check how well they match the shape of the clusters. The colored groups pair up at each vertex, and we draw in the shape of these too — a single line matches the structures reasonably well.</p>
<p>The final step of the spin and brush clustering is to clean up this solution, touching up the color groups by continuing to tour, and repainting a point here and there. When we finish, we have found seven clusters in this data that form a very strong geometric object in the data space: a two-dimensional (2D) triangle, with two one-dimensional (1D) strands extending in different directions from each vertex. The lines confirm our understanding of this object’s shape, because the points stay close to the lines in all of the projections observed in a tour.</p>
<!-- % Figure 4
\begin{figure}
\centerline{
   \includegraphics[width=1.5in]{chap-clust/prim7-pp13-model.pdf}
   \includegraphics[width=3in]{chap-clust/prim7-par.pdf}
}
\caption[The \Data{PRIM7} model summarized]{The \Data{PRIM7} model
summarized.  The model summary {\bf (left)} was formed by adding line
segments manually.  In the parallel coordinate plot, the profiles
highlighted in dark gray correspond to the points in the 2D triangle
at the center of the model.  }
\label{prim7-model}
\end{figure}
-->
<p>The next stage of cluster analysis is to characterize the nature of the clusters. To do that, we would calculate summary statistics for each cluster, and plot the clusters (<span class="quarto-unresolved-ref">?fig-prim7-model</span>). When we plot the clusters of the particle physics data, we find that the 2D triangle exists primarily in the plane defined by X3 and X5. If you do the same, notice that the variance in measurements for the gray group is large in variables X3 and X5, but negligible in the other variables. The linear pieces can also be characterized by their distributions on each of the variables. With this example, we have shown that it is possible to uncover very unusual clusters in data without any domain knowledge.</p>
<p>Here are several tips about the spin and brush approach.</p>
<ul>
<li>Save the dataset frequently during the exploration of a complex dataset, being sure to save your colors and glyphs, because it may take several sessions to arrive at a final clustering.<br>
</li>
<li>Manual controls are useful for refining the optimal projection because another projection in the neighborhood may be more revealing.<br>
</li>
<li>The holes index is usually the most successful projection pursuit index for finding clusters.</li>
<li>Principal component coordinates may provide a better starting point than the raw variables.</li>
</ul>
<p>Finally, the spin and brush method will not work well if there are no clear separations in the data, and the clusters are high-dimensional, unlike the low-dimensional clusters found in this example.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./nn.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Neural networks and deep learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./hierarchical-clustering.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hierarchical clustering</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>