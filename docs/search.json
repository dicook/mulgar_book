[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "",
    "text": "Preface\nIt is important to visualise your data because you might discover things that you could never have anticipated. Although there are many resources available for data visualisation, there are few comprehensive resources on high-dimensional data visualisation. High-dimensional (or multivariate) data arises when many different things are measured for each observation. While we can learn many things from plotting with 1D and 2D or 3D methods there are likely more structures hidden in the higher dimensions. This book provides guidance on visualising high-dimensional data and models using linear projections, with R.\nHigh-dimensional data spaces are fascinating places. You may think that there’s a lot of ways to plot one or two variables, and a lot of types of patterns that can be found. You might use a density plot and see skewness or a dot plot to find outliers. A scatterplot of two variables might reveal a non-linear relationship or a barrier beyond which no observations exist. We don’t as yet have so many different choices of plot types for high-dimensions, but these types of patterns are also what we seek in scatterplots of high-dimensional data. The additional dimensions can clarify these patterns, that clusters are likely to be more distinct. Observations that did not appear to be very different can be seen to be lonely anomalies in high-dimensions, that no other observations have quite the same combination of values.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#whats-in-this-book",
    "href": "index.html#whats-in-this-book",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "What’s in this book?",
    "text": "What’s in this book?\nThe book can be divided into these parts:\n\n\nIntroduction: Here we introduce you to high-dimensional spaces, how they can be visualised, and notation that is useful for describing methods in later chapters.\n\n\nDimension reduction: This part covers linear and non-linear dimension reduction. It includes ways to help decide on the number of dimensions needed to summarise the high dimensional data, whether linear dimension reduction is appropriate, detecting problems that might affect the dimension reduction, and examining how well or badly a non-linear dimension reduction is representing the data.\n\nCluster analysis: This part described methods for finding groups in data. Although it includes an explanation of a purely graphical approach, it is mostly on using graphics in association with numerical clustering algorithms. There are explanations of assessing the suitability of different numerical techniques for extracting clusters, based on the data shapes, evaluating the clustering result, and showing the solutions in high dimensions.\n\nClassification: This part describes methods for exploring known groups in the data. You’ll learn how to check model assumptions, to help decide if a method is suited to the data, examine classification boundaries and explore where errors arise. \n\n\nIn each of these parts an emphasis is also showing your model with your data in the high dimensional space.\nOur hopes are that you will come away with understanding the importance of plotting your high dimensional data as a regular step in your statistical or machine learning analyses. There are many examples of what you might miss if you don’t plot the data. Effective use of graphics goes hand-in-hand with analytical techniques. With high dimensions visualisation is a challenge but it is fascinating, and leads to many surprising moments.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#audience",
    "href": "index.html#audience",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "Audience",
    "text": "Audience\nHigh-dimensional data arises in many fields such as biology, social sciences, finance, and more. Anyone who is doing exploratory data analysis and model fitting for more than two variables will benefit from learning how to effectively visualise high-dimensions. This book will be useful for students and teachers of multivariate data analysis and machine learning, and researchers, data analysts, and industry professionals who work in these areas.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#how-to-use-the-book",
    "href": "index.html#how-to-use-the-book",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "How to use the book?",
    "text": "How to use the book?\nThe book provides explanations and plots accompanied by R code. We would hope that you run the code to explore the examples as you read the explanations. The chapters are organised by types of analysis and focus on how to use the high-dimensional visualisation to complement the commonly used analytical methods. An overview of the primary high-dimensional visualisation methods discussed in the book and how to get started is provided in the toolbox chapter in the Appendix.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#what-should-i-know-before-reading-this-book",
    "href": "index.html#what-should-i-know-before-reading-this-book",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "What should I know before reading this book?",
    "text": "What should I know before reading this book?\nThe examples assume that you already use R, and have a working knowledge of base R and tidyverse way of thinking about data analysis. It also assumes that you have some knowledge of statistical methods, and some experience with machine learning methods.\nIf you feel like you need build up your skills in these areas in preparation for working through this book, these are our recommended resources:\n\n\nR for Data Science by Wickham and Grolemund for learning about data wrangling and visualisation.\n\nIntroduction to Modern Statistics by Çetinkaya-Rundel and Hardin to learn about introductory statistics.\n\nHands-On Machine Learning with R by Boehmke and Greenwell to learn about machine learning.\n\nTidy Modeling with R by Kuhn and Silge to learn how to tidily do machine learning.\n\nWe will assume you know how to plot your data and models in 2D. Our material starts from 2D and beyond.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#setting-up-your-workflow",
    "href": "index.html#setting-up-your-workflow",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "Setting up your workflow",
    "text": "Setting up your workflow\nTo get started set up your computer with the current versions of R and ideally also with Rstudio Desktop.\nThe examples are created using the tourr and detourr packages. In addition, we have made an R package to share most of the data and functions used in this book, called mulgar.12 Ideally the methods described are not entirely bound by the current available packages, and still applicable as new technology arises.\n\ninstall.packages(\"tourr\", dependencies=TRUE)\ninstall.packages(\"detourr\", dependencies=TRUE)\ninstall.packages(\"mulgar\", dependencies=TRUE)\n\nand development versions can be installed from the GitHub repositories for the packages. To get a copy of the code and additional data used and an RStudio project to get started, you can download with this code:\n\nu &lt;- \"https://dicook.github.io/mulgar_book/code_and_data.zip\"\nusethis::use_zip(url=u)\n\nYou will be able to click on the mulgar_book.Rproj to get started with the code.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#suggestion-feedback-or-error",
    "href": "index.html#suggestion-feedback-or-error",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "Suggestion, feedback or error?",
    "text": "Suggestion, feedback or error?\nWe welcome suggestions, feedback or details of errors. You can report them as an issue at the Github repo for this book.\nPlease make a small reproducible example and report the error encountered. Reproducible examples have these components:\n\na small amount of data\nsmall amount of code that generates the error\ncopy of the error message that was generated",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#citing",
    "href": "index.html#citing",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "Citing",
    "text": "Citing\nPlease use this text and bibtex for citing the book:\nCook D., Laa, U. (2024) Interactively exploringhigh-dimensional data and models in R, https://dicook.github.io/mulgar_book/, accessed on YYYY/MM/DD. \n\n@misc{cook-laa,\n  title = {Interactively exploringhigh-dimensional data and models in R},\n  author = {Dianne Cook and Ursula Laa},\n  year = 2024,\n  url = {https://dicook.github.io/mulgar_book/},\n  note = {accessed  on YYYY/MM/DD}\n}",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "License",
    "text": "License\nThe online version of this book is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan den Boogaart, K. G., Tolosana-Delgado, R., & Bren, M. (2024). Compositions: Compositional data analysis. http://www.stat.boogaart.de/compositions/\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "",
    "text": "The mulga is an iconic landscape in Australia. It is a woodland dominated by the mulga tree (Acacia aneura). As you travel through mulga the trees look very regular, sometimes like a stand of lollipops, which is apparently due to close neighbours being clones! The wood is especially hardy, durable and resistant to pests. The climate is semi-arid and it can be found across Australia, Queensland, New South Wales, South Australia and Western Australia. This landscape is host to numerous species: red kangaroos, spinifex hopping mice, mulga parrots, dunnarts, thorny devils, bearded dragons, and pests like feral goats. Here mulgar is an acronym for MULtivariate Graphical Analysis with R.↩︎\nPhoto of mulga tree taken by L. G. Cook.↩︎",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "1-intro.html",
    "href": "1-intro.html",
    "title": "1  Picturing high dimensions",
    "section": "",
    "text": "1.1 Getting familiar with tours\nHigh-dimensional data means that we have a large number of features or variables, which can be considered as dimensions in a mathematical space. The variables can be different types, such as categorical or temporal, but the handling of these variables involves different techniques. Here we focus on primarily numeric variables, which might be considered as belonging to a Euclidean space where each observation is a vector and the distance between observations can be described by a distance metric.\nModels that operate on high-dimensional data can be thought of as decomposing observations into two sets of values, fitted values and residuals from the fit. The fitted values capture the systematic or predictable variation between variables, and can be considered a sharpened view of the data, to see through the noise in the data. The residuals capture this noise, and represent random variation. When using models for high-dimensional data, such as unsupervised or supervised classification, or dimension reduction, it is important to use visualisation to assess how well the model fits the data. If it fits well, picturing the model fit might be a clearer view of the relationships between variables.\nOne approach to visualise numeric high dimensional data and models is by using linear projections, as done in a tour (Asimov, 1985; Buja & Asimov, 1986; Cook et al., 2006; S. Lee et al., 2022). You can think of projections of high-dimensional data like shadows (Figure 1.1). Unlike shadow puppets, though the object stays fixed, and with multiple projections we can obtain a view of the object from all sides. A tour will pick directions to look at by selecting a set of linear projections. The views are interpolated to move from one linear projection to the next, this is displayed as an animation.\nFigure 1.2 illustrates a tour for 2D data and 1D projections. The (grand) tour will generate all possible 1D projections of the data, and display with a univariate plot like a histogram or density plot. For this data, the simple_clusters data, depending on the projection, the distribution might be clustered into two groups (bimodal), or there might be no clusters (unimodal). In this example, all projections are generated by rotating a line around the centre of the plot. Clustering can be seen in many of the projections, with the strongest being when the contribution of both variables is equal, and the projection is (0.707,  0.707) or (-0.707, -0.707). (If you are curious about the number 0.707, the Chapter 2 provides the explanation.)\nFigure 1.3 illustrates a tour for 3D data using 2D projections. The data are points on the surface of a donut shape. By showing the projections using a scatterplot the donut looks transparent and we can see through the data. The donut shape can be inferred from watching many 2D projections but some are more revealing that others. The projection shown in (b) is where the hole in the donut is clearly visible.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#getting-familiar-with-tours",
    "href": "1-intro.html#getting-familiar-with-tours",
    "title": "1  Picturing high dimensions",
    "section": "",
    "text": "(a) 2D data\n\n\n\n\n\n\n\n\n\n\n(b) 1D grand tour of the 2D data\n\n\n\n\n\n\nFigure 1.2: How a tour can be used to explore high-dimensional data illustrated using (a) 2D data with two clusters and (b) a tour of 1D projections shown as a density plot. Imagine spinning a line around the centre of the data plot, with points projected orthogonally onto the line. With this data, when the line is at x1=x2 (0.707, 0.707) or (-0.707, -0.707) the clustering is the strongest. When it is at x1=-x2  (0.707, -0.707) there is no clustering.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) 2D tour of 3D data\n\n\n\n\n\n\n\n\n\n\n(b) A projection revealing the hole\n\n\n\n\n\n\n\nFigure 1.3: How a tour can be used to explore high-dimensional data illustrated by showing a sequence of random 2D projections of 3D data (a). The data has a donut shape with the hole revealed in a single 2D projection (b). Data usually arrives with a given number of observations, and when we plot it like this using a scatterplot, it is like shadows of a transparent object.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#whats-different-about-space-beyond-2d",
    "href": "1-intro.html#whats-different-about-space-beyond-2d",
    "title": "1  Picturing high dimensions",
    "section": "\n1.3 What’s different about space beyond 2D?",
    "text": "1.3 What’s different about space beyond 2D?\nThe term “high-dimensional” in this book refers to the dimensionality of the Euclidean space. Figure 1.4 shows a way to imagine this. It shows a sequence of cube wireframes, ranging from one-dimensional (1D) through to five-dimensional (5D), where beyond 2D is a linear projection of the cube. As the dimension increases, a new orthogonal axis is added. For cubes, this is achieved by doubling the cube: a 2D cube consists of two 1D cubes, a 3D cube consists of two 2D cubes, and so forth. This is a great way to think about the space being examined by the visual methods, and also all of the machine learning methods mentioned, in this book.\n\n\n\n\n\n\n\n\nFigure 1.4: Space can be considered to be a high-dimensional cube. Here we have pictured a sequence of increasing dimension cubes, from 1D to 5D, as wireframes, it can be seen that as the dimension increase by one, the cube doubles.\n\n\n\n\nInterestingly, the struggle with imagining high-dimensions this way is described in a novel titled “Flatland: A Romance of Many Dimensions” published in 1884 (Abbott, 1884) 1. Yes, more than 100 years ago! This is a story about characters living in a 2D world, being visited by an alien 3D character. It also is a social satire, serving the reader strong messages about gender inequity, although this provides the means to explain more intricacies in perceiving dimensions. There have been several movies made based on the book in recent decades (e.g. Martin (1965), D. Johnson & Travis (2007)). Although purchasing the movies may be prohibitive, watching the trailers available for free online is sufficient to gain enough geometric intuition on the nature of understanding high-dimensional spaces while living in a low-dimensional world.\nWhen we look at high-dimensional spaces from a low-dimensional space, we meet the “curse of dimensionality”, a term introduced by Bellman (1961) to express the difficulty of doing optimization in high dimensions because of the exponential growth in space as dimension increases. A way to imagine this is look at the cubes in Figure 1.4: As you go from 1D to 2D, 2D to 3D, the space expands a lot, and imagine how vast space might get as more dimensions are added2. The volume of the space grows exponentially with dimension, which makes it infeasible to sample enough points – any sample will be less densely covering the space as dimension increases. The effect is that most points will be far from the sample mean, on the edge of the sample space.\n\nFor visualisation, the curse manifests in an opposite manner. Projecting from high to low dimensions creates a crowding or piling of points near the center of the distribution. This was noted by Diaconis & Freedman (1984a). Figure 1.5 illustrates this phenomenon, using samples that are uniformly distributed in \\(p\\)-dimensional spheres. As dimension increases, the points crowd the centre, even with as few as ten dimensions. This is something that we may need to correct for when exploring high dimensions with low-dimensional projections.\n\n\n\n\n\n\n\n\nFigure 1.5: Illustration of data crowding in the low-dimensional projection as dimension increases, here from 3, 10, 100. The samples are generated from a uniform distribution in \\(p\\)-dimensional spheres. Colour shows the number of points in each hexagon bin (pink is large, navy is small). As dimension increases the points concentrate near the centre.\n\n\n\n\nFigure 1.6 shows 2D tours of two different 5D data sets. One has clusters (a) and the other has two outliers and a plane (b). Can you see these? One difference in the viewing of data with more than three dimensions with 2D projections is that the points seem to shrink towards the centre, and then expand out again. This the effect of dimensionality, with different variance or spread in some directions.\n\n\n\n\n\n\n\n\n\n(a) Clusters\n\n\n\n\n\n\n\n\n\n(b) Outliers\n\n\n\n\n\n\nFigure 1.6: Two 5D datasets shown as tours of 2D projections. Can you see clusters of points in (a) and two outliers with a plane in (b)?",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#what-can-you-learn",
    "href": "1-intro.html#what-can-you-learn",
    "title": "1  Picturing high dimensions",
    "section": "\n1.4 What can you learn?",
    "text": "1.4 What can you learn?\nThere are two ways of detecting structure in tours:\n\npatterns in a single low-dimensional projection\nmovement patterns\n\nwith the latter being especially useful when displaying the projected data as a scatterplot. Figure 1.7 shows examples of patterns we typically look for when making a scatterplot of data. These include clustering, linear and non-linear association, outliers, barriers where there is a sharp edge beyond which no observations are seen. Not shown, but it also might be possible to observe multiple modes, or density of observations, L-shapes, discreteness or uneven spread of points. The tour is especially useful if these patterns are only visible in combinations of variables.\n\n\n\n\n\n\n\nFigure 1.7: Example structures that might be visible in a 2D projection that imply presence of structure in high dimensions. These include clusters, linear and non-linear association, outliers and barriers.\n\n\n\n\nFigure 1.8 illustrates how movement patterns of points when using scatterplots to display 2D projections indicate clustering (a, b) and outliers (c, d).\n\n\n\n\n\n\n\n\n\n(a) Clustering\n\n\n\n\n\n\n\n\n\n(b) Outliers\n\n\n\n\n\n\nFigure 1.8: The movement of points give further clues about the structure of the data in high-dimensions. In the data with clustering, often we can see a group of points moving differently from the others. Because there are three clusters, you should see three distinct movement patterns. It is similar with outliers, except these may be individual points moving alone, and different from all others. This can be seen in the static plot, one point (top left) has a movement pattern upwards whereas most of the other observations near it are moving down towards the right.\n\n\nThis type of visualisation is useful for many activities in dealing with high-dimensional data, including:\n\nexploring high-dimensional data.\ndetecting if the data lives in a lower dimensional space than the number of variables.\nchecking assumptions required for multivariate models to be applicable.\ncheck for potential problems in modeling such as multicollinearity among predictors.\nchecking assumptions required for probabilities calculated for statistical hypothesis testing to be valid.\ndiagnosing the fit of multivariate models.\n\n\nYou use a tour when analysing multivariate data so that you can see what exists in the data and what your models are fitting, in the same way that you walk down the street with your eyes open to avoid being hit by a bus or to discover a delightful shop.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#a-little-history",
    "href": "1-intro.html#a-little-history",
    "title": "1  Picturing high dimensions",
    "section": "\n1.5 A little history",
    "text": "1.5 A little history\nViewing high-dimensional data based on low-dimensional projections can probably be traced back to the early work on principal component analysis by Pearson (1901) and Hotelling (1933), which was extended to known classes as part of discriminant analysis by Fisher (1936a).\nWith computer graphics, the capability of animating plots to show more than a single best projection became possible. The video library (ASA Statistical Graphics Section, 2023) is the best place to experience the earliest work. Kruskal’s 1962 animation of multidimensional scaling showed the process of finding a good 2D representation of high dimensional data, although the views are not projections. Chang’s 1970 video shows her rotating a high dimensional point cloud along coordinate axes to find a special projection where all the numbers align. The classic video that must be watched is PRIM9 (Fisherkeller et al., 1973) where a variety of interactive and dynamic tools are used together to explore high dimensional physics data, documented in Fisherkeller et al. (1974).\nThe methods in this book primarily emerge from Asimov (1985)’s grand tour method. The algorithm provided the first smooth and continuous sequence of low dimensional projections, and guaranteed that all possible low dimensional projections were likely to be shown. The algorithm was refined in Buja & Asimov (1986) (and documented in detail in Buja et al. (2005)) to make it efficiently show all possible projections. Since then there have been numerous varieties of tour algorithms developed to focus on specific tasks in exploring high dimensional data, and these are documented in S. Lee et al. (2022).\nThis book is an evolution from Cook & Swayne (2007). One of the difficulties in working on interactive and dynamic graphics research has been the rapid change in technology. Programming languages have changed a little (FORTRAN to C to java to python) but graphics toolkits and display devices have changed a lot! The tour software used in this book evolved from XGobi, which was written in C and used the X Window System, which was then rewritten in GGobi using gtk. The video library has engaging videos of these software systems. There have been several other short-lived implementations, including orca (Sutherland et al., 2000a), written in java, and cranvas (Xie et al., 2014), written in R with a back-end provided by wrapper functions to qt libraries.\nAlthough attempts were made with these ancestor systems to connect the data plots to a statistical analysis system, these were always limited. With the emergence of R, having graphics in the data analysis workflow has been much easier, albeit at the cost of the interactivity with graphics that matches the old systems. We are mostly using the R package, tourr (Wickham et al., 2011a) for examples in this book. It provides the machinery for running a tour, and has the flexibility that it can be ported, modified, and used as a regular element of data analysis.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#exercises",
    "href": "1-intro.html#exercises",
    "title": "1  Picturing high dimensions",
    "section": "Exercises",
    "text": "Exercises\n\nRandomly generate data points that are uniformly distributed in a hyper-cube of 3, 5 and 10 dimensions, with 500 points in each sample, using the cube.solid.random() function of the geozoo package. What differences do we expect to see? Now visualise each set in a grand tour and describe how they differ, and whether this matched your expectations?\nUse the geozoo package to generate samples from different shapes and use them to get a better understanding of how shapes appear in a grand tour. You can start with exploring the conic spiral in 3D, a torus in 4D and points along the wire frame of a cube in 5D.\nFor each of the challenge data sets, c1, …, c7 from the mulgar package, use the grand tour to view and try to identify structure (outliers, clusters, non-linear relationships).\nThe datasets package in R has some classic data to explore.\n\nExamine the USArrests data, using a grand tour (animate_xy()). Explain the structure, and why the scale of the variables might affect your interpretation of the structure. Re-run the tour on standardised variables (option recale=TRUE). Do you see any outliers?\nExamine the swiss data, using a grand tour, making sure to use standardised variables. Explain the patterns that you see.\n\n\nThe MASS package has two data sets that are interesting to examine.\n\nUsing a grand tour of the physical variables (FL, RW, CL, CW, BD) variables in the crabs data with the points coloured by species (sp) what can you see? Is there a difference in the species? (Note that for this data you don’t need to standardise. All are measured in the same units, and are not too different in scale, so the associations can still be seen well enough.)\nUsing a grand tour of the chemical % (Na:Fe) variables in the fgl data with the points coloured by type what can you see? Is there a difference in the types of glass? (Here, the variables need to be standardised. Even though they are %’s, the different amounts of each impede the ability to assess the associations without rescaling.)\n\n\nThere are several interesting data sets available on the GGobi web site, for example, one of Tukey’s original data set PRIM7. Examine this data for different types of patterns. The olive, PBC, and music data sets are also interesting to explore. PRIM7 can be read using:\n\n\nCodelibrary(readr)\nprim7 &lt;- read_csv(\"http://ggobi.org/book/data/prim7.csv\",\n                  show_col_types = FALSE)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#footnotes",
    "href": "1-intro.html#footnotes",
    "title": "1  Picturing high dimensions",
    "section": "",
    "text": "Thanks to Barret Schloerke for directing co-author Cook to this history when he was an undergraduate student and we were starting the geozoo project.↩︎\n“Space is big. Really big. You might think it’s a long way to the pharmacy, but that’s peanuts to space.” from Douglas Adams’ Hitchhiker’s Guide to the Galaxy always springs to mind when thinking about high dimensions!↩︎",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "2-notation.html",
    "href": "2-notation.html",
    "title": "2  Technical details",
    "section": "",
    "text": "2.1 Notation conventions and R objects\nThe data can be considered to be a matrix of numbers with the columns corresponding to variables, and the rows correspond to observations. It can be helpful to write this in mathematical notation, like:\n\\[\\begin{eqnarray*}\nX_{n\\times p} =\n[X_1~X_2~\\dots~X_p]_{n\\times p} = \\left[ \\begin{array}{cccc}\nX_{11} & X_{12} & \\dots & X_{1p} \\\\\nX_{21} & X_{22} & \\dots & X_{2p}\\\\\n\\vdots & \\vdots &  & \\vdots \\\\\nX_{n1} & X_{n2} & \\dots & X_{np} \\end{array} \\right]_{n\\times p}\n\\end{eqnarray*}\\]\nwhere \\(X\\) indicates the \\(n\\times p\\) data matrix, \\(X_j\\) indicates variable \\(j, j=1, \\dots, p\\) and \\(X_{ij}\\) indicates the value of the \\(j^{th}\\) variable for the \\(i^{th}\\) observation. (It can be confusing to distinguish whether one is referring to the observation or a variable, because \\(X_i\\) is used to indicate observation. In descriptions where it is unclear we will use \\(X_{i.}\\) to indicate observation/row and \\(X_{.j}\\) to indicate variable/column. Also this will usually accompanied by qualifying words such as observation or variable.)\nWhen there is a response variable(s), it is common to consider \\(X\\) to be the predictors, and use \\(Y\\) to indicate the response variable(s). \\(Y\\) could be a matrix, also, and would be \\(n\\times q\\), where commonly \\(q=1\\). \\(Y\\) could be numeric or categorical, and this would change how it is handled with visualisation.\nTo make a low-dimensional projection (shadow) of the data onto \\(d\\) dimensions (\\(d &lt; p\\)), we need an orthonormal basis:\n\\[\\begin{eqnarray*}\nA_{p\\times d} = \\left[ \\begin{array}{cccc}\nA_{11} & A_{12} & \\dots & A_{1d} \\\\\nA_{21} & A_{22} & \\dots & A_{2d}\\\\\n\\vdots & \\vdots &  & \\vdots \\\\\nA_{p1} & A_{p2} & \\dots & A_{pd} \\end{array} \\right]_{p\\times d}\n\\end{eqnarray*}\\]\n\\(A\\) should be an orthonormal matrix, which means that the \\(\\sum_{j=1}^p A_{jk}^2=1, k=1, \\dots, d\\) (columns represent vectors of length 1) and \\(\\sum_{j=1}^p A_{jk}A_{jl}=0, k,l=1, \\dots, d; k\\neq l\\) (columns represent vectors that are orthogonal to each other). In matrix notation, this can be written as \\(A^{\\top}A = I_d\\).\nThen the projected data is written as:\n\\[\\begin{eqnarray*}\nY_{n\\times d} = XA = \\left[ \\begin{array}{cccc}\ny_{11} & y_{12} & \\dots & y_{1d} \\\\\ny_{21} & y_{22} & \\dots & y_{2d}\\\\\n\\vdots & \\vdots &  & \\vdots \\\\\ny_{n1} & y_{n2} & \\dots & y_{nd} \\end{array} \\right]_{n\\times d}\n\\end{eqnarray*}\\]\nwhere \\(y_{ij} = \\sum_{k=1}^p X_{ik}A_{kj}\\). Note that we are using \\(Y\\) as the projected data here, as well as it possibly being used for a response variable. Where necessary, this will be clarified with words in the text, when notation is used in explanations later.\nWhen using R, if we only have the data corresponding to \\(X\\) it makes sense to use a matrix object. However, if the response variable is included and it is categorical, then we might use a data.frame or a tibble which can accommodate non-numerical values. Then to work with the data, we can use the base R methods:\nX &lt;- matrix(c(1.1, 1.3, 1.4, 1.2, \n              2.7, 2.6, 2.4, 2.5, \n              3.5, 3.4, 3.2, 3.6), \n            ncol=4, byrow=TRUE)\nX\n\n     [,1] [,2] [,3] [,4]\n[1,]  1.1  1.3  1.4  1.2\n[2,]  2.7  2.6  2.4  2.5\n[3,]  3.5  3.4  3.2  3.6\nwhich is a data matrix with \\(n=3, p=4\\) and to extract a column (variable):\nX[,2]\n\n[1] 1.3 2.6 3.4\nor a row (observation):\nX[2,]\n\n[1] 2.7 2.6 2.4 2.5\nor an individual cell (value):\nX[3,2]\n\n[1] 3.4\nTo make the data projection we need an orthonormal matrix:\nA &lt;- matrix(c(0.707,0.707,0,0,0,0,0.707,0.707), ncol=2, byrow=FALSE)\nA\n\n      [,1]  [,2]\n[1,] 0.707 0.000\n[2,] 0.707 0.000\n[3,] 0.000 0.707\n[4,] 0.000 0.707\nYou can check that it is orthonormal by\nsum(A[,1]^2)\n\n[1] 0.999698\n\nsum(A[,1]*A[,2])\n\n[1] 0\nand compute the projected data using matrix multiplication:\nX %*% A\n\n       [,1]   [,2]\n[1,] 1.6968 1.8382\n[2,] 3.7471 3.4643\n[3,] 4.8783 4.8076\nThe magical number 0.707 used above and to create the projection in Figure 1.2 arises from normalising a vector with equal contributions from each variable, (1, 1). Dividing by sqrt(2) gives (0.707, 0.707).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical details</span>"
    ]
  },
  {
    "objectID": "2-notation.html#exercises",
    "href": "2-notation.html#exercises",
    "title": "2  Technical details",
    "section": "Exercises",
    "text": "Exercises\n\nGenerate a matrix \\(A\\) with \\(p=5\\) (rows) and \\(d=2\\) (columns), where each value is randomly drawn from a standard normal distribution. Extract the element at row 3 and column 1.\nWe will interpret \\(A\\) as an orthonormal basis and therefore it needs to be checked for orthonormality, and if it fails, then to be orthonormalised. Use the function tourr::is_orthonormal to explicitly check that each column is normalised and that the two columns are orthogonal. If they are not, then use tourr::orthonormalise to make them so. For the fixed version of \\(A\\), which dimensions contribute most to the projection, horizontally and vertically?\nUse matrix multiplication to calculate the projection of the mulgar::clusters data onto the 2D plane defined by \\(A\\). Make a scatterplot of the projected data. Can you identify clustering in this view?\nUse save_history() to generate a grand tour path for the mulgar::clusters data, with three target planes. Extract and report the second target basis, and plot the resulting data.\nUsing the saved path, generate the interpolation between the target planes, using interpolate(). How many bases are in the tour path? Plot the first four in set of planes, and explain what is happening. Save tour path, extract basis and plot data\nRepeat save_history() but use a holes index guided tour. Plot the final projection. Does the guided tour find the three clusters? Which of the variables have the largest contributions to the differences between groups?\nRepeat save_history() using a radial tour, starting from the best projection basis from the guided tour, and exploring the contribution of x1 (mvar=1). Why should the length of the path be set to three? Why is the last basis the same as the first? Examine the second target basis, and explain how it is different from the first basis.\nRun the tours from in 4-7 using the animate_xy(). You can use the planned_tour method, but it is more interesting to simply re-generate using the different tour_path methods. It is interesting to examine the importance of x5 and x4 to the clustering seen in the best projection from the guided tour.\nExamine tours of 1D projections of the mulgar::clusters data, using density or histogram rendering. Can the three clusters be seen with 1D projections?\nExplore the use of the slice tour on these geometric objects, that can be simulated using geozoo:\n\n\nRoman Surface, generated by\n\n\nCoders &lt;- geozoo::roman.surface()$points |&gt; scale() |&gt; as.data.frame()`\n\n\n\nsolid 4D sphere, generated by\n\n\nCodes_solid &lt;- geozoo::sphere.solid.random(4, 2000)$points |&gt; as.data.frame()`\n\n\n\nhollow 4D sphere, generated by\n\n\nCodes_hollow &lt;- geozoo::sphere.hollow(4, 2000)$points |&gt; as.data.frame()`\n\n\nUse both regular tours, and the slice tours on each. What does the slice tour allow us to see in the Roman Surface? What is the difference between the solid and hollow spheres?",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical details</span>"
    ]
  },
  {
    "objectID": "3-intro-dimred.html",
    "href": "3-intro-dimred.html",
    "title": "3  Overview",
    "section": "",
    "text": "Exercises\nThis chapter will focus on methods for reducing dimension, and how the tour1 can be used to assist with the common methods such as principal component analysis (PCA), multidimensional scaling (MDS), t-stochastic neighbour embedding (t-SNE), and factor analysis.\nDimension is perceived in a tour using the spread of points. When the points are spread far apart, then the data is filling the space. Conversely when the points “collapse” into a sub-region then the data is only partially filling the space, and some dimension reduction to reduce to this smaller dimensional space may be worthwhile.\nLet’s start with some 2D examples. You need at least two variables to be able to talk about association between variables. Figure 3.1 shows three plots of two variables. Plot (a) shows two variables that are strongly linearly associated2, because when x1 is low, x2 is low also, and conversely when x1 is high, x2 is also high. This can also be seen by the reduction in spread of points (or “collapse”) in one direction making the data fill less than the full square of the plot. So from this we can conclude that the data is not fully 2D. The second step is to infer which variables contribute to this reduction in dimension. The axes for x1 and x2 are drawn extending from \\((0,0)\\) and because they both extend out of the cloud of points, in the direction away from the collapse of points we can say that they are jointly responsible for the dimension reduction.\nFigure 3.1 (b) shows a pair of variables that are not linearly associated. Variable x1 is more varied than x3 but knowing the value on x1 tells us nothing about possible values on x3. Before running a tour all variables are typically scaled to have equal spread. The purpose of the tour is to capture association and relationships between the variables, so any univariate differences should be removed ahead of time. Figure 3.1 (c) shows what this would look like when x3 is scaled - the points are fully spread in the full square of the plot.\nNow let’s think about what this looks like with five variables. Figure 3.2 shows a grand tour on five variables, with (a) data that is primarily 2D, (b) data that is primarily 3D and (c) fully 5D data. You can see that both (a) and (b) the spread of points collapse in some projections, with it happening more in (a). In (c) the data is always spread out in the square, although it does seem to concentrate or pile in the centre. This piling is typical when projecting from high dimensions to low dimensions. The sage tour (Laa et al., 2022) makes a correction for this.\nThe next step is to determine which variables contribute. In the examples just provided, all variables are linearly associated in the 2D and 3D data. You can check this by making a scatterplot matrix, Figure 3.3.\nTo make an example where not all variables contribute, we have added two additional variables to the plane data set, which are purely noise.\nNow we have 2D structure in 7D, but only five of the variables contribute to the 2D structure, that is, five of the variables are linearly related with each other. The other two variables (x6, x7) are not linearly related to any of the others.\nThe data is viewed with a grand tour in Figure 3.5. We can still see the concentration of points along a line in some dimensions, which tells us that the data is not fully 7D. Then if you look closely at the variable axes you will see that the collapsing to a line only occurs when any of x1-x5 contribute strongly in the direction orthogonal to this. This does not happen when x6 or x7 contribute strongly to a projection - the data is always expanded to fill much of the space. That tells us that x6 and x7 don’t substantially contribute to the dimension reduction, that is, they are not linearly related to the other variables.\nThe simulated data here is very simple, and what we have learned from the tour could also be learned from principal component analysis. However, if there are small complications, such as outliers or nonlinear relationships, that might not be visible from principal component analysis, the tour can help you to see them.\nFigure 3.6 and Figure 3.7(a) show example data with an outlier and Figure 3.7(b) shows data with non-linear relationships.\nCodelibrary(tidyverse)\nlibrary(tourr)\nlibrary(GGally)\nset.seed(946)\nd &lt;- tibble(x1=runif(200, -1, 1), \n            x2=runif(200, -1, 1), \n            x3=runif(200, -1, 1))\nd &lt;- d %&gt;%\n  mutate(x4 = x3 + runif(200, -0.1, 0.1))\n# outlier is visible in d\nd &lt;- bind_rows(d, c(x1=0, x2=0, x3=-0.5, x4=0.5))\n\n# Point is hiding in d_r\nd_r &lt;- d %&gt;%\n  mutate(x1 = cos(pi/6)*x1 + sin(pi/6)*x3,\n         x3 = -sin(pi/6)*x1 + cos(pi/6)*x3,\n         x2 = cos(pi/6)*x2 + sin(pi/6)*x4,\n         x4 = -sin(pi/6)*x2 + cos(pi/6)*x4)",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dimension reduction overview</span>"
    ]
  },
  {
    "objectID": "3-intro-dimred.html#exercises",
    "href": "3-intro-dimred.html#exercises",
    "title": "3  Overview",
    "section": "",
    "text": "Multicollinearity is when the predictors for a model are strongly linearly associated. It can adversely affect the fitting of most models, because many possible models may be equally as good. Variable importance might be masked by correlated variables, and confidence intervals generated for linear models might be too wide. Check the for multicollinearity or other associations between the predictors in:\n\n2001 Australian election data\n2016 Australian election data\n\n\nExamine 5D multivariate normal samples drawn from populations with a range of variance-covariance matrices. (You can use the mvtnorm package to do the sampling, for example.) Examine the data using a grand tour. What changes when you change the correlation from close to zero to close to 1? Can you see a difference between strong positive correlation and strong negative correlation?\nThe following code shows how to hide a point in a four-dimensional space, so that it is not visible in any of the plots of two variables. Generate both d and d_r and confirm that the point is visible in a scatterplot matrix of d, but not in the scatterplot matrix of d_r. Also confirm that it is visible in both data sets when you use a tour.\n\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dimension reduction overview</span>"
    ]
  },
  {
    "objectID": "3-intro-dimred.html#footnotes",
    "href": "3-intro-dimred.html#footnotes",
    "title": "3  Overview",
    "section": "",
    "text": "Note that the animated tours from this chapter can be viewed at https://dicook.github.io/mulgar_book/3-intro-dimred.html.↩︎\nIt is generally better to use associated than correlated. Correlation is a statistical quantity, measuring linear association. The term associated can be prefaced with the type of association, such as linear or non-linear.↩︎",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dimension reduction overview</span>"
    ]
  },
  {
    "objectID": "4-pca.html",
    "href": "4-pca.html",
    "title": "\n4  Principal component analysis\n",
    "section": "",
    "text": "4.1 Determining how many dimensions\nReducing dimensionality using principal component analysis (PCA) dates back to Pearson (1901) and Hotelling (1933), and Jolliffe & Cadima (2016) provides a current overview. The goal is to find a smaller set of variables, \\(q (&lt; p)\\), that contain as much information as the original as possible. The new set of variables, known as principal components (PCs), are linear combinations of the original variables. The PCs can be used to represent the data in a lower-dimensional space.\nThe process is essentially an optimisation procedure, although PCA has an analytical solution. It solves the problem of\n\\[\n\\max_{a_k} ~\\text{Var} (Xa_k),\n\\] where \\(X\\) is the \\(n \\times p\\) data matrix, \\(a_k (k=1, ..., p)\\) is a 1D projection vector, called an eigenvector, and the \\(\\text{Var} (Xa_k)\\) is called an eigenvalue. So PCA is a sequential process, that will find the direction in the high-dimensional space (as given by the first eigenvector) where the data is most varied, and then find the second most varied direction, and so on. The eigenvectors define the combination of the original variables, and the eigenvalues define the amount of variance explained by the reduced number of variables.\nPCA is very broadly useful for summarising linear association by using combinations of variables that are highly correlated. However, high correlation can also occur when there are outliers, or clustering. PCA is commonly used to detect these patterns also.\nPCA is not very effective when the distribution of the variables is highly skewed, so it can be helpful to transform variables to make them more symmetrically distributed before conducting PCA. It is also possible to summarise different types of structure by generalising the optimisation criteria to any function of projected data, \\(f(XA)\\), which is called projection pursuit (PP). PP has a long history (Kruskal (1964a), Friedman & Tukey (1974), Diaconis & Freedman (1984a), Jones & Sibson (1987), Huber (1985)), and there are regularly new developments (e.g. E.-K. Lee & Cook (2009), Perisic & Posse (2005), Y. D. Lee et al. (2013), Loperfido (2018), Bickel et al. (2018), C. Zhang et al. (2023)).\nWe would start by examining the data using a grand tour. The goal is to check whether there might be potential issues for PCA, such as skewness, outliers or clustering, or even non-linear dependencies.\nWe’ll start be showing PCA on the simulated data from Chapter 3. The scree plots show that PCA supports that the data are 2D, 3D and 5D respectively.\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(mulgar)\ndata(plane)\ndata(box)\nlibrary(geozoo)\ncube5d &lt;- data.frame(cube.solid.random(p=5, n=300)$points)\ncolnames(cube5d) &lt;- paste0(\"x\", 1:5)\ncube5d &lt;- data.frame(apply(cube5d, 2, \n                           function(x) (x-mean(x))/sd(x)))\np_pca &lt;- prcomp(plane)\nb_pca &lt;- prcomp(box)\nc_pca &lt;- prcomp(cube5d)\np_scree &lt;- ggscree(p_pca, q = 5) + theme_minimal()\n\nb_scree &lt;- ggscree(b_pca, q = 5) + theme_minimal()\nc_scree &lt;- ggscree(c_pca, q = 5) + theme_minimal()\nFigure 4.1: Scree plots for the three simulated data sets shown in Figure 3.2. The 2D in 5D is clearly recognised by PCA to be 2D because the variance drops substantially between 2-3 principal components. The 3D in 5D is possibly 3D because the variance drops from 3-4 principal components. The fully 5D data has no drop in variance, and all values are close to the typical value one would observe if the data was fully 5D.\nThe next step is to look at the coefficients for the selected number of PCs. Table 4.1 shows the coefficients for the first two PCs of the plane data. All five variables contribute, with x1, x2, x3 contributing more to PC1, and x4, x5 contributing more to PC2. Table 4.2 shows the coefficients for the first three PCs. Variables x1, x2, x3 contribute strongly to PC1, PC2 has contributions from all variables except x3 and variables x4 and x5 contribute strongly to PC3.\nCode to print PC coefficientslibrary(gt)\np_pca$rotation[,1:2] %&gt;%\n  as_tibble(rownames=\"Variable\") %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = c(PC1, PC2),\n             decimals = 2)\n\n\nTable 4.1: Coefficients for the first two PCs for the plane data.\n\n\n\n\n\n\nVariable\nPC1\nPC2\n\n\n\nx1\n0.58\n−0.06\n\n\nx2\n−0.55\n0.21\n\n\nx3\n0.47\n−0.41\n\n\nx4\n0.25\n0.64\n\n\nx5\n−0.29\n−0.62\nCode to print PC coefficientsb_pca$rotation[,1:3] %&gt;%\n  as_tibble(rownames=\"Variable\") %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = c(PC1, PC2, PC3),\n             decimals = 2)\n\n\nTable 4.2: Coefficients for the first three PCs for the box data.\n\n\n\n\n\n\nVariable\nPC1\nPC2\nPC3\n\n\n\nx1\n−0.51\n0.46\n0.11\n\n\nx2\n0.51\n0.46\n0.00\n\n\nx3\n−0.65\n−0.09\n0.23\n\n\nx4\n−0.22\n0.36\n−0.87\n\n\nx5\n0.02\n0.66\n0.43\nIn each of these simulated data sets, all five variables contributed to the dimension reduction. If we added two purely noise variables to the plane data, as done in Chapter 3, the scree plot would indicate that the data is now 4D, and we would get a different interpretation of the coefficients from the PCA. We see that PC1 and PC2 are approximately the same as before, with main variables being (x1, x2, x3) and (x4, x5) respectively. PC3 and PC4 are both x6 and x7.\nset.seed(5143)\nplane_noise &lt;- plane\nplane_noise$x6 &lt;- rnorm(100)\nplane_noise$x7 &lt;- rnorm(100)\nplane_noise &lt;- data.frame(apply(plane_noise, 2, function(x) (x-mean(x))/sd(x)))\n\npn_pca &lt;- prcomp(plane_noise)\nggscree(pn_pca, q = 7) + theme_minimal()\n\n\n\n\n\n\nFigure 4.2: Additional noise variables expands the data to 4D.\nCode to print PC coefficientspn_pca$rotation[,1:4] %&gt;%\n  as_tibble(rownames=\"Variable\") %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = c(PC1, PC2, PC3, PC4),\n             decimals = 2)\n\n\nTable 4.3: Coefficients for the first four PCs for the box data.\n\n\n\n\n\n\nVariable\nPC1\nPC2\nPC3\nPC4\n\n\n\nx1\n0.58\n0.04\n0.01\n0.00\n\n\nx2\n−0.55\n−0.18\n−0.03\n0.07\n\n\nx3\n0.47\n0.37\n0.05\n−0.20\n\n\nx4\n0.24\n−0.62\n−0.06\n0.17\n\n\nx5\n−0.28\n0.60\n0.07\n−0.14\n\n\nx6\n0.05\n0.29\n−0.58\n0.76\n\n\nx7\n−0.02\n−0.08\n−0.81\n−0.58",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Principal component analysis</span>"
    ]
  },
  {
    "objectID": "4-pca.html#determining-how-many-dimensions",
    "href": "4-pca.html#determining-how-many-dimensions",
    "title": "\n4  Principal component analysis\n",
    "section": "",
    "text": "4.1.1 Example: pisa\n\nThe pisa data contains simulated data from math, reading and science scores, totalling 30 variables. PCA is used here to examine the association. We might expect that it is 3D, but what we see suggests it is primarily 1D. This means that a student that scores well in math, will also score well in reading and science.\n\ndata(pisa)\npisa_std &lt;- pisa %&gt;%\n  filter(CNT == \"Australia\") %&gt;%\n  select(-CNT) %&gt;%\n  mutate_all(mulgar:::scale2)\npisa_pca &lt;- prcomp(pisa_std)\npisa_scree &lt;- ggscree(pisa_pca, q = 15) + theme_minimal()\n\nThe scree plot in Figure 4.3 shows a big drop from one to two PCs in the amount of variance explained. A grand tour on the 30 variables can be run using animate_xy():\n\nanimate_xy(pisa_std, half_range=1)\n\nor rendered as an animated gif using render_gif():\n\nrender_gif(pisa_std, \n           grand_tour(), \n           display_xy(half_range=0.9),\n           gif_file=\"gifs/pisa_gt.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\nand we can see that the data is elliptical in most projections, sometimes shrinking to be a small circle. This pattern strongly indicates that there is one primary direction of variation in the data, with only small variation in any direction away from it. Shrinking to the small circle is analogous to to how a pencil or cigar or water bottle in 3D looks from some angles.\n\n\n\n\n\n\n\nScree plot for the PCA on the pisa data suggests that the data is 1D.\n\n\n\n\n\n\n\n\n\n(a) Grand tour of the pisa data.\n\n\n\n\n\n\nFigure 4.3: Scree plot and tour of the pisa data, with 30 variables being the plausible scores for Australian students.\n\n\nThe coefficients of the first PC (first eigenvector) are roughly equal in magnitude (as shown below), which tells us that all variables roughly contribute. Interestingly, they are all negative, which is not actually meaningful. With different software these could easily have been all positive. The sign of the coefficients can be reversed, as long as all are reversed, which is the same as an arrow pointing one way, changing and pointing the other way.\n\nCode to print PC coefficientsround(pisa_pca$rotation[,1], 2)\n\n PV1MATH  PV2MATH  PV3MATH  PV4MATH  PV5MATH  PV6MATH  PV7MATH  PV8MATH \n   -0.18    -0.18    -0.18    -0.18    -0.18    -0.18    -0.18    -0.18 \n PV9MATH PV10MATH  PV1READ  PV2READ  PV3READ  PV4READ  PV5READ  PV6READ \n   -0.18    -0.18    -0.19    -0.18    -0.19    -0.19    -0.19    -0.19 \n PV7READ  PV8READ  PV9READ PV10READ  PV1SCIE  PV2SCIE  PV3SCIE  PV4SCIE \n   -0.19    -0.19    -0.19    -0.19    -0.18    -0.18    -0.19    -0.18 \n PV5SCIE  PV6SCIE  PV7SCIE  PV8SCIE  PV9SCIE PV10SCIE \n   -0.19    -0.18    -0.19    -0.18    -0.19    -0.18 \n\n\n\nThe tour verifies that the pisa data is primarily 1D, indicating that a student who scores well in math, probably scores well in reading and science, too. More interestingly, the regular shape of the data strongly indicates that it is “synthetic”, simulated rather than observed.\n\n\n4.1.2 Example: aflw\n\nThis data has player statistics for all the matches in the 2021 season. We would be interested to know which variables contain similar information, and thus might be combined into single variables. We would expect that many statistics to group into a few small sets, such as offensive and defensive skills. We might also expect that some of the statistics are skewed, most players have low values and just a handful of players are stellar. It is also possible that there are some extreme values. These are interesting features, but they will distract from the main purpose of grouping the statistics. Thus the tour is used to check for potential problems with the data prior to conducting PCA.\n\nlibrary(tourr)\ndata(aflw)\naflw_std &lt;- aflw %&gt;%\n  mutate_if(is.numeric, function(x) (x-\n      mean(x, na.rm=TRUE))/\n      sd(x, na.rm=TRUE))\n\nTo look at all of the 29 player statistics in a grand tour in Figure 4.4.\n\nCode to generate touranimate_xy(aflw_std[,7:35], half_range=0.9)\nrender_gif(aflw_std[,7:35], \n           grand_tour(), \n           display_xy(half_range=0.9),\n           gif_file=\"gifs/aflw_gt.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\n\n\nFigure 4.4: Grand tour of the AFLW player statistics.\n\n\nNo major surprises! There is a small amount of skewness, and there are no major outliers. Skewness indicates that most players have reasonably similar skills (bunching of points), except for some key players (the moderate outliers). The skewness could be reduced by applying a log or square root transformation to some variables prior to running the PCA. However, we elect not to do this because the moderate outliers are of interest. These correspond to talented players that we’d like to explore further with the analysis.\nBelow we have the conventional summary of the PCA, a scree plot showing the reduction in variance to be explained when each additional PC is considered. It is also conventional to look at a table summarising the proportions of variance explained by PCs, but with almost 30 variables it is easier to make some decision on the number of PCs needed based on the scree plot.\n\nCode to make screeplotaflw_pca &lt;- prcomp(aflw_std[,7:35], \n               scale = FALSE, \n               retx=TRUE)\n\nggscree(aflw_pca, q = 29) + theme_minimal()\n\n\n\n\n\n\nFigure 4.5: Scree plot showing decay in variance of PCs.\n\n\n\n\n\nFrom the scree plot in Figure 4.5, we see a sharp drop from one to two, two to three and then smaller drops. After four PCs the variance drops again at six PCs and then gradually decays. We will choose four PCs to examine more closely. This explains 67.2% of the variance.\n\nCode to print PC coefficientslibrary(gt)\naflw_pca$rotation[,1:4] %&gt;%\n  as_tibble(rownames=\"Variable\") %&gt;% \n  arrange(desc(PC1), desc(PC2), desc(PC3)) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = c(PC1, PC2, PC3, PC4),\n             decimals = 2)\n\n\nTable 4.4: Coefficients for the first four PCs.\n\n\n\n\n\n\nVariable\nPC1\nPC2\nPC3\nPC4\n\n\n\ndisposals\n0.31\n−0.05\n−0.03\n0.07\n\n\npossessions\n0.31\n−0.03\n−0.07\n0.09\n\n\nkicks\n0.29\n−0.04\n0.09\n−0.12\n\n\nmetres\n0.28\n−0.03\n0.10\n−0.15\n\n\ncontested\n0.28\n0.01\n−0.12\n0.23\n\n\nuncontested\n0.28\n−0.06\n−0.01\n−0.05\n\n\nturnovers\n0.27\n−0.01\n−0.01\n−0.29\n\n\nclearances\n0.23\n0.00\n−0.29\n0.19\n\n\nclangers\n0.23\n−0.02\n−0.06\n−0.33\n\n\nhandballs\n0.23\n−0.04\n−0.19\n0.31\n\n\nfrees_for\n0.21\n0.02\n−0.13\n0.18\n\n\nmarks\n0.21\n0.03\n0.32\n0.02\n\n\ntackles\n0.20\n0.01\n−0.28\n0.09\n\n\ntime_pct\n0.16\n−0.04\n0.35\n−0.02\n\n\nintercepts\n0.13\n−0.28\n0.24\n0.03\n\n\nrebounds_in50\n0.13\n−0.28\n0.24\n−0.06\n\n\nfrees_against\n0.13\n0.03\n−0.16\n−0.23\n\n\nassists\n0.09\n0.23\n0.00\n0.05\n\n\nbounces\n0.09\n0.03\n0.02\n−0.28\n\n\nbehinds\n0.09\n0.32\n0.08\n−0.02\n\n\nshots\n0.08\n0.38\n0.12\n−0.03\n\n\ntackles_in50\n0.07\n0.27\n−0.18\n0.03\n\n\nmarks_in50\n0.06\n0.34\n0.18\n0.04\n\n\ncontested_marks\n0.05\n0.16\n0.34\n0.15\n\n\ngoals\n0.04\n0.37\n0.16\n0.03\n\n\naccuracy\n0.04\n0.34\n0.10\n0.06\n\n\none_pct\n0.03\n−0.21\n0.33\n0.08\n\n\ndisposal\n0.02\n−0.13\n0.20\n0.50\n\n\nhitouts\n−0.04\n0.00\n−0.03\n0.32\n\n\n\n\n\n\n\n\n\nWhen there are as many variables as this, it can be hard to digest the combinations of variables most contributing to each PC. Rearranging the table by sorting on a selected PC can help. Table 4.4 has been sorted according to the PC 1 coefficients.\nPC 1 is primarily composed of disposals, possessions, kicks, metres, uncontested, contested, …. Actually almost all variables positively contribute, albeit in different amounts! It is quite common in PCA for the first PC to be a combination of all variables, although it might commonly be a closer to equal contribution, and it tells us that there is one main direction of variation in the data. For PC 1 in the aflw data, PCA is telling us that the primary variation is through a combination of skills, and this maps to basic football playing skills, where some skills (e.g. disposals, possessions, kicks, …) are more important.\nThus the second PC might be the more interesting. PC 2 is primarily a combination of shots, goals, marks_in50, accuracy, and behinds contrasted against rebounds_in50 and intercepts. The negative coefficients are primary offensive skills and the positive coefficients are defensive skills. This PC is reasonable measure of the offensive vs defensive skills of a player.\n\nWe would continue to interpret each PC by examining large coefficients to help decide how many PCs are a suitable summary of the information in the data. Briefly, PC 3 is a measure of worth of the player because time_pct has a large coefficient, so players that are on the field longer will contribute strongly to this new variable. It also has large (and opposite) contributions from clearances, tackles, contested_marks. PC 4 appears to be related to aggressive play with clangers, turnovers, bounces and frees_against featuring. So all four PCs have useful information. (Note, if we had continued to examine large coefficients on PC 5 we would find that all variables already have had reasonably large coefficients on PC 1-4, which supports restricting attention to the first four.)\n\nIdeally, when we tour the four PCs, we’d like to be able to stop and identify players. This involves creating a pre-computed animation, with additional mouse-over. This is only feasible with a small number of observations, like the aflw data, because all of the animation frames are constructed in a single object and passed to plotly. This object gets large very quickly!\n\nCode to make tour animationlibrary(plotly)\nlibrary(htmlwidgets)\nset.seed(20)\nb &lt;- basis_random(4, 2)\naflw_pct &lt;- tourr::save_history(aflw_pca$x[,1:4], \n                    tour_path = grand_tour(),\n                    start = b,\n                    max_bases = 5)\n# To reconstruct projected data plots, later\nsave(aflw_pct, file=\"data/aflw_pct.rda\") \naflw_pcti &lt;- interpolate(aflw_pct, 0.1)\naflw_anim &lt;- render_anim(aflw_pca$x[,1:4],\n                         frames=aflw_pcti, \n             obs_labels=paste0(aflw$surname,\n                               aflw$given_name))\n\naflw_gp &lt;- ggplot() +\n     geom_path(data=aflw_anim$circle, \n               aes(x=c1, y=c2,\n                   frame=frame), linewidth=0.1) +\n     geom_segment(data=aflw_anim$axes, \n                  aes(x=x1, y=y1, \n                      xend=x2, yend=y2, \n                      frame=frame), \n                  linewidth=0.1) +\n     geom_text(data=aflw_anim$axes, \n               aes(x=x2, y=y2, \n                   frame=frame, \n                   label=axis_labels), \n               size=5) +\n     geom_point(data=aflw_anim$frames, \n                aes(x=P1, y=P2, \n                    frame=frame, \n                    label=obs_labels), \n                alpha=0.8) +\n     xlim(-1,1) + ylim(-1,1) +\n     coord_equal() +\n     theme_bw() +\n     theme(axis.text=element_blank(),\n         axis.title=element_blank(),\n         axis.ticks=element_blank(),\n         panel.grid=element_blank())\naflw_pctour &lt;- ggplotly(aflw_gp,\n                        width=500,\n                        height=550) %&gt;%\n       animation_button(label=\"Go\") %&gt;%\n       animation_slider(len=0.8, x=0.5,\n                        xanchor=\"center\") %&gt;%\n       animation_opts(easing=\"linear\", transition = 0)\n\nhtmlwidgets::saveWidget(aflw_pctour,\n          file=\"html/aflw_pca.html\",\n          selfcontained = TRUE)\n\n\n\n\n\n\n\n\nFigure 4.6: Animation of four PCs of the aflw data with interactive labelling.\n\n\nFrom Figure 4.6 the shape of the four PCs is similar to that of all the variables, bunching of points in the centre with a lot of moderate outliers.\n\nCode to generate interactive plot of frame 18library(plotly)\nload(\"data/aflw_pct.rda\")\naflw_pcti &lt;- interpolate(aflw_pct, 0.1)\nf18 &lt;- matrix(aflw_pcti[,,18], ncol=2)\np18 &lt;- render_proj(aflw_pca$x[,1:4], f18, \n                   obs_labels=paste0(aflw$surname,\n                               aflw$given_name))\npg18 &lt;- ggplot() +\n  geom_path(data=p18$circle, aes(x=c1, y=c2)) +\n  geom_segment(data=p18$axes, aes(x=x1, y=y1, xend=x2, yend=y2)) +\n  geom_text(data=p18$axes, aes(x=x2, y=y2, label=rownames(p18$axes))) +\n  geom_point(data=p18$data_prj, aes(x=P1, y=P2, label=obs_labels)) +\n  xlim(-1,1) + ylim(-1, 1) +\n  #ggtitle(\"Frame 18\") +\n  theme_bw() +\n  theme(\n    axis.text=element_blank(),\n    axis.title=element_blank(),\n    axis.ticks=element_blank(),\n    panel.grid=element_blank())\nggplotly(pg18, width=500, height=500)\n\n\n\n\n\n\nFigure 4.7: Frame 18 re-plotted so that players can be identified on mouse-over.\n\n\n\nFor any particular frame, like 18 re-plotted in Figure 4.7, we can investigate further. Here there is a branching pattern, where the branch points in the direction of PC 1. Mouse-over the players at the tip of this branch and we find players like Alyce Parker, Brittany Bonnici, Dana Hooker, Kiara Bowers. If you look up the bios of these players you’ll find they all have generally good player descriptions like “elite disposals”, “powerful left foot”, “hard-running midfielder”, “best and fairest”.\nIn the direction of PC 2, you’ll find players like Lauren Ahrens, Stacey Livingstone who are star defenders. Players in this end of PC 1, have high scores on intercepts and rebounds_in50.\nAnother interesting frame for inspecting PC 2 is 59. PC 2 at one end has players with high goal scoring skills, and the other good defending skills. So mousing over the other end of PC 2 finds players like Gemma Houghton and Katie Brennan who are known for their goal scoring. The branch pattern is an interesting one, because it tells us there is some combination of skills that are lacking among all players, primarily this appears to be there some distinction between defenders skills and general playing skills. It’s not as simple as this because the branching is only visible when PC 1 and PC 2 are examined with PC 3.\nPCA is useful for getting a sense of the variation in a high-dimensional data set. Interpreting the principal components is often useful, but it can be discombobulating. For the aflw data it would be good to think about it as a guide to the main directions of variation and to follow with a more direct engineering of variables into interesting player characteristics. For example, calculate offensive skill as an equal combination of goals, accuracy, shots, behinds. A set of new variables specifically computed to measure particular skills would make explaining an analysis easier.\n\nThe tour verifies that PCA on the aflw data is complicated and doesn’t capture all of the variation. However, it does provide useful insights. It detected outstanding players, and indicated the different skills sets of top goal scorers and top defensive players.",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Principal component analysis</span>"
    ]
  },
  {
    "objectID": "4-pca.html#examining-the-pca-model-in-the-data-space",
    "href": "4-pca.html#examining-the-pca-model-in-the-data-space",
    "title": "\n4  Principal component analysis\n",
    "section": "\n4.2 Examining the PCA model in the data space",
    "text": "4.2 Examining the PCA model in the data space\n\nWhen you choose a smaller number of PCs \\((k)\\) than the number of original variables, this is essentially producing a model for the data. The model is the lower dimensional \\(k\\)-D space. It is analogous to a linear regression model, except that the residuals from the model are \\((p-k)\\)-D.\nIt is common to show the model, that is the data projected into the \\(k\\)-D model space. When \\(k=2\\) this is called a “biplot”. For the plane and plane_noise data the biplots are shown in Figure 4.8. This is useful for checking which variables contribute most to the new principal component variables, and also to check for any problems that might have affected the fit, such as outliers, clusters or non-linearity. Interestingly, biplots are typically only made in 2D, even if the data should be summarised by more than two PCs. Occasionally you will see the biplot made for PC \\(j\\) vs PC \\(k\\) also. With the pca_tour() function in the tourr package you can view a \\(k\\)-D biplot. This will display the \\(k\\) PCs with the axes displaying the original variables, and thus see their contribution to the PCs.\n\nlibrary(ggfortify)\nlibrary(patchwork)\nplane_pca &lt;- prcomp(plane)\npl1 &lt;- autoplot(plane_pca, loadings = TRUE, \n         loadings.label = TRUE) + \n  ggtitle(\"(a)\") +\n  theme_minimal() + \n  theme(aspect.ratio=1)\nplane_noise_pca &lt;- prcomp(plane_noise)\npl2 &lt;- autoplot(plane_noise_pca, loadings = TRUE, \n         loadings.label = TRUE) + \n  ggtitle(\"(b)\") +\n  theme_minimal() + \n  theme(aspect.ratio=1)\npl1 + pl2\n\n\n\n\n\n\nFigure 4.8: Biplots of the plane (a) and plane + noise (b) data. All five variables contribute strongly to the two principal components in (a): PC1 is primarily x1, x2 and x3 and PC2 is primarily x4 and x5. In (b) the same four variables contribute in almost the same way, with variables x6 and x7 contributing very little. The data was constructed this way, that these two dimensions were purely noise.\n\n\n\n\nIt can be useful to examine this model using the tour. The model is simply a plane in high dimensions. This would be considered to be the model in the data space. The reason to do this is to check how well the model fits the data. The plane corresponding to the model should be oriented along the main direction of the points, and the spread of points around the plane should be small. We should also be able to see if there has been any strong non-linear relationship missed by the model, or outliers and clusters.\nThe function pca_model() from the mulgar package can be used to represent the model as a \\(k\\)-D wire-frame plane. Figure 4.9 shows the models for the plane and box data, 2D and 3D respectively.\n\nWe look at the model in the data space to check how well the model fits the data. If it fits well, the points will cluster tightly around the model representation, with little spread in other directions.\n\n\nplane_m &lt;- pca_model(plane_pca)\nplane_m_d &lt;- rbind(plane_m$points, plane)\nanimate_xy(plane_m_d, edges=plane_m$edges,\n           axes=\"bottomleft\",\n           edges.col=\"#E7950F\",\n           edges.width=3)\nrender_gif(plane_m_d, \n           grand_tour(), \n           display_xy(half_range=0.9,\n                      edges=plane_m$edges, \n                      edges.col=\"#E7950F\",\n                      edges.width=3),\n           gif_file=\"gifs/plane_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\nbox_pca &lt;- prcomp(box)\nbox_m &lt;- pca_model(box_pca, d=3)\nbox_m_d &lt;- rbind(box_m$points, box)\nanimate_xy(box_m_d, edges=box_m$edges, \n           axes=\"bottomleft\", edges.col=\"#E7950F\", edges.width=3)\nrender_gif(box_m_d, \n           grand_tour(), \n           display_xy(half_range=0.9,\n                      edges=box_m$edges, \n                      edges.col=\"#E7950F\",\n                      edges.width=3),\n           gif_file=\"gifs/box_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n\n(a) Model for the 2D in 5D data.\n\n\n\n\n\n\n\n\n\n(b) Model for the 3D in 5D data.\n\n\n\n\n\n\nFigure 4.9: PCA model overlaid on the data for the 2D in 5D, and 3D in 5D simulated data.\n\n\n\n4.2.1 Example: pisa\n\nThe model for the pisa data is a 1D vector, shown in Figure 4.10.\n\npisa_model &lt;- pca_model(pisa_pca, d=1, s=2)\n\npisa_all &lt;- rbind(pisa_model$points, pisa_std)\nanimate_xy(pisa_all, edges=pisa_model$edges,\n           edges.col=\"#E7950F\", edges.width=3)\nrender_gif(pisa_all, \n           grand_tour(), \n           display_xy(half_range=0.9,\n                      edges=pisa_model$edges, \n                      edges.col=\"#E7950F\", \n                      edges.width=5),\n           gif_file=\"gifs/pisa_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\n\n\n\n\n\nFigure 4.10: PCA model of the pisa data. The 1D model captures the primary variation in the data and there is a small amount of spread in all directions away from the model.\n\n\n\nThe pisa data fits fairly closely to the 1D PCA model. The variance of points away from the model is symmetric and relatively small. These suggest the 1D model is a reasonably summary of the test scores.\n\n\n4.2.2 Example: aflw\n\nIt is less useful to examine the PCA model for the aflw data, because the main patterns that were of interest were the exceptional players. However, we will do it anyway! Figure 4.11 shows the 4D PCA model overlain on the data. Even though the distribution of points is not as symmetric and balanced as the other examples, we can see that the cube structure mirrors the variation. We can see that the relationships between variables are not strictly linear, because the spread extends unevenly away from the box.\n\naflw_model &lt;- pca_model(aflw_pca, d=4, s=1)\n\naflw_all &lt;- rbind(aflw_model$points, aflw_std[,7:35])\nanimate_xy(aflw_all, edges=aflw_model$edges,\n           edges.col=\"#E7950F\", \n           edges.width=3, \n           half_range=0.8, \n           axes=\"off\")\nrender_gif(aflw_all, \n           grand_tour(), \n           display_xy(half_range=0.8,\n                      edges=aflw_model$edges, \n                      edges.col=\"#E7950F\", \n                      edges.width=3, \n                      axes=\"off\"),\n           gif_file=\"gifs/aflw_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\n\n\n\n\n\nFigure 4.11: PCA model of the aflw data. The linear model is not ideal for this data, which has other patterns like outliers, and some branching. However, the model roughly captures the linear associations, and leaves unequal variation in different directions.\n\n\n\nFrom the tour we see that the 4D model leaves substantial variation unexplained. It is also not symmetric, and there is some larger variation away from the model in some combinations of variables than others.",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Principal component analysis</span>"
    ]
  },
  {
    "objectID": "4-pca.html#when-relationships-are-not-linear",
    "href": "4-pca.html#when-relationships-are-not-linear",
    "title": "\n4  Principal component analysis\n",
    "section": "\n4.3 When relationships are not linear",
    "text": "4.3 When relationships are not linear\n\n4.3.1 Example: outliers\n\nFigure 4.12 shows the scree plot for the planar data with noise and outliers. It is very similar to the scree plot on the data without the outliers (Figure 4.2). However, what we see from Figure 4.13 is that PCA loses the outliers. The animation in (a) shows the full data, and the outliers marked by colour and labels 1, 2, are clearly unusual in some projections. When we examine the tour of the first four PCs (as suggested by the scree plot) the outliers are not unusual. They are almost contained in the point cloud. The reason is clear when all the PCs are plotted, and the outliers can be seen to be clearly detected only in PC5, PC6 and PC7.\n\nplane_n_o_pca &lt;- prcomp(plane_noise_outliers)\nggscree(plane_n_o_pca, q = 7) + theme_minimal()\n\n\n\n\n\n\nFigure 4.12: Scree plot of the planar data with noise and an outlier. It is almost the same as the data without the outliers.\n\n\n\n\n\nCodeclrs &lt;- hcl.colors(12, \"Zissou 1\")\np_col &lt;- c(rep(\"black\", 100), clrs[11], clrs[11])\np_obs_labels &lt;- c(rep(\"\", 100), \"1\", \"2\")\n\nanimate_xy(plane_n_o_pca$x[,1:4],\n           col=p_col,\n           obs_labels=p_obs_labels)\nanimate_xy(plane_noise_outliers,\n           col=p_col,\n           obs_labels=p_obs_labels)\nrender_gif(plane_noise_outliers, \n           grand_tour(), \n           display_xy(half_range=0.8,\n                      col=p_col,\n             obs_labels=p_obs_labels),\n           gif_file=\"gifs/plane_n_o_clr.gif\",\n           frames=500,\n           width=200,\n           height=200,\n           loop=FALSE)\nrender_gif(plane_n_o_pca$x[,1:4], \n           grand_tour(), \n           display_xy(half_range=0.8,\n                      col=p_col,\n             obs_labels=p_obs_labels),\n           gif_file=\"gifs/plane_n_o_pca.gif\",\n           frames=500,\n           width=200,\n           height=200,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n\n\n(a) Outliers clearly visible.\n\n\n\n\n\n\n\n\n\n(b) Outliers not clearly visible in PC1-4.\n\n\n\n\n\n\nFigure 4.13: Examining the handling of outliers in the PCA of the planar data with noise variables and two outliers. PCA has lost these two extreme values.\n\n\n\nCode to make scatterplot matrixlibrary(GGally)\nggscatmat(plane_n_o_pca$x) + theme_minimal()\n\n\n\n\n\n\nFigure 4.14: From the scatterplot matrix we can see that the outliers are present in PC5, PC6 and PC7. That means by reducing the dimensionality to the first four PCs the model has missed some important characteristics in the data.\n\n\n\n\n\n4.3.2 Example: Non-linear associations\n\nFigure 4.16 shows the tour of the full 5D data containing non-linear relationships in comparison with a tour of the first three PCs, as recommended by the scree plot (Figure 4.15). The PCs capture some clear and very clean non-linear relationship, but it looks like it has missed some of the complexities of the relationships. The scatterplot matrix of all 5 PCs (Figure 4.17) shows that PC4 and PC5 contain interesting features: more non-linearity, and curiously an outlier.\n\ndata(plane_nonlin)\nplane_nonlin_pca &lt;- prcomp(plane_nonlin)\nggscree(plane_nonlin_pca, q = 5) + theme_minimal()\n\n\n\n\n\n\nFigure 4.15: Scree plot of the non-linear data suggests three PCs.\n\n\n\n\n\nCode to generate touranimate_xy(plane_nonlin_pca$x[,1:3])\nrender_gif(plane_nonlin_pca$x[,1:3], \n           grand_tour(), \n           display_xy(half_range=0.8),\n           gif_file=\"gifs/plane_nonlin_pca.gif\",\n           frames=500,\n           width=200,\n           height=200)\n\n\n\n\n\n\n\n\n\n\n\n(a) Non-linear relationship between several variables seen in a tour on all five variables.\n\n\n\n\n\n\n\n\n\n(b) The first three principal components reveal a strong non-linear relationship.\n\n\n\n\n\n\nFigure 4.16: Comparison of the full data and first three principal components. Some of the non-linearity is clearly visible in the reduced dimension space, but the full data has more complexities.\n\n\n\nCode to make scatterplot matrixggscatmat(plane_nonlin_pca$x)\n\n\n\n\n\n\nFigure 4.17: From the scatterplot matrix we can see that the there is a non-linear relationship visible in PC1 and PC2, with perhaps a small contribution from PC3. However, we can see that when the data is reduced to three PCs, it misses catching all on the non-linear relationships and also interestingly it seems that there is an unusual observation also.\n\n\n\n\n\nOne of the dangers of PCA is that interesting and curious details of the data only emerge in the lowest PCs, that are usually discarded. The tour, and examining the smaller PCs, can help to discover them.",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Principal component analysis</span>"
    ]
  },
  {
    "objectID": "4-pca.html#exercises",
    "href": "4-pca.html#exercises",
    "title": "\n4  Principal component analysis\n",
    "section": "Exercises",
    "text": "Exercises\n\nMake a scatterplot matrix of the first four PCs of the aflw data. Is the branch pattern visible in any pair?\nConstruct five new variables to measure these skills offense, defense, playing time, ball movement, errors. Using the tour, examine the relationship between these variables. Map out how a few players could be characterised based on these directions of skills.\nSymmetrise any aflw variables that have skewed distributions using a log or square root transformation. Then re-do the PCA. What do we learn that is different about associations between the skill variables?\nExamine the bushfires data using a grand tour on the numeric variables, ignoring the cause (class) variable. Note any issues such as outliers, or skewness that might affect PCA. How many principal components would be recommended by the scree plot? Examine this PCA model with the data, and explain how well it does or doesn’t fit.\nUse the pca_tour to examine the first five PCs of the bushfires data. How do all of the variables contribute to this reduced space?\nReduce the dimension of the sketches data to 12 PCs. How much variation does this explain? Is there any obvious clustering in this lower dimensional space?",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Principal component analysis</span>"
    ]
  },
  {
    "objectID": "4-pca.html#project",
    "href": "4-pca.html#project",
    "title": "\n4  Principal component analysis\n",
    "section": "Project",
    "text": "Project\nLinear dimension reduction can optimise for other criteria, and here we will explore one example: the algorithm implemented in the dobin package finds a basis in which the first few directions are optimized for the detection of outliers in the data. We will examine how it performs for the plane_noise_outliers data (the example where outliers were hidden in the first four principal components.)\n\nStart by looking up the documentation of dobin::dobin. How many parameters does the method depend on?\nWe first apply the function to the plane_noise_outliers data using default values for all parameters.\nRecall that the outliers were added in rows 101 and 102 of the data. Make a scatter plots showing the projection onto the first, second and third component, using color to highlight the outliers. Are they visible as outliers with three components?\nAdjust the frac parameter of the dobin function to frac = 0.99 and repeat the graphical evaluation from point 3. How does it compare to the previous solution?\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Principal component analysis</span>"
    ]
  },
  {
    "objectID": "5-nldr.html",
    "href": "5-nldr.html",
    "title": "\n5  Non-linear dimension reduction\n",
    "section": "",
    "text": "5.1 Explanation of NLDR methods\nNon-linear dimension reduction (NLDR) aims to find a low-dimensional representation of the high-dimensional data that shows the main features of the data. In statistics, it dates back to the work of Kruskal (1964a) on multidimensional scaling (MDS). Some techniques only require an interpoint similarity or distance matrix as the main ingredient, rather than the full data. We’ll focus on when the full data is available here, so we can also compare structure perceived using the tour on the high-dimensional space, relative to structure revealed in the low-dimensional embedding.\nThere are many methods available for generating non-linear low dimensional representations of the data. Classically, MDS minimises some function of the difference between two interpoint distance matrices, the distance between points in the high-dimensions, and in the low-dimensional representations.\n\\[\n\\mbox{Stress}_D(x_1, ..., x_n) = \\left(\\sum_{i, j=1; i\\neq j}^n (d_p(i,j) - d_k(i,j))^2\\right)^{1/2}\n\\] where \\(D\\) is an \\(n\\times n\\) matrix of distances \\((d_p(i,j))\\) between all pairs of points, and \\(d_k(i,j)\\) is the distance between the points in the low-dimensional space. PCA is a special case of MDS. The result from PCA is a linear projection, but generally MDS can provide non-linear transformations to represent unusual high-dimensional patterns. A good resource for learning about MDS is Borg & Groenen (2005).\nCode to generate the 2D non-linear representationlibrary(mulgar)\nlibrary(Rtsne)\nlibrary(uwot)\nlibrary(ggplot2)\nlibrary(patchwork)\nset.seed(42)\ncnl_tsne &lt;- Rtsne(clusters_nonlin)\ncnl_umap &lt;- umap(clusters_nonlin)\nn1 &lt;- ggplot(as.data.frame(cnl_tsne$Y), aes(x=V1, y=V2)) +\n  geom_point() + \n  ggtitle(\"(a) t-SNE\") +\n  theme_minimal() + \n  theme(aspect.ratio=1)\nn2 &lt;- ggplot(as.data.frame(cnl_umap), aes(x=V1, y=V2)) +\n  geom_point() + \n  ggtitle(\"(b) UMAP\") +\n  theme_minimal() + \n  theme(aspect.ratio=1)\nn1 + n2\n\n\n\n\n\n\nFigure 5.1: Two non-linear embeddings of the non-linear clusters data: (a) t-SNE, (b) UMAP. Both suggest four clusters, with two being non-linear in some form.\nPopular methods in current use for NLDR include t-SNE (Maaten & Hinton, 2008) and UMAP (McInnes et al., 2018). The approach of t-SNE is to compare interpoint distances with a standard probability distribution (eg \\(t\\)-distribution) to exaggerate local neighbourhood differences. UMAP compares the interpoint distances with what might be expected if the data was uniformly distributed in the high-dimensions.\nFigure 5.1 shows two NLDR views of the clusters_nonlin data set from the mulgar package. Both suggest that there are four clusters, and that some clusters are non-linearly shaped. They disagree on the type of non-linear pattern, where t-SNE represents one cluster as a wavy-shape and UMAP both have a simple parabolic shape.\nThe full 4D data is shown with a grand tour in Figure 5.2. The four clusters suggested by the NLDR methods can be seen. We also get a better sense of the relative size and proximity of the clusters. There are two small spherical clusters, one quite close to the end of the large sine wave cluster. The fourth cluster is relatively small, and has a slight curve, like a bent rod. The t-SNE representation is slightly more accurate than the UMAP representation. We would expect that the wavy cluster is the sine wave seen in the tour.",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-linear dimension reduction</span>"
    ]
  },
  {
    "objectID": "5-nldr.html#explanation-of-nldr-methods",
    "href": "5-nldr.html#explanation-of-nldr-methods",
    "title": "\n5  Non-linear dimension reduction\n",
    "section": "",
    "text": "Figure 5.2: Grand tour of the nonlinear clusters data set, shows four clusters. Two are very small and spherical in shape. One is large, and has a sine wave shape, and the other is fairly small with a bent rod shape.\n\n\n\n\nNLDR can provide useful low-dimensional summaries of high-dimensional structure but you need to check whether it is a sensible and accurate representation by comparing with what is perceived from a tour.",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-linear dimension reduction</span>"
    ]
  },
  {
    "objectID": "6-intro-clust.html",
    "href": "6-intro-clust.html",
    "title": "\n6  Overview\n",
    "section": "",
    "text": "6.1 What are clusters?\nUnsupervised classification, or cluster analysis, organizes observations into similar groups. Cluster analysis is a commonly used, appealing, and conceptually intuitive statistical method. Some of its uses include market segmentation, where customers are grouped into clusters with similar attributes for targeted marketing; gene expression analysis, where genes with similar expression patterns are grouped together; and the creation of taxonomies for animals, insects, or plants. Clustering can be used as a way of reducing a massive amount of data because observations within a cluster can be summarized by its centre. Also, clustering effectively subsets the data thus simplifying analysis because observations in each cluster can be analyzed separately.\nOrganizing objects into groups is a common task to help make sense of the world around us. Perhaps this is why it is an appealing method of data analysis. However, cluster analysis is more complex than it initially appears. Many people imagine that it will produce neatly separated clusters like those in Figure 6.1(a), but it almost never does. Such ideal clusters are rarely encountered in real data, so we often need to modify our objective from find the natural clusters in this data. Instead, we need to organize the cases into groups that are similar in some way. Even though this may seem disappointing when compared with the ideal, it is still often an effective means of simplifying and understanding a dataset.\nFigure 6.1: Different structures in data impact cluster analysis. When there are well-separated groups (a), it is simple to group similar observations. Even when there are not, partitioning observations into groups may still be useful. There may be nuisance observations (b) or nuisance variables (c) that affect the interpoint distance calculations and distract the clustering algorithm, and there may oddly shaped clusters (d) which are hard to numerically describe.\nAt the heart of the clustering process is the work of discovering which variables are most important for defining the groups. It is often true that we only require a subset of the variables for finding clusters, whereas another subset (called nuisance variables) has no impact. In the bottom left plot of Figure 6.1, it is clear that the variable plotted horizontally is important for splitting this data into two clusters, whereas the variable plotted vertically is a nuisance variable. Nuisance is an apt term for these variables, because they can radically change the interpoint distances and impair the clustering process.\nDynamic graphical methods help us to find and understand the cluster structure in high dimensions. With the tools in our toolbox, primarily tours, along with linked scatterplots and parallel coordinate plots, we can see clusters in high-dimensional spaces. We can detect gaps between clusters, the shape and relative positions of clusters, and the presence of nuisance variables. We can even find unusually shaped clusters, like those in the bottom right plot in Figure 6.1. In simple situations we can use graphics alone to group observations into clusters, using a “spin and brush” method. In more difficult data problems, we can assess and refine numerical solutions using graphics.\nThis part of the book discusses the use of interactive and dynamic graphics in the clustering of data. Section 6.2 introduces cluster analysis, focusing on interpoint distance measures. Chapter 7 describes an example of a purely graphical approach to cluster analysis, the spin and brush method. In the example shown in that section, we were able to find simplifications of the data that had not been found using numerical clustering methods, and to find a variety of structures in high-dimensional space. Chapter 8 describes methods for reducing the interpoint distance matrix to an intercluster distance matrix using hierarchical algorithms, Chapter 10 covers model-based clustering, and Chapter 11 described clustering with self-organising maps. Each of these chapters shows how graphical tools can be used to assess the results of numerical methods. Chapter 12 summarizes the chapter and revisits the data analysis strategies used in the examples. Additional references that provide good companions to the material presented in these chapters are Venables & Ripley (2002a), Boehmke & Greenwell (2019), Hennig et al. (2015), Giordani et al. (2020), Kassambara (2017), and the CRAN Task View (Gruen, 2024). Chapter 12 summarizes the chapter and revisits the data analysis strategies used in the examples.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to clustering</span>"
    ]
  },
  {
    "objectID": "6-intro-clust.html#what-are-clusters",
    "href": "6-intro-clust.html#what-are-clusters",
    "title": "\n6  Overview\n",
    "section": "",
    "text": "Knowing what shapes are in your data helps to decide on the best method and to diagnose the result. For example, if the clusters are elliptical model-based clustering is recommended.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to clustering</span>"
    ]
  },
  {
    "objectID": "6-intro-clust.html#sec-clust-bg",
    "href": "6-intro-clust.html#sec-clust-bg",
    "title": "\n6  Overview\n",
    "section": "\n6.2 The importance of defining similar",
    "text": "6.2 The importance of defining similar\nBefore we can begin finding groups of cases that are similar1, we need to decide how to define or measure whether they are close together or far apart. Consider a dataset with three cases \\((a_1, a_2, a_3)\\) and four variables \\((V_1, V_2, V_3, V_4)\\), described in matrix format as\n\\[\\begin{align*}\nX = \\begin{bmatrix}\n& {\\color{grey} V_1} & {\\color{grey} V_2} & {\\color{grey} V_3} & {\\color{grey} V_4} \\\\\\hline\n{\\color{grey} a_1} | & x_{11} & x_{12} & x_{13} & x_{14} \\\\\n{\\color{grey} a_2} | & x_{21} & x_{22} & x_{23} & x_{24} \\\\\n{\\color{grey} a_3} | & x_{31} & x_{32} & x_{33} & x_{34}    \n\\end{bmatrix}\n=  \\begin{bmatrix}\n& {\\color{grey} V_1} & {\\color{grey} V_2} & {\\color{grey} V_3} & {\\color{grey} V_4} \\\\\\hline\n{\\color{grey} a_1} | & 7.3 & 7.6 & 7.7 & 8.0 \\\\\n{\\color{grey} a_2} | & 7.4 & 7.2 & 7.3 & 7.2 \\\\\n{\\color{grey} a_3} | & 4.1 & 4.6 & 4.6 & 4.8\n\\end{bmatrix}\n\\end{align*}\\]\nwhich is plotted in Figure 6.2. The Euclidean distance between two cases (rows of the matrix) with \\(p\\) elements is defined as\n\\[\\begin{align*}\nd_{\\rm Euc}(a_i,a_j) &=& ||a_i-a_j|| %\\\\\n% &=& \\sqrt{(x_{i1}-x_{j1})^2+\\dots + (x_{ip}-x_{jp})^2},\n~~~~~~i,j=1,\\dots, n,\n\\end{align*}\\]\nwhere \\(||x_i||=\\sqrt{x_{i1}^2+x_{i2}^2+\\dots +x_{ip}^2}\\). For example, the Euclidean distance between cases 1 and 2 in the above data, is\n\\[\\begin{align*}\nd_{\\rm Euc}(a_1,a_2) &= \\sqrt{(7.3-7.4)^2+(7.6-7.2)^2+ (7.7-7.3)^2+(8.0-7.2)^2} \\\\\n&= 1.0\n\\end{align*}\\]\n\nFor the three cases, the interpoint Euclidean distance matrix is\n\n\\[\n\\require{mathtools}\n\\definecolor{grey}{RGB}{192, 192, 192}\n\\]\n\n\\[\\begin{align*}\nd_{\\rm Euc} = \\begin{bmatrix}\n& {\\color{grey} a_1} & {\\color{grey} a_2} & {\\color{grey} a_3} \\\\\\hline\n{\\color{grey} a_1} | & 0.0 & 1.0 & 6.3 \\\\\n{\\color{grey} a_2} | & 1.0 & 0.0 & 5.5 \\\\\n{\\color{grey} a_3} | & 6.3 & 5.5 & 0.0\n\\end{bmatrix}\n\\end{align*}\\]\nCode for plotx &lt;- data.frame(V1 = c(7.3, 7.4, 4.1),\n                    V2 = c(7.6, 7.2, 4.6),\n                    V3 = c(7.7, 7.3, 4.6),\n                    V4 = c(8.0, 7.2, 4.8),\n                    point = factor(c(\"a1\", \"a2\", \"a3\")))\nlibrary(GGally)\nlibrary(colorspace)\nlibrary(gridExtra)\npscat &lt;- ggpairs(x, columns=1:4,\n                 upper=list(continuous=\"points\"),\n                 diag=list(continuous=\"blankDiag\"),\n                 axisLabels=\"internal\",\n                 ggplot2::aes(colour=point)) +\n    scale_colour_discrete_divergingx(\n      palette = \"Zissou 1\", nmax=4) +\n    xlim(3.7, 8.5) + ylim(3.7, 8.5) + \n    theme_minimal() +\n    theme(aspect.ratio=1)\npscat\nppar &lt;- ggparcoord(x, columns=1:4, \n                   groupColumn = 5, \n                   scale = \"globalminmax\") +\n    scale_colour_discrete_divergingx(\n      palette = \"Zissou 1\", nmax=4) +\n  xlab(\"\") + ylab(\"\") + \n  theme_minimal() + \n  theme(axis.ticks.y = element_blank(),\n        axis.text.y = element_blank(),\n        legend.title = element_blank())\nppar\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.2: The scatterplot matrix (left) shows that cases \\(a_1\\) and \\(a_2\\) have similar values. The parallel coordinate plot (right) allows a comparison of other structure, which shows the similarity in the trend of the profiles on cases \\(a_1\\) and \\(a_3\\).\n\n\nCases \\(a_1\\) and \\(a_2\\) are more similar to each other than they are to case \\(a_3\\), because the Euclidean distance between cases \\(a_1\\) and \\(a_2\\) is much smaller than the distance between cases \\(a_1\\) and \\(a_3\\) and between cases \\(a_2\\) and \\(a_3\\).\nThere are many different ways to calculate similarity. Similarity measures based on correlation distance can be useful. It is typically used where similarity of structure or shape is more important than similarity in magnitude.\n\nAs an example, see the parallel coordinate plot of the sample data at the right of Figure 6.2. Cases \\(a_1\\) and \\(a_3\\) are widely separated, but their shapes are similar (low, medium, medium, high). Case \\(a_2\\), although overlapping with case \\(a_1\\), has a very different shape (high, medium, medium, low). The Pearson correlation between two cases, \\(\\rho(a_i,a_j)\\), is defined as\n\\[\\begin{align*}\n\\rho(a_i,a_j) = \\frac{(a_i-c_i)^\\top(a_j-c_j)}\n{\\sqrt(a_i-c_i)^\\top(a_i-c_i) \\sqrt(a_j-c_j)^\\top(a_j-c_j)}\n\\label{corc}\n\\end{align*}\\]\nTypically, \\(c_i, c_j\\) are the sample means of each case, \\(\\bar{a}_i,\\bar{a}_j\\). For these three observations, \\(c_1=\\bar{a}_1=7.650, c_2=\\bar{a}_2=7.275, c_3=\\bar{a}_3=4.525\\). An interesting geometric fact, is that if \\(c_i, c_j\\) are set to be 0, as is commonly done, \\(\\rho\\) is a generalized correlation that describes the angle between the two data vectors. The correlation is then converted to a distance metric, with one possibility being as follows:\n\\[\\begin{align*}\nd_{\\rm Cor}(a_i,a_j) = \\sqrt{2(1-\\rho(a_i,a_j))}\n\\end{align*}\\]\nThis distance metric will treat cases that are strongly negatively correlated as the most distant. If you want to consider strong negative correlation as close, then you could take the absolute value of \\(\\rho(a_i,a_j)\\) in the above equation, and remove the multiplication by 2.\nThe interpoint distance matrix for the sample data using \\(d_{\\rm Cor}\\) and the Pearson correlation coefficient is\n\\[\\begin{align*}\nd_{\\rm Cor} = \\begin{bmatrix}\n& {\\color{grey} a_1} & {\\color{grey} a_2} & {\\color{grey} a_3} \\\\\\hline\n{\\color{grey} a_1} | & 0.0 & 3.6 & 0.1 \\\\\n{\\color{grey} a_2} | & 3.6 & 0.0 & 3.8 \\\\\n{\\color{grey} a_3} | & 0.1 & 3.8 & 0.0\n\\end{bmatrix}\n\\end{align*}\\]\nBy this metric, cases \\(a_1\\) and \\(a_3\\) are the most similar, because the correlation distance is smaller between these two cases than the other pairs of cases. \nNote that these interpoint distances differ dramatically from those for Euclidean distance. As a consequence, the way the cases would be clustered is also very different. Choosing the appropriate distance measure is an important part of a cluster analysis.\nAfter a distance metric has been chosen and a cluster analysis has been performed, the analyst must evaluate the results, and this is actually a difficult task. A cluster analysis does not generate \\(p\\)-values or other numerical criteria, and the process tends to produce hypotheses rather than testing them. Even the most determined attempts to produce the “best” results using modeling and validation techniques may result in clusters that, although seemingly significant, are useless for practical purposes. As a result, cluster analysis is best thought of as an exploratory technique, and it can be quite useful despite the lack of formal validation because of its power in data simplification.\n\nDefining an appropriate distance metric from the context of the problem is a most important decision. For example, if your variables are all numeric, and on the same scale then Euclidean distance might be best. If your variables are categorical, you might need to use something like Hamming distance.\n\nThe context in which the data arises is the key to assessing the results. If the clusters can be characterized in a sensible manner, and they increase our knowledge of the data, then we are on the right track. To use an even more pragmatic criterion, if a company can gain an economic advantage by using a particular clustering method to carve up their customer database, then that is the method they should use.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to clustering</span>"
    ]
  },
  {
    "objectID": "6-intro-clust.html#exercises",
    "href": "6-intro-clust.html#exercises",
    "title": "\n6  Overview\n",
    "section": "Exercises",
    "text": "Exercises\nUse the following data to answer these questions:\n\n\n     x1   x2   x3\na1 0.13 0.21 0.09\na2 0.91 0.95 0.85\na3 0.62 0.73 0.65\na4 0.21 0.92 0.43\n\n\n\nCompute the Euclidean distance between cases a1, a2, a3, a4.\nCompute the correlation distance (as defined above) between cases a1, a2, a3, a4.\nWhich two points have the (a) biggest (b) smallest Mahalanobis (statistical) distance, assuming that the covariance matrix is:\n\n\n\n    x1  x2  x3\nx1 1.0 0.8 0.8\nx2 0.8 1.0 0.8\nx3 0.8 0.8 1.0\n\n\n(The function mahalanobis will calculate this in R. Technically this gives distance between each case and the mean vector.)\n\nIs the ordering of distance between cases the same if Manhattan distance is used instead of Euclidean?\nCompute the Chebychev distance between cases a1, a2, a3, a4.\nCompute Bray-Curtis distance between cases a1, a2, a3, a4.\nMake a plot of the data, and write a paragraph describing how the different distance metrics agree and disagree on how close or far the cases are from each other.\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to clustering</span>"
    ]
  },
  {
    "objectID": "6-intro-clust.html#footnotes",
    "href": "6-intro-clust.html#footnotes",
    "title": "\n6  Overview\n",
    "section": "",
    "text": "Both similarity and dissimilarity measures are used for defining how similar cases are. It can be confusing! They measure similar in opposite directions. With a dissimilarity measure, a smaller number means the cases are closer, as in a distance metric. A similarity measure usually ranges between 0 and 1, with 1 indicating that the cases are closer, for example, correlation.↩︎",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to clustering</span>"
    ]
  },
  {
    "objectID": "7-spin-and-brush.html",
    "href": "7-spin-and-brush.html",
    "title": "7  Spin-and-brush approach",
    "section": "",
    "text": "Exercises\nSeveral examples of the spin-and-brush approach are documented in the literature, such as Cook et al. (1995a) and Wilhelm et al. (1999). The steps are:\nSpin-and-brush is useful for exploring clustering when the data is numeric, and contains well-separated clusters. Patterns that adversely affect numerical techniques, such as nuisance variables or cases, differences in variances or shapes between clusters, don’t pose any problems for spin-and-brush. It is also effective if the data has connected low-dimensional (1D or 2D) clusters in high dimensions.\nIt will not work very well when there are no distinct clusters and the purpose of clustering is to partition the data into subsets. Here, you could begin with a solution provided by some numerical clustering algorithm, and to use visual tools to evaluate it, with goal of refining the results.\nWith a complex problem where there are many clusters, one can work sequentially, and remove each cluster after it is brushed, to de-clutter the display, in order to find more clusters.\nSpin-and-brush is best achieved using a fully interactive graphics system like in the detourr package, where the results can be saved for further analysis. The code is very easy, and then all the controls are interactive.\nFigure 7.1 shows the stages of spin-and-brush on the penguins data using detourr. The final results can be examined and used for later analysis. Because this data came with a class variable, the penguin species, it is interesting to see how close the spin-and-brush clustering approach came to recovering these:\nIt’s quite close! All but two of the 119 Gentoo penguins were identified as a cluster (labelled as “3e9eb6” from the chosen light blue hex colour), and all but three of the 146 Adelie penguins were identified as a cluster, (labelled as “000000” which is the unbrushed black group). Most of the Chinstrap species were recovered also (labelled as “f5191c” for the red hex colour).\nlibrary(detourr)\n\n# Use a random starting basis because the first two variables make it too easy\nstrt &lt;- tourr::basis_random(10, 2)\ndetour(multicluster, \n       tour_aes(projection = -group)) |&gt;\n       tour_path(grand_tour(2), start=strt, fps = 60) |&gt;\n       show_scatter(alpha = 0.7, axes = FALSE)\nYou can use the download button to save the data with the colours. Tabulate the branches id variable in the original data with the colour groups created from brushing, to see how closely you have recovered the original classes.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spin-and-brush approach</span>"
    ]
  },
  {
    "objectID": "7-spin-and-brush.html#exercises",
    "href": "7-spin-and-brush.html#exercises",
    "title": "7  Spin-and-brush approach",
    "section": "",
    "text": "Use the spin-and-brush approach to identify the three clusters in the mulgar::clusters data set.\nUse the spin-and-brush approach to identify the six clusters in the mulgar::multicluster data set. (The code below using detourr could be useful.)\nUse spin-and-brush on the challenge data sets, c1-c7 from the mulgar package. How many clusters do you detect in each?\n\n\n\nUse the spin-and-brush technique to identify the branches of the fake_trees data. The result should look something like this:\n\n\n\n\n\n\nFigure 7.2: Example solution after spin-and-brush on fake trees data.\n\n\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spin-and-brush approach</span>"
    ]
  },
  {
    "objectID": "8-hierarchical.html",
    "href": "8-hierarchical.html",
    "title": "8  Hierarchical clustering",
    "section": "",
    "text": "8.1 Overview\nHierarchical cluster algorithms sequentially fuse neighboring points to form ever-larger clusters, starting from a full interpoint distance matrix. Distance between clusters is described by a “linkage method”, of which there are many. For example, single linkage measures the distance between clusters by the smallest interpoint distance between the members of the two clusters, complete linkage uses the maximum interpoint distance, and average linkage uses the average of the interpoint distances. Wards linkage, which usually produces the best clustering solutions, defines the distance as the reduction in the within-group variance. A good discussion on cluster analysis and linkage can be found in Boehmke & Greenwell (2019), on Wikipedia or any multivariate textbook.\nHere we will take a look at hierarchical clustering, using Wards linkage, on the simple_clusters data. The steps taken are to:\nLoad librarieslibrary(ggplot2)\nlibrary(mulgar)\nlibrary(ggdendro)\nlibrary(dplyr)\nlibrary(patchwork)\nlibrary(tourr)\nlibrary(plotly)\nlibrary(htmlwidgets)\nlibrary(colorspace)\nlibrary(GGally)\ndata(simple_clusters)\n\n# Compute hierarchical clustering with Ward's linkage\ncl_hw &lt;- hclust(dist(simple_clusters[,1:2]),\n                method=\"ward.D2\")\ncl_ggd &lt;- dendro_data(cl_hw, type = \"triangle\")\n\n# Compute dendrogram in the data\ncl_hfly &lt;- hierfly(simple_clusters, cl_hw, scale=FALSE)\n\n# Show result\nsimple_clusters &lt;- simple_clusters %&gt;%\n  mutate(clw = factor(cutree(cl_hw, 2)))\nFigure 8.1 illustrates the hierarchical clustering approach for a simple simulated data set (a) with two well-separated clusters in 2D. The dendrogram (b) is a representation of the order that points are joined into clusters. The dendrogram strongly indicates two clusters because the two branches representing the last join are much longer than all of the other branches.\nAlthough, the dendrogram is usually a good summary of the steps taken by the algorithm, it can be misleading. The dendrogram might indicate a clear clustering (big differences in heights of branches) but the result may be awful. You need to check this by examining the result on the data, called model-in-the-data space by Wickham et al. (2015).\nPlot (c) shows the dendrogram in 2D, overlaid on the data. The segments show how the points are joined to make clusters. In order to represent the dendrogram this way, new points (represented by a “+” here) need to be added corresponding to the centroid of groups of points that have been joined. These are used to draw the segments between other points and other clusters. We can see that the longest (two) edges stretches across the gap between the two clusters. This corresponds to the top of the dendrogram, the two long branches where we would cut it to make the two-cluster solution. This two-cluster solution is shown in plot (d).\nCode to make the four plots# Plot the data\npd &lt;- ggplot(simple_clusters, aes(x=x1, y=x2)) +\n  geom_point(colour=\"#3B99B1\", size=2, alpha=0.8) +\n  ggtitle(\"(a)\") + \n  theme_minimal() +\n  theme(aspect.ratio=1) \n\n# Plot the dendrogram\nph &lt;- ggplot() +\n  geom_segment(data=cl_ggd$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=cl_ggd$labels, aes(x=x, y=y),\n             colour=\"#3B99B1\", alpha=0.8) +\n  ggtitle(\"(b)\") + \n  theme_minimal() +\n  theme_dendro()\n\n# Plot the dendrogram on the data\npdh &lt;- ggplot() +\n  geom_segment(data=cl_hfly$segments, \n                aes(x=x, xend=xend,\n                    y=y, yend=yend)) +\n  geom_point(data=cl_hfly$data, \n             aes(x=x1, y=x2,\n                 shape=factor(node),\n                 colour=factor(node),\n                 size=1-node), alpha=0.8) +\n  xlab(\"x1\") + ylab(\"x2\") +\n  scale_shape_manual(values = c(16, 3)) +\n  scale_colour_manual(values = c(\"#3B99B1\", \"black\")) +\n  scale_size(limits=c(0,17)) +\n  ggtitle(\"(c)\") + \n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Plot the resulting clusters\npc &lt;- ggplot(simple_clusters) +\n  geom_point(aes(x=x1, y=x2, colour=clw), \n             size=2, alpha=0.8) +\n  scale_colour_discrete_divergingx(palette = \"Zissou 1\",\n                                   nmax=5, rev=TRUE) +\n  ggtitle(\"(d)\") + \n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\npd + ph + pdh + pc + plot_layout(ncol=2)\n\n\n\n\n\n\nFigure 8.1: Hierarchical clustering on simulated data: (a) data, (b) dendrogram, (c) dendrogram on the data, and (d) two cluster solution. The extra points corresponding to nodes of the dendrogram are indicated by + in (c). The last join in the dendrogram (b), can be seen to correspond to the edges connecting the gap, when displayed with the data (c). The other joins can be seen to be pulling together points within each clump.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hierarchical clustering</span>"
    ]
  },
  {
    "objectID": "8-hierarchical.html#overview",
    "href": "8-hierarchical.html#overview",
    "title": "8  Hierarchical clustering",
    "section": "",
    "text": "Hierarchical clustering is summarised by a dendrogram, which sequentially shows points being joined to form a cluster, with the corresponding distances. Breaking the data into clusters is done by cutting the dendrogram at the long edges.\n\n\n\nPlot the data to check for presence of clusters and their shape.\nCompute the hierarchical clustering.\nPlot the dendrogram to help decide on an appropriate number of clusters, using the dendro_data function from the ggdendro package.\nShow the dendrogram overlaid on the data, calculated by the hierfly function in mulgar.\nPlot the clustering result, by colouring points in the plot of the data.\n\n\n\n\n\n\n\n\n\nPlotting the dendrogram in the data space can help you understand how the hierarchical clustering has collected the points together into clusters. You can learn if the algorithm has been confused by nuisance patterns in the data, and how different choices of linkage method affects the result.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hierarchical clustering</span>"
    ]
  },
  {
    "objectID": "8-hierarchical.html#common-patterns-which-confuse-clustering-algorithms",
    "href": "8-hierarchical.html#common-patterns-which-confuse-clustering-algorithms",
    "title": "8  Hierarchical clustering",
    "section": "\n8.2 Common patterns which confuse clustering algorithms",
    "text": "8.2 Common patterns which confuse clustering algorithms\nFigure 8.2 shows two examples of structure in data that will confuse hierarchical clustering: nuisance variables and nuisance cases. We usually do not know that these problems exist prior to clustering the data. Discovering these iteratively as you conduct a clustering analysis is important for generating useful results.\n\nCode to make plots# Nuisance observations\nset.seed(20190514)\nx &lt;- (runif(20)-0.5)*4\ny &lt;- x\nd1 &lt;- data.frame(x1 = c(rnorm(50, -3), \n                            rnorm(50, 3), x),\n                 x2 = c(rnorm(50, -3), \n                            rnorm(50, 3), y),\n                 cl = factor(c(rep(\"A\", 50), \n                             rep(\"B\", 70))))\nd1 &lt;- d1 %&gt;% \n  mutate_if(is.numeric, function(x) (x-mean(x))/sd(x))\npd1 &lt;- ggplot(data=d1, aes(x=x1, y=x2)) + \n  geom_point() +\n    ggtitle(\"Nuisance observations\") + \n  theme_minimal() +\n    theme(aspect.ratio=1) \n\n# Nuisance variables\nset.seed(20190512)\nd2 &lt;- data.frame(x1=c(rnorm(50, -4), \n                            rnorm(50, 4)),\n                 x2=c(rnorm(100)),\n                 cl = factor(c(rep(\"A\", 50), \n                             rep(\"B\", 50))))\nd2 &lt;- d2 %&gt;% \n  mutate_if(is.numeric, function(x) (x-mean(x))/sd(x))\npd2 &lt;- ggplot(data=d2, aes(x=x1, y=x2)) + \n  geom_point() +\n    ggtitle(\"Nuisance variables\") + \n  theme_minimal() +\n    theme(aspect.ratio=1)\n\npd1 + pd2 + plot_layout(ncol=2)\n\n\n\n\n\n\nFigure 8.2: Two examples of data structure that causes problems for hierarchical clustering. Nuisance observations can cause problems because the close observations between the two clusters can cause some chaining in the hierarchical joining of observations. Nuisance variables can cause problems because observations across the gap can seem closer than observations at the end of each cluster.\n\n\n\n\nIf an outlier is a point that is extreme relative to other observations, an “inlier” is a point that is extreme relative to a cluster, but inside the domain of all of the observations. Nuisance observations are inliers, cases that occur between larger groups of points. If they were excluded there might be a gap between clusters. These can cause problems for clustering when distances between clusters are measured, and can be very problematic when single linkage hierarchical clustering is used. Figure 8.3 shows how nuisance observations affect single linkage but not Wards linkage hierarchical clustering.\n\nCode to make plots# Compute single linkage\nd1_hs &lt;- hclust(dist(d1[,1:2]),\n                method=\"single\")\nd1_ggds &lt;- dendro_data(d1_hs, type = \"triangle\")\npd1s &lt;- ggplot() +\n  geom_segment(data=d1_ggds$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=d1_ggds$labels, aes(x=x, y=y),\n             colour=\"#3B99B1\", alpha=0.8) +\n  theme_minimal() +\n  ggtitle(\"(a) Single linkage dendrogram\") +\n  theme_dendro()\n\n# Compute dendrogram in data\nd1_hflys &lt;- hierfly(d1, d1_hs, scale=FALSE)\n\npd1hs &lt;- ggplot() +\n  geom_segment(data=d1_hflys$segments, \n                aes(x=x, xend=xend,\n                    y=y, yend=yend)) +\n  geom_point(data=d1_hflys$data, \n             aes(x=x1, y=x2,\n                 shape=factor(node),\n                 colour=factor(node),\n                 size=1-node), alpha=0.8) +\n  scale_shape_manual(values = c(16, 3)) +\n  scale_colour_manual(values = c(\"#3B99B1\", \"black\")) +\n  scale_size(limits=c(0,17)) +\n  ggtitle(\"(b) Dendrogram in data space\") + \n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Show result\nd1 &lt;- d1 %&gt;%\n  mutate(cls = factor(cutree(d1_hs, 2)))\npc_d1s &lt;- ggplot(d1) +\n  geom_point(aes(x=x1, y=x2, colour=cls), \n             size=2, alpha=0.8) +\n  scale_colour_discrete_divergingx(palette = \"Zissou 1\",\n                                   nmax=4, rev=TRUE) +\n  ggtitle(\"(c) Two-cluster solution\") + \n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Compute Wards linkage\nd1_hw &lt;- hclust(dist(d1[,1:2]),\n                method=\"ward.D2\")\nd1_ggdw &lt;- dendro_data(d1_hw, type = \"triangle\")\npd1w &lt;- ggplot() +\n  geom_segment(data=d1_ggdw$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=d1_ggdw$labels, aes(x=x, y=y),\n             colour=\"#3B99B1\", alpha=0.8) +\n  ggtitle(\"(d) Ward's linkage dendrogram\") +\n  theme_minimal() +\n  theme_dendro()\n\n# Compute dendrogram in data\nd1_hflyw &lt;- hierfly(d1, d1_hw, scale=FALSE)\n\npd1hw &lt;- ggplot() +\n  geom_segment(data=d1_hflyw$segments, \n                aes(x=x, xend=xend,\n                    y=y, yend=yend)) +\n  geom_point(data=d1_hflyw$data, \n             aes(x=x1, y=x2,\n                 shape=factor(node),\n                 colour=factor(node),\n                 size=1-node), alpha=0.8) +\n  scale_shape_manual(values = c(16, 3)) +\n  scale_colour_manual(values = c(\"#3B99B1\", \"black\")) +\n  scale_size(limits=c(0,17)) +\n  ggtitle(\"(e) Dendrogram in data space\") + \n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Show result\nd1 &lt;- d1 %&gt;%\n  mutate(clw = factor(cutree(d1_hw, 2)))\npc_d1w &lt;- ggplot(d1) +\n  geom_point(aes(x=x1, y=x2, colour=clw), \n             size=2, alpha=0.8) +\n  scale_colour_discrete_divergingx(palette = \"Zissou 1\",\n                                   nmax=4, rev=TRUE) +\n  ggtitle(\"(f) Two-cluster solution\") + \n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\npd1s + pd1hs + pc_d1s + \n  pd1w + pd1hw + pc_d1w +\n  plot_layout(ncol=3)\n\n\n\n\n\n\nFigure 8.3: The effect of nuisance observations on single linkage (a, b, c) and Ward’s linkage hierarchical clustering (d, e, f). The single linkage dendrogram is very different to the Wards linkage dendrogram. When plotted with the data (b) we can see a pin cushion or asterisk pattern, where points are joined to others through a place in the middle of the line of nuisance observations. This results in the bad two cluster solution of a singleton cluster, and all the rest. Conversely, Ward’s dendrogram (d) strongly suggests two clusters, although the final join corresponds to just a small gap when shown on the data (e) but results in two sensible clusters.\n\n\n\n\nNuisance variables are ones that do not contribute to the clustering, such as x2 here. When we look at this data we see a gap between two elliptically shape clusters, with the gap being only in the horizontal direction, x1. When we compute the distances between points, in order to start clustering, without knowing that x2 is a nuisance variable, points across the gap might be considered to be closer than points within the same cluster. Figure 8.4 shows how nuisance variables affects complete linkage but not Wards linkage hierarchical clustering. (Wards linkage can be affected but it isn’t for this data.) Interestingly, the dendrogram for complete linkage looks ideal, that it suggests two clusters. It is not until you examine the resulting clusters in the data that you can see the error, that it has clustered across the gap.\n\nCode# Compute complete linkage\nd2_hc &lt;- hclust(dist(d2[,1:2]),\n                method=\"complete\")\nd2_ggdc &lt;- dendro_data(d2_hc, type = \"triangle\")\npd2c &lt;- ggplot() +\n  geom_segment(data=d2_ggdc$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=d2_ggdc$labels, aes(x=x, y=y),\n             colour=\"#3B99B1\", alpha=0.8) +\n  ggtitle(\"(a) Complete linkage dendrogram\") +\n  theme_minimal() +\n  theme_dendro()\n\n# Compute dendrogram in data\nd2_hflyc &lt;- hierfly(d2, d2_hc, scale=FALSE)\n\npd2hc &lt;- ggplot() +\n  geom_segment(data=d2_hflyc$segments, \n                aes(x=x, xend=xend,\n                    y=y, yend=yend)) +\n  geom_point(data=d2_hflyc$data, \n             aes(x=x1, y=x2,\n                 shape=factor(node),\n                 colour=factor(node),\n                 size=1-node), alpha=0.8) +\n  scale_shape_manual(values = c(16, 3)) +\n  scale_colour_manual(values = c(\"#3B99B1\", \"black\")) +\n  scale_size(limits=c(0,17)) +\n  ggtitle(\"(b) Dendrogram in data space\") + \n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Show result\nd2 &lt;- d2 %&gt;%\n  mutate(clc = factor(cutree(d2_hc, 2)))\npc_d2c &lt;- ggplot(d2) +\n  geom_point(aes(x=x1, y=x2, colour=clc), \n             size=2, alpha=0.8) +\n  scale_colour_discrete_divergingx(palette = \"Zissou 1\",\n                                   nmax=4, rev=TRUE) +\n  ggtitle(\"(c) Two-cluster solution\") + \n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Compute Wards linkage\nd2_hw &lt;- hclust(dist(d2[,1:2]),\n                method=\"ward.D2\")\nd2_ggdw &lt;- dendro_data(d2_hw, type = \"triangle\")\npd2w &lt;- ggplot() +\n  geom_segment(data=d2_ggdw$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=d2_ggdw$labels, aes(x=x, y=y),\n             colour=\"#3B99B1\", alpha=0.8) +\n  ggtitle(\"(d) Ward's linkage dendrogram\") +\n  theme_minimal() +\n  theme_dendro()\n\n# Compute dendrogram in data\nd2_hflyw &lt;- hierfly(d2, d2_hw, scale=FALSE)\n\npd2hw &lt;- ggplot() +\n  geom_segment(data=d2_hflyw$segments, \n                aes(x=x, xend=xend,\n                    y=y, yend=yend)) +\n  geom_point(data=d2_hflyw$data, \n             aes(x=x1, y=x2,\n                 shape=factor(node),\n                 colour=factor(node),\n                 size=1-node), alpha=0.8) +\n  scale_shape_manual(values = c(16, 3)) +\n  scale_colour_manual(values = c(\"#3B99B1\", \"black\")) +\n  scale_size(limits=c(0,17)) +\n  ggtitle(\"(e) Dendrogram in data space\") + \n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Show result\nd2 &lt;- d2 %&gt;%\n  mutate(clw = factor(cutree(d2_hw, 2)))\npc_d2w &lt;- ggplot(d2) +\n  geom_point(aes(x=x1, y=x2, colour=clw), \n             size=2, alpha=0.8) +\n  scale_colour_discrete_divergingx(palette = \"Zissou 1\",\n                                   nmax=4, rev=TRUE) +\n  ggtitle(\"(f) Two-cluster solution\") + \n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\npd2c + pd2hc + pc_d2c + \n  pd2w + pd2hw + pc_d2w +\n  plot_layout(ncol=3)\n\n\n\n\n\n\nFigure 8.4: Complete linkage clustering (a, b, c) on nuisance variables in comparison to Ward’s linkage (d, e, f). The two dendrograms (a, d) look similar but when plotted on the data (b, e) we can see they are very different solutions. The complete linkage result breaks the data into clusters across the gap (c), which is a bad solution. It has been distract by the nuisance variables. Conversely, the Wards linkage two-cluster solution does as hoped, divided the data into two clusters separated by the gap (f).\n\n\n\n\n\nTwo dendrograms might look similar but the resulting clustering can be very different. They can also look very different but correspond to very similar clusterings. Plotting the dendrogram in the data space is important for understanding how the algorithm operated when grouping observations, even more so for high dimensions.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hierarchical clustering</span>"
    ]
  },
  {
    "objectID": "8-hierarchical.html#dendrograms-in-high-dimensions",
    "href": "8-hierarchical.html#dendrograms-in-high-dimensions",
    "title": "8  Hierarchical clustering",
    "section": "\n8.3 Dendrograms in high-dimensions",
    "text": "8.3 Dendrograms in high-dimensions\nThe first step with any clustering with high dimensional data is also to check the data. You typically don’t know whether there are clusters, or what shape they might be, or if there are nuisance observations or variables. A pairs plot like in Figure 8.5 is a nice complement to using the tour (Figure 8.6) for this. Here you can see three elliptical clusters, with one is further from the others.\n\nCode for scatterplot matrixload(\"data/penguins_sub.rda\")\nggscatmat(penguins_sub[,1:4]) + \n  theme_minimal() +\n  xlab(\"\") + ylab(\"\")\n\n\n\n\n\n\nFigure 8.5: Make a scatterplot matrix to check for the presence of clustering, shape of clusters and presence of nuisance observations and variables. In the penguins it appears that there might be three elliptically shaped clusters, with some nuisance observations.\n\n\n\n\n\nCode to create tourset.seed(20230329)\nb &lt;- basis_random(4,2)\npt1 &lt;- save_history(penguins_sub[,1:4], \n                    max_bases = 500, \n                    start = b)\nsave(pt1, file=\"data/penguins_tour_path.rda\")\n\n# To re-create the gifs\nload(\"data/penguins_tour_path.rda\")\nanimate_xy(penguins_sub[,1:4], \n           tour_path = planned_tour(pt1), \n           axes=\"off\", rescale=FALSE, \n           half_range = 3.5)\n\nrender_gif(penguins_sub[,1:4], \n           planned_tour(pt1), \n           display_xy(half_range=0.9, axes=\"off\"),\n           gif_file=\"gifs/penguins_gt.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\n\n\nFigure 8.6: Use a grand tour of your data to check for clusters, the shape of clusters and for nuisance observations and variables. Here the penguins data looks like it has possibly three elliptical clusters, one more separated than the other two, with some nuisance observations.\n\n\nThe process is the same as for the simpler example. We compute and draw the dendrogram in 2D, compute it in \\(p\\)-D and view with a tour. Here we have also chosen to examine the three cluster solution for single linkage and wards linkage clustering.\n\np_dist &lt;- dist(penguins_sub[,1:4])\np_hcw &lt;- hclust(p_dist, method=\"ward.D2\")\np_hcs &lt;- hclust(p_dist, method=\"single\")\n\np_clw &lt;- penguins_sub %&gt;% \n  mutate(cl = factor(cutree(p_hcw, 3))) %&gt;%\n  as.data.frame()\np_cls &lt;- penguins_sub %&gt;% \n  mutate(cl = factor(cutree(p_hcs, 3))) %&gt;%\n  as.data.frame()\n\np_w_hfly &lt;- hierfly(p_clw, p_hcw, scale=FALSE)\np_s_hfly &lt;- hierfly(p_cls, p_hcs, scale=FALSE)\n\n\nCode to draw dendrograms# Generate the dendrograms in 2D\np_hcw_dd &lt;- dendro_data(p_hcw)\npw_dd &lt;- ggplot() +\n  geom_segment(data=p_hcw_dd$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=p_hcw_dd$labels, aes(x=x, y=y),\n             alpha=0.8) +\n  theme_dendro()\n\np_hcs_dd &lt;- dendro_data(p_hcs)\nps_dd &lt;- ggplot() +\n  geom_segment(data=p_hcs_dd$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=p_hcs_dd$labels, aes(x=x, y=y),\n             alpha=0.8) +\n  theme_dendro()\n\n\n\nCode to create tours of dendrogram in dataload(\"data/penguins_tour_path.rda\")\nglyphs &lt;- c(16, 46)\npchw &lt;- glyphs[p_w_hfly$data$node+1]\npchs &lt;- glyphs[p_s_hfly$data$node+1]\n\nanimate_xy(p_w_hfly$data[,1:4], \n           #col=colw, \n           tour_path = planned_tour(pt1),\n           pch = pchw,\n           edges=p_w_hfly$edges, \n           axes=\"bottomleft\")\n\nanimate_xy(p_s_hfly$data[,1:4], \n           #col=colw, \n           tour_path = planned_tour(pt1),\n           pch = pchs,\n           edges=p_s_hfly$edges, \n           axes=\"bottomleft\")\n\nrender_gif(p_w_hfly$data[,1:4], \n           planned_tour(pt1),\n           display_xy(half_range=0.9,            \n                      pch = pchw,\n                      edges = p_w_hfly$edges,\n                      axes = \"off\"),\n           gif_file=\"gifs/penguins_hflyw.gif\",\n           frames=500,\n           loop=FALSE)\n\nrender_gif(p_s_hfly$data[,1:4], \n           planned_tour(pt1), \n           display_xy(half_range=0.9,            \n                      pch = pchs,\n                      edges = p_s_hfly$edges,\n                      axes = \"off\"),\n           gif_file=\"gifs/penguins_hflys.gif\",\n           frames=500,\n           loop=FALSE)\n\n# Show three cluster solutions\nclrs &lt;- hcl.colors(3, \"Zissou 1\")\nw3_col &lt;- clrs[p_w_hfly$data$cl[p_w_hfly$data$node == 0]]\nrender_gif(p_w_hfly$data[p_w_hfly$data$node == 0, 1:4], \n           planned_tour(pt1), \n           display_xy(half_range=0.9,   \n                      col=w3_col,\n                      axes = \"off\"),\n           gif_file=\"gifs/penguins_w3.gif\",\n           frames=500,\n           loop=FALSE)\n\ns3_col &lt;- clrs[p_s_hfly$data$cl[p_w_hfly$data$node == 0]]\nrender_gif(p_s_hfly$data[p_w_hfly$data$node == 0,1:4], \n           planned_tour(pt1), \n           display_xy(half_range=0.9,   \n                      col=s3_col,\n                      axes = \"off\"),\n           gif_file=\"gifs/penguins_s3.gif\",\n           frames=500,\n           loop=FALSE)\n\n\nFigure 8.7 and Figure 8.8 show results for single linkage and wards linkage clustering of the penguins data. fig-penguins-ddw shows the 2D dendrograms. The 2D dendrograms are very different. Wards linkage produces a clearer indication of clusters, with a suggestion of three, or possibly four or five clusters. The dendrogram for single linkage suggests two clusters, and has the classical waterfall appearance that is often seen with this type of linkage. (If you look carefully, though, you will see it is actually a three cluster solution. At the very top of the dendrogram there is another branch connecting one observation to the other two clusters.)\nFigure 8.8 (a) and (b) show the dendrograms in 4D overlaid on the data. The two are starkly different. The single linkage clustering is like pins pointing to (three) centres, with some long extra edges.\nPlots (c) and (d) show the three cluster solutions, with Wards linkage almost recovering the clusters of the three species. Single linkage has two big clusters, and the singleton cluster. Although the Wards linkage produces the best result, single linkage does provide some interesting and useful information about the data. That singleton cluster is an outlier, an unusually-sized penguin. We can see it as an outlier just from the tour in Figure 8.6 but single linkage emphasizes it, bringing it more strongly to our attention.\n\n\n\n\n\n\n\nFigure 8.7: Wards linkage (left) and single linkage (right).\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Wards linkage\n\n\n\n\n\n\n\n\n\n(b) Single linkage\n\n\n\n\n\n\n\n\n\n\n\n(c) Wards linkage\n\n\n\n\n\n\n\n\n\n(d) Single linkage\n\n\n\n\n\n\nFigure 8.8: Dendrograms for Wards and single linkage of the penguins data, shown in 2D (top) and in 4D (middle), and the three-cluster solution of each.\n\n\n\nSingle linkage on the penguins has a very different joining pattern to Wards! While Wards provides the better result, single linkage provides useful information about the data, such as emphasizing the outlier.\n\nFigure 8.9 provides HTML objects of the dendrograms, so that they can be directly compared. The same tour path is used, so the sliders allow setting the view to the same projection in each plot.\n\nCode to make html objects of the dendrogram in 4Dload(\"data/penguins_tour_path.rda\")\n# Create a smaller one, for space concerns\npt1i &lt;- interpolate(pt1[,,1:5], 0.1)\npw_anim &lt;- render_anim(p_w_hfly$data,\n                       vars=1:4,\n                       frames=pt1i, \n                       edges = p_w_hfly$edges,\n             obs_labels=paste0(1:nrow(p_w_hfly$data),\n                               p_w_hfly$data$cl))\n\npw_gp &lt;- ggplot() +\n     geom_segment(data=pw_anim$edges, \n                    aes(x=x, xend=xend,\n                        y=y, yend=yend,\n                        frame=frame)) +\n     geom_point(data=pw_anim$frames, \n                aes(x=P1, y=P2, \n                    frame=frame, \n                    shape=factor(node),\n                    label=obs_labels), \n                alpha=0.8, size=1) +\n     xlim(-1,1) + ylim(-1,1) +\n     scale_shape_manual(values=c(16, 46)) +\n     coord_equal() +\n     theme_bw() +\n     theme(legend.position=\"none\", \n           axis.text=element_blank(),\n           axis.title=element_blank(),\n           axis.ticks=element_blank(),\n           panel.grid=element_blank())\n\npwg &lt;- ggplotly(pw_gp, width=450, height=500,\n                tooltip=\"label\") %&gt;%\n       animation_button(label=\"Go\") %&gt;%\n       animation_slider(len=0.8, x=0.5,\n                        xanchor=\"center\") %&gt;%\n       animation_opts(easing=\"linear\", transition = 0)\nhtmlwidgets::saveWidget(pwg,\n          file=\"html/penguins_cl_ward.html\",\n          selfcontained = TRUE)\n\n# Single\nps_anim &lt;- render_anim(p_s_hfly$data, vars=1:4,\n                         frames=pt1i, \n                       edges = p_s_hfly$edges,\n             obs_labels=paste0(1:nrow(p_s_hfly$data),\n                               p_s_hfly$data$cl))\n\nps_gp &lt;- ggplot() +\n     geom_segment(data=ps_anim$edges, \n                    aes(x=x, xend=xend,\n                        y=y, yend=yend,\n                        frame=frame)) +\n     geom_point(data=ps_anim$frames, \n                aes(x=P1, y=P2, \n                    frame=frame, \n                    shape=factor(node),\n                    label=obs_labels), \n                alpha=0.8, size=1) +\n     xlim(-1,1) + ylim(-1,1) +\n     scale_shape_manual(values=c(16, 46)) +\n     coord_equal() +\n     theme_bw() +\n     theme(legend.position=\"none\", \n           axis.text=element_blank(),\n           axis.title=element_blank(),\n           axis.ticks=element_blank(),\n           panel.grid=element_blank())\n\npsg &lt;- ggplotly(ps_gp, width=450, height=500,\n                tooltip=\"label\") %&gt;%\n       animation_button(label=\"Go\") %&gt;%\n       animation_slider(len=0.8, x=0.5,\n                        xanchor=\"center\") %&gt;%\n       animation_opts(easing=\"linear\", transition = 0)\nhtmlwidgets::saveWidget(psg,\n          file=\"html/penguins_cl_single.html\",\n          selfcontained = TRUE)\n\n\n\n\n\n\n\n\n\n\nFigure 8.9: Animation of dendrogram from Wards (top) and single (bottom) linkage clustering of the penguins data.\n\n\n\nViewing the dendrograms in high-dimensions provides insight into how the observations have joined points to clusters. For example, single linkage often has edges leading to a single focal point, which might not be yield a useful clustering but might help to identify outliers. If the edges point to multiple focal points, with long edges bridging gaps in the data, the result is more likely yielding a useful clustering.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hierarchical clustering</span>"
    ]
  },
  {
    "objectID": "8-hierarchical.html#exercises",
    "href": "8-hierarchical.html#exercises",
    "title": "8  Hierarchical clustering",
    "section": "Exercises",
    "text": "Exercises\n\nCompute complete linkage clustering for the nuisance observations data set. Does it perform more similarly to single linkage or Wards linkage?\nCompute single linkage clustering for the nuisance variables data. Does it perform more similarly to complete linkage or Wards linkage?\nUse hierarchical clustering with Euclidean distance and Wards linkage to split the clusters_nonlin data into four clusters. Look at the dendrogram in 2D and 4D. In 4D you can also include the cluster assignment as color. Does this look like a good solution?\nRepeat the same exercise using single linkage instead of Wards linkage. How does this solution compare to what we have found with Wards linkage? Does the solution match how you would cluster the data in a spin-and-brush approach?\nArgue why single linkage might not perform well for the fake_trees data. Which method do you think will work best with this data? Conduct hierarchical clustering with your choice of linkage method. Does the 2D dendrogram suggest 10 clusters for the 10 branches? Take a look at the high-dimensional representation of the dendrogram. Has your chosen method captured the branches well, or not, explaining what you think worked well or poorly?\nWhat would a useful clustering of the first four PCs of the aflw data be? What linkage method would you expect works best to cluster it this way? Conduct the clustering. Examine the 2D dendrogram and decide on how many clusters should be used. Examine the cluster solution using a tour with points coloured by cluster.\n\nBased on your assessment of the cluster structure in the challenge data sets, c1-c7, from the mulgar package, which linkage method would you recommend. Use your suggested linkage method to cluster each data set, and summarise how well it performed in detecting the clusters that you have seen.\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hierarchical clustering</span>"
    ]
  },
  {
    "objectID": "9-kmeans.html",
    "href": "9-kmeans.html",
    "title": "9  \\(k\\)-means clustering",
    "section": "",
    "text": "9.1 Examining results in 2D\nOne of the simplest and efficient techniques for clustering data is the \\(k\\)-means algorithm. The algorithm begins with a choice for \\(k\\), the number of clusters to divide the data into. It is seeded with \\(k\\) initial means, and sequentially iterates through the observations, assigning them to the nearest mean, and re-calculating the \\(k\\) means. It stops at a given number of iterations or when points no longer change clusters. The algorithm will tend to segment the data into roughly equal sized, or spherical clusters, and thus will work well if the clusters are separated and equally spherical in shape.\nA good place to learn ore about the \\(k\\)-means algorithm is Chapter 20 of Boehmke & Greenwell (2019). The algorithm has been in use for a long time! It was named \\(k\\)-means by MacQueen (1967), but developed by Lloyd in 1957 (as described in Lloyd (1982)) and separately by Forgy (1965), and perhaps others as it is a very simple procedure.\nFigure 9.1 shows the results of \\(k\\)-means clustering on the 2D simple_clusters data and two variables of the penguins data. We can see that it works well when the clusters are spherical, but for the penguins data it fails because the shape of the clusters is elliptical. It actually makes a mistake that would not be made if we simply visually clustered: cluster 3 has grouped points across a gap, a divide that visually we would all agree should form a separation.\nlibrary(mulgar)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(colorspace)\nlibrary(patchwork)\ndata(\"simple_clusters\")\nload(\"data/penguins_sub.rda\")\n\nset.seed(202305)\nsc_bl_bd_km &lt;- kmeans(simple_clusters[,1:2], centers=2, \n                     iter.max = 50, nstart = 5)\nsc_bl_bd_km_means &lt;- data.frame(sc_bl_bd_km$centers) %&gt;%\n  mutate(cl = factor(rownames(sc_bl_bd_km$centers)))\nsc_bl_bd_km_d &lt;- simple_clusters[,1:2] %&gt;% \n  mutate(cl = factor(sc_bl_bd_km$cluster))\nCode to make plotssc_bl_bd_km_p &lt;- ggplot() +\n  geom_point(data=sc_bl_bd_km_d, \n             aes(x=x1, y=x2, colour=cl), \n             shape=16, alpha=0.4) +\n  geom_point(data=sc_bl_bd_km_means, \n             aes(x=x1, y=x2, colour=cl), \n             shape=3, size=5) +\n    scale_color_discrete_divergingx(\"Zissou 1\") +\n  ggtitle(\"(a)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, \n        legend.position = \"bottom\",\n        legend.title = element_blank()) \n\np_bl_bd_km &lt;- kmeans(penguins_sub[,1:2], centers=3, \n                     iter.max = 50, nstart = 5)\np_bl_bd_km_means &lt;- data.frame(p_bl_bd_km$centers) %&gt;%\n  mutate(cl = factor(rownames(p_bl_bd_km$centers)))\np_bl_bd_km_d &lt;- penguins_sub[,1:2] %&gt;% \n  mutate(cl = factor(p_bl_bd_km$cluster))\n\np_bl_bd_km_p &lt;- ggplot() +\n  geom_point(data=p_bl_bd_km_d, \n             aes(x=bl, y=bd, colour=cl), \n             shape=16, alpha=0.4) +\n  geom_point(data=p_bl_bd_km_means, \n             aes(x=bl, y=bd, colour=cl), \n             shape=3, size=5) +\n    scale_color_discrete_divergingx(\"Zissou 1\") +\n  ggtitle(\"(b)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, \n        legend.position = \"bottom\",\n        legend.title = element_blank()) \n\nsc_bl_bd_km_p + p_bl_bd_km_p + plot_layout(ncol=2)\n\n\n\n\n\n\nFigure 9.1: Examining \\(k\\)-means clustering results for simple clusters (a) and two variables of the penguins data (b). The means are indicated by a \\(+\\). The results are perfect for the simple clusters but not for the penguins data. The penguin clusters are elliptically shaped which is not captured by \\(k\\)-means. Cluster 3 has observations grouped across a gap in the data.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>$k$-means clustering</span>"
    ]
  },
  {
    "objectID": "9-kmeans.html#examining-results-in-high-dimensions",
    "href": "9-kmeans.html#examining-results-in-high-dimensions",
    "title": "9  \\(k\\)-means clustering",
    "section": "\n9.2 Examining results in high dimensions",
    "text": "9.2 Examining results in high dimensions\nThis approach extends to high-dimensions. One colours observations by the cluster label, and overlays the final cluster means. If we see gaps in points in a single cluster it would mean that \\(k\\)-means fails to see important cluster structure. This is what happens with the 4D penguins data as shown in Figure 9.2.\n\np_km &lt;- kmeans(penguins_sub[,1:4], centers=3, \n                     iter.max = 50, nstart = 5)\np_km_means &lt;- data.frame(p_km$centers) %&gt;%\n  mutate(cl = factor(rownames(p_km$centers)))\np_km_d &lt;- penguins_sub[,1:4] %&gt;% \n  mutate(cl = factor(p_km$cluster))\n\n\nCode to make animated gifslibrary(tourr)\np_km_means &lt;- p_km_means %&gt;%\n  mutate(type = \"mean\")\np_km_d &lt;- p_km_d %&gt;%\n  mutate(type = \"data\")\np_km_all &lt;- bind_rows(p_km_means, p_km_d)\np_km_all$type &lt;- factor(p_km_all$type, levels=c(\"mean\", \"data\"))\np_pch &lt;- c(3, 20)[as.numeric(p_km_all$type)]\np_cex &lt;- c(3, 1)[as.numeric(p_km_all$type)]\nanimate_xy(p_km_all[,1:4], col=p_km_all$cl, \n           pch=p_pch, cex=p_cex, axes=\"bottomleft\")\nrender_gif(p_km_all[,1:4],\n           grand_tour(),\n           display_xy(col=p_km_all$cl, \n                      pch=p_pch, \n                      cex=p_cex, \n                      axes=\"bottomleft\"),\n           gif_file=\"gifs/p_km.gif\",\n           width=400,\n           height=400,\n           frames=500)\n\n\n\n\n\n\n\nFigure 9.2: Exploring the k-means clustering result for the 4D penguins data. You can see cluster 2 clearly separated from the other observations. Cluster 3, like in the 2D example, is a mix of observations across a gap. Even the mean of the cluster is almost in the gap.\n\n\nGenerally, there is no need to choose \\(k\\) ahead of time. One would re-fit \\(k\\)-means with various choices of \\(k\\), and compare the tot.withinss and examine the clusters visually, to decide on the optimal final value of \\(k\\). This can be assessed in a similar way to the scree plot for PCA.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>$k$-means clustering</span>"
    ]
  },
  {
    "objectID": "9-kmeans.html#exercises",
    "href": "9-kmeans.html#exercises",
    "title": "9  \\(k\\)-means clustering",
    "section": "Exercises",
    "text": "Exercises\n\nCompute a \\(k\\)-means clustering for the fake_trees data, varying \\(k\\) to about 20. Choose your best \\(k\\), and examine the solution using the first 10 PCs on the data. It should capture the data quite nicely, although it will break up each branch into multiple clusters.\nCompute a \\(k\\)-means clustering of the first four PCs of the aflw data. Examine the best solution (you choose which \\(k\\)), and describe how it divides the data. By examining the means, can you tell if it extracts clusters of offensive vs defensive vs midfield players? Or does it break the data into high skills vs low skills?\nUse \\(k\\)-means clustering on the challenge data sets, c1-c7 from the mulgar package. Explain what choice of \\(k\\) is best for each data set, and why or why not the cluster structure, as you have described it from earlier chapters, is detected or not.\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>$k$-means clustering</span>"
    ]
  },
  {
    "objectID": "10-model-based.html",
    "href": "10-model-based.html",
    "title": "10  Model-based clustering",
    "section": "",
    "text": "10.1 Examining the model in 2D\nModel-based clustering Fraley & Raftery (2002) fits a multivariate normal mixture model to the data. It uses the EM algorithm to fit the parameters for the mean, variance–covariance of each population, and the mixing proportion. The variance-covariance matrix is re-parametrized using an eigen-decomposition\n\\[\n\\Sigma_k = \\lambda_kD_kA_kD_k^\\top, ~~~k=1, \\dots, g ~~\\mbox{(number of clusters)}\n\\]\nresulting in several model choices, ranging from simple to complex, as shown in Table 10.1.\nNote the distribution descriptions “spherical” and “ellipsoidal”. These are descriptions of the shape of the variance-covariance for a multivariate normal distribution. A standard multivariate normal distribution has a variance-covariance matrix with zeros in the off-diagonal elements, which corresponds to spherically shaped data. When the variances (diagonals) are different or the variables are correlated, then the shape of data from a multivariate normal is ellipsoidal.\nThe models are typically scored using the Bayes Information Criterion (BIC), which is based on the log likelihood, number of variables, and number of mixture components. They should also be assessed using graphical methods, as we demonstrate using the penguins data.\nWe start with two of the four real-valued variables (bl, fl) and the three species. The goal is to determine whether model-based methods can discover clusters that closely correspond to the three species. Based on the scatterplot in Figure 10.1 we would expect it to do well, and suggest an elliptical variance-covariance of roughly equal sizes as the model.\nCode to make plotload(\"data/penguins_sub.rda\")\nggplot(penguins_sub, aes(x=bl, \n                         y=fl)) + #, \n                         #colour=species)) +\n  geom_point() +\n  geom_density2d(colour=\"#3B99B1\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\n\n\n\n\n\n\nFigure 10.1: Scatterplot of flipper length by bill length of the penguins data.\npenguins_BIC &lt;- mclustBIC(penguins_sub[,c(1,3)])\nggmc &lt;- ggmcbic(penguins_BIC, cl=2:9, top=4) + \n  scale_color_discrete_divergingx(palette = \"Roma\") +\n  ggtitle(\"(a)\") +\n  theme_minimal() \npenguins_mc &lt;- Mclust(penguins_sub[,c(1,3)], \n                      G=3, \n                      modelNames = \"EVE\")\npenguins_mce &lt;- mc_ellipse(penguins_mc)\npenguins_cl &lt;- penguins_sub[,c(1,3)]\npenguins_cl$cl &lt;- factor(penguins_mc$classification)\nggell &lt;- ggplot() +\n   geom_point(data=penguins_cl, aes(x=bl, y=fl,\n                                    colour=cl),\n              alpha=0.3) +\n   geom_point(data=penguins_mce$ell, aes(x=bl, y=fl,\n                                         colour=cl),\n              shape=16) +\n   geom_point(data=penguins_mce$mn, aes(x=bl, y=fl,\n                                        colour=cl),\n              shape=3, size=2) +\n  scale_color_discrete_divergingx(palette = \"Zissou 1\")  +\n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position=\"none\") +\n  ggtitle(\"(b)\")\nggmc + ggell + plot_layout(ncol=2)\n\n\n\n\n\n\nFigure 10.2: Summary plots from model-based clustering: (a) BIC values for clusters 2-9 of top four models, (b) variance-covariance ellipses and cluster means (+) corresponding to the best model. The best model is three-cluster EVE, which has differently shaped variance-covariances albeit the same volume and orientation.\nFigure 10.2 summarises the results. All models agree that three clusters is the best. The different variance-covariance models for three clusters have similar BIC values with EVE (different shape, same volume and orientation) being slightly higher. These plots are made from the mclust package output using the ggmcbic and mc_ellipse functions fro the mulgar package.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model-based clustering</span>"
    ]
  },
  {
    "objectID": "10-model-based.html#extending-to-higher-dimensions",
    "href": "10-model-based.html#extending-to-higher-dimensions",
    "title": "10  Model-based clustering",
    "section": "\n10.2 Extending to higher dimensions",
    "text": "10.2 Extending to higher dimensions\nNow we will examine how model-based clustering will group the penguins data using all four variables.\n\npenguins_BIC &lt;- mclustBIC(penguins_sub[,1:4])\nggmc &lt;- ggmcbic(penguins_BIC, cl=2:9, top=7) + \n  scale_color_discrete_divergingx(palette = \"Roma\") +\n  theme_minimal() \nggmc\n\n\n\n\n\n\nFigure 10.3: BIC values for the top models for 2-9 clusters on the penguins data. The interpretation is mixed: if one were to choose three clusters any of the variance-covariance models would be equally as good, but the very best model is the four-cluster VEE.\n\n\n\n\n\npenguins_mc &lt;- Mclust(penguins_sub[,1:4], \n                      G=4, \n                      modelNames = \"VEE\")\npenguins_mce &lt;- mc_ellipse(penguins_mc)\npenguins_cl &lt;- penguins_sub\npenguins_cl$cl &lt;- factor(penguins_mc$classification)\n\npenguins_mc_data &lt;- penguins_cl %&gt;%\n  select(bl:bm, cl) %&gt;%\n  mutate(type = \"data\") %&gt;%\n  bind_rows(bind_cols(penguins_mce$ell,\n                      type=rep(\"ellipse\",\n                               nrow(penguins_mce$ell)))) %&gt;%\n  mutate(type = factor(type))\n\n\nCode to make animated gifsanimate_xy(penguins_mc_data[,1:4],\n           col=penguins_mc_data$cl,\n           pch=c(4, 20 )[as.numeric(penguins_mc_data$type)], \n           axes=\"off\")\n\nload(\"data/penguins_tour_path.rda\")\nrender_gif(penguins_mc_data[,1:4], \n           planned_tour(pt1), \n           display_xy(col=penguins_mc_data$cl,\n               pch=c(4, 20)[\n                 as.numeric(penguins_mc_data$type)], \n                      axes=\"off\",\n               half_range = 0.7),\n           gif_file=\"gifs/penguins_best_mc.gif\",\n           frames=500,\n           loop=FALSE)\n\npenguins_mc &lt;- Mclust(penguins_sub[,1:4], \n                      G=3, \n                      modelNames = \"EEE\")\npenguins_mce &lt;- mc_ellipse(penguins_mc)\npenguins_cl &lt;- penguins_sub\npenguins_cl$cl &lt;- factor(penguins_mc$classification)\n\npenguins_mc_data &lt;- penguins_cl %&gt;%\n  select(bl:bm, cl) %&gt;%\n  mutate(type = \"data\") %&gt;%\n  bind_rows(bind_cols(penguins_mce$ell,\n                      type=rep(\"ellipse\",\n                               nrow(penguins_mce$ell)))) %&gt;%\n  mutate(type = factor(type))\n\nanimate_xy(penguins_mc_data[,1:4],\n           col=penguins_mc_data$cl,\n           pch=c(4, 20)[as.numeric(penguins_mc_data$type)], \n           axes=\"off\")\n\n# Save the animated gif\nload(\"data/penguins_tour_path.rda\")\nrender_gif(penguins_mc_data[,1:4], \n           planned_tour(pt1), \n           display_xy(col=penguins_mc_data$cl,\n               pch=c(4, 20)[\n                 as.numeric(penguins_mc_data$type)], \n                      axes=\"off\",\n               half_range = 0.7),\n           gif_file=\"gifs/penguins_simpler_mc.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n\n\n(a) Best model: four-cluster VEE\n\n\n\n\n\n\n\n\n\n(b) Three-cluster EEE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Three-cluster EEE\n\n\n\n\n\n\nFigure 10.4: Examining the model-based clustering results for the penguins data: (a) best model according to BIC value, (b) simpler three-cluster model. Dots are ellipse points, and “x” are data points. It is important to note that the three cluster solution fits the data better, even though it has a lower BIC.\n\n\n\nUsing the tour to visualise the final choices of models with similarly high BIC values helps to choose which best fits the data. It may not be the one with the highest BIC value.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model-based clustering</span>"
    ]
  },
  {
    "objectID": "10-model-based.html#exercises",
    "href": "10-model-based.html#exercises",
    "title": "10  Model-based clustering",
    "section": "Exercises",
    "text": "Exercises\n\nExamine the three cluster EVE, VVE and VEE models with the tour, and explain whether these are distinguishably different from the EEE three cluster model.\nFit model-based clustering to the the clusters. Does it suggest the data has three clusters? Using the tour examine the best model model. How well does this fit the data?\nFit model-based clustering to the the multicluster. Does it suggest the data has six clusters? Using the tour examine the best model model. How well does this fit the data?\nFit model-based clustering to the fake_trees data. Does it suggest that the data has 10 clusters? If not, why do you think this is? Using the tour examine the best model model. How well does this fit the branching structure?\nTry fitting model-based clustering to the aflw data? What is the best model? Is the solution related to offensive vs defensive vs mid-fielder skills?\nUse model-based clustering on the challenge data sets, c1-c7 from the mulgar package. Explain why or why not the best model fits the cluster structure or not.\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model-based clustering</span>"
    ]
  },
  {
    "objectID": "11-som.html",
    "href": "11-som.html",
    "title": "11  Self-organizing maps",
    "section": "",
    "text": "Exercises\nA self-organizing map (SOM) Kohonen (2001) is constructed using a constrained \\(k\\)-means algorithm. A 1D or 2D net is stretched through the data. The knots, in the net, form the cluster means, and the points closest to the knot are considered to belong to that cluster. The similarity of nodes (and their corresponding clusters) is defined as proportional to their distance from one another on the net. Unlike \\(k\\)-means one would normally choose a largish net, with more nodes than expected clusters. A well-separated cluster in the data would likely be split across multiple nodes in the net. Examining the net where nodes are empty of points we would interpret this as a gap in the original data.\nFigure 11.1 illustrates how the SOM fits the penguins data. SOM is not ideal for clustered data where there are gaps. It is better suited for data that lies on a non-linear low-dimensional manifold. To model data like the penguins the first step is to set up a net that will cover more than the three clusters. Here we have chosen to use a \\(5\\times 5\\) rectangular grid. (The option allows for a hexagonal grid, which would make for a better tiled 2D map, but this is not useful for viewing the model in high dimensions.) Like \\(k\\)-means clustering the fitted model can change substantially depending on the initialisation, so setting a seed will ensure a consistent result. We have also initialised the positions of the knots using PCA, which stretches the net in the main two directions of variance of the data, generally giving better results.\nThe resulting model object is used to construct an object containing the original data, the 2D map, the map in \\(p\\)-D, with edges, and segments to connect points to represent the next using the som_model() function from mulgar. The 2D map shows a configuration of the data in 2D which best displays the clusters, much like how a PCA or LDA plot would eb used.\nThe object can also be modified into the pieces needed to show the net in \\(p\\)-D. You need the data, points marking the net, and edges indicating which points to connect to draw the net.\nExamining the SOM map views in 2D and with the data in 4D. Points are coloured by species, which was not used for the modeling. The 2D map shows that the map 2 direction is primarily distinguishing the Gentoo from the others, and map 1 is imperfectly distinguishing the Chinstrap from Adelie. The map in the data space shows how it is woven into the shape of the data.\nThe SOM fit, with a \\(5\\times 5\\) grid, for the penguins has the data clustered into 25 groups. This doesn’t work as a clustering technique on its own, if we remember that the data has three clusters corresponding to three species of penguins. Using species to colour the points helps to see what SOM has done. It has used about seven nodes to capture the separated Gentoo group. These are mostly in the map 2 direction, which means that this direction (like a direction in PCA) is useful for distinguishing the Gentoo penguins from the others. The other two species are mixed on the map, but roughly spread out on the direction of map 1.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Self-organizing maps</span>"
    ]
  },
  {
    "objectID": "11-som.html#exercises",
    "href": "11-som.html#exercises",
    "title": "11  Self-organizing maps",
    "section": "",
    "text": "Fit an SOM to the first four PCs of the aflw data. Examine the best solution (you choose the size of the net), and describe how the map lays out the data. Does it show offensive vs defensive vs midfield players? Or does it tend to show high skills vs low skills?\nFit an SOM to the first 10 PCs of the fake_trees data, using your choice of net size. How well does the map show the branching structure?\nExamine a range of SOM nets fitted to the first 10 PCs of the fake_trees data in the 10D space using a tour. Set the values of rlen to be 5, 50, 500. How does the net change on this parameter?\nPlot the distances output for the SOM fit to the penguins data. Mark the observations that have the 5 biggest distances, and show these in a tour. These are the observations where the net has fitted least well, and may be outliers.\nUse SOM on the challenge data sets, c1-c7 from the mulgar package. What is the best choice of number of knots for each? Explain why or why not the model fits the cluster structure of each or not.\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Self-organizing maps</span>"
    ]
  },
  {
    "objectID": "12-summary-clust.html",
    "href": "12-summary-clust.html",
    "title": "12  Summarising and comparing clustering results",
    "section": "",
    "text": "12.1 Summarising results\nThe key elements for summarising cluster results are the centres of the clusters and the within-cluster variability of the observations. Adding cluster means to any plot, including tour plots, is easy. You add the additional rows, or a new data set, and set the point shape to be distinct.\nSummarising the variability is difficult. For model-based clustering, the shape of the clusters is assumed to be elliptical, so \\(p\\)-dimensional ellipses can be used to show the solution, as done in Chapter 10. Generally, it is common to plot a convex hull of the clusters, as in Figure 12.1. This can also be done in high-dimensions, using the R package cxhull to compute the \\(p\\)-D convex hull.\nLoad librarieslibrary(mclust) \nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(gt)\nlibrary(cxhull)\nlibrary(ggplot2)\nlibrary(colorspace)\nCode to do clusteringlibrary(mclust) \nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(gt)\nlibrary(cxhull)\nlibrary(ggplot2)\nlibrary(colorspace)\nload(\"data/penguins_sub.rda\")\np_dist &lt;- dist(penguins_sub[,1:4])\np_hcw &lt;- hclust(p_dist, method=\"ward.D2\")\n\np_cl &lt;- data.frame(cl_w = cutree(p_hcw, 3))\n\npenguins_mc &lt;- Mclust(penguins_sub[,1:4], \n                      G=3, \n                      modelNames = \"EEE\")\np_cl &lt;- p_cl %&gt;% \n  mutate(cl_mc = penguins_mc$classification)\n\np_cl &lt;- p_cl %&gt;% \n  mutate(cl_w_j = jitter(cl_w),\n         cl_mc_j = jitter(cl_mc))\n\n# Arranging by cluster id is important to define edges \npenguins_cl &lt;- penguins_sub %&gt;%\n  mutate(cl_w = p_cl$cl_w,\n         cl_mc = p_cl$cl_mc) %&gt;%\n  arrange(cl_w)\nCode for convex hulls in 2D# Penguins in 2D\n# Duplicate observations need to be removed fo convex hull calculation\npsub &lt;- penguins_cl %&gt;%\n  select(bl, bd) \ndup &lt;- duplicated(psub)\npsub &lt;- penguins_cl %&gt;%\n  select(bl, bd, cl_w) %&gt;%\n  filter(!dup) %&gt;%\n  arrange(cl_w)\n\nncl &lt;- psub %&gt;%\n  count(cl_w) %&gt;%\n  arrange(cl_w) %&gt;%\n  mutate(cumn = cumsum(n))\nphull &lt;- NULL\nfor (i in unique(psub$cl_w)) {\n  x &lt;- psub %&gt;%\n    dplyr::filter(cl_w == i) %&gt;%\n    select(bl, bd) \n  ph &lt;- cxhull(as.matrix(x))$edges\n  if (i &gt; 1) {\n    ph &lt;- ph + ncl$cumn[i-1]\n  }\n  ph &lt;- cbind(ph, rep(i, nrow(ph)))\n  phull &lt;- rbind(phull, ph)\n}\nphull &lt;- as.data.frame(phull)\ncolnames(phull) &lt;- c(\"from\", \"to\", \"cl_w\") \nphull_segs &lt;- data.frame(x = psub$bl[phull$from],\n                         y = psub$bd[phull$from],\n                         xend = psub$bl[phull$to],\n                         yend = psub$bd[phull$to],\n                         cl_w = phull$cl_w)\nphull_segs$cl_w &lt;- factor(phull$cl_w) \npsub$cl_w &lt;- factor(psub$cl_w)\np_chull2D &lt;- ggplot() +\n  geom_point(data=psub, aes(x=bl, y=bd, \n                            colour=cl_w)) + \n  geom_segment(data=phull_segs, aes(x=x, xend=xend,\n                                    y=y, yend=yend,\n                                    colour=cl_w)) +\n  scale_colour_discrete_divergingx(palette = \"Zissou 1\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\nCode to generate pD convex hull and view in tourncl &lt;- penguins_cl %&gt;%\n  count(cl_w) %&gt;%\n  arrange(cl_w) %&gt;%\n  mutate(cumn = cumsum(n))\nphull &lt;- NULL\nfor (i in unique(penguins_cl$cl_w)) {\n  x &lt;- penguins_cl %&gt;%\n    dplyr::filter(cl_w == i) \n  ph &lt;- cxhull(as.matrix(x[,1:4]))$edges\n  if (i &gt; 1) {\n    ph &lt;- ph + ncl$cumn[i-1]\n  }\n  ph &lt;- cbind(ph, rep(i, nrow(ph)))\n  phull &lt;- rbind(phull, ph)\n}\nphull &lt;- as.data.frame(phull)\ncolnames(phull) &lt;- c(\"from\", \"to\", \"cl_w\") \nphull$cl_w &lt;- factor(phull$cl_w)\npenguins_cl$cl_w &lt;- factor(penguins_cl$cl_w)\n\nanimate_xy(penguins_cl[,1:4], col=penguins_cl$cl_w,\n           edges=as.matrix(phull[,1:2]), edges.col=phull$cl_w)\nrender_gif(penguins_cl[,1:4], \n           tour_path = grand_tour(),\n           display = display_xy(col=penguins_cl$cl_w,\n                                edges=as.matrix(phull[,1:2]),\n                                edges.col=phull$cl_w),\n           gif_file = \"gifs/penguins_chull.gif\",\n           frames = 500, \n           width = 400,\n           height = 400)\nConvex hulls summarising the extent of Wards linkage clustering in 2D and 4D.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Summarising and comparing clustering results</span>"
    ]
  },
  {
    "objectID": "12-summary-clust.html#summarising-results",
    "href": "12-summary-clust.html#summarising-results",
    "title": "12  Summarising and comparing clustering results",
    "section": "",
    "text": "(a) 2D\n\n\n\n\n\n\n\n\n\n\n(b) 4D\n\n\n\n\n\n\nFigure 12.1",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Summarising and comparing clustering results</span>"
    ]
  },
  {
    "objectID": "12-summary-clust.html#comparing-two-clusterings",
    "href": "12-summary-clust.html#comparing-two-clusterings",
    "title": "12  Summarising and comparing clustering results",
    "section": "\n12.2 Comparing two clusterings",
    "text": "12.2 Comparing two clusterings\nEach cluster analysis will result in a vector of class labels for the data. To compare two results we would tabulate and plot the pair of integer variables. The labels given to each cluster will likely differ. If the two methods agree, there will be just a few cells with large counts among mostly empty cells.\nBelow is a comparison between the three cluster results of Wards linkage hierarchical clustering (rows) and model-based clustering (columns). The two methods mostly agree, as seen from the three cells with large counts, and most cells with zeros. They disagree only on eight penguins. These eight penguins would be considered to be part of cluster 1 by Wards, but model-based considers them to be members of cluster 2.\nThe two methods label them clusters differently: what Wards labels as cluster 3, model-based labels as cluster 2. The labels given by any algorithm are arbitrary, and can easily be changed to coordinate between methods.\n\nCode for confusion tablep_cl %&gt;% \n  count(cl_w, cl_mc) %&gt;% \n  pivot_wider(names_from = cl_mc, \n              values_from = n, \n              values_fill = 0) %&gt;%\n  gt() %&gt;%\n  tab_spanner(label = \"cl_mc\", columns=c(`2`, `3`, `1`)) %&gt;%\n  cols_width(everything() ~ px(60))\n\n\n\n\n\n\ncl_w\ncl_mc\n\n\n2\n3\n1\n\n\n\n\n1\n8\n0\n149\n\n\n2\n0\n119\n0\n\n\n3\n57\n0\n0\n\n\n\n\n\n\nWe can examine the disagreement by linking a plot of the table, with a tour plot. Here is how to do this with liminal. Figure 12.2 and Figure 12.3 show screenshots of the exploration of the eight penguins on which the methods disagree. It makes sense that there is some confusion. These penguins are part of the large clump of observations that don’t separate cleanly into two clusters. The eight penguins are in the middle of this clump. Realistically, both methods result in a plausible clustering, and it is not clear how these penguins should be grouped.\n\nCode to do linked brushing with liminallibrary(liminal)\nlimn_tour_link(\n  p_cl[,3:4],\n  penguins_cl,\n  cols = bl:bm,\n  color = cl_w\n)\n\n\n\n\n\n\n\nFigure 12.2: Linking the confusion table with a tour using liminal. Points are coloured according to Wards linkage. The disagreement on eight penguins is with cluster 1 from Wards and cluster 2 from model-based.\n\n\n\n\n\n\n\nFigure 12.3: Highlighting the penguins where the methods disagree so we can see where these observations are located relative to the two clusters.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Summarising and comparing clustering results</span>"
    ]
  },
  {
    "objectID": "12-summary-clust.html#exercises",
    "href": "12-summary-clust.html#exercises",
    "title": "12  Summarising and comparing clustering results",
    "section": "Exercises",
    "text": "Exercises\n\nCompare the results of the four cluster model-based clustering with that of the four cluster Wards linkage clustering of the penguins data.\nCompare the results from clustering of the fake_trees data for two different choices of \\(k\\). (This follows from the exercise in Chapter 9.) Which choice of \\(k\\) is best? And what choice of \\(k\\) best captures the 10 known branches?\nCompare and contrast the cluster solutions for the first four PCs of the aflw data, conducted in Chapter 8 and Chapter 9. Which provides the most useful clustering of this data?\nPick your two clusterings on one of the challenge data sets, c1-c7 from the mulgar package, that give very different results. Compare and contrast the two solutions, and decide which is the better solution.",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Summarising and comparing clustering results</span>"
    ]
  },
  {
    "objectID": "12-summary-clust.html#project",
    "href": "12-summary-clust.html#project",
    "title": "12  Summarising and comparing clustering results",
    "section": "Project",
    "text": "Project\nMost of the time your data will not neatly separate into clusters, but partitioning it into groups of similar observations can still be useful. In this case our toolbox will be useful in comparing and contrasting different methods, understanding to what extend a cluster mean can describe the observations in the cluster, and also how the boundaries between clusters have been drawn. To explore this we will use survey data that examines the risk taking behavior of tourists. The data was collected in Australia in 2015 (Hajibaba et al., 2016) and includes six types of risks (recreational, health, career, financial, safety and social) with responses on a scale from 1 (never) to 5 (very often). You can download the data from  risk_MSA.rds .\n\nWe first examine the data in a grand tour. Do you notice that each variable was measured on a discrete scale?\nNext we explore different solutions from hierarchical clustering of the data. For comparison we will keep the number of clusters fixed to 6 and we will perform the hierarchical clustering with different combinations of distance functions (Manhattan distance and Euclidean distance) and linkage (single, complete and Ward linkage). Which combinations make sense based on what we know about the method and the data?\nFor each of the hierarchical clustering solutions draw the dendrogram in 2D and also in the data space. You can also map the grouping into 6 clusters to different colors. How would you describe the different solutions?\nUsing the method introduced in this chapter, compare the solution using Manhattan distance and complete linkage to one using Euclidean distance and Ward linkage. First compute a confusion table and then use liminal to explore some of the differences. For example, you should be able to see how small subsets where the two clustering solutions disagree can be outlying and are grouped differently depending on the choices we make.\nSelecting your preferred solution from hierarchical clustering, we will now compare it to what is found using \\(k\\)-means clustering with \\(k=6\\). Use a tour to show the cluster means together with the data points (make sure to pick an appropriate symbol for the data points to avoid too much overplotting). What can you say about the variation within the clusters? Can you match some of the clusters with the most relevant variables from following the movement of the cluster means during the tour?\nUse a projection pursuit guided tour to best separate the clusters identified with \\(k\\)-means clustering. How are the clusters related to the different types of risk?\nUse the approaches from this chapter to summarize and compare the \\(k\\)-means solution to your selected hierarchical clustering results. Are the groupings mostly similar? You can also use convex hulls to better compare what part of the space is occupied. Either look at subsets (selected from the liminal display) or you could facet the display using tourr::animate_groupxy.\nSome other possible activities include examining how model-based methods would cluster the data. We expect it should be similar to Wards hierarchical or \\(k\\)-means, that it will partition into roughly equal chunks with an EII variance-covariance model being optimal. Also examining an SOM fit. SOM is not ideal for this data because the data fills the space. If the SOM model is fitted properly it should be a tangled net where the nodes (cluster means) are fairly evenly spread out. Thus the result should again be similar to Wards hierarchical or \\(k\\)-means. A common problem with fitting an SOM is that optimisation stops early, before fully capturing the data set. This is the reasons to use the tour for SOM. If the net is bunched in one part of the data space, it means that the optimisation wasn’t successful.\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Cluster analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Summarising and comparing clustering results</span>"
    ]
  },
  {
    "objectID": "13-intro-class.html",
    "href": "13-intro-class.html",
    "title": "\n13  Overview\n",
    "section": "",
    "text": "Methods for supervised classification originated in the field of Statistics in the early nineteenth century, under the moniker discriminant analysis (see, for example, Fisher (1936a)). An increase in the collection of data, and storage in databases, in the late twentieth century has inspired a growing desire to extract knowledge from data, particularly to be able accurately predict the class labels. This has contributed to an explosion of research on new methods, especially on algorithms that focus on accurate prediction of new data based on training samples.\n\nIn contrast to unsupervised classification, the class label (categorical response variable) is known, in the training sample. The training sample is used to build the prediction model, and also to estimate the accuracy, or inversely error, of the model for future data. It is also important to understand the model and to interpret it, so that we can know how predictions are made. High-dimensional visualisation can help with this, and helps to tackle questions like:\n\nAre the classes well separated in the data space, so that they correspond to distinct clusters? If so, what are the shapes of the clusters? Is each cluster sufficiently ellipsoidal so that we can assume that the data arises from a mixture of multivariate normal distributions? Do the clusters exhibit characteristics that suggest one algorithm in preference to others?\nWhere does the boundary between classes fall? Are the classes linearly separable, or does the difference between classes suggest a non-linear boundary? How do changes in the input parameters affect these boundaries? How do the boundaries generated by different methods vary?\nWhat cases are misclassified, or have more uncertain predictions? Are there places in the data space where predictions are especially good or bad?\nWhich predictors most contribute to the model predictions? Is it possible to reduce the set of explanatory variables?\n\nAddressing these types of queries also motivate the emerging field called explainable artificial intelligence (XAI), which goes beyond predictive accuracy to more completely satisfy the desire to extract knowledge from data.\nAlthough we focus on categorical response, some of the techniques here can be modified or adapted for problems with a numeric, or continuous, response variable. With a categorical response, and numerical predictors, we map colour to the response variable and use the tour to examine the relationship between predictors, and the different classes.\n\n\n\n\n\n\n\nFigure 13.1: Examples of supervised classification patterns: (a) linearly separable, (b) linear but not completely separable, (c) non-linearly separable, (d) non-linear, but not completely separable.\n\n\n\n\nFigure 13.1 shows some 2D examples where the two classes are (a) linearly separable, (b) not completely separable but linearly different, (c) non-linearly separable and (d) not completely separable but with a non-linear difference. We can also see that in (a) only the horizontal variable would be important for the model because the two classes are completely separable in this direction. Although the pattern in (c) is separable classes, most models would have difficulty capturing the separation. It is for this reason that it is important to understand the boundary between classes produced by a fitted model. In each of b, c, d it is likely that some observations would be misclassified. Identifying these cases, and inspecting where they are in the data space is important for understanding the model’s future performance.\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduction to supervised classification</span>"
    ]
  },
  {
    "objectID": "14-lda.html",
    "href": "14-lda.html",
    "title": "14  Linear discriminant analysis",
    "section": "",
    "text": "14.1 Extracting the key elements of the model\nLinear discriminant analysis (LDA) dates to the early 1900s. It’s one of the most elegant and simple techniques for both modeling separation between groups, and as an added bonus, producing a low-dimensional representation of the differences between groups. LDA has two strong assumptions: the groups are samples from multivariate normal distributions, and each have the same variance-covariance. If the latter assumption is relaxed, a slightly less elegant solution results from quadratic discriminant analysis.\nUseful explanations can be found in Venables & Ripley (2002a) and Ripley (1996). A good general treatment of parametric methods for supervised classification can be found in R. A. Johnson & Wichern (2002) or another similar multivariate analysis textbook. It’s also useful to know that hypothesis testing for the difference in multivariate means using multivariate analysis of variance (MANOVA) has similar assumptions to LDA. Also model-based clustering assumes that each cluster arises from a multivariate normal distribution, and is related to LDA. The methods described here can be used to check these assumptions when applying these methods, too.\nLDA builds the model on the between-group sum-of-square matrix\n\\[B=\\sum_{k=1}^g n_k(\\bar{X}_k-\\bar{X})(\\bar{X}_k-\\bar{X})^\\top\\] which measures the differences between the class means, compared with the overall data mean \\(\\bar{X}\\) and the within-group sum-of-squares matrix,\n\\[\nW =\n\\sum_{k=1}^g\\sum_{i=1}^{n_k}\n(X_{ki}-\\bar{X}_k)(X_{ki}-\\bar{X}_k)^\\top\n\\]\nwhich measures the variation of values around each class mean. The linear discriminant space is generated by computing the eigenvectors (canonical coordinates) of \\(W^{-1}B\\), and this is the \\((g-1)\\)-D space where the group means are most separated with respect to the pooled variance-covariance. For each class we compute\n\\[\n\\delta_k(x) = (x-\\mu_k)^\\top W^{-1}\\mu_k + \\log \\pi_k\n\\]\nwhere \\(\\pi_k\\) is a prior probability for class \\(k\\) that might be based on unequal sample sizes, or cost of misclassification. The LDA classifier rule is to assign a new observation to the class with the largest value of \\(\\delta_k(x)\\).\nWe can fit an LDA model using the lda() function from the MASS package. Here we have used the penguins data, assuming equal prior probability, to illustrate.\n# Code to fit the model\nlibrary(dplyr)\nlibrary(mulgar)\nlibrary(MASS)\nload(\"data/penguins_sub.rda\")\n\np_lda &lt;- lda(species~bl+bd+fl+bm, \n             data=penguins_sub,\n             prior=c(1/3, 1/3, 1/3))\noptions(digits=2)\n# p_lda\nBecause there are three classes the dimension of the discriminant space is 2D. We can easily extract the group means from the model.\n# Extract the sample means\np_lda$means\n\n             bl    bd    fl    bm\nAdelie    -0.95  0.60 -0.78 -0.62\nChinstrap  0.89  0.64 -0.37 -0.59\nGentoo     0.65 -1.10  1.16  1.10\nThe coefficients to project the data into the discriminant space, that is the eigenvectors of \\(W^{-1}B\\) are:\n# Extract the discriminant space\np_lda$scaling\n\n     LD1   LD2\nbl -0.24 -2.31\nbd  2.04  0.19\nfl -1.20  0.08\nbm -1.22  1.24\nand the predicted values, which include class predictions, and coordinates in the discriminant space are generated as:\n# Extract the fitted values\np_lda_pred &lt;- predict(p_lda, penguins_sub)\nThe best separation between classes can be viewed from this object, which can be shown to match the original data projected using the scaling component of the model object (see Figure 14.1).\nCode to generate LDA plots# Check calculations from the fitted model, and equations\nlibrary(colorspace)\nlibrary(ggplot2)\nlibrary(ggpubr)\n# Using the predicted values from the model object\np_lda_pred_x1 &lt;- data.frame(p_lda_pred$x)\np_lda_pred_x1$species &lt;- penguins_sub$species\np_lda1 &lt;- ggplot(p_lda_pred_x1, \n                 aes(x=LD1, y=LD2, \n                     colour=species)) + \n  geom_point() +\n  xlim(-6, 8) + ylim(-6.5, 5.5) +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  ggtitle(\"(a)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, legend.title = element_blank()) \n\n# matches the calculations done manually\np_lda_pred_x2 &lt;- data.frame(as.matrix(penguins_sub[,1:4]) %*%\n                              p_lda$scaling)\np_lda_pred_x2$species &lt;- penguins_sub$species\np_lda2 &lt;- ggplot(p_lda_pred_x2, \n                 aes(x=LD1, y=LD2, \n                     colour=species)) + \n  geom_point() +\n  xlim(-6, 8) + ylim(-7, 5.5) +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  ggtitle(\"(b)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, legend.title = element_blank()) \nggarrange(p_lda1, p_lda2, ncol=2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\n\nFigure 14.1: Penguins projected into the 2D discriminant space, done two ways: (a) using the predicted values, (b) directly projecting using the model component. The scale is not quite the same but the projected data is identical in shape.\nThe \\(W\\) and \\(B\\) matrices cannot be extracted from the model object, so we need to compute these separately. We only need \\(W\\) actually. It is useful to think of this as the pooled variance-covariance matrix. Because the assumption for LDA is that the population group variance-covariances are identical, we estimate this by computing them for each class and then averaging them to get the pooled variance-covariance matrix. It’s laborious, but easy.\n# Compute pooled variance-covariance\np_vc_pool &lt;- mulgar::pooled_vc(penguins_sub[,1:4],\n                               penguins_sub$species)\np_vc_pool\n\n     bl   bd   fl   bm\nbl 0.31 0.18 0.13 0.18\nbd 0.18 0.32 0.14 0.20\nfl 0.13 0.14 0.23 0.16\nbm 0.18 0.20 0.16 0.31\nThis can be used to draw an ellipse corresponding to the pooled variance-covariance that is used by the LDA model.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Linear discriminant analysis</span>"
    ]
  },
  {
    "objectID": "14-lda.html#checking-assumptions",
    "href": "14-lda.html#checking-assumptions",
    "title": "14  Linear discriminant analysis",
    "section": "\n14.2 Checking assumptions",
    "text": "14.2 Checking assumptions\nThis LDA approach is widely applicable, but it is useful to check the underlying assumptions on which it depends: (1) that the cluster structure corresponding to each class forms an ellipse, showing that the class is consistent with a sample from a multivariate normal distribution, and (2) that the variance of values around each mean is nearly the same. Figure 14.2 and Figure 14.3 illustrates two datasets, of which only one is consistent with these assumptions. Other parametric models, such as quadratic discriminant analysis or logistic regression, also depend on assumptions about the data which should be validated. \n\nTo check the equal and elliptical variance-covariance assumption, generate points on the surface of an ellipse corresponding to the variance-covariance for each group. When watching these ellipses in a tour, they should similar in all projections.\n\n \n\nCode# Generate ellipses for each group's variance-covariance\np_ell &lt;- NULL\nfor (i in unique(penguins_sub$species)) {\n  x &lt;- penguins_sub %&gt;% dplyr::filter(species == i)\n  e &lt;- gen_xvar_ellipse(x[,1:2], n=150, nstd=1.5)\n  e$species &lt;- i\n  p_ell &lt;- bind_rows(p_ell, e)\n}\n\n\n\nCode for penguins data and ellipse plotslda1 &lt;- ggplot(penguins_sub, aes(x=bl, \n                         y=bd, \n                         colour=species)) +\n  geom_point() +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  xlim(-2.5, 3) + ylim(-2.5, 2.5) +\n  ggtitle(\"(a)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1) \nlda2 &lt;- ggplot(p_ell, aes(x=bl, \n                         y=bd, \n                         colour=species)) +\n  geom_point() +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  xlim(-2.5, 3) + ylim(-2.5, 2.5) +\n  ggtitle(\"(b)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\nggarrange(lda1, lda2, ncol=2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\n\nFigure 14.2: Scatterplot of flipper length by bill length of the penguins data, and corresponding variance-covariance ellipses. There is a small amount of difference between the ellipses, but they are similar enough to be confident in assuming the population variance-covariances are equal.\n\n\n\n\n\nCode for bushfires data and ellipse plots# Now repeat for a data set that violates assumptions\ndata(bushfires)\nlda3 &lt;- ggplot(bushfires, aes(x=log_dist_cfa, \n                         y=log_dist_road, \n                         colour=cause)) +\n  geom_point() +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  xlim(6, 11) + ylim(-1, 10.5) +\n  ggtitle(\"(a)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\nb_ell &lt;- NULL\nfor (i in unique(bushfires$cause)) {\n  x &lt;- bushfires %&gt;% dplyr::filter(cause == i)\n  e &lt;- gen_xvar_ellipse(x[,c(57, 59)], n=150, nstd=2)\n  e$cause &lt;- i\n  b_ell &lt;- bind_rows(b_ell, e)\n}\nlda4 &lt;- ggplot(b_ell, aes(x=log_dist_cfa, \n                         y=log_dist_road, \n                         colour=cause)) +\n  geom_point() +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  xlim(6, 11) + ylim(-1, 10.5) +\n  ggtitle(\"(b)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\nggarrange(lda3, lda4, ncol=2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\n\nFigure 14.3: Scatterplot of distance to cfa and road for the bushfires data, and corresponding variance-covariance ellipses. There is a lot of difference between the ellipses, so it cannot be assumed that the population variance-covariances are equal.\n\n\n\n\n\n\nThe equal and elliptical variance-covariance assumption is reasonable for the penguins data because the ellipse shapes roughly match the spread of the data. It is not a suitable assumption for the bushfires data, because the spread is not elliptically-shaped and varies in size between groups.\n\nThis approach extends to any dimension. We would use the same projection sequence to view both the data and the variance-covariance ellipses, as in Figure 14.4. It can be seen that there is some difference in the shape and size of the ellipses between species, in some projections, and also with the spread of points in the projected data. However, it is the differences are small, so it would be safe to assume that the population variance-covariances are equal.\n\nCode for making animated gifslibrary(tourr)\np_ell &lt;- NULL\nfor (i in unique(penguins_sub$species)) {\n  x &lt;- penguins_sub %&gt;% dplyr::filter(species == i)\n  e &lt;- gen_xvar_ellipse(x[,1:4], n=150, nstd=1.5)\n  e$species &lt;- i\n  p_ell &lt;- bind_rows(p_ell, e)\n}\np_ell$species &lt;- factor(p_ell$species)\nload(\"data/penguins_tour_path.rda\")\nanimate_xy(p_ell[,1:4], col=factor(p_ell$species))\nrender_gif(penguins_sub[,1:4], \n           planned_tour(pt1), \n           display_xy(half_range=0.9, axes=\"off\", col=penguins_sub$species),\n           gif_file=\"gifs/penguins_lda1.gif\",\n           frames=500,\n           loop=FALSE)\nrender_gif(p_ell[,1:4], \n           planned_tour(pt1), \n           display_xy(half_range=0.9, axes=\"off\", col=p_ell$species),\n           gif_file=\"gifs/penguins_lda2.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n\n\n(a) Data\n\n\n\n\n\n\n\n\n\n(b) Variance-covariance ellipses\n\n\n\n\n\n\nFigure 14.4: Checking the assumption of equal variance-covariance matrices for the 4D penguins data. Each ellipse corresponds to the sample variance-covariance for each species.\n\n\nAs a further check, we could generate three ellipses corresponding to the pooled variance-covariance matrix, as would be used in the model, centered at each of the means. Overlay this with the data, as done in Figure 14.5. Now you will compare the spread of the observations in the data, with the elliptical shape of the pooled variance-covariance. If it matches reasonably we can safely use LDA. This can also be done group by group when multiple groups make it difficult to view all together.\n\nTo check the fit of the equal variance-covariance assumption, simulate points on the ellipse corresponding to the pooled sample variance-covariance matrix. Generate one for each group centered at the group mean, and compare with the data.\n\n \n\nCode for adding ellipses to data# Create an ellipse corresponding to pooled vc\npool_ell &lt;- gen_vc_ellipse(p_vc_pool, \n                           xm=rep(0, ncol(p_vc_pool)))\n\n# Add means to produce ellipses for each species\np_lda_pool &lt;- data.frame(rbind(\n  pool_ell +\n    matrix(rep(p_lda$means[1,],\n      each=nrow(pool_ell)), ncol=4),\n  pool_ell +\n    matrix(rep(p_lda$means[2,],\n      each=nrow(pool_ell)), ncol=4),\n  pool_ell +\n    matrix(rep(p_lda$means[3,],\n      each=nrow(pool_ell)), ncol=4)))\n# Create one data set with means, data, ellipses\np_lda_pool$species &lt;- factor(rep(levels(penguins_sub$species),\n                          rep(nrow(pool_ell), 3)))\np_lda_pool$type &lt;- \"ellipse\"\np_lda_means &lt;- data.frame(\n  p_lda$means,\n  species=factor(rownames(p_lda$means)),\n                          type=\"mean\")\np_data &lt;- data.frame(penguins_sub[,1:5], \n                     type=\"data\")\np_lda_all &lt;- bind_rows(p_lda_means,\n                       p_data,\n                       p_lda_pool)\np_lda_all$type &lt;- factor(p_lda_all$type, \n   levels=c(\"mean\", \"data\", \"ellipse\"))\nshapes &lt;- c(3, 4, 20)\np_pch &lt;- shapes[p_lda_all$type]\n\n\n\nCode to generate animated gifs# Code to run the tour\nanimate_xy(p_lda_all[,1:4], col=p_lda_all$species, pch=p_pch)\nload(\"data/penguins_tour_path.rda\")\nrender_gif(p_lda_all[,1:4], \n           planned_tour(pt1), \n           display_xy(col=p_lda_all$species, pch=p_pch, \n                      axes=\"off\", half_range = 0.7),\n           gif_file=\"gifs/penguins_lda_pooled1.gif\",\n           frames=500,\n           loop=FALSE)\n\n# Focus on one species\nrender_gif(p_lda_all[p_lda_all$species == \"Gentoo\",1:4], \n           planned_tour(pt1), \n           display_xy(col=\"#F5191C\", \n                      pch=p_pch[p_lda_all$species == \"Gentoo\"], \n                      axes=\"off\", half_range = 0.7),\n           gif_file=\"gifs/penguins_lda_pooled2.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n\n\n(a) All species\n\n\n\n\n\n\n\n\n\n(b) Gentoo\n\n\n\n\n\n\nFigure 14.5: Checking how the pooled variance-covariance matches the spread of points in each group.\n\n\n\nFrom the tour, we can see that the assumption of equal elliptical variance-covariance is a reasonable assumption for the penguins data. In all projections the ellipse is reasonably matching the spread of the observations.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Linear discriminant analysis</span>"
    ]
  },
  {
    "objectID": "14-lda.html#examining-results",
    "href": "14-lda.html#examining-results",
    "title": "14  Linear discriminant analysis",
    "section": "\n14.3 Examining results",
    "text": "14.3 Examining results\nThe boundaries for a classification model can be examined by:\n\ngenerating a large number of test points in the domain of the data\npredicting the class for each test point\n\nWe’ll look at this for 2D using the LDA model fitted to bl, and bd of the penguins data.\n\np_bl_bd_lda &lt;- lda(species~bl+bd, data=penguins_sub, \n                                  prior = c(1/3, 1/3, 1/3))\n\nThe fitted model means \\(\\bar{x}_{Adelie} = (\\) -0.95, 0.6\\()^\\top\\), \\(\\bar{x}_{Chinstrap} = (\\) 0.89, 0.64\\()^\\top\\), and \\(\\bar{x}_{Gentoo} = (\\) 0.65, -1.1\\()^\\top\\) can be added to the plots.\nThe boundaries can be examined using the explore() function from the classifly package, which generates observations in the range of all values ofbl and bd and predicts their class. Figure 14.6 shows the resulting prediction regions, with the observed data and the sample means overlaid.\n\n# Compute points in domain of data and predict\nlibrary(classifly)\n\np_bl_bd_lda_boundaries &lt;- explore(p_bl_bd_lda, penguins_sub)\np_bl_bd_lda_m1 &lt;- ggplot(p_bl_bd_lda_boundaries) +\n  geom_point(aes(x=bl, y=bd, \n                 colour=species, \n                 shape=.TYPE), alpha=0.8) + \n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  scale_shape_manual(values=c(46, 16)) +\n  theme_minimal() +\n  theme(aspect.ratio = 1, legend.position = \"none\")\n\np_bl_bd_lda_means &lt;- data.frame(p_bl_bd_lda$means,\n                        species=rownames(p_bl_bd_lda$means))\np_bl_bd_lda_m1 +   \n  geom_point(data=p_bl_bd_lda_means, \n             aes(x=bl, y=bd), \n             colour=\"black\", \n             shape=3,\n             size=3) \n\n\n\n\n\n\nFigure 14.6: Prediction regions of the LDA model for two variables of the three species of penguins indicated by the small points. Large points are the observations, and the sample mean of each species is represented by the plus. The boundaries between groups can be seen to be roughly half-way between the means, taking the elliptical spread into account, and mostly distinguishes the three species.\n\n\n\n\n \nThis approach can be readily extended to higher dimensions. One first fits the model with all four variables, and uses the explore() to generate points in the 4D space with predictions, generating a representation of the prediction regions. Figure 14.7(a) shows the results using a slice tour (Laa et al., 2020a). Points inside the slice are shown in larger size. The slice is made in the centre of the data, to show the boundaries in this neighbourhood. As the tour progresses we see a thin slice through the centre of the data, parallel with the projection plane. In most projections there is some small overlap of points between groups, which happens because we are examining a 4D object with 2D. The slice helps ot alleviate this, allowing a focus on the boundaries in the centre of the cube. In all projections the boundaries between groups is linear, as would be expected when using LDA. We can also see that the model roughly divides the cube into three relatively equally-sized regions.\nFigure 14.7(b) shows the three prediction regions, represented by points in 4D, projected into the discriminant space. Linear boundaries neatly divide the full space, which is to be expected because the LDA model computes it’s classification rules in this 2D space.\n\np_lda &lt;- lda(species ~ ., penguins_sub[,1:5], prior = c(1/3, 1/3, 1/3))\np_lda_boundaries &lt;- explore(p_lda, penguins_sub)\n\n\nCode for generating slice tour# Code to run the tour\np_lda_boundaries$species\nanimate_slice(p_lda_boundaries[p_lda_boundaries$.TYPE == \"simulated\",1:4], col=p_lda_boundaries$species[p_lda_boundaries$.TYPE == \"simulated\"], v_rel=0.02, axes=\"bottomleft\")\nrender_gif(p_lda_boundaries[p_lda_boundaries$.TYPE == \"simulated\",1:4],\n           planned_tour(pt1),\n           display_slice(v_rel=0.02, \n             col=p_lda_boundaries$species[p_lda_boundaries$.TYPE == \"simulated\"], \n             axes=\"bottomleft\"),                     gif_file=\"gifs/penguins_lda_boundaries.gif\",\n           frames=500,\n           loop=FALSE\n           )\n\n\n\nCode for projecting into LDA space# Project the boundaries into the 2D discriminant space\np_lda_b_sub &lt;- p_lda_boundaries[\n  p_lda_boundaries$.TYPE == \"simulated\", \n  c(1:4, 6)]\np_lda_b_sub_ds &lt;- data.frame(as.matrix(p_lda_b_sub[,1:4]) %*%\n  p_lda$scaling)\np_lda_b_sub_ds$species &lt;- p_lda_b_sub$species\np_lda_b_sub_ds_p &lt;- ggplot(p_lda_b_sub_ds, \n       aes(x=LD1, y=LD2, \n           colour=species)) +\n  geom_point(alpha=0.5) +  \n  geom_point(data=p_lda_pred_x1, aes(x=LD1, \n                               y=LD2, \n                               shape=species),\n             inherit.aes = FALSE) +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  scale_shape_manual(values=c(1, 2, 3)) +\n  theme_minimal() +\n  theme(aspect.ratio = 1, \n        legend.position = \"bottom\",\n        legend.title = element_blank()) \n\n\n\n\n\n\n\n\n\n\n\n(a) 4D\n\n\n\n\n\n\n\n\n\n\n(b) Discriminant space\n\n\n\n\n\n\n\nFigure 14.7: Examining the boundaries produced by the LDA model in the full 4D with a slice tour (left) and in the discriminant space (right). Large points indicate observations within the slice, and dots are observations outside the slice. Focusing on the within-slice points, there is some overlap of points between regions in most views which represents the occlusion of 4D shapes when examining projections with thin slices. The linear boundaries are seen exactly in the discriminant space, that is they are orthogonal to these two dimensions.\n\n\n\nFrom the tour, we can see that the LDA boundaries divide the classes only in the discriminant space. It is not using the space orthogonal to the 2D discriminant space. You can see this because the boundary is sharp in just one 2D projection, while most of the projections show some overlap of regions.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Linear discriminant analysis</span>"
    ]
  },
  {
    "objectID": "14-lda.html#exercises",
    "href": "14-lda.html#exercises",
    "title": "14  Linear discriminant analysis",
    "section": "Exercises",
    "text": "Exercises\n\nFor the simple_clusters compute the LDA model, and make a plot of the data, with points coloured by the class. Overlay variance-covariance ellipses, and a \\(+\\) indicating the sample mean for each class. Is it reasonable to assume that the two classes are sampled from populations with the same variance-covariance?\nExamine the clusters corresponding to the classes in the clusters data set, using a tour. Based on the shape of the data is the assumption of equal variance-covariance reasonable?\nExamine the pooled variance-covariance for the clusters data, overlaid on the data in a tour on the 5D. Does it fit the variance of each cluster nicely?\nFit an LDA model to the simple_clusters data. Examine the boundaries produced by the model, in 2D.\nFit an LDA model to the clusters data. Examine the boundaries produced by the model in 5D.\nAssess the LDA assumptions for the multicluster data. Is LDA an appropriate model?\nCompute the first 12 PCs of the sketches data. Check the assumption of equal, elliptical variance-covariance of the 6 groups. Regardless of whether you decide that the assumption is satisfied or not, fit an LDA to the 12 PCs. Extract the discriminant space (the x component of the predict object), and examine the separation (or not) of the 6 groups in this 5D space. Is LDA providing a good classification model for this data?\nEven though the bushfires data does not satisfy the assumptions for LDA, fit LDA to the first five PCs. Examine the class differences in the 3D discriminant space.\nCompute the boundary between classes, for the LDA model where the prior probability reflects the sample size, and the LDA model where the priors are equal for all groups. How does the boundary between lightning caused fires and the other groups change?\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Linear discriminant analysis</span>"
    ]
  },
  {
    "objectID": "15-forests.html",
    "href": "15-forests.html",
    "title": "15  Trees and forests",
    "section": "",
    "text": "15.1 Trees\nThe tree algorithm (Breiman et al., 1984) is a simple and versatile algorithmic method for supervised classification. The basic tree algorithm generates a classification rule by sequentially splitting the data into two buckets. Splits are made between sorted data values of individual variables, with the goal of obtaining pure classes on each side of the split. The inputs for a simple tree classifier commonly include (1) an impurity measure, an indication of the relative diversity among the cases in the terminal nodes; (2) a parameter that sets the minimum number of cases in a node, or the minimum number of observations in a terminal node of the tree; and (3) a complexity measure that controls the growth of a tree, balancing the use of a simple generalizable tree against a more accurate tree tailored to the sample. When applying tree methods, exploring the effects of the input parameters on the tree is instructive; for example, it helps us to assess the stability of the tree model.\nAlthough algorithmic models do not depend on distributional assumptions, that does not mean that every algorithm is suitable for all data. For example, the tree model works best when all variables are independent within each class, because it does not take such dependencies into account. Visualization can help us to determine whether a particular model should be applied. In classification problems, it is useful to explore the cluster structure, comparing the clusters with the classes and looking for evidence of correlation within each class. The plots in Figure 14.2 and Figure 14.4 shows a strong correlation between the variables within each species, which indicates that the tree model may not give good results for the penguins data. We’ll show how this is the case with two variables initially, and then extend to the four variables.\nDraw tree and model boundarieslibrary(mulgar)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(colorspace)\nlibrary(classifly)\nlibrary(ggplot2)\nlibrary(ggdendro)\nlibrary(patchwork)\nlibrary(ggthemes)\n\nload(\"data/penguins_sub.rda\")\np_bl_bd_tree &lt;- rpart(species~bl+bd, data=penguins_sub)\n#f1 &lt;- rpart.plot(p_bl_bd_tree, box.palette=\"Grays\")\nd &lt;- dendro_data(p_bl_bd_tree)\nf1 &lt;- ggplot() +\n  geom_segment(data = d$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) +\n  geom_text(data = d$labels, \n            aes(x = x, y = y, \n                label = label), size = 2.7, \n            vjust = 1.2) +\n  geom_text(data = d$leaf_labels,\n            aes(x = x, y = y, \n                label = label), size = 2.5, \n            vjust = 2, hjust=c(0,0.5,0,0.5)) + \n  expand_limits(x=0.9, y=0) +\n  theme_dendro()\n\np_bl_bd_tree_boundaries &lt;- explore(p_bl_bd_tree, penguins_sub)\nf2 &lt;- ggplot(p_bl_bd_tree_boundaries) +\n  geom_point(aes(x=bl, y=bd, colour=species, shape=.TYPE)) + \n  scale_color_discrete_divergingx(palette=\"Zissou 1\") +\n  scale_shape_manual(values=c(46, 16)) +\n  theme_minimal() +\n  theme(aspect.ratio = 1, legend.position = \"none\")\n\nf1 + f2 + plot_layout(ncol=2)\n\n\n\n\n\n\nFigure 15.1: The association between variables in the penguins data causes problems for fitting a tree model. Although the model, computed using only bl and bd, is simple (left), the fit is poor (right) because it doesn’t adequately utilise combinations of variables.\nThe plots in Figure 15.1 show the inadequacies of the tree fit. The background color indicates the class predictions, and thus boundaries produced by the tree fit. They can be seen to be boxy, and missing the elliptical nature of the penguin clusters. This produces errors in the classification of observations which are indefensible. One could always force the tree to fit the data more closely by adjusting the parameters, but the main problem persists: that one is trying to fit elliptical shapes using boxes.\nThe boundaries for the tree model on all four variables of the penguins data can be viewed similarly, by predicting a set of points randomly generated in the 4D domain of observed values. Figure 15.2 shows the prediction regions for LDA and a default tree in a slice tour (Laa et al., 2020a). The slice tour is used to help see into the middle of the 4D cube. It slices the cube through the centre of the data, where the boundaries of the regions should meet.\nThe prediction regions of the default fitted tree are shown in comparison to those from the LDA model. We don’t show the tree diagram here, but it makes only six splits of the tree model, which is delightfully simple. However, just like the model fitted to two variables, the result is not adequate for the penguins data. The tree model generates boxy boundaries, whereas the LDA model splits the 4D cube obliquely. The boxy regions don’t capture the differences between the elliptically-shaped clusters. Overlaying the observed data on this display would make this clearer, but the boundaries are easier to examine without them.\nCode to make animated gifs of slice tour of boundariesp_tree &lt;- rpart(species~., data=penguins_sub[,1:5])\nrpart.plot(p_tree, box.palette=\"Grays\")\n\np_tree_boundaries &lt;- explore(p_tree, penguins_sub)\nanimate_slice(p_tree_boundaries[p_tree_boundaries$.TYPE == \"simulated\",1:4], col=p_tree_boundaries[p_tree_boundaries$.TYPE == \"simulated\",6], v_rel=0.02, axes=\"bottomleft\")\nload(\"data/penguins_tour_path.rda\")\nrender_gif(p_tree_boundaries[p_tree_boundaries$.TYPE == \"simulated\",1:4],\n           planned_tour(pt1),\n           display_slice(v_rel=0.02, \n             col=p_tree_boundaries[p_tree_boundaries$.TYPE == \"simulated\",6], \n             axes=\"bottomleft\"),                     gif_file=\"gifs/penguins_tree_boundaries.gif\",\n           frames=500,\n           loop=FALSE\n           )",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Trees and forests</span>"
    ]
  },
  {
    "objectID": "15-forests.html#sec-trees",
    "href": "15-forests.html#sec-trees",
    "title": "15  Trees and forests",
    "section": "",
    "text": "There are less strict assumptions for a non-parametric model but it is still important to understand the model fit relative to the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) LDA model\n\n\n\n\n\n\n\n\n\n(b) Tree model\n\n\n\n\n\n\nFigure 15.2: Comparison of the boundaries produced by the LDA (a) and the tree (b) model, using a slice tour. The tree boundaries are more box-shaped than the LDA boundaries, which does not adequately capture the differences between the elliptically-shaped clusters of the penguins data.\n\n\n\nWith the penguins data, a tree model may not be a good choice due to the strong correlation between variables. The best separation is in combinations of variables, not the single variable tree splits.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Trees and forests</span>"
    ]
  },
  {
    "objectID": "15-forests.html#random-forests",
    "href": "15-forests.html#random-forests",
    "title": "15  Trees and forests",
    "section": "\n15.2 Random forests",
    "text": "15.2 Random forests\n\nA random forest (Breiman, 2001) is a classifier that is built from multiple trees generated by randomly sampling the cases and the variables. The random sampling (with replacement) of cases has the fortunate effect of creating a training (“in-bag”) and a test (“out-of-bag”) sample for each tree computed. The class of each case in the out-of-bag sample for each tree is predicted, and the predictions for all trees are combined into a vote for the class identity.\nA random forest is a computationally intensive method, a “black box” classifier, but it produces several diagnostics that make the outcome less mysterious. Some diagnostics that help us to assess the model are the votes, the measure of variable importance, and the proximity matrix.\n\n15.2.1 Examining the votes matrix\nHere we show how to use the randomForest (Liaw & Wiener, 2002) votes matrix for the penguins data to investigate confusion between classes, and observations which are problematic to classify. The votes matrix can be considered to be predictive probability distribution, where the values for each observation sum to 1. With only three classes the votes matrix is only a 2D object, and thus easy to examine. With four or more classes the votes matrix needs to be examined in a tour. \n\nlibrary(randomForest)\nlibrary(dplyr)\npenguins_rf &lt;- randomForest(species~.,\n                             data=penguins_sub[,1:5],\n                             importance=TRUE)\n\n\nCodepenguins_rf\n\n\nCall:\n randomForest(formula = species ~ ., data = penguins_sub[, 1:5],      importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 2.4%\nConfusion matrix:\n          Adelie Chinstrap Gentoo class.error\nAdelie       143         2      1 0.020547945\nChinstrap      4        64      0 0.058823529\nGentoo         0         1    118 0.008403361\n\n\nTo examine the votes matrix, we extract the votes element from the random forest model object. The first five rows are:\n\nCodehead(penguins_rf$votes, 5)\n\n  Adelie Chinstrap Gentoo\n1 1.0000   0.00000      0\n2 0.9737   0.02632      0\n3 0.9884   0.01156      0\n4 1.0000   0.00000      0\n5 1.0000   0.00000      0\n\n\nThis has three columns corresponding to the three species, but because each row is a set of proportions it is only a 2D object. To reduce the dimension from 3D to the 2D we use a Helmert matrix (Lancaster, 1965). A Helmert matrix has a first row of all 1’s. The remaining components of the matrix are 1’s in the lower triangle, and 0’s in the upper triangle and the diagonal elements are the negative row sum. The rows are usually normalised to have length 1. They are used to create contrasts to test combinations of factor levels for post-testing after Analysis of Variance (ANOVA). For compositional data, like the votes matrix, when the first row is removed a Helmert matrix can be used to reduce the dimension appropriately. For three classes, this will generate the common 2D ternary diagram, but for higher dimensions it will reduce to a \\((g-1)\\)-dimensional simplex. For the penguins data, the Helmert matrix for 3D is \n\nCode to compute Helmert matrixgeozoo::f_helmert(3)\n\n          [,1]    [,2]    [,3]\nhelmert 0.5774  0.5774  0.5774\nx       0.7071 -0.7071  0.0000\nx       0.4082  0.4082 -0.8165\n\n\nWe drop the first row, transpose it, and use matrix multiplication with the votes matrix to get the ternary diagram.\n\n# Project 4D into 3D\nlibrary(geozoo)\nproj &lt;- t(geozoo::f_helmert(3)[-1,])\np_rf_v_p &lt;- as.matrix(penguins_rf$votes) %*% proj\ncolnames(p_rf_v_p) &lt;- c(\"x1\", \"x2\")\np_rf_v_p &lt;- p_rf_v_p %&gt;%\n  as.data.frame() %&gt;%\n  mutate(species = penguins_sub$species)\n\n\n# Add simplex\nsimp &lt;- simplex(p=2)\nsp &lt;- data.frame(cbind(simp$points), simp$points[c(2,3,1),])\ncolnames(sp) &lt;- c(\"x1\", \"x2\", \"x3\", \"x4\")\nsp$species = sort(unique(penguins_sub$species))\np_ternary &lt;- ggplot() +\n  geom_segment(data=sp, aes(x=x1, y=x2, xend=x3, yend=x4)) +\n  geom_text(data=sp, aes(x=x1, y=x2, label=species),\n            nudge_x=c(-0.06, 0.07, 0),\n            nudge_y=c(0.05, 0.05, -0.05)) +\n  geom_point(data=p_rf_v_p, aes(x=x1, y=x2, \n                                colour=species), \n             size=2, alpha=0.5) +\n  scale_color_discrete_divergingx(palette=\"Zissou 1\") +\n  theme_map() +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n\nCode to generate animated gifs# Look at the votes matrix, in its 3D space\nanimate_xy(penguins_rf$votes, col=penguins_sub$species)\n\n# Save an animated gif\nrender_gif(penguins_rf$votes,\n           grand_tour(),\n           display_xy(v_rel=0.02, \n             col=penguins_sub$species, \n             axes=\"bottomleft\"), \n           gif_file=\"gifs/penguins_rf_votes.gif\",\n           frames=500,\n           loop=FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n(a) 3D\n\n\n\n\n\n\n\n\n\n\n(b) 2D ternary diagram\n\n\n\n\n\n\n\nFigure 15.3: Examining the votes matrix from a random forest fit to the penguins: (a) from a tour of the 3D, (b) projected into 2D, to make a ternary diagram. In 3D the points can be seen to lie along a 2D plane, which is due to the constraint that the values sum to 1. From the ternary diagram, the classification can be seen to be reasonably well distinguished because points mostly lie at the vertex. There are a few penguins that are confused with a different species, as seen from the few points spread between vertices.\n\n\nWe can use the geozoo package to generate the surrounding simplex, which for 2D is a triangle.\nThe votes matrix reports the proportion of trees each observation is classified as each class. From the tour of the votes matrix, as in Figure 15.3(a), it can be seen to be 2D in 3D space. This is due to the constraint that the three proportions for each observation sum to 1. Using a Helmert matrix, this data can be projected into the 2D space, or more generally the \\((g-1)\\)-dimensional space where it resides, shown in Figure 15.3(b). In 2D this is called a ternary diagram, and in higher dimensions the bounding shapes might be considered to be a simplex. The vertices of this shape correspond to \\((1,0,0), (0,1,0), (0,0,1)\\) (and analogously for higher dimensions), which represent perfect confidence, that an observation is classified into that group all the time.\nWhat we can see here is a concentration of points in the corners of the triangle indicates that most of the penguins are confidently classified into their correct class. Then there is more separation between the Gentoo and the others, than between Chinstrap and Adelie. That means that as a group Gentoo are more distinguishable. Only one of the Gentoo penguins has substantial confusion, mostly confused as a Chinstrap, but occasionally confused as an Adelie – if it was only ever confused as a Chinstrap it would fall on the edge between Gentoo and Chinstrap. There are quite a few Chinstrap and Adelie penguins confused as each other, with a couple of each more confidently predicted to be the other class. This can be seen because there are points of the wrong colour close to those vertices.\nThe votes matrix is useful for investigating the fit, but one should remember that there are some structural elements of the penguins data that don’t lend themselves to tree models. Although a forest has the capacity to generate non-linear boundaries by combining predictions from multiple trees, it is still based on the boxy boundaries of trees. This makes it less suitable for the penguins data with elliptical classes. You could use the techniques from the previous section to explore the boundaries produced by the forest, and you will find that the are more boxy than the LDA models. \n\nBy visualising the votes matrix we can understand which observations are harder to classify, which of the classes are more easily confused with each other.\n\nTo examine a vote matrix for a problem with more classes, we will examine the 10 class fake_trees data example. The full data has 100 variables, and we have seen from Chapter 7 that reducing to 10 principal components allows the linear branching structure in the data to be seen. Given that the branches correspond to the classes, it will be interesting to see how well the random forest model performs. \n\nlibrary(mulgar)\nlibrary(dplyr)\nlibrary(liminal)\nft_pca &lt;- prcomp(fake_trees[,1:100], \n                 scale=TRUE, retx=TRUE)\nft_pc &lt;- as.data.frame(ft_pca$x[,1:10])\nft_pc$branches &lt;- fake_trees$branches\nlibrary(randomForest)\nft_rf &lt;- randomForest(branches~., data=ft_pc, \n                            importance=TRUE)\n\n\nCodehead(ft_rf$votes, 5)\n\n    0 1    2     3    4    5 6 7     8    9\n1 0.9 0 0.02 0.000 0.01 0.11 0 0 0.006 0.00\n2 0.7 0 0.02 0.000 0.02 0.31 0 0 0.000 0.00\n3 0.8 0 0.04 0.000 0.11 0.02 0 0 0.000 0.02\n4 0.9 0 0.01 0.000 0.00 0.08 0 0 0.000 0.00\n5 0.6 0 0.04 0.005 0.03 0.28 0 0 0.005 0.00\n\n\n\nft_rf_votes &lt;- ft_rf$votes %&gt;%\n  as_tibble() %&gt;%\n  mutate(branches = fake_trees$branches)\n\nproj &lt;- t(geozoo::f_helmert(10)[-1,])\nf_rf_v_p &lt;- as.matrix(ft_rf_votes[,1:10]) %*% proj\ncolnames(f_rf_v_p) &lt;- c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\")\nf_rf_v_p &lt;- f_rf_v_p %&gt;%\n  as.data.frame() %&gt;%\n  mutate(branches = fake_trees$branches)\n\nsimp &lt;- geozoo::simplex(p=9)\nsp &lt;- data.frame(simp$points)\ncolnames(sp) &lt;- c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\")\nsp$branches = \"\"\nf_rf_v_p_s &lt;- bind_rows(sp, f_rf_v_p) %&gt;%\n  mutate(branches = factor(branches))\nlabels &lt;- c(\"0\" , \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\",\n                rep(\"\", 3000))\n\n\nCode to make animated gifsanimate_xy(f_rf_v_p_s[,1:9], col = f_rf_v_p_s$branches, \n           axes = \"off\", half_range = 0.8,\n           edges = as.matrix(simp$edges),\n           obs_labels = labels, palette = \"Viridis\")\n\nrender_gif(f_rf_v_p_s[,1:9],\n           grand_tour(),\n           display_xy(col = f_rf_v_p_s$branches, \n           axes = \"off\", half_range = 0.8,\n           edges = as.matrix(simp$edges),\n           obs_labels = labels, palette=\"Viridis\"),\n           gif_file=\"gifs/ft_votes.gif\",\n           frames=500) \n\n\n\n\n\n\n\n\n\n\n\n(a) The 9D votes matrix for the 10 class fake_trees data in a tour.\n\n\n\n\n\n\n\n\n\n(b) Several static views from the tour revealing how clusters connect.\n\n\n\n\n\n\nFigure 15.4: A tour and several static views of the votes matrix. Lines are the edges of the 8D simplex, which bounds the shape. Points mostly concentrate in the vertices, or spread along one of the edges, which means that most observations are clearly belonging to one group, or confused with a single other group. The exception to this is class 0, which spreads in many directions.\n\n\n The votes matrix is 9D, due to the 9 groups. With this many dimensions, if the cluster structure is weak, it will look messy in a tour. However, what we can see in Figure 15.4 is that the structure is relatively simple, and very interesting in that it suggests a strong clustering of classes. Points are coloured by their true class. The lines represent the 8D simplex that bounds the observations, akin to the triangle in the ternary diagram.\nPoints concentrate at the vertices, which means that most are confidently predicted to be their true class. The most spread of points is along single edges, between pairs of vertices. This means that when there is confusion it is mostly with just one other group. One vertex (0) which has connections to all other vertexes. That is, there are points stretching from this vertex to every other. It means that some observations in every other class can be confused with class 0, and class 0 observations can be confused with every other class. This information suggests that cluster 0 is central to all the other clusters.\nSome of this information could also be inferred from the confusion matrix for the model. However visualising the votes matrix provides more intricate details. Here we have seen that the points spread out from a vertex, with fewer and fewer the further one gets. It allows us to see the distribution of points, which is not possible from the confusion matrix alone. The same misclaassification rate could be due to a variety of distributions. The visual pattern in the votes matrix is striking, and gives additional information about how the clustering distribution, and shapes of clusters, matches the class labels. It reinforces the clusters are linear extending into different dimensions in the 100D space, but really only into about 8D (as we’ll see from the variable importance explanation below). We also see that nine of the clusters are all connected to a single cluster.\n\nThe votes matrix for the fake trees has a striking geometric structure, with one central cluster connected to all other clusters, each of which is distinct from each other.\n\n\n15.2.2 Using variable importance\n\nThe variable importance score across all classes, and for each class is useful for choosing variables to enter into a tour, to explore class differences. This is particularly so when there are many variables, as in the fake_trees data. We would also expect that this data will have a difference between importance for some classes.\n\nlibrary(gt)\nft_rf$importance %&gt;% \n  as_tibble(rownames=\"Var\") %&gt;% \n  rename(Acc=MeanDecreaseAccuracy,\n         Gini=MeanDecreaseGini) %&gt;%\n  #arrange(desc(Gini)) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = c(`0`,`1`,`2`,`3`,`4`,\n                         `5`,`6`,`7`,`8`,`9`),\n             decimals = 1) %&gt;% \n  fmt_number(columns = Acc,\n             decimals = 2) %&gt;%\n  fmt_number(columns = Gini,\n             decimals = 0)\n\n\nTable 15.1: Variable importance from the random forest fit to the fake trees data, for each of the 9 classes, and using the accuracy and Gini metrics.\n\n\n\n\n\n\nVar\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nAcc\nGini\n\n\n\nPC1\n0.1\n0.3\n0.5\n0.3\n0.2\n0.5\n0.4\n0.2\n0.3\n0.3\n0.31\n484\n\n\nPC2\n0.1\n0.2\n0.2\n0.5\n0.3\n0.3\n0.2\n0.4\n0.2\n0.3\n0.28\n376\n\n\nPC3\n0.1\n0.1\n0.1\n0.1\n0.5\n0.1\n0.1\n0.1\n0.2\n0.2\n0.16\n304\n\n\nPC4\n0.1\n0.5\n0.1\n0.0\n0.1\n0.0\n0.4\n0.1\n0.1\n0.1\n0.14\n342\n\n\nPC5\n0.1\n0.1\n0.3\n0.1\n0.2\n0.2\n0.1\n0.1\n0.3\n0.2\n0.18\n337\n\n\nPC6\n0.1\n0.2\n0.2\n0.2\n0.0\n0.1\n0.0\n0.3\n0.1\n0.2\n0.15\n282\n\n\nPC7\n0.1\n0.0\n0.2\n0.0\n0.1\n0.1\n0.1\n0.3\n0.1\n0.1\n0.11\n258\n\n\nPC8\n0.0\n0.1\n0.0\n0.2\n0.1\n0.1\n0.0\n0.0\n0.1\n0.3\n0.09\n216\n\n\nPC9\n0.1\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.02\n58\n\n\nPC10\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.01\n43\n\n\n\n\n\n\n\n\n\nFrom the variable importance (Table 15.1), we can see that PC9 and PC10 do not substantially contribute. That means the 100D data can be reduced to 8D without losing the information about the cluster structure. PC1 is most important overall, and the order matches the PC order, as might be expected because highest variance corresponds to the most spread clusters. Each cluster has a different set of variables that are important. For example, the variables important for distinguishing cluster 1 are PC1 and PC4, and for cluster 2 they are PC1 and PC5.\n\nClass-wise variable importance helps to find a subspace on which to tour to examine how this class cluster differs from the others.\n\nWe can use the accuracy information to choose variables to provide to the tour. Overall, one would sequentially add the variables into a tour based on their accuracy or Gini value. Here it is simply starting with the first three PCs, and then sequentially adding the PCs to examine how distinct the clusters are with ot without the extra variable. It can be helpful to focus on a single class against all the others. To do this create a new binary class variable, indicating that the observation belongs to class \\(k\\) or not, as follows:\n\nft_pc &lt;- ft_pc %&gt;%\n  mutate(cl1 = factor(case_when(\n                 branches == \"0\" ~ \"0\",\n                 branches == \"1\" ~ \"1\",\n                 .default = \"other\"\n  )))\n\n\nCode to make animated gifsanimate_xy(ft_pc[,c(\"PC1\", \"PC2\", \"PC4\", \"PC6\")], col=ft_pc$cl1, palette=\"Viridis\")\nrender_gif(ft_pc[,c(\"PC1\", \"PC2\", \"PC4\", \"PC6\")],\n           grand_tour(),\n           display_xy(col=ft_pc$cl1, palette=\"Viridis\"),\n           gif_file=\"gifs/ft_cl1.gif\",\n           frames=500)\n\n\n\nCode to make plotft_pc_cl1 &lt;- ggplot(ft_pc, aes(x=PC4, y=PC1, col=cl1)) +\n  geom_point(alpha=0.7, size=1) +\n  scale_color_discrete_sequential(palette=\"Viridis\", rev=FALSE) +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\n\n\nFrom Figure 15.5 we can see how cluster 1 is distinct from all of the other observations, albeit with a close connection to the trunk of the tree (cluster 0). The distinction is visible whenever PC4 contributes to the projection, but can be seen clearly with only PC1 and PC4.\n\n\n\n\n\n\n\n\n\n(a) Tour of most important variables for class 1.\n\n\n\n\n\n\n\n\n\n\n(b) PC1 and PC4 together reveal cluster 1.\n\n\n\n\n\n\n\nFigure 15.5: Focusing on class 1 in the fake_trees data. The most important variables were PC1 and PC4. A combination of PC2 and PC4 reveals the difference between cluster 1 and all the other clusters.\n\n\nFor a problem like this, it can be useful to several classes together. We’ve chosen to start with class 8 (light green), because from Figure 15.4 it appears to have less connection with class 0, and closer connection with another class. This is class 6 (medium green). A good guess because it has one observation confused with class 8 according to the confusion matrix (printed below). \nWhen we examine these two clusters in association with class 0, we can see that there is a third cluster that is connected with clusters 6 and 8. It turns out to be cluster 1. It’s confusing, because the confusion matrix would suggest that the overlap from all is with cluster 0, but not each other.\n\nCodeft_rf$confusion\n\n    0   1   2   3   4   5   6   7   8   9 class.error\n0 263   7   2   3   3   6   5   2   6   3       0.123\n1  14 286   0   0   0   0   0   0   0   0       0.047\n2   8   0 290   0   2   0   0   0   0   0       0.033\n3   5   0   0 289   0   0   0   5   0   1       0.037\n4  13   0   0   0 287   0   0   0   0   0       0.043\n5  11   0   0   0   0 289   0   0   0   0       0.037\n6  13   0   0   0   0   0 286   0   1   0       0.047\n7   6   0   0   4   0   0   0 290   0   0       0.033\n8   7   0   0   0   0   0   0   0 293   0       0.023\n9   6   0   0   0   0   0   0   1   0 293       0.023\n\n\n\nft_pc &lt;- ft_pc %&gt;%\n  mutate(cl8 = factor(case_when(\n                 branches == \"0\" ~ \"0\",\n                 branches == \"6\" ~ \"6\",\n                 branches == \"1\" ~ \"1\",\n                 branches == \"8\" ~ \"8\",\n                 .default = \"other\"\n  )))\n\n\nCode to make animated gifanimate_xy(ft_pc[,c(\"PC1\", \"PC2\", \"PC4\", \"PC5\", \"PC6\")], col=ft_pc$cl8, palette=\"Viridis\")\nrender_gif(ft_pc[,c(\"PC1\", \"PC2\", \"PC4\", \"PC5\", \"PC6\")],\n           grand_tour(),\n           display_xy(col=ft_pc$cl8, palette=\"Viridis\"),\n           gif_file=\"gifs/ft_cl8.gif\",\n           frames=500)\n\n\n\nCode to make plotft_pc_cl8 &lt;- ggplot(ft_pc, aes(x=PC1, y=PC5, col=cl8)) +\n  geom_point(alpha=0.7, size=1) +\n  scale_color_discrete_sequential(palette=\"Viridis\", rev=FALSE) +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\n\n\nFrom the tour in Figure 15.6 we can see that clusters 1, 6, and 8 share one end of the trunk (cluster 0). Cluster 8 is almost more closely connected with cluster 6, though, than cluster 0. PC1 and PC5 mostly show the distinction between cluster 8 and the rest of the points, but it is clearer if more variables are used.\n\n\n\n\n\n\n\n\n\n(a) Tour of most important variables for class 1.\n\n\n\n\n\n\n\n\n\n\n(b) PC1 and PC5 together mostly reveal cluster 8.\n\n\n\n\n\n\n\nFigure 15.6: Focusing on class 8 in the fake_trees data, relative to nearby clusters 1 and 6. The most important variables for cluster 8 are PC1, PC2, PC5, but to explore in association with clusters 1 and 6, we include PC4 and PC6. A combination of PC1 and PC5 reveals the difference between cluster 8, 6, 1 and 0.\n\n\n\nAlthough the confusion matrix suggests that class clusters are separated except for class 0, focusing on a few classes and using the variable importance to examine smaller subspaces, reveals they are connected in groups of three to class 0.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Trees and forests</span>"
    ]
  },
  {
    "objectID": "15-forests.html#exercises",
    "href": "15-forests.html#exercises",
    "title": "15  Trees and forests",
    "section": "Exercises",
    "text": "Exercises\n\nUsing a grand tour compare the boundaries from the random forest model on the penguins data to that of (a) a default tree model, (b) an LDA model. Is it less boxy than the tree model, but still more boxy than that of the LDA model?\nTinker with the parameters of the tree model to force it to fit a tree more closely to the data. Compare the boundaries from this with the default tree, and with the forest model. Is it less boxy than the default tree, but more boxy than the forest model?\nFit a random forest model to the bushfires data using the cause variable as the class. It is a highly imbalanced classification problem. What is the out-of-bag error rate for the forest? Are there some classes that have lower error rate than others? Examine the 4D votes matrix with a tour, and describe the confusion between classes. This is interesting because it is difficult to accurately classify the fire ignition cause, and only some groups are often confused with each other. You should be able to see this from the 3D votes matrix.\nFit a forest model to the first 21 PCs of the sketches data. Explore the 5D votes matrix. Why does it look star-shaped?\nChoose a cluster (or group of clusters) from the fake_trees data (2, 3, 4, 5, 7, 9) to explore in detail like done in Section 15.2.2. Be sure to choose which PCs are the most useful using a tour, and follow-up by making a scatterplot showing the best distinction between your chosen cluster and the other observations.\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Trees and forests</span>"
    ]
  },
  {
    "objectID": "16-svm.html",
    "href": "16-svm.html",
    "title": "\n16  Support vector machines\n",
    "section": "",
    "text": "16.1 Components of the SVM model\nA support vector machine (SVM) (Vapnik, 1999) looks for gaps between clusters in the data, based on the extreme observations in each class. In this sense it mirrors the graphical approach described Chapter 7, in which we searched for gaps between groups. It can be viewed as similar to LDA, in that the boundary between classes is a hyperplane. The difference between LDA and SVM is the placement of the boundary. LDA uses the means and covariance matrices of the classes to place the boundary, but SVM uses extreme observations.\nSVM is widely used for it’s ability to fit non-linear classification models in a simple fashion using kernels in the boundary equation. We are focusing on linear methods here because it makes for a useful comparison with how the models differ from those provided by SVM. SVM tends to place the boundary between groups in a gap, if it exists. This is nice from a visual perspective because when we look at differences between classes using a tour, we naturally focus on the gaps. SVM better fits this perception than LDA.\nNon-linear SVM models are interesting to examine also. Mostly one would examine the boundaries between classes which can be done in the same way that is documented in the Chapter 14 and Chapter 15.\nTo illustrate the approach, we use two simple simulated data examples. Both have only two variables, and two classes. Explaining SVM is easier when there are just two groups. In the first data set the two classes have different covariances matrices, which will cause trouble for LDA, but SVM should see the gap between the two clusters and place the separating hyperplane in the middle of the gap. In the second data set the two groups are concentric circles, with the inner one solid. A non-linear SVM should be fitted to this data, which should see circular gap between the two classes.\nNote that the svm function in the e1071 package will automatically scale observations into the range \\([0,1]\\). To make it easier to examine the fitted model, it is best to scale your data first, and then fit the model.\nCode to simulate data examples# Toy examples\nlibrary(mulgar)\nlibrary(ggplot2)\nlibrary(geozoo)\nlibrary(tourr)\n\nset.seed(1071)\nn1 &lt;- 162\nvc1 &lt;- matrix(c(1, -0.7, -0.7, 1), ncol=2, byrow=TRUE)\nc1 &lt;- rmvn(n=n1, p=2, mn=c(-2, -2), vc=vc1)\nvc2 &lt;- matrix(c(1, -0.4, -0.4, 1)*2, ncol=2, byrow=TRUE)\nn2 &lt;- 138\nc2 &lt;- rmvn(n=n2, p=2, mn=c(2, 2), vc=vc2)\ndf1 &lt;- data.frame(x1=mulgar:::scale2(c(c1[,1], c2[,1])), \n                 x2=mulgar:::scale2(c(c1[,2], c2[,2])), \n                 cl = factor(c(rep(\"A\", n1), \n                               rep(\"B\", n2))))\nc1 &lt;- sphere.hollow(p=2, n=n1)$points*3 + \n  c(rnorm(n1, sd=0.3), rnorm(n1, sd=0.3))\nc2 &lt;- sphere.solid.random(p=2, n=n2)$points\ndf2 &lt;- data.frame(x1=mulgar:::scale2(c(c1[,1], c2[,1])), \n                  x2=mulgar:::scale2(c(c1[,2], c2[,2])), \n                  cl = factor(c(rep(\"A\", n1), \n                               rep(\"B\", n2))))\nlibrary(classifly)\nlibrary(e1071)\ndf1_svm &lt;- svm(cl~., data=df1, \n                     probability=TRUE, \n                     kernel=\"linear\", \n               scale=FALSE)\ndf1_svm_e &lt;- explore(df1_svm, df1)\n\ndf2_svm &lt;- svm(cl~., data=df2,  \n                     probability=TRUE, \n                     kernel=\"radial\")\ndf2_svm_e &lt;- explore(df2_svm, df2)\nCode to make plotslibrary(patchwork)\nlibrary(colorspace)\ns1 &lt;- ggplot() + \n  geom_point(data=df1, aes(x=x1, y=x2, colour=cl),\n             shape=20) +\n  scale_colour_discrete_divergingx(palette=\"Zissou 1\") +\n  geom_point(data=df1_svm_e[(!df1_svm_e$.BOUNDARY)&(df1_svm_e$.TYPE==\"simulated\"),], \n             aes(x=x1, y=x2, colour=cl), shape=3) +\n  geom_point(data=df1[df1_svm$index,], \n             aes(x=x1, y=x2, colour=cl), \n             shape=4, size=4) +\n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position = \"none\") +\n  ggtitle(\"(a)\")\n\ns2 &lt;- ggplot() + \n  geom_point(data=df2, aes(x=x1, y=x2, colour=cl), shape=20) +\n  scale_colour_discrete_divergingx(palette=\"Zissou 1\") +\n  geom_point(data=df2_svm_e[(!df2_svm_e$.BOUNDARY)&(df2_svm_e$.TYPE==\"simulated\"),], \n             aes(x=x1, y=x2, colour=cl), \n             shape=3) +\n  geom_point(data=df2[df2_svm$index,], \n             aes(x=x1, y=x2, colour=cl), \n             shape=4, size=4) +\n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position = \"none\") +\n  ggtitle(\"(b)\")\n\ns1+s2\n\n\n\n\n\n\nFigure 16.1: SVM classifier fit overlaid on two simulated data examples: (a) groups with different variance-covariance, fitted using a linear kernel, (b) groups with non-linear separation, fitted using a radial kernel. The band of points shown as ‘+’ mark the SVM boundary, and points marked by ‘x’ are the support vectors used to define the boundary.\nFigure 16.1 shows the two data sets and the important aspects of the fitted SVM model for each. The observations are represented by dots, the separating hyperplane (just a line for 2D) is represented by ‘+’. Where the two colours merge is the actual location of the boundary between classes. It can be seen that this is located right down the middle of the gap, for both data sets. Even though the boundary is circular for the second data set, in a transformed high-dimensional space it would be linear.\nSVMs use a subset of the observations to define the boundary, and these are called the support vectors. For each of the data sets these are marked with ‘x’. For the linear boundary, there are nine support vectors, five in one group and four in the other. There is one interesting observation in the red group, which falls on the other side of the boundary. It is marked as a support vector, but its contribution to the fitted hyperplane is limited by a control parameter in the model fitting process.\nLinear SVMs can be assessed similarly to regression models. The components of the model are:\ndf1_svm$index\n\n[1]  15  45 123 135 155 180 202 239 292\ndf1_svm$coefs\n\n            [,1]\n [1,]  0.3771240\n [2,]  0.1487726\n [3,]  1.0000000\n [4,]  1.0000000\n [5,]  1.0000000\n [6,] -0.5258966\n [7,] -1.0000000\n [8,] -1.0000000\n [9,] -1.0000000\nwhich indicate that all but 15, 45 and 180 are actually bounded support vectors (their coefficients are bounded to magnitude 1).\ndf1_svm$rho\n\n[1] 0.3520001\ncan be used to compute the equation of the fitted hyperplane.\nw = t(df1_svm$SV) %*% df1_svm$coefs\nw\n\n        [,1]\nx1 -1.501086\nx2 -1.356237\nGiving the equation to be -1.5 \\(x_1 +\\) -1.36 \\(x_2 +\\) -0.35 \\(=0\\), or alternatively, \\(x_2 =\\) -1.11 \\(x_1 +\\) -0.26.\nwhich can be used to generate a line to show the boundary with the data.\ns1 + geom_abline(intercept=df1_svm$rho/w[2],\n                 slope=-w[1]/w[2])\nNote that care in scaling of data is important to get the intercept calculated exactly. We have standardised the data, and set the scale=FALSE parameter in the svm function. The slope calculation is quite robust to the data scaling.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Support vector machines</span>"
    ]
  },
  {
    "objectID": "16-svm.html#components-of-the-svm-model",
    "href": "16-svm.html#components-of-the-svm-model",
    "title": "\n16  Support vector machines\n",
    "section": "",
    "text": "The points that are the support vectors:\n\n\n\nTheir coefficients:\n\n\n\n\nthat when used with the intercept:\n\n\n\n\n\n\n\n\n\nLike LDA, a linear SVM model for two groups can be written using the equation of a hyperplane. The fitted model coefficients are then used to generate points on this plane, to examine the boundary between groups.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Support vector machines</span>"
    ]
  },
  {
    "objectID": "16-svm.html#examining-the-model-components-in-high-dimensions",
    "href": "16-svm.html#examining-the-model-components-in-high-dimensions",
    "title": "\n16  Support vector machines\n",
    "section": "\n16.2 Examining the model components in high-dimensions",
    "text": "16.2 Examining the model components in high-dimensions\nFor higher dimensions, the procedures are similar, with the hyperplane and support vectors being examined using a tour. Here we examine the model for differentiating male and female Chinstrap penguins. The Chinstrap penguins have a noticeable difference in size of the sexes, unlike the other two species. Working with a two-class problem is easier for explaining SVM, but multi-class calculations can also follow this approach.\n\nlibrary(dplyr)\nload(\"data/penguins_sub.rda\")\nchinstrap &lt;- penguins_sub %&gt;%\n  filter(species == \"Chinstrap\") %&gt;%\n  select(-species) %&gt;%\n  mutate_if(is.numeric, mulgar:::scale2)\nchinstrap_svm &lt;- svm(sex~., data=chinstrap, \n                     kernel=\"linear\",\n                     probability=TRUE, \n                     scale=FALSE)\nchinstrap_svm_e &lt;- explore(chinstrap_svm, chinstrap)\n\n\nCode to make the tours# Tour raw data\nanimate_xy(chinstrap[,1:4], col=chinstrap$sex)\n# Add all SVs, including bounded\nc_pch &lt;- rep(20, nrow(chinstrap))\nc_pch[chinstrap_svm$index] &lt;- 4\nanimate_xy(chinstrap[,1:4], col=chinstrap$sex, pch=c_pch)\n# Only show the SVs with |coefs| &lt; 1\nc_pch &lt;- rep(20, nrow(chinstrap))\nc_pch[chinstrap_svm$index[abs(chinstrap_svm$coefs)&lt;1]] &lt;- 4\nc_cex &lt;- rep(1, nrow(chinstrap))\nc_cex[chinstrap_svm$index[abs(chinstrap_svm$coefs)&lt;1]] &lt;- 2\nanimate_xy(chinstrap[,1:4], col=chinstrap$sex, \n           pch=c_pch, cex=c_cex)\nrender_gif(chinstrap[,1:4],\n           grand_tour(),\n           display_xy(col=chinstrap$sex, pch=c_pch, cex=c_cex),\n           gif_file=\"gifs/chinstrap_svs.gif\",\n           width=400,\n           height=400,\n           frames=500)\n\n# Tour the separating hyperplane also\nsymbols &lt;- c(3, 20)\nc_pch &lt;- symbols[as.numeric(chinstrap_svm_e$.TYPE[!chinstrap_svm_e$.BOUNDARY])]\nanimate_xy(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4], \n           col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY],\n           pch=c_pch)\nrender_gif(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4],\n           grand_tour(),\n           display_xy(col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY], pch=c_pch),\n           gif_file=\"gifs/chinstrap_svm.gif\",\n           width=400,\n           height=400,\n           frames=500)\n\n\n\n\n\n\n\n\n\n\n\n(a) Support vectors\n\n\n\n\n\n\n\n\n\n(b) SVM boundary\n\n\n\n\n\n\nFigure 16.2: SVM model for distinguishing the sexes of the Chinstrap penguins. The separating hyperplane is 3D, and separates primarily on variables bl and bd, as seen because these two axes extend out from the plane when it is seen on its side, separating the two groups.\n\n\n \n\nMark the support vectors by point shape, and examine where these are relative to the difference between groups.\n\nExamining the hyperplane in a grand tour display (Figure 16.2) indicates that two of the variables, bl and bd, are important for separating the two classes. We can check this interpretation using the radial tour. Using the components from the model, the coefficients of the hyperplane are:\n\nt(chinstrap_svm$SV) %*% chinstrap_svm$coefs\n\n         [,1]\nbl -0.9102439\nbd -1.1073475\nfl -0.5223364\nbm -0.2846370\n\n\nThe coefficients for bl and bd are the largest (in magnitude) which supports the the interpretation that they are most important. This vector can be used to set the starting point for radial tour, once it is normalised. Any orthonormal vector serves to turn this into a 2D projection, to visualise the boundary.\n\nset.seed(1022)\nprj1 &lt;- mulgar::norm_vec(t(chinstrap_svm$SV) %*%\n                           chinstrap_svm$coefs)\nprj2 &lt;- basis_random(4, 1)\nprj &lt;- orthonormalise(cbind(prj1, prj2))\nprj\n\n         [,1]        [,2]\nbl -0.5865081 -0.06412875\nbd -0.7135101  0.51192498\nfl -0.3365631 -0.77713899\nbm -0.1834035 -0.36038216\n\n\n\nCode to conduct the radial toursanimate_xy(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4], \n           tour_path = radial_tour(start=prj, mvar = 2),\n           col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY],\n           pch=c_pch)\nrender_gif(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4],\n           radial_tour(start=prj, mvar = 2),\n           display_xy(col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY], pch=c_pch),\n           gif_file=\"gifs/chinstrap_rad_bd.gif\",\n           apf = 1/30,\n           width=400,\n           height=400,\n           frames=500)\nrender_gif(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4],\n           radial_tour(start=prj, mvar = 1),\n           display_xy(col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY], pch=c_pch),\n           gif_file=\"gifs/chinstrap_rad_bl.gif\",\n           apf = 1/30,\n           width=400,\n           height=400,\n           frames=500)\nrender_gif(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4],\n           radial_tour(start=prj, mvar = 3),\n           display_xy(col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY], pch=c_pch),\n           gif_file=\"gifs/chinstrap_rad_fl.gif\",\n           apf = 1/30,\n           width=400,\n           height=400,\n           frames=500)\nrender_gif(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4],\n           radial_tour(start=prj, mvar = 4),\n           display_xy(col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY], pch=c_pch),\n           gif_file=\"gifs/chinstrap_rad_bm.gif\",\n           apf = 1/30,\n           width=400,\n           height=400,\n           frames=500)\n\n\nThis projection is show in Figure 16.3. You can see the boundary between the two sexes as a clear line, marked by a sample of points on either side. We use the radial tour to remove each of the variables from the projection using the radial tour to examine it’s importance on the model, and hence the boundary. If the clear view of the boundary gets jumbled when a variable is removed we infer that this variable is very important for the model (as seen for bl and bd). If there is little change in the clarity when a variable is removed, then it is less important (as seen for fl and bm). \n\n\n\n\n\n\n\n\n\n(a) bl\n\n\n\n\n\n\n\n\n\n(b) bd\n\n\n\n\n\n\n\n\n\n\n\n(c) fl\n\n\n\n\n\n\n\n\n\n(d) bm\n\n\n\n\n\n\nFigure 16.3: Exploring the importance of the four variables to the separating hyperplane using a radial tour where the contribution of each variable is reduced to 0, and then increased to it’s original value. You can see that bl and bd contribute most to the plane, because when they are removed the plane is no longer on it side marking the boundary. Variables fl and bm contribute a small amount to the separating hyperplane, but it is possible that these two could be removed without affecting the strength of the separation between the sexes.\n\n\n\nUse a radial tour to zero out coefficients defining the separating hyperplane to explore the variable importance.\n\nIn this example, we can see that clarity of the boundary changes substantially when either bl and bd are removed. There is a small change when fl and bm are removed, so they are less important. This interpretation matches the interpretation that would be made from the magnitude of the coefficients of the hyperplane (printed earlier). They reinforce each other. It is possible that the interpretation of the coefficients could differ after using the radial tour, most likely in terms of simplifying the vector, supporting the forcing some coefficients to zero.\n\nWhen we use the radial tour to examine how the different variables contribute to the separating hyperplane between the sexes, we learn that bl and bd are the most important variables. We could (almost) ignore fl and bm for this classification.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Support vector machines</span>"
    ]
  },
  {
    "objectID": "16-svm.html#exercises",
    "href": "16-svm.html#exercises",
    "title": "\n16  Support vector machines\n",
    "section": "Exercises",
    "text": "Exercises\n\nGenerate a small subset from the bushfire data: we keep the variables log_dist_cfa, log_dist_road and cause, and we select only observations where cause is either lightning or arson. Fit a linear SVM model to separate the two classes and show the decision boundary together with the data. Compare to the boundary obtained by LDA and argue how the two models place the separating hyperplane in different ways.\nWe extend this into a multivariate setting by also including amaxt180 and amaxt720 as predictors. Fit a linear SVM model and calculate the hyperplane to judge which of these variables are important.\nCalculate the decision boundary and look at it with a radial tour to see the effect from including individual predictors in a projection. Also explore what happens when rotating out multiple variables together. What can you learn from this?\nFrom the sketches_train data select all observations of class banana or boomerang For this subset use PCA to find the first 5 PCs. Fit two SVM models: once with linear kernel and once with radial kernel and default value for the gamma parameter. Compare the number of missclassified observations in the training data for the two models.\nCompute the model predictions and compare the decision boundaries between the linear and radial SVM using a slice tour. Does the shape match what you expect given the respective kernel function?\nSVM models are defined for separating two classes, but and ensemble of such models can be used when we want to distinguish more than two classes. Look up the documentation of the svm function to learn how this works, then fit an SVM model to separate the three penguin species. In this case we primarily use the model predictions to investigate the decision boundaries, you can use explore together with the slice tour to do this. You can use different kernels and compare the resulting decision boundaries.\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Support vector machines</span>"
    ]
  },
  {
    "objectID": "17-nn.html",
    "href": "17-nn.html",
    "title": "\n17  Neural networks and deep learning\n",
    "section": "",
    "text": "17.1 Setting up the model\nNeural networks (NN) can be considered to be nested additive (or even ensemble) models where explanatory variables are combined, and transformed through an activation function like a logistic. These transformed combinations are added recursively to yield class predictions. They are considered to be black box models, but there is a growing demand for interpretability. Although interpretability is possible, it can be unappealing to understand a complex model constructed to tackle a difficult classification task. Nevertheless, this is the motivation for the explanation of visualisation for NN models in this chapter.\nIn the simplest form, we might write the equation for a NN as\n\\[\n\\hat{y} = f(x) = a_0+\\sum_{h=1}^{s}\nw_{0h}\\phi(a_h+\\sum_{i=1}^{p} w_{ih}x_i)\n\\] where \\(s\\) indicates the number of nodes in the hidden (middle layer), and \\(\\phi\\) is a choice of activation function. In a simple situation where \\(p=3\\), \\(s=2\\), and linear output layer, the model could be written as:\n\\[\n\\begin{aligned}\n\\hat{y} = a_0+ & w_{01}\\phi(a_1+w_{11}x_1+w_{21}x_2+w_{31}x_3) +\\\\\n& w_{02}\\phi(a_2+w_{12}x_1+w_{22}x_2+w_{32}x_3)\n\\end{aligned}\n\\] which is a combination of two (linear) models, each of which could be examined for their role in making predictions.\nIn practice, a model may have many nodes, and several hidden layers, a variety of activation functions, and regularisation modifications. One should keep in mind the principle of parsimony is important when applying NNs, because it is tempting to make an overly complex, and thus over-parameterised, construction. Fitting NNs is still problematic. One would hope that fitting produces a stable result, whatever the starting seed the same parameter estimates are returned. However, this is not the case, and different, sometimes radically different, results are routinely obtained after each attempted fit (Wickham et al., 2015).\nFor these examples we use the software keras (Allaire & Chollet, 2023) following the installation and tutorial details at https://tensorflow.rstudio.com/tutorials/. Because it is an interface to python it can be tricky to install. If this is a problem, the example code should be possible to convert to use nnet (Venables & Ripley, 2002a) or neuralnet (Fritsch et al., 2019). We will use the penguins data to illustrate the fitting, because it makes it easier to understand the procedures and the fit. However, a NN is like using a jackhammer instead of a trowel to plant a seedling, more complicated than necessary to build a good classification model for this data.\nA first step is to decide how many nodes the NN architecture should have, and what activation function should be used. To make these decisions, ideally you already have some knowledge of the shapes of class clusters. For the penguins classification, we have seen that it contains three elliptically shaped clusters of roughly the same size. This suggests two nodes in the hidden layer would be sufficient to separate three clusters (Figure 17.1). Because the shapes of the clusters are convex, using linear activation (“relu”) will also be sufficient. The model specification is as follows:\nCodelibrary(keras)\ntensorflow::set_random_seed(211)\n\n# Define model\np_nn_model &lt;- keras_model_sequential()\np_nn_model %&gt;% \n  layer_dense(units = 2, activation = 'relu', \n              input_shape = 4) %&gt;% \n  layer_dense(units = 3, activation = 'softmax')\np_nn_model %&gt;% summary\n\nloss_fn &lt;- loss_sparse_categorical_crossentropy(\n  from_logits = TRUE)\n\np_nn_model %&gt;% compile(\n  optimizer = \"adam\",\n  loss      = loss_fn,\n  metrics   = c('accuracy')\n)\nNote that tensorflow::set_random_seed(211) sets the seed for the model fitting so that we can obtain the same result to discuss later. It needs to be set before the model is defined in the code. The model will also be saved in order to diagnose and make predictions.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Neural networks and deep learning</span>"
    ]
  },
  {
    "objectID": "17-nn.html#setting-up-the-model",
    "href": "17-nn.html#setting-up-the-model",
    "title": "\n17  Neural networks and deep learning\n",
    "section": "",
    "text": "Figure 17.1: Network architecture for the model on the penguins data. The round nodes indicate original or transformed variables, and each arrow connecting these is represented as one of the weights \\(w_{ih}\\) in the definition. The boxes indicate the additive constant entering the nodes, and the corresponding arrows represent the terms \\(a_h\\).",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Neural networks and deep learning</span>"
    ]
  },
  {
    "objectID": "17-nn.html#checking-the-trainingtest-split",
    "href": "17-nn.html#checking-the-trainingtest-split",
    "title": "\n17  Neural networks and deep learning\n",
    "section": "\n17.2 Checking the training/test split",
    "text": "17.2 Checking the training/test split\n\nSplitting the data into training and test is an essential way to protect against overfitting, for most classifiers, but especially so for the copiously parameterised NNs. The model specified for the penguins data with only two nodes is unlikely to be overfitted, but it is nevertheless good practice to use a training set for building and a test set for evaluation.\nFigure 17.2 shows the tour being used to examine the split into training and test samples for the penguins data. Using random sampling, particularly stratified by group, should result the two sets being very similar, as can be seen here. It does happen that several observations in the test set are on the extremes of their class cluster, so it could be that the model makes errors in the neighbourhoods of these points.\n\nCode# Split the data intro training and testing\nlibrary(ggthemes)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(rsample)\nlibrary(ggbeeswarm)\nlibrary(tidymodels)\nlibrary(tourr)\n\nload(\"data/penguins_sub.rda\") # from mulgar book\n\nset.seed(821)\np_split &lt;- penguins_sub %&gt;% \n  select(bl:species) %&gt;%\n  initial_split(prop = 2/3, \n                strata=species)\np_train &lt;- training(p_split)\np_test &lt;- testing(p_split)\n\n# Check training and test split\np_split_check &lt;- bind_rows(\n  bind_cols(p_train, type = \"train\"), \n  bind_cols(p_test, type = \"test\")) %&gt;%\n  mutate(type = factor(type))\n\n\n\nCode to run toursanimate_xy(p_split_check[,1:4], \n           col=p_split_check$species,\n           pch=p_split_check$type, \n           shapeset=c(16,1))\nanimate_xy(p_split_check[,1:4], \n           guided_tour(lda_pp(p_split_check$species)),\n           col=p_split_check$species,\n           pch=p_split_check$type, \n           shapeset=c(16,1))\nrender_gif(p_split_check[,1:4],\n           grand_tour(),\n           display_xy( \n             col=p_split_check$species, \n             pch=p_split_check$type, \n             shapeset=c(16,1),\n             cex=1.5,\n             axes=\"bottomleft\"), \n           gif_file=\"gifs/p_split.gif\",\n           frames=500,\n           loop=FALSE\n)\nrender_gif(p_split_check[,1:4],\n           guided_tour(lda_pp(p_split_check$species)),\n           display_xy( \n             col=p_split_check$species, \n             pch=p_split_check$type, \n             shapeset=c(16,1),\n             cex=1.5,\n             axes=\"bottomleft\"), \n           gif_file=\"gifs/p_split_guided.gif\",\n           frames=500,\n           loop=FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n(a) Grand tour\n\n\n\n\n\n\n\n\n\n(b) Guided tour\n\n\n\n\n\n\nFigure 17.2: Evaluating the training/test split, where we expect that the two samples should roughly match. There are a few observations in the test set that are on the outer edges of the clusters, which will likely result in the model making an error in these regions. However, the two samples roughly match.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Neural networks and deep learning</span>"
    ]
  },
  {
    "objectID": "17-nn.html#fit-the-model",
    "href": "17-nn.html#fit-the-model",
    "title": "\n17  Neural networks and deep learning\n",
    "section": "\n17.3 Fit the model",
    "text": "17.3 Fit the model\n\nThe data needs to be specially formatted for the model fitted using keras. The explanatory variables need to be provided as a matrix, and the categorical response needs to be separate, and specified as a numeric variable, beginning with 0.\n\nCode# Data needs to be matrix, and response needs to be numeric\np_train_x &lt;- p_train %&gt;%\n  select(bl:bm) %&gt;%\n  as.matrix()\np_train_y &lt;- p_train %&gt;% pull(species) %&gt;% as.numeric() \np_train_y &lt;- p_train_y-1 # Needs to be 0, 1, 2\np_test_x &lt;- p_test %&gt;%\n  select(bl:bm) %&gt;%\n  as.matrix()\np_test_y &lt;- p_test %&gt;% pull(species) %&gt;% as.numeric() \np_test_y &lt;- p_test_y-1 # Needs to be 0, 1, 2\n\n\nThe specified model is reasonably simple, four input variables, two nodes in the hidden layer and a three column binary matrix for output. This corresponds to 5+5+3+3+3=19 parameters.\n\n\nModel: \"sequential\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_1 (Dense)                    (None, 2)                       10          \n dense (Dense)                      (None, 3)                       9           \n================================================================================\nTotal params: 19 (76.00 Byte)\nTrainable params: 19 (76.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n\n\nCode# Fit model\np_nn_fit &lt;- p_nn_model %&gt;% keras::fit(\n  x = p_train_x, \n  y = p_train_y,\n  epochs = 200,\n  verbose = 0\n)\n\n\nBecause we set the random number seed we will get the same fit each time the code provided here is run. However, if the model is re-fit without setting the seed, you will see that there is a surprising amount of variability in the fits. Setting epochs = 200 helps to usually get a good fit. One expects that keras is reasonably stable so one would not expect the huge array of fits as observed in Wickham et al. (2015) using nnet. That this can happen with the simple model used here reinforces the notion that fitting of NN models is fiddly, and great care needs to be taken to validate and diagnose the fit.\n\nFitting NN models is fiddly, and very different fitted models can result from restarts, parameter choices, and architecture.\n\n\nCodelibrary(keras)\nlibrary(ggplot2)\nlibrary(colorspace)\n\n# load fitted model\np_nn_model &lt;- load_model_tf(\"data/penguins_cnn\")\n\n\nThe fitted model that we have chosen as the final one has reasonably small loss and high accuracy. Plots of loss and accuracy across epochs showing the change during fitting can be plotted, but we don’t show them here, because they are generally not very interesting.\n\nCodep_nn_model %&gt;% evaluate(p_test_x, p_test_y, verbose = 0)\n\n     loss  accuracy \n0.2563850 0.9553571 \n\n\nThe model object can be saved for later use with:\n\nCodesave_model_tf(p_nn_model, \"data/penguins_cnn\")",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Neural networks and deep learning</span>"
    ]
  },
  {
    "objectID": "17-nn.html#extracting-model-components",
    "href": "17-nn.html#extracting-model-components",
    "title": "\n17  Neural networks and deep learning\n",
    "section": "\n17.4 Extracting model components",
    "text": "17.4 Extracting model components\n\n\nView the individual node models to understand how they combine to produce the overall model.\n\nBecause nodes in the hidden layers of NNs are themselves (relatively simple regression) models, it can be interesting to examine these to understand how the model is making it’s predictions. Although it’s rarely easy, most software will allow the coefficients for the models at these nodes to be extracted. With the penguins NN model there are two nodes, so we can extract the coefficients and plot the resulting two linear combinations to examine the separation between classes.\n\nCode# Extract hidden layer model weights\np_nn_wgts &lt;- keras::get_weights(p_nn_model, trainable=TRUE)\np_nn_wgts \n\n[[1]]\n           [,1]        [,2]\n[1,]  0.6216676  1.33304155\n[2,]  0.1851478 -0.01596385\n[3,] -0.1680396 -0.30432791\n[4,] -0.8867414 -0.36627045\n\n[[2]]\n[1]  0.12708087 -0.09466381\n\n[[3]]\n           [,1]     [,2]       [,3]\n[1,] -0.1646167 1.527644 -1.9215064\n[2,] -0.7547278 1.555889  0.3210194\n\n[[4]]\n[1]  0.4554813 -0.9371488  0.3577386\n\n\nThe linear coefficients for the first node in the model are 0.62, 0.19, -0.17, -0.89, and the second node in the model are 1.33, -0.02, -0.3, -0.37. We can use these like we used the linear discriminants in LDA to make a 2D view of the data, where the model is separating the three species. The constants 0.13, -0.09 are not important for this. They are only useful for drawing the location of the boundaries between classes produced by the model.\nThese two sets of model coefficients provide linear combinations of the original variables. Together, they define a plane on which the data is projected to view the classification produced by the model. Ideally, though this plane should be defined using an orthonormal basis otherwise the shape of the data distribution might be warped. So we orthonormalise this matrix before computing the data projection.\n\nCode# Orthonormalise the weights to make 2D projection\np_nn_wgts_on &lt;- tourr::orthonormalise(p_nn_wgts[[1]])\np_nn_wgts_on\n\n           [,1]       [,2]\n[1,]  0.5593355  0.7969849\n[2,]  0.1665838 -0.2145664\n[3,] -0.1511909 -0.1541475\n[4,] -0.7978314  0.5431528\n\n\n\n# Hidden layer\np_train_m &lt;- p_train %&gt;%\n  mutate(nn1 = as.matrix(p_train[,1:4]) %*%\n           as.matrix(p_nn_wgts_on[,1], ncol=1),\n         nn2 = as.matrix(p_train[,1:4]) %*%\n           matrix(p_nn_wgts_on[,2], ncol=1))\n\n# Now add the test points on.\np_test_m &lt;- p_test %&gt;%\n  mutate(nn1 = as.matrix(p_test[,1:4]) %*%\n           as.matrix(p_nn_wgts_on[,1], ncol=1),\n         nn2 = as.matrix(p_test[,1:4]) %*%\n           matrix(p_nn_wgts_on[,2], ncol=1))\np_train_m &lt;- p_train_m %&gt;%\n  mutate(set = \"train\")\np_test_m &lt;- p_test_m %&gt;%\n  mutate(set = \"test\")\np_all_m &lt;- bind_rows(p_train_m, p_test_m)\nggplot(p_all_m, aes(x=nn1, y=nn2, \n                     colour=species, shape=set)) + \n  geom_point() +\n  scale_colour_discrete_divergingx(palette=\"Zissou 1\") +\n  scale_shape_manual(values=c(16, 1)) +\n  theme_minimal() +\n  theme(aspect.ratio=1)\n\n\n\n\n\n\nFigure 17.3: Plot of the data in the linear combinations from the two nodes in the hidden layer. The three species are clearly different, although with some overlap between all three. A main issue to notice is that there isn’t a big gap between Gentoo and the other species, which we know is there based on our data exploration done in other chapters. This suggests this fitted model is sub-optimal.\n\n\n\n\nFigure 17.3 shows the data projected into the plane determined by the two linear combinations of the two nodes in the hidden layer. Training and test sets are indicated by empty and solid circles. The three species are clearly different but there is some overlap or confusion for a few penguins. The most interesting aspect to learn is that there is no big gap between the Gentoo and other species, which we know exists in the data. The model has not found this gap, and thus is likely to unfortunately and erroneously confuse some Gentoo penguins, particularly with Adelie.\nWhat we have shown here is a process to use the models at the nodes of the hidden layer to produce a reduced dimensional space where the classes are best separated, at least as determined by the model. The process will work in higher dimensions also.\nWhen there are more nodes in the hidden layer than the number of original variables it means that the space is extended to achieve useful classifications that need more complicated non-linear boundaries. The extra nodes describe the non-linearity. Wickham et al. (2015) provides a good illustration of this in 2D. The process of examining each of the node models can be useful for understanding this non-linear separation, also in high dimensions.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Neural networks and deep learning</span>"
    ]
  },
  {
    "objectID": "17-nn.html#examining-predictive-probabilities",
    "href": "17-nn.html#examining-predictive-probabilities",
    "title": "\n17  Neural networks and deep learning\n",
    "section": "\n17.5 Examining predictive probabilities",
    "text": "17.5 Examining predictive probabilities\n\nWhen the predictive probabilities are returned by a model, as is done by this NN, we can use a ternary diagram for three class problems, or high-dimensional simplex when there are more classes to examine the strength of the classification. This done in the same way that was used for the votes matrix from a random forest in Section 15.2.1.\n\nCode# Predict training and test set\np_train_pred &lt;- p_nn_model %&gt;% \n  predict(p_train_x, verbose = 0)\np_train_pred_cat &lt;- levels(p_train$species)[\n  apply(p_train_pred, 1,\n        which.max)]\np_train_pred_cat &lt;- factor(\n  p_train_pred_cat,\n  levels=levels(p_train$species))\ntable(p_train$species, p_train_pred_cat)\n\n           p_train_pred_cat\n            Adelie Chinstrap Gentoo\n  Adelie        92         4      1\n  Chinstrap      0        45      0\n  Gentoo         1         0     78\n\nCodep_test_pred &lt;- p_nn_model %&gt;% \n  predict(p_test_x, verbose = 0)\np_test_pred_cat &lt;- levels(p_test$species)[\n  apply(p_test_pred, 1, \n        which.max)]\np_test_pred_cat &lt;- factor(\n  p_test_pred_cat,\n  levels=levels(p_test$species))\ntable(p_test$species, p_test_pred_cat)\n\n           p_test_pred_cat\n            Adelie Chinstrap Gentoo\n  Adelie        45         3      1\n  Chinstrap      0        23      0\n  Gentoo         1         0     39\n\n\n\nCode# Set up the data to make the ternary diagram\n# Join data sets\ncolnames(p_train_pred) &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")\ncolnames(p_test_pred) &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")\np_train_pred &lt;- as_tibble(p_train_pred)\np_train_m &lt;- p_train_m %&gt;%\n  mutate(pspecies = p_train_pred_cat) %&gt;%\n  bind_cols(p_train_pred) %&gt;%\n  mutate(set = \"train\")\np_test_pred &lt;- as_tibble(p_test_pred)\np_test_m &lt;- p_test_m %&gt;%\n  mutate(pspecies = p_test_pred_cat) %&gt;%\n  bind_cols(p_test_pred) %&gt;%\n  mutate(set = \"test\")\np_all_m &lt;- bind_rows(p_train_m, p_test_m)\n\n# Add simplex to make ternary\nlibrary(geozoo)\nproj &lt;- t(geozoo::f_helmert(3)[-1,])\np_nn_v_p &lt;- as.matrix(p_all_m[,c(\"Adelie\", \"Chinstrap\", \"Gentoo\")]) %*% proj\ncolnames(p_nn_v_p) &lt;- c(\"x1\", \"x2\")\np_nn_v_p &lt;- p_nn_v_p %&gt;%\n  as.data.frame() %&gt;%\n  mutate(species = p_all_m$species,\n         set = p_all_m$set)\n\nsimp &lt;- geozoo::simplex(p=2)\nsp &lt;- data.frame(cbind(simp$points), simp$points[c(2,3,1),])\ncolnames(sp) &lt;- c(\"x1\", \"x2\", \"x3\", \"x4\")\nsp$species = sort(unique(penguins_sub$species))\n\n\n\nCode# Plot it\nggplot() +\n  geom_segment(data=sp, aes(x=x1, y=x2, xend=x3, yend=x4)) +\n  geom_text(data=sp, aes(x=x1, y=x2, label=species),\n            nudge_x=c(-0.1, 0.15, 0),\n            nudge_y=c(0.05, 0.05, -0.05)) +\n  geom_point(data=p_nn_v_p, aes(x=x1, y=x2, \n                                colour=species,\n                                shape=set), \n             size=2, alpha=0.5) +\n  scale_color_discrete_divergingx(palette=\"Zissou 1\") +\n  scale_shape_manual(values=c(19, 1)) +\n  theme_map() +\n  theme(aspect.ratio=1, legend.position = \"right\")\n\n\n\nTernary diagram for the three groups of the predictive probabilities of both training ans test sets. From what we already know about the penguins data this fit is not good. Both Chinstrap and Gentoo penguins are confused with Adelie, or at risk of it. Gentoo is very well-separated from the other two species when several variables are used, and this fitted model is blind to it. One useful finding is that there is little difference between training and test sets, so the model has not been over-fitted.\n\n\n\n\nIf the training and test sets look similar when plotted in the model space then the model is not suffering from over-fitting.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Neural networks and deep learning</span>"
    ]
  },
  {
    "objectID": "17-nn.html#local-explanations",
    "href": "17-nn.html#local-explanations",
    "title": "\n17  Neural networks and deep learning\n",
    "section": "\n17.6 Local explanations",
    "text": "17.6 Local explanations\n \nIt especially important to be able to interpret or explain a model, even more so when the model is complex or black-box’y. A good resource for learning about the range of methods is Molnar (2022). Local explanations provide some information about variables that are important for making the prediction for a particular observation. The method that we use here is Shapley value, as computed using the kernelshap package (Mayer & Watson, 2023).\n\nCode# Explanations\n# https://www.r-bloggers.com/2022/08/kernel-shap/\nlibrary(kernelshap)\nlibrary(shapviz)\np_explain &lt;- kernelshap(\n    p_nn_model,\n    p_train_x, \n    bg_X = p_train_x,\n    verbose = FALSE\n  )\np_exp_sv &lt;- shapviz(p_explain)\nsave(p_exp_sv, file=\"data/p_exp_sv.rda\")\n\n\nA Shapley value for an observation indicates how the variable contributes to the model prediction for that observation, relative to other variables. It is an average, computed from the change in prediction when all combinations of presence or absence of other variables. In the computation, for each combination, the prediction is computed by substituting absent variables with their average value, like one might do when imputing missing values.\nFigure 17.4 shows the Shapley values for Gentoo observations (both training and test sets) in the penguins data, as a parallel coordinate plot. The values for the single misclassified Gentoo penguin (in the training set) is coloured orange. Overall, the Shapley values don’t vary much on bl, bd and fl but they do on bm. The effect of other variables is seems to be only important for bm.\nFor the misclassified penguin, the effect of bm for all combinations of other variables leads to a decline in predicted value, thus less confidence in it being a Gentoo. In contrast, for this same penguin when considering the effect of bl the predicted value increases on average.\n\nCodeload(\"data/p_exp_sv.rda\")\np_exp_gentoo &lt;- p_exp_sv$Class_3$S\np_exp_gentoo &lt;- p_exp_gentoo %&gt;%\n  as_tibble() %&gt;%\n  mutate(species = p_train$species,\n         pspecies = p_train_pred_cat,\n  ) %&gt;%\n  mutate(error = ifelse(species == pspecies, 0, 1))\n\n\n\nCodep_exp_gentoo %&gt;%\n  filter(species == \"Gentoo\") %&gt;%\n  pivot_longer(bl:bm, names_to=\"var\", values_to=\"shap\") %&gt;%\n  mutate(var = factor(var, levels=c(\"bl\", \"bd\", \"fl\", \"bm\"))) %&gt;%\n  ggplot(aes(x=var, y=shap, colour=factor(error))) +\n  geom_quasirandom(alpha=0.8) +\n  scale_colour_discrete_divergingx(palette=\"Geyser\") +\n  #facet_wrap(~var) +\n  xlab(\"\") + ylab(\"SHAP\") +\n  theme_minimal() + \n  theme(legend.position = \"none\")\n\n\n\nCodelibrary(ggpcp)\np_exp_gentoo %&gt;%\n  filter(species == \"Gentoo\") %&gt;%\n  pcp_select(1:4) %&gt;%\n  ggplot(aes_pcp()) +\n    geom_pcp_axes() + \n    geom_pcp_boxes(fill=\"grey80\") + \n    geom_pcp(aes(colour = factor(error)), \n             linewidth = 2, alpha=0.3) +\n  scale_colour_discrete_divergingx(palette=\"Geyser\") +\n  xlab(\"\") + ylab(\"SHAP\") +\n  theme_minimal() + \n  theme(legend.position = \"none\")\n\n\n\n\n\n\nFigure 17.4: SHAP values focused on Gentoo class, for each variable. The one misclassified penguin (orange) has a much lower value for body mass, suggesting that this variable is used differently for the prediction than for other penguins.\n\n\n\n\nIf we examine the data Figure 17.5 the explanation makes some sense. The misclassified penguin has an unusually small value on bm. That the SHAP value for bm was quite different pointed to this being a potential issue with the model, particularly for this penguin. This penguin’s prediction is negatively impacted by bm being in the model.\n\nCodelibrary(patchwork)\n# Check position on bm\nshap_proj &lt;- p_exp_gentoo %&gt;%\n  filter(species == \"Gentoo\", error == 1) %&gt;%\n  select(bl:bm)\nshap_proj &lt;- as.matrix(shap_proj/sqrt(sum(shap_proj^2)))\np_exp_gentoo_proj &lt;- p_exp_gentoo %&gt;%\n  rename(shap_bl = bl, \n         shap_bd = bd,\n         shap_fl = fl, \n         shap_bm = bm) %&gt;%\n  bind_cols(as_tibble(p_train_x)) %&gt;%\n  mutate(shap1 = shap_proj[1]*bl+\n           shap_proj[2]*bd+\n           shap_proj[3]*fl+\n           shap_proj[4]*bm)\nsp1 &lt;- ggplot(p_exp_gentoo_proj, aes(x=bm, y=bl, \n             colour=species, \n             shape=factor(1-error))) +\n    geom_point(alpha=0.8) +\n  scale_colour_discrete_divergingx(palette=\"Zissou 1\") +\n  scale_shape_manual(\"error\", values=c(19, 1)) +\n  theme_minimal() + \n  theme(aspect.ratio=1, legend.position=\"bottom\")\nsp2 &lt;- ggplot(p_exp_gentoo_proj, aes(x=bm, y=shap1, \n             colour=species, \n             shape=factor(1-error))) +\n    geom_point(alpha=0.8) +\n  scale_colour_discrete_divergingx(palette=\"Zissou 1\") +\n  scale_shape_manual(\"error\", values=c(19, 1)) +\n  ylab(\"SHAP\") +\n  theme_minimal() + \n  theme(aspect.ratio=1, legend.position=\"bottom\")\nsp2 &lt;- ggplot(p_exp_gentoo_proj, aes(x=shap1, \n             fill=species, colour=species)) +\n  geom_density(alpha=0.5) +\n  geom_vline(xintercept = p_exp_gentoo_proj$shap1[\n    p_exp_gentoo_proj$species==\"Gentoo\" &\n    p_exp_gentoo_proj$error==1], colour=\"black\") +\n  scale_fill_discrete_divergingx(palette=\"Zissou 1\") +\n  scale_colour_discrete_divergingx(palette=\"Zissou 1\") +\n  theme_minimal() + \n  theme(aspect.ratio=1, legend.position=\"bottom\")\nsp2 &lt;- ggplot(p_exp_gentoo_proj, aes(x=bm, y=bd, \n             colour=species, \n             shape=factor(1-error))) +\n    geom_point(alpha=0.8) +\n  scale_colour_discrete_divergingx(palette=\"Zissou 1\") +\n  scale_shape_manual(\"error\", values=c(19, 1)) +\n  theme_minimal() + \n  theme(aspect.ratio=1, legend.position=\"bottom\")\nsp1 + sp2 + plot_layout(ncol=2, guides = \"collect\") &\n  theme(legend.position=\"bottom\",\n        legend.direction=\"vertical\")\n\n\n\n\n\n\nFigure 17.5: Plots of the data to help understand what the SHAP values indicate. The misclassified Gentoo penguin has an unusually low body mass value which makes it appear to be more like an Adelie penguin, particularly when considered in relation to it’s bill length.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Neural networks and deep learning</span>"
    ]
  },
  {
    "objectID": "17-nn.html#examining-boundaries",
    "href": "17-nn.html#examining-boundaries",
    "title": "\n17  Neural networks and deep learning\n",
    "section": "\n17.7 Examining boundaries",
    "text": "17.7 Examining boundaries\n\nFigure 17.7 shows the boundaries for this NN model along with those of the LDA model.\n\nCode# Generate grid over explanatory variables\np_grid &lt;- tibble(\n  bl = runif(10000, min(penguins_sub$bl), max(penguins_sub$bl)),\n  bd = runif(10000, min(penguins_sub$bd), max(penguins_sub$bd)),\n  fl = runif(10000, min(penguins_sub$fl), max(penguins_sub$fl)),\n  bm = runif(10000, min(penguins_sub$bm), max(penguins_sub$bm))\n)\n# Predict grid\np_grid_pred &lt;- p_nn_model %&gt;%\n  predict(as.matrix(p_grid), verbose=0)\np_grid_pred_cat &lt;- levels(p_train$species)[apply(p_grid_pred, 1, which.max)]\np_grid_pred_cat &lt;- factor(p_grid_pred_cat,\n                          levels=levels(p_train$species))\n\n# Project into weights from the two nodes\np_grid_proj &lt;- as.matrix(p_grid) %*% p_nn_wgts_on\ncolnames(p_grid_proj) &lt;- c(\"nn1\", \"nn2\")\np_grid_proj &lt;- p_grid_proj %&gt;% \n  as_tibble() %&gt;%\n  mutate(species = p_grid_pred_cat)\n\n# Plot\nggplot(p_grid_proj, aes(x=nn1, y=nn2, \n                     colour=species)) + \n  geom_point(alpha=0.5) +\n  geom_point(data=p_all_m, aes(x=nn1, \n                               y=nn2, \n                               shape=species),\n             inherit.aes = FALSE) +\n  scale_colour_discrete_divergingx(palette=\"Zissou 1\") +\n  scale_shape_manual(values=c(1, 2, 3)) +\n  theme_minimal() +\n  theme(aspect.ratio=1, \n        legend.position = \"bottom\",\n        legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n(a) LDA model\n\n\n\n\n\n\n\n\n\n(b) NN model\n\n\n\n\n\n\nFigure 17.6: Comparison of the boundaries produced by the LDA (a) and the NN (b) model, using a slice tour.\n\n\n\n\n\n\n\n\n\n\n\n(a) LDA model\n\n\n\n\n\n\n\n\n\n(b) NN model\n\n\n\n\n\n\nFigure 17.7: Comparison of the boundaries produced by the LDA (a) and the NN (b) model, using a slice tour.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Neural networks and deep learning</span>"
    ]
  },
  {
    "objectID": "17-nn.html#application-to-a-large-dataset",
    "href": "17-nn.html#application-to-a-large-dataset",
    "title": "\n17  Neural networks and deep learning\n",
    "section": "\n17.8 Application to a large dataset",
    "text": "17.8 Application to a large dataset\nTo see how these methods apply in the setting where we have a large number of variables, observations and classes we will look at a neural network that predicts the category for the fashion MNIST data. The code for designing and fitting the model is following the tutorial available from https://tensorflow.rstudio.com/tutorials/keras/classification and you can find additional information there. Below we only replicate the steps needed to build the model from scratch. We also note that a similar investigation was presented in Li et al. (2020), with a focus on investigating the model at different epochs during the training. \nThe first step is to download and prepare the data. Here we scale the observations to range between zero and one, and we define the label names.\n\nCodelibrary(keras)\n\n# download the data\nfashion_mnist &lt;- dataset_fashion_mnist()\n\n# split into input variables and response\nc(train_images, train_labels) %&lt;-% fashion_mnist$train\nc(test_images, test_labels) %&lt;-% fashion_mnist$test\n\n# for interpretation we also define the category names\nclass_names = c('T-shirt/top',\n                'Trouser',\n                'Pullover',\n                'Dress',\n                'Coat',\n                'Sandal',\n                'Shirt',\n                'Sneaker',\n                'Bag',\n                'Ankle boot')\n\n# rescaling to the range (0,1)\ntrain_images &lt;- train_images / 255\ntest_images &lt;- test_images / 255\n\n\nIn the next step we define the neural network and train the model. Note that because we have many observations, even a very simple structure returns a good model. And because this example is well-known, we do not need to tune the model or check the validation accuracy.\n\nCode# defining the model\nmodel_fashion_mnist &lt;- keras_model_sequential()\nmodel_fashion_mnist %&gt;%\n  # flatten the image data into a long vector\n  layer_flatten(input_shape = c(28, 28)) %&gt;%\n  # hidden layer with 128 units\n  layer_dense(units = 128, activation = 'relu') %&gt;%\n  # output layer for 10 categories\n  layer_dense(units = 10, activation = 'softmax')\n\nmodel_fashion_mnist %&gt;% compile(\n  optimizer = 'adam',\n  loss = 'sparse_categorical_crossentropy',\n  metrics = c('accuracy')\n)\n\n# fitting the model, if we did not know the model yet we\n# would add a validation split to diagnose the training\nmodel_fashion_mnist %&gt;% fit(train_images,\n              train_labels,\n              epochs = 5)\nsave_model_tf(model_fashion_mnist, \"data/fashion_nn\")\n\n\nWe have defined a flat neural network with a single hidden layer with 128 nodes. To investigate the model we can start by comparing the activations to the original input data distribution. Since both the input space and the space of activations is large, and they are of different dimensionality, we will first use principal component analysis. This simplifies the analysis, and in general we do not need the original pixel or hidden node information for the interpretation here. The comparison is using the test-subset of the data.\n\nCode# get the fitted model\nmodel_fashion_mnist &lt;- load_model_tf(\"data/fashion_nn\")\n# observed response labels in the test set\ntest_tags &lt;- factor(class_names[test_labels + 1],\n                    levels = class_names)\n\n# calculate activation for the hidden layer, this can be done\n# within the keras framework\nactivations_model_fashion &lt;- keras_model(\n  inputs = model_fashion_mnist$input,\n  outputs = model_fashion_mnist$layers[[2]]$output\n)\nactivations_fashion &lt;- predict(\n  activations_model_fashion,\n  test_images, verbose = 0)\n\n# PCA for activations\nactivations_pca &lt;- prcomp(activations_fashion)\nactivations_pc &lt;- as.data.frame(activations_pca$x)\n\n# PCA on the original data\n# we first need to flatten the image input\ntest_images_flat &lt;- test_images\ndim(test_images_flat) &lt;- c(nrow(test_images_flat), 784)\nimages_pca &lt;- prcomp(as.data.frame(test_images_flat))\nimages_pc &lt;- as.data.frame(images_pca$x)\n\n\n\nCode to run toursp2 &lt;- ggplot(activations_pc,\n       aes(PC1, PC2, color = test_tags)) +\n  geom_point(size = 0.1) +\n  ggtitle(\"Activations\") +\n  scale_color_discrete_qualitative(palette = \"Dynamic\") +\n  theme_bw() +\n  theme(legend.position = \"none\", aspect.ratio = 1)\n\np1 &lt;- ggplot(images_pc,\n       aes(PC1, PC2, color = test_tags)) +\n  geom_point(size = 0.1) +\n  ggtitle(\"Input space\") +\n  scale_color_discrete_qualitative(palette = \"Dynamic\") +\n  theme_bw() +\n  theme(legend.position = \"none\", aspect.ratio = 1)\n\nlegend_labels &lt;- cowplot::get_legend(\n  p1 + \n    guides(color = guide_legend(nrow = 1)) +\n    theme(legend.position = \"bottom\",\n          legend.title = element_blank()) +\n    guides(color = guide_legend(override.aes = list(size = 1))) \n)\n\nWarning in get_plot_component(plot, \"guide-box\"): Multiple components found;\nreturning the first one. To return all, use `return_all = TRUE`.\n\nCode to run tours# hide plotting code\ncowplot::plot_grid(cowplot::plot_grid(p1, p2), legend_labels,\n                   rel_heights = c(1, .3), nrow = 2)\n\n\n\n\n\n\n\nLooking only at the first two principal components we note some clear differences from the transformation in the hidden layer. The observations seem to be more evenly spread in the input space, while in the activations space we notice grouping along specific directions. In particular the category “Bag” appears to be most different from all other classes, and the non-linear transformation in the activations space shows that they are clearly different from the shoe categories, while in the input space we could note some overlap in the linear projection. To better identify differences between other groups we will use the tour on the first five principal components.\n\nCode to run toursanimate_xy(images_pc[,1:5], col = test_tags,\n        cex=0.2, palette = \"Dynamic\")\nanimate_xy(activations_pc[,1:5], col = test_tags,\n        cex=0.2, palette = \"Dynamic\")\n\nrender_gif(images_pc[,1:5],\n           grand_tour(),\n           display_xy( \n             col=test_tags, \n             cex=0.2,\n             palette = \"Dynamic\",\n             axes=\"bottomleft\"), \n           gif_file=\"gifs/fashion_images_gt.gif\",\n           frames=500,\n           loop=FALSE\n)\nrender_gif(activations_pc[,1:5],\n           grand_tour(),\n           display_xy( \n             col=test_tags, \n             cex=0.2,\n             palette = \"Dynamic\",\n             axes=\"bottomleft\"), \n           gif_file=\"gifs/fashion_activations_gt.gif\",\n           frames=500,\n           loop=FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n(a) Input space\n\n\n\n\n\n\n\n\n\n(b) Activations\n\n\n\n\n\n\nFigure 17.8: Comparison of the test observations in the first five principal components of the input space (left) and in the hidden layer activations (right). The activation function results in more clearly defined grouping of the different classes.\n\n\nAs with the first two principal components we get a much more spread out distribution in the original space. Nevertheless we can see differences between the classes, and that some groups are varying along specific directions in that space. Overall the activations space shows tighter clusters as expected after including the ReLU activation function, but the picture is not as neat as the first two principal components would suggest. While certain groups appear very compact even in this larger subspace, others vary quite a bit within part of the space. For example we can clearly see the “Bag” observations as different from all other images, but also notice that there is a large variation within this class along certain directions.\nFinally we will investigate the model performance through the misclassifications and uncertainty between classes. We start with the error matrix for the test observations. To fit the error matrix we use the numeric labels, the ordering is as defined above for the labels.\n\nCodefashion_test_pred &lt;- predict(model_fashion_mnist,\n                             test_images, verbose = 0)\nfashion_test_pred_cat &lt;- levels(test_tags)[\n  apply(fashion_test_pred, 1,\n        which.max)]\npredicted &lt;- factor(\n  fashion_test_pred_cat,\n  levels=levels(test_tags)) %&gt;%\n  as.numeric() - 1\nobserved &lt;- as.numeric(test_tags) -1\ntable(observed, predicted)\n\n        predicted\nobserved    0    1    2    3    4    5    6    7    8    9\n       0  128    0   84  719   10    0   51    7    1    0\n       1    0   42   15  941    0    0    0    2    0    0\n       2    6    0  824   38  121    0    3    8    0    0\n       3    1    0   14  976    8    0    1    0    0    0\n       4    1    0  205  181  605    0    0    8    0    0\n       5    1    0    0    2    0   77    0  902    1   17\n       6   24    0  231  282  405    0   44   12    2    0\n       7    0    0    0    0    0    0    0 1000    0    0\n       8   17    1   78  102   49    0    5  730   16    2\n       9    0    0    0    2    0    0    0  947    0   51\n\n\nHere the labels are used as 0 - T-shirt/top, 1 - Trouser, 2 - Pullover, 3 - Dress, 4 - Coat, 5 - Sandal, 6 - Shirt, 7 - Sneaker, 8 - Bag, 9 - Ankle boot. From this we see that the model mainly confuses certain categories with each other, and within expected groups (e.g. different types of shoes can be confused with each other, or different types of shirts). We can further investigate this by visualizing the full probability matrix for the test observations, to see which categories the model is uncertain about.\n\nCode to visualize probabilities# getting the probabilities from the output layer\nfashion_test_pred &lt;- predict(model_fashion_mnist,\n                             test_images, verbose = 0)\n\n# this is the same code as was used in the RF chapter\nproj &lt;- t(geozoo::f_helmert(10)[-1,])\nf_nn_v_p &lt;- as.matrix(fashion_test_pred) %*% proj\ncolnames(f_nn_v_p) &lt;- c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\")\n\nf_nn_v_p &lt;- f_nn_v_p %&gt;%\n  as.data.frame() %&gt;%\n  mutate(class = test_tags)\n\nsimp &lt;- geozoo::simplex(p=9)\nsp &lt;- data.frame(simp$points)\ncolnames(sp) &lt;- c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\")\nsp$class = \"\"\nf_nn_v_p_s &lt;- bind_rows(sp, f_nn_v_p) %&gt;%\n  mutate(class = ifelse(class %in% c(\"T-shirt/top\",\n                                     \"Pullover\",\n                                     \"Shirt\",\n                                     \"Coat\"), class, \"Other\")) %&gt;%\n  mutate(class = factor(class, levels=c(\"T-shirt/top\",\n                                        \"Pullover\",\n                                        \"Shirt\",\n                                        \"Coat\",\n                                        \"Other\"))) \n\nanimate_xy(f_nn_v_p_s[,1:9], col = f_nn_v_p_s$class, \n           axes = \"off\", cex=0.2,\n           edges = as.matrix(simp$edges),\n           edges.width = 0.05,\n           palette = \"Viridis\")\n\nrender_gif(f_nn_v_p_s[,1:9],\n           grand_tour(),\n           display_xy( \n             col=f_nn_v_p_s$class, \n             cex=0.2,\n             palette = \"Viridis\",\n             axes=\"off\",\n             edges = as.matrix(simp$edges),\n             edges.width = 0.05), \n           gif_file=\"gifs/fashion_confusion_gt.gif\",\n           frames=500,\n           loop=FALSE\n)\n\n\n\n\n\n\n\n\n\n(a) Input space\n\n\n\n\nFigure 17.9: A tour of the confusion matrix for the fashion MNIST test observations, focusing on a subset of items. Often observations get confused between two of the classes, this appears as points falling along one of the edges, for example some Shirts look more like T-shirts/tops, while others get confused with Coats. We can also notice that a subset of three other classes not mapped to colors as very separate from this group.\n\n\nThe tour of the class probabilities shows that the model is often confused between two classes, this appears as points falling along one edge in the simplex. In particular for the highlighted categories we can notice some interesting patterns, where pairs of classes get confused with each other. We also see some three-way confusions, these are observations that fall on one surface triangle defined via three corners of the simplex, for example between Pullover, Shirt and Coat.\nFor this data using explainers like SHAP is not so interesting, since the individual pixel contribution to a prediction are typically not of interest. With image classification a next step might be to further investigate which part of the image is important for a prediction, and this can be visualized as a heat map placed over the original image. This is especially interesting in the case of difficult or misclassified images. This however is beyond the scope of this book.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Neural networks and deep learning</span>"
    ]
  },
  {
    "objectID": "17-nn.html#exercises",
    "href": "17-nn.html#exercises",
    "title": "\n17  Neural networks and deep learning\n",
    "section": "Exercises",
    "text": "Exercises\n\nThe problem with the NN model fitted to the penguins is that the Gentoo are poorly classified, when they should be perfectly predictable due to the big gap between class clusters. Re-fit the NN to the penguins data, to find a better model that appropriately perfectly predicts Gentoo penguins. Support this by plotting the model (using the hidden layer), and the predictive probabilities as a ternary plot. Do the SHAP values also support that bd plays a stronger role in your best model? (bd is the main variable for distinguishing Gentoo’s from the other species, particularly when used with fl or bl.)\nFor the fashion MNIST data we have seen that certain categories are more likely to be confused with each other. Select a subset of the data including only the categories Ankle boot, Sneaker and Sandal and see if you can reproduce the analysis of the penguins data in this chapter with this subset.\nCan you fit a neural network that can predict the class in the fake tree data? Because the data is noisy and we do not have that many observations, it can be easy to overfit the data. Once you find a setting that works, think about what aspects of the model might be interesting for visualization. What comparisons with a random forest model could be of interest?\nThe sketches data could also be considered a classic image classification problem, and we have seen that we can get a reasonable accuracy with a random forest model. Because we only have a smaller number of observations (compared to the fashion MNIST data) when fitting a neural network we need to be very careful not to overfit the training data. Try fitting a flat neural network (similar to what we did for the fashion MNIST data) and check the test accuracy of the model.\nChallenge: try to design a more accurate neural network for the sketches data. Here you can investigate using a convolutional neural network in combination with data augmentation. In addition, using batch normalization should improve the model performance.\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan den Boogaart, K. G., Tolosana-Delgado, R., & Bren, M. (2024). Compositions: Compositional data analysis. http://www.stat.boogaart.de/compositions/\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Neural networks and deep learning</span>"
    ]
  },
  {
    "objectID": "18-summary-class.html",
    "href": "18-summary-class.html",
    "title": "\n18  Exploring misclassifications\n",
    "section": "",
    "text": "18.1 Errors for a single model\nTo examine misclassifications, we can create a separate variable that identifies the errors or not. Constructing this for each class, and exploring in small steps is helpful. Let’s do this using the random forest model for the penguins fit. The random forest fit has only a few misclassifications. There are four Adelie penguins confused with Chinstrap, and similarly four Chinstrap confused with Adelie. There is one Gentoo penguin confused with a Chinstrap. This is interesting, because the Gentoo cluster is well separated from the clusters of the other two penguin species.\nCode to fit forestlibrary(randomForest)\nlibrary(dplyr)\nload(\"data/penguins_sub.rda\")\n\npenguins_rf &lt;- randomForest(species~.,\n                             data=penguins_sub[,1:5],\n                             importance=TRUE)\npenguins_rf$confusion\n\n          Adelie Chinstrap Gentoo class.error\nAdelie       143         3      0 0.020547945\nChinstrap      4        64      0 0.058823529\nGentoo         0         1    118 0.008403361\n\npenguins_errors &lt;- penguins_sub %&gt;%\n  mutate(err = ifelse(penguins_rf$predicted !=\n                        penguins_rf$y, 1, 0))\nCode to make animated gifslibrary(tourr)\nsymbols &lt;- c(1, 16)\np_pch &lt;- symbols[penguins_errors$err+1]\np_cex &lt;- rep(1, length(p_pch))\np_cex[penguins_errors$err==1] &lt;- 2\nanimate_xy(penguins_errors[,1:4],\n           col=penguins_errors$species,\n           pch=p_pch, cex=p_cex)\nrender_gif(penguins_errors[,1:4],\n           grand_tour(),\n           display_xy(col=penguins_errors$species,\n                      pch=p_pch, cex=p_cex),\n           gif_file=\"gifs/p_rf_errors.gif\",\n           frames=500,\n           width=400,\n           height=400)\n\nanimate_xy(penguins_errors[,1:4],\n           guided_tour(lda_pp(penguins_errors$species)),\n           col=penguins_errors$species,\n           pch=pch)\n\nrender_gif(penguins_errors[,1:4],\n           guided_tour(lda_pp(penguins_errors$species)),\n           display_xy(col=penguins_errors$species,\n                      pch=p_pch, cex=p_cex),\n           gif_file=\"gifs/p_rf_errors_guided.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\nFigure 18.1 shows a grand tour, and a guided tour, of the penguins data, where the misclassifications are marked by an asterisk. (If the gifs are too small to see the different glyphs, you can zoom in to make the figures larger.) It can be seen that the one Gentoo penguin that is mistaken for a Chinstrap by the forest model is always moving with its other Gentoo (yellow) family. It can occasionally be seen to be on the edge of the group, closer to the Chinstraps, in some projections in the grand tour. But in the final projection from the guided tour it is hiding well among the other Gentoos. This is an observation where a mistake has been made because of the inadequacies of the forest algorithm. Forests are only as good as the trees they are constructed from, and we have seen from Section 15.1 that the splits only on single variables done by trees does not adequately utilise the covariance structure in each class. They make mistakes based on the boxy nature of the boundaries. This can carry through to the forests model. Even though many trees are combined to generate smoother boundaries, forests do not effectively utilise covariance in clusters either. The other mistakes, where Chinstrap are predicted to be Adelie, and vice versa, are more sensible. These mistaken observations can be seen to lie in the border region between the two clusters, and reflect genuine uncertainty about the classification of penguins in these two species.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Exploring misclassifications</span>"
    ]
  },
  {
    "objectID": "18-summary-class.html#errors-for-a-single-model",
    "href": "18-summary-class.html#errors-for-a-single-model",
    "title": "\n18  Exploring misclassifications\n",
    "section": "",
    "text": "(a) Grand tour\n\n\n\n\n\n\n\n\n\n(b) Guided tour\n\n\n\n\n\n\nFigure 18.1: Examining the misclassified cases (marked as solid circles) from a random forest fit to the penguins data. The one Gentoo penguin mistaken for a Chinstrap is a mistake made because the forest method suffers from the same problems as trees - cutting on single variables rather than effectively using covariance structure. The mistakes between the Adelie and Chinstrap penguins are more sensible because all of these observations lie is the bordering regions between the two clusters.\n\n\n\nSome errors are reasonable because there is overlap between the class clusters. Some errors are not reasonable because the model used is inadequate.",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Exploring misclassifications</span>"
    ]
  },
  {
    "objectID": "18-summary-class.html#comparison-between-lda-and-cnn",
    "href": "18-summary-class.html#comparison-between-lda-and-cnn",
    "title": "\n18  Exploring misclassifications\n",
    "section": "\n18.2 Comparison between LDA and CNN",
    "text": "18.2 Comparison between LDA and CNN",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Exploring misclassifications</span>"
    ]
  },
  {
    "objectID": "18-summary-class.html#constructing-data-to-diagnose-your-model",
    "href": "18-summary-class.html#constructing-data-to-diagnose-your-model",
    "title": "\n18  Exploring misclassifications\n",
    "section": "\n18.3 Constructing data to diagnose your model",
    "text": "18.3 Constructing data to diagnose your model",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Exploring misclassifications</span>"
    ]
  },
  {
    "objectID": "18-summary-class.html#explainability",
    "href": "18-summary-class.html#explainability",
    "title": "\n18  Exploring misclassifications\n",
    "section": "\n18.4 Explainability",
    "text": "18.4 Explainability",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Exploring misclassifications</span>"
    ]
  },
  {
    "objectID": "18-summary-class.html#exercises",
    "href": "18-summary-class.html#exercises",
    "title": "\n18  Exploring misclassifications\n",
    "section": "Exercises",
    "text": "Exercises\n\nExamine misclassifications from a random forest model for the fake_trees data between cluster 1 and 0, using the\n\nprincipal components\nvotes matrix. Describe where these errors relative to their true and predicted class clusters. When examining the simplex, are the misclassifications the points that are furthest from any vertices?\n\n\nExamine the misclassifications for the random forest model on the sketches data, focusing on cactus sketches that were mistaken for bananas. Follow up by plotting the images of these errors, and describe whether the classifier is correct that these sketches are so poor their true cactus or banana identity cannot be determined.\nHow do the errors from the random forest model compare with those of your best fitting CNN model? Are the the corresponding images poor sketches of cacti or bananas?\nNow examine the misclassifications of the sketches data in the\n\nvotes matrix from the random forest model\npredictive probability distribution from the CNN model, using the simplex approach. Are they as expected, points lying in the middle or along an edge of the simplex?\n\n\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Supervised classification",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Exploring misclassifications</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions.\nDover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic\nQueries for Information\nExploration: An Implementation\nand Evaluation. ACM CHI ‘92 Conference\nProceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R\ninterface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method\nfor the Analysis of Complex\nProblems. Proceedings of the National Academy of\nScience, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of\nHigh-dimensional Data. Biometrics,\n28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971).\nTransformations of Multivariate\nData. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory\nSpatial Data Analysis\nLinking SpaceStat and\nArcView. In M. M. Fischer & A. Getis\n(Eds.), Recent Developments in\nSpatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for\nggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video\nLibrary. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand\nTour: A Tool for\nViewing Multidimensional Data.\nSIAM Journal of Scientific and Statistical Computing,\n6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\"\ngraphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences.\n(2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative\ntour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame\ninterpolation for high-dimensional data visualisation using the woylier\npackage. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An\nenvironment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing\nScatterplots. In W. S. Cleveland & M. E. McGill (Eds.),\nDynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The\nVisual Design and Control of\nTrellis Displays. Journal of Computational\nand Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of\ninformation visualization: Readings and reflections. Morgan\nKaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in\nhigh dimensions. Proceedings of the National Academy of\nSciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and\nMachine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine\nlearning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM:\nInteractive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006).\nScientific visualization: The visual extraction of knowledge from\ndata. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern\nMultidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine\nLearning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022).\nrandomForest: Breiman and cutler’s random forests for classification\nand regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984).\nClassification and Regression Trees.\nWadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods\nin the Analysis of Customer Panel\nData: Comment. Journal of Business &\nEconomic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour\nMethods: An Outline.\nComputing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988).\nElements of a Viewing Pipeline\nfor Data Analysis. In W. S. Cleveland & M.\nE. McGill (Eds.), Dynamic graphics for statistics (pp.\n277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic\nProjections in High-Dimensional\nVisualization: Theory and\nComputational Methods.\nAT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005).\nComputational Methods for\nHigh-Dimensional Rotations in\nData Visualization. In C. R. Rao, E. J.\nWegman, & J. L. Solka (Eds.), Handbook of statistics: Data\nmining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive\nHigh-Dimensional Data\nVisualization. Journal of Computational and Graphical\nStatistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data\nViewer for Multivariate Data.\nComputing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization\nMethodology for Multidimensional\nScaling. Journal of Classification,\n19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., &\nChen, L. (2008). Data visualization with multidimensional scaling.\nJournal of Computational and Graphical Statistics,\n17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and\nGraphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R.\n(2018). Integrating single-cell transcriptomic data across different\nconditions, technologies, and species. Nature Biotechnology,\n36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999).\nReadings in information visualization. Morgan Kaufmann\nPublishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996).\nExplorN: Design\nConsiderations Past and\nPresent (Technical Report No. 129). Center for\nComputational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide.\nChapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of\nData Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly\nselecting cell-type marker genes for single-cell clustering analyses.\nCell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks:\nA Review from a Statistical\nPerspective. Statistical Science, 9(1),\n2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget\ninteractivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to\nRepresent Points in k-dimensional Space\nGraphically. Journal of the American Statistical\nAssociation, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy\nWeighted Regression and Smoothing\nScatterplots. Journal of American Statistics\nAssociation, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart\nPress.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic\ngraphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual\nControls For\nHigh-Dimensional Data\nProjections. Journal of Computational and Graphical\nStatistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection\nPursuit Indexes Based on\nOrthonormal Function Expansions.\nJournal of Computational and Graphical Statistics,\n2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand\nTour and Projection Pursuit.\nJournal of Computational and Graphical Statistics,\n4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand\nTour and Projection Pursuit.\nJournal of Computational and Graphical Statistics,\n4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele,\nE. (2007). Exploring Gene Expression\nData, Using Plots. Journal of\nData Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing\ndata for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006).\nGrand Tours, Projection\nPursuit Guided Tours and\nManual Controls. In C.-H. Chen, W. Härdle,\n& A. Unwin (Eds.), Handbook of Data\nVisualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996).\nDynamic Graphics in a GIS:\nExploring and Analyzing\nMultivariate Spatial Data using\nLinked Software. Computational Statistics:\nSpecial Issue on Computer Aided Analyses of Spatial Data,\n11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic\ngraphics for data analysis: With R and\nGGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational\nMethods for Dynamic Graphs.\nJournal of Computational & Graphical Statistics,\n12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector\nNetworks. Machine Learning, 20(3),\n273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées\nParallèles et Axiales: Méthode de\ntransformation géométrique et procédé nouveau de calcul graphique\ndéduits de la considération des coordonnées paralléles.\nGauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with\nR. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping\nMultivariate Time Series: A\nCase Study. Proceedings of the IEEE\nWorkshop on Temporal Data Mining:\nAlgorithms, Theory and\nApplications, in Conjunction with the Conference on Data\nMining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create\ndendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a).\nCFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b).\nRecreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of\nGraphical Projection Pursuit.\nAnnals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical\nprojection pursuit. Annals of Statistics, 12(3),\n793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation\nanalysis: Understanding it, doing it, and making it useful (pp.\n11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring\ngeovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D.,\nHofmann, H., & Wickham, H. (2013). The generalized pairs plot.\nJournal of Computational and Graphical Statistics,\n22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011).\nCluster Analysis (5th ed). John Wiley & Sons,\nLtd.\n\n\nFienberg, S. E. (1979). Graphical Methods in\nStatistics. Journal of American Statistical\nAssociation, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple\nMeasurements in Taxonomic\nProblems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic\nproblems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical\nUtilization of Multiple\nMeasurements. Annals of Eugenics, 8,\n376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973).\nPRIM-9, an interactive multidimensional data display\nand analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974).\nPRIM-9, an interactive multidimensional data display and\nanalysis system. In W. S. Cleveland (Ed.), The collected works of\njohn w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of\nthe two-party preferred vote in australian federal elections: 2001–2016.\nAustralian & New Zealand Journal of Statistics,\n62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific\nillustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency\nversus interpretability of classification. Biometrics,\n21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based\nClustering, Discriminant\nAnalysis, Density Estimation.\nJournal of the American Statistical Association, 97,\n611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust:\nGaussian mixture modelling for model-based clustering, classification,\nand density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection\nPursuit. Journal of American Statistical\nAssociation, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A\nProjection Pursuit Algorithm for\nExploratory Data Analysis.\nIEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history\nof thematic cartography, statistical graphics, and data\nvisualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet:\nTraining of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views:\nDimensional Inference Through\nSections and Projections. Journal of\nComputational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical\nDisplay of Matrices with\nApplications to Principal\nComponent Analysis. Biometrika,\n58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook\nof computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An\nintroduction to clustering with R. Springer Singapore.\nhttps://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of\nMultivariate Chemical Data by\nProjection Pursuit. Chemometrics and\nIntelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and\nBootstrap Tests of\nHypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite\nmixture models (Version 2024-08-20).\nhttps://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open\ntheir homes to tourists when disaster strikes. Journal of Travel\nResearch, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization\nhandbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler,\nA., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P.,\nStoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A.,\nStuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated\nanalysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high\ndimensions, demonstrated with scRNA-seq data. The R Journal,\n15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high\ndimensions, demonstrated with scRNA-seq data. The R Journal,\n15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant\ntour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for\nContingency Tables. Computer Science and\nStatistics: Proceedings of the 13th Symposium on the Interface,\n268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of\nTelevision Ratings. The American\nStatistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991).\nDynamic Graphics for Exploring\nSpatial Data with Application to\nLocating Global and Local\nAnomalies. The American Statistician,\n45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The\nElements of Statistical\nLearning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015).\nHandbook of cluster analysis. Chapman; Hall/CRC.\nhttps://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the\nExploration of Multivariate\nCategorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading\nMosaicplots. Computational Statistics and Data\nAnalysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in\nMANET. Computational Statistics, 13(1),\n77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization\ntools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization\ntools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer\narchipelago penguins data in the palmerpenguins r package - an\nalternative to anderson’s irises. The R Journal, 14,\n244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer\narchipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables\ninto principal components. Journal of Educational Psychology,\n24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with\ndiscussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data\nanalysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo,\nJ. (2024). Gt: Easily create presentation-ready display tables.\nhttps://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A\nLanguage for Data Analysis and\nGraphics. Journal of Computational and Graphical\nStatistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke,\nC. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A\ntoolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with\nParallel Coordinates. The Visual\nComputer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download.\nhttps://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie.\nhttps://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate\nstatistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis:\nA review and recent developments. Phil. Trans. R. Soc. A.,\n374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is\nProjection Pursuit? (With discussion).\nJournal of the Royal Statistical Society, Series A,\n150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction\nfor outlier detection using DOBIN. Journal of Computational and\nGraphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in\nR: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready\nplots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps\n(3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive\nGraphical Methods in the Analysis\nof Customer Panel Data (with\ndiscussion). Journal of Business and Economic Statistics,\n14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor\nembedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by\nOptimizing Goodness of Fit to a\nNonmetric Hypothesis. Psychometrika,\n29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional\nScaling: A Numerical Method.\nPsychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional\nScaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of\npackages for modeling and machine learning using tidyverse\nprinciples. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and\nload the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the\ncurse of dimensionality in the visualization of high-dimensional data.\nJournal of Computational and Graphical Statistics,\n31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding\nhollowness in high-dimensional data. Journal of Computational and\nGraphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding\nhollowness in high-dimensional data. Journal of Computational and\nGraphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American\nMathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing\nprojection pursuit classification trees. Journal of Statistical\nSoftware, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large\np small n data. Statistics and\nComputing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005).\nProjection Pursuit for\nExploratory Supervised\nClassification. Journal of Computational and Graphical\nStatistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours\nand embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., &\nZhang, H. S. (2022). The state-of-the-art on tours for dynamic\nvisualization of high-dimensional data. WIREs Computational\nStatistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree.\nElectronic Journal of Statistics, 7(none), 1369–1386.\nhttps://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture\nmodels. In Handbook of data visualization (pp. 561–587).\nSpringer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural\nnetworks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by\nrandomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992).\nVisualizing the Embedding of Objects in\nEuclidean Space. Computing Science and\nStatistics: Proceedings of the 24th Symposium on the Interface,\n208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE\nTransactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W.\n(2005). Geographic information systems and science. John Wiley\n& Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational\napproach. Computational Statistics & Data Analysis,\n120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using\nt-SNE. J. Mach. Learn. Res.,\n9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of\nmultivariate observations. In L. M. L. Cam & J. Neyman (Eds.),\nProc. Of the fifth berkeley symposium on mathematical statistics and\nprobability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics\nusing R - an example-based approach. Cambridge\nUniversity Press.\n\n\nMartin, E. (1965). Flatland.\nhttp://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical\nSensitivity Analysis for\nMultidimensional Scaling. Journal of\nComputational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018).\nUMAP: Uniform manifold approximation and projection for\ndimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data\nAnalysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data\ncollection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F.\n(2024). e1071: Misc functions of the department of statistics,\nprobability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced\nversion of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML\ntables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for\nmaking black box models explainable (2nd ed).\nhttps://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B.,\nChen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R.,\nIvanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing\nstructure and transitions for biological data exploration. Nature\nBiotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump\nretrieved from https://planet.osm.org .\nhttps://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems\nof points in space. The London, Edinburgh, and Dublin Philosophical\nMagazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on\nthe empirical distribution function. Journal of Computational and\nGraphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit\nDiscriminant Analysis. Computational\nStatistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit\nDiscriminant Analysis for Two\nGroups. Communications in Statistics, Part A – Theory\nand Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional\nProjection Pursuit. Journal of\nComputational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor -\nUser’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical\ncomputing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple\nMeasurements in Problems of\nBiological Classification (with discussion).\nJournal of the Royal Statistical Society, Series B,\n10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of\nStatistics, Vol. 9. Elsevier Science\nPublishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006).\nHandbook of Statistics: Data\nMining and Visualization.\nElsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and\nNeural Networks. Cambridge University\nPress.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and\nmultinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and\ndatasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus\nSimilarity and Errors in Some\nPaired-associate Learning Tasks.\nJournal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A.\n(2015). Spatial reconstruction of single-cell gene expression data.\nNature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M.,\nThoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension\nto ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape\nfrom boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a).\nModel-based clustering, classification, and density estimation using\nmclust in R. Chapman;\nHall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b).\nModel-based clustering, classification, and density estimation using\nmclust in R. Chapman;\nHall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of\nProximities: Multidimensional\nScaling with an Unknown Distance\nFunction, I and II.\nPsychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r,\nplotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K.,\nCorvellec, M., & Despouy, P. (2024). Plotly: Create interactive\nweb graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K.,\n& Zabor, E. C. (2024). Gtsummary: Presentation-ready data\nsummary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange,\nJ. (2021). Reproducible summary tables with the gtsummary package.\nThe R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position\nnon-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P.,\nPadgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of\nmeteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for\ninteraction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009).\nSomewhere over the rainbow: How to make effective use of colors in\nmeteorological visualizations. Bulletin of the American\nMeteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III,\nW. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019).\nComprehensive integration of single-cell data. Cell,\n177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J.,\nCox, Z., & Cook, D. (2000a). Orca: A\nVisualization Toolkit for\nHigh-Dimensional Data.\nJournal of Computational and Graphical Statistics,\n9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J.,\nCox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for\nhigh-dimensional data. Journal of Computational and Graphical\nStatistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory\nvisual analysis of graphs in GGobi. In J. Antoch (Ed.),\nCompStat: Proceedings in computational statistics, 16th\nsymposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi:\nInteractive Dynamic Graphics in\nthe X Window System with a\nLink to S. American Statistical\nAssociation 1991 Proceedings of the Section on Statistical\nGraphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive\ndynamic data visualization in the x window system. Journal of\nComputational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary.\nComputational Statistics: Special Issue on The Use of Interactive\nGraphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003).\nGGobi: Evolving from XGobi into\nan Extensible Framework for\nInteractive Data Visualization.\nComputational Statistics & Data Analysis, 43,\n423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing\nData in Interactive\nHigh-Dimensional Data\nVisualization. Computational Statistics,\n13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour.\nComputing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic\nGraphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.),\nHandbook of computational statistics: Concepts and methods (pp.\n293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A\nCodeless Visual Programming\nEnvironment for Geoscientific\nData Analysis and Visualization.\nThe Journal of Computers and Geosciences, 28(10),\n1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified\ninterface to visualize statistical result of popular r packages. The\nR Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and\nself–consistent points of elliptical distributions. The Annals of\nStatistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006).\nrggobi: An\nInterface between R and\nGGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive\npartitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data\nVisualization Using Mondrian.\nJournal of Statistical Software, 7(11),\nhttp://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection\nSequences – Interactive Analysis\nof Massive Data Sets.\nComputing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation\nPolytopes and Exploratory\nGraphical Methods for Ranked\nData. The Annals of Statistics, 21,\n1401–1430.\n\n\nTierney, L. (1991). LispStat:\nAn Object-Orientated\nEnvironment for Statistical\nComputing and Dynamic\nGraphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to\nfacilitate missing data exploration, visualization and assessment of\nimputations. Journal of Statistical Software, 105(7),\n1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to\nfacilitate missing data exploration, visualization and assessment of\nimputations. Journal of Statistical Software, 105(7),\n1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar:\nData structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1.\nTheory and Method. Psychometrika,\n17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative\ninformation. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of\nStatistics. The American Statistician,\n19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996).\nInteractive Graphics for Data\nSets with Missing Values -\nMANET. Journal of Computational and Graphical\nStatistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct\nManipulation Graphics for Data\nMining. Journal of Image and Graphics,\n2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of\nLarge Datasets: Visualizing a\nMillion. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel\nCoordinates for Exploratory\nModelling Analysis. Comput. Stat. Data\nAnal., 43(4), 553–564. https://doi.org/{\\tt\nhttp://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots:\nHigh Interaction Graphics for\nR. In K. Hornik, F. Leisch, & A. Zeileis (Eds.),\nProceedings of the 3rd international workshop on distributed\nstatistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and\nsimplified manual controls for projection and slice tours, with\napplication to exploring classification boundaries in high dimensions.\nJournal of Computational and Graphical Statistics,\n32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., &\nRussell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based\nalgorithms. Journal of Machine Learning Research, 15,\n3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing\nhigh-dimensional data using t-SNE. Journal of Machine Learning\nResearch, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of\nStatistical Learning Theory.\nSpringer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk\nhandbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern\nApplied Statistics with S.\nSpringer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied\nstatistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied\nstatistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed).\nLEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The\nCommercial and Political Atlas,\nRepresenting, by means of Stained\nCopper-Plate Charts,\nThe Progress of the Commerce,\nRevenues, Expenditure, and Debts\nof England, during the whole of the Eighteenth\nCentury, by William\nPlayfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The\nStatistical Breviary; Shewing on\na Principle entirely new, the resources of every state and\nkingdom in Europe; illustrated with Stained\nCopper-Plate Charts, representing\nthe physical powers of each distinct nation with ease and perspicuity by\nWilliam Playfair. Cambridge University\nPress.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical\nRepresentation of Multivariate\nData. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021).\nUnderstanding how dimension reduction tools work: An empirical approach\nto deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization.\nJournal of Machine Learning Research, 22(201), 1–73.\nhttp://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data\nAnalysis Using Parallel\nCoordinates. Journal of American Statistics\nAssociation, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in\nk-Dimensions\n(Technical Report No. 68). Center for Computational Statistics, George\nMason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical\nGraphics and Visualization (C. R. Rao,\nEd.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image\nGrand Tour. Automatic Target Recognition\nVIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing\nmaps in R: The kohonen package.\nJournal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing\nmaps in kohonen 3.0. Journal of\nStatistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and\nunsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data\nanalysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high\ndimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K.,\nWilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T.\n(2024). ggplot2: Create elegant data visualisations using the\ngrammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for\nmultivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical\nmodels: Removing the blindfold. Statistical Analysis and Data\nMining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr:\nAn R Package for\nExploring Multivariate Data with\nProjections. Journal of Statistical Software,\n40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring\nmultivariate data with projections. Journal of Statistical\nSoftware, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D.\n(2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read\nrectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual\nClustering and Classification:\nThe Oronsay Particle\nSize Data Set\nRevisited. Computational Statistics: Special Issue on\nInteractive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive\nVisualization of Very Large\nGraphs. Journal of Computational and Graphical\nStatistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics.\nStatistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual\nStatistics: Seeing Data with\nDynamic Interactive\nGraphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D.,\nMurrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and\nassessing colors and palettes. Journal of Statistical Software,\n96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping\nRGBland: Selecting colors for statistical graphics.\nComputational Statistics & Data Analysis, 53(9),\n3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on\nprojection pursuit in high dimensions: Feasible or infeasible feature\nextraction. International Statistical Review, 91(1),\n140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P.\n(2021). Visual diagnostics for constrained optimisation with application\nto guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P.\n(2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and\npipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "A1-toolbox.html",
    "href": "A1-toolbox.html",
    "title": "Appendix A — Toolbox",
    "section": "",
    "text": "A.1 Using tours in the tourr package",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Toolbox</span>"
    ]
  },
  {
    "objectID": "A1-toolbox.html#using-tours-in-the-tourr-package",
    "href": "A1-toolbox.html#using-tours-in-the-tourr-package",
    "title": "Appendix A — Toolbox",
    "section": "",
    "text": "A.1.1 Installation\nYou can install the released version of tourr from CRAN with:\ninstall.packages(\"tourr\")\nand the development version from the GitHub repo with:\n# install.packages(\"remotes\")\nremotes::install_github(\"ggobi/tourr\")\n\nA.1.2 Getting started\nTo run a tour in R, use one of the animate functions. The following code will show a 2D tour displayed as a scatterplot on a 6D data set with three labelled classes.\nanimate_xy(flea[,-7], col=flea$species)\nWickham et al. (2011a) remains a good reference for learning more about this package. The package website has a list of current functionality.\n\nA.1.3 Different tours\nThe two main components of the tour algorithm are the projection dimension which affects the choice of display to use, and the algorithm that delivers the projection sequence. The primary functions for these two parts are\n\nFor display of different projection dimensions:\n\n\n\ndisplay_dist(): choice of density, histogram or average shifted histogram (ash) display of the 1D projections.\n\ndisplay_xy(), display_density2d(), display_groupxy(), display_pca(), display_sage(), display_slice(), display_trails(): choices in display of 2D projections.\n\ndisplay_depth(), display_stereo(): choices to display 3D projections.\n\ndisplay_pcp(), display_scatmat(), display_stars(), display_faces(): choices for displaying three or more variables.\n\ndisplay_image(): to use with multispectral images, where different combinations of spectral bands are displayed. See E. J. Wegman et al. (1998) and Symanzik (2002) for applications.\n\ndisplay_andrews(): 1D projections as Andrews curves.\n\n\nTo change the way projections are delivered:\n\n\n\ngrand_tour(): Smooth sequence of random projections to view all possible projections as quickly as possible. Good for getting an overview of the high-dimensional data, especially when you don’t know what you are looking for.\n\nguided_tour(): Follow a projection pursuit optimisation to find projections that have particular patterns. This is used when you want to learn if the data has particular patterns, such as clustering or outliers. Use the holes() index to find projections with gaps that allow one to see clusters, or lda_pp() or pda_pp() when class labels are known and you want to find the projections where the clusters are separated.\n\nlittle_tour(): Smoothly interpolate between pairs of variables, to show all the marginal views of the data.\n\nlocal_tour(): Makes small movements around a chosen projections to explore a small neighbourhood. Very useful to learn if small distances away from a projection change the pattern substantially or not.\n\nradial_tour(): Interpolates a chosen variable out of the projection, and then back into the projection. This is useful for assessing importance of variables to pattern in a projection. If the pattern changes a lot when the variable is rotated out, then the variable is important for producing it.\n\ndependendence_tour(): Delivers two sequences of 1D grand tours, to examine associations between two sets of variables. This is useful for displaying two groups of variables as in multiple regression, or multivariate regression or canonical correlation analysis, as two independent 1D projections.\n\nfrozen_tour(): This is an interesting one! it allows the coefficient for some variables to be fixed, and others to vary.\n\nA.1.4 The importance of scale\nScaling of multivariate data is really important in many ways. It affects most model fitting, and can affect the perception of patterns when data is visualised. Here we describe a few scaling issues to take control of when using tours.\nPre-processing data\nIt is generally useful to standardise your data to have mean 0 and variance-covariance equal to the identity matrix before using the tour. We use the tour to discover associations between variables. Characteristics of single variables should be examined and understood before embarking on looking for high-dimensional structure.\nThe rescale parameter in the animate() function will scale all variables to range between 0 and 1, prior to starting the tour. This will force all to have the same range. It is not the default, and without this data with different ranges across variable may have some strange patterns. You should set rescale=TRUE. If you have already scaled the data yourself, even if using a different scaling such as using standardised variables then the default rescale=FALSE is best.\nA more severe transformation that can be useful prior to starting a tour is to sphere the data. This is also an option in the animate() function, but is FALSE by default. Sphering is the same as conducting a principal component analysis, and using the principal components as the variables. It removes all linear association between variables! This can be especially useful if you want to focus on finding non-linear associations, including clusters, and outliers.\nScaling to fit into plot region\nThe half_range parameter in most of the display types sets the range used to scale the data into the plot. It is estimated when a tour is started, but you may need to change it if you find that the data keeps escaping the plot window or is not fully using the space. Space expands exponentially as dimension increases, and the estimation takes this into account. However, different distributions of data points lead to different variance of observations in high-dimensional space. A skewed distribution will be more varied than a normal distribution. It is hard to estimate precisely how the data should be scaled so that it fits nicely into the plot space for all projections viewed.\nThe center parameter is used to centre each projection by setting the mean to be at the middle of the plot space. With different distributions the mean of the data can vary around the plot region, and this can be distracting. Fixing the mean of each projection to always be at the center of the plot space makes it easier to focus on other patterns.\n\nA.1.5 Saving your tour\nThe functions save_history() and planned_tour() allow the tour path to be pre-computed, and re-played in your chosen way. The tour path is saved as a list of projection vectors, which can also be passed to external software for displaying tours easily. Only a minimal set of projections is saved, by default, and a full interpolation path of projections can always be generated from it using the interpolate() function.\nVersions and elements of tours can be saved for publication using a variety of functions:\n\n\nrender_gif(): Save a tour as an animated gif, using the gifski package.\n\nrender_proj(): Save an object that can be used to produce a polished rendering of a single projection, possibly with ggplot.\n\nrender_anim(): Creates an object containing a sequence of projections that can be used with plotly() to produce an HTML animation, with interactive control.\n\nA.1.6 Understanding your tour path\nFigure A.1 shows tour paths on 3D data spaces. For 1D projections the space of all possible projections is a \\(p\\)-dimensional sphere (Figure A.1 (a)). For 2D projections the space of all possible projections is a \\(p\\times 2\\)-dimensional torus (Figure A.1 (b))! The geometry is elegant.\nIn these figures, the space is represented by the light colour, and is constructed by simulating a large number of random projections. The two darker colours indicate paths generated by a grand tour and a guided tour. The grand tour will cover the full space of all possible projections if allowed to run for some time. The guided tour will quickly converge to an optimal projection, so will cover only a small part of the overall space.\n\nLoad librarieslibrary(ferrn)\nlibrary(tourr)\nlibrary(geozoo)\nlibrary(dplyr)\nlibrary(purrr)\n\n\n\n\n\n\n\n\n\n\n\n(a) 1D tour paths\n\n\n\n\n\n\n\n\n\n(b) 2D tour paths\n\n\n\n\n\n\nFigure A.1: Grand and guided tour paths of 1D and 2D projections of 3D data. The light points represent the space of all 1D and 2D projections respectively. You can see the grand tour is more comprehensively covering the space, as expected, whereas the guided tour is more focused, and quickly moves to the best projection.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Toolbox</span>"
    ]
  },
  {
    "objectID": "A1-toolbox.html#what-not-to-do",
    "href": "A1-toolbox.html#what-not-to-do",
    "title": "Appendix A — Toolbox",
    "section": "\nA.2 What not to do",
    "text": "A.2 What not to do\n\nA.2.1 Discrete and categorical data\nTour methods are for numerical data, particularly real-valued measurements. If your data is numerical, but discrete the data can look artificially clustered. Figure A.2 shows an example. The data is numeric but discrete, so it is ok to examine it in a tour. In this example, there will be overplotting of observations and the artificial clustering (plot a). It can be helpful to jitter observations, by adding a small amount of noise (plot b). This helps to remove the artificial clustering, but preserve the main pattern which is the strong linear association. Generally, jittering is a useful tool for working with discrete data, so that you can focus on examining the multivariate association. If the data is categorical, with no natural ordering of categories, the tour is not advised.\n\nDiscrete data codeset.seed(430)\ndf &lt;- data.frame(x1 = sample(1:6, 107, replace=TRUE)) %&gt;% \n          mutate(x2 = x1 + sample(1:2, 107, replace=TRUE),\n                 x3 = x1 - sample(1:2, 107, replace=TRUE),\n                 x4 = sample(1:3, 107, replace=TRUE))\nanimate_xy(df)\nrender_gif(df,           \n           grand_tour(),\n           display_xy(),\n           gif_file = \"gifs/discrete_data.gif\",\n           frames = 100,\n           width = 300, \n           height = 300)\n\ndfj &lt;- df %&gt;%\n  mutate(x1 = jitter(x1, 2), \n         x2 = jitter(x2, 2),\n         x3 = jitter(x3, 2),\n         x4 = jitter(x4, 2))\nanimate_xy(dfj)\nrender_gif(dfj,           \n           grand_tour(),\n           display_xy(),\n           gif_file = \"gifs/jittered_data.gif\",\n           frames = 100,\n           width = 300, \n           height = 300)\n\n\n\n\n\n\n\n\n\n\n\n(a) Discrete data\n\n\n\n\n\n\n\n\n\n(b) Jittered data\n\n\n\n\n\n\nFigure A.2: Discrete data can look like clusters, which is misleading. Adding a small amount of jitter (random number) can help. The noise is not meaningful but it could allow the viewer to focus on linear or non-linear association between variables without being distracted by artificial clustering.\n\n\n\nA.2.2 Missing values\n\nCode to handle missing valueslibrary(naniar)\nlibrary(ggplot2)\nlibrary(colorspace)\ndata(\"oceanbuoys\")\nob_p &lt;- oceanbuoys %&gt;%\n  filter(year == 1993) %&gt;%\n  ggplot(aes(x = air_temp_c,\n           y = humidity)) +\n     geom_miss_point() +\n  scale_color_discrete_divergingx(palette=\"Zissou 1\") +\n  theme_minimal() + \n  theme(aspect.ratio=1)\nob_nomiss_below &lt;- oceanbuoys %&gt;%\n  filter(year == 1993) %&gt;%\n  rename(st = sea_temp_c,\n         at = air_temp_c,\n         hu = humidity) %&gt;%\n  select(st, at, hu) %&gt;%\n  rowwise() %&gt;%\n  mutate(anymiss = factor(ifelse(naniar:::any_na(c(st, at, hu)), TRUE, FALSE))) %&gt;%\n  add_shadow(st, at, hu) %&gt;%\n  impute_below_if(.predicate = is.numeric) \nob_nomiss_mean &lt;- oceanbuoys %&gt;%\n  filter(year == 1993) %&gt;%\n  rename(st = sea_temp_c,\n         at = air_temp_c,\n         hu = humidity) %&gt;%\n  select(st, at, hu) %&gt;%\n  rowwise() %&gt;%\n  mutate(anymiss = factor(ifelse(naniar:::any_na(c(st, at, hu)), TRUE, FALSE))) %&gt;%\n  add_shadow(st, at, hu) %&gt;%\n  impute_mean_if(.predicate = is.numeric) \nob_p_below &lt;- ob_nomiss_below %&gt;%\n  ggplot(aes(x=st, y=hu, colour=anymiss)) +\n  geom_point() +\n  scale_color_discrete_divergingx(palette=\"Zissou 1\") +\n  theme_minimal() + \n  theme(aspect.ratio=1, legend.position = \"None\")\nob_p_mean &lt;- ob_nomiss_mean %&gt;%\n  ggplot(aes(x=st, y=hu, colour=anymiss)) +\n  geom_point() +\n  scale_color_discrete_divergingx(palette=\"Zissou 1\") +\n  theme_minimal() + \n  theme(aspect.ratio=1, legend.position = \"None\")\n\n\n\nCode to make animationanimate_xy(ob_nomiss_below[,1:3], col=ob_nomiss$anymiss)\nrender_gif(ob_nomiss_below[,1:3],\n           grand_tour(),\n           display_xy(col=ob_nomiss_below$anymiss), \n           gif_file = \"gifs/missing_values1.gif\",\n           frames = 100,\n           width = 300, \n           height = 300)\nrender_gif(ob_nomiss_mean[,1:3],\n           grand_tour(),\n           display_xy(col=ob_nomiss_mean$anymiss), \n           gif_file = \"gifs/missing_values2.gif\",\n           frames = 100,\n           width = 300, \n           height = 300)\n\n\nMissing values can also pose a problem for high-dimensional visualisation, but they shouldn’t just be ignored or removed. Methods used in 2D to display missings as done in the naniar package (N. Tierney & Cook, 2023a) like placing them below the complete data don’t translate well to high dimensions. Figure A.3 illustrates this. It leads to artificial clustering of observations (Figure A.3 (b)). It is better to impute the values, and mark them with colour when plotting. The cases are then included in the visualisation so we can assess the multivariate relationships, and also obtain some sense of how these cases should be handled, or imputed. In the example in Figure A.3 (d) we imputed the values simply, using the mean of the complete cases. We can see this is not an ideal approach for imputation for this data because some of the imputed values are outside the domain of the complete cases.\n\n\n\n\n\n\n\n\n\n\n(a) Missings below in 2D\n\n\n\n\n\n\n\n\n\n\n(b) Missings below in high-D\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Missings imputed in 2D\n\n\n\n\n\n\n\n\n\n\n(d) Missings imputed in high-D\n\n\n\n\n\n\nFigure A.3: Ways to visualise missings for 2D don’t transfer to higher dimensions. When the missings are set at 10% below the complete cases it appears to be clustered data when viewed in a tour (b). It is better to impute the value, and use colour to indicate that it is originally a missing value (d).\n\n\n\nA.2.3 Context such as time and space\nWe occasionally hear statements like “time is the fourth dimension” or “space is the fifth dimension”. This is not a useful way to think about dimensionality.\nIf you have data with spatial or temporal context, we recommend avoiding using the time index or the spatial coordinates along with the multiple variables in the tour. Time and space are different types of variables, and should not be combined with the multivariate measurements.\nFor multivariate temporal data, we recommend using a dependence tour, where one axis is reserved for the time index, and the other axis is used to tour on the multiple variables. For spatial data, we recommend using an image tour, where horizontal and vertical axes are used for spatial coordinates and colour of a tile is used for the tour of multiple variables.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Toolbox</span>"
    ]
  },
  {
    "objectID": "A1-toolbox.html#tours-in-other-software",
    "href": "A1-toolbox.html#tours-in-other-software",
    "title": "Appendix A — Toolbox",
    "section": "\nA.3 Tours in other software",
    "text": "A.3 Tours in other software\nThere are tours available in various software packages. For most examples we use the tourr package, but the same purpose could be achieved by using other software. We also use some of the software this book, when the tourr package is not up for the task. For information about these packages, their websites are the best places to start\n\n\nliminal: to combine tours with (non-linear) dimension reduction algorithms.\n\ndetourr: animations for {tourr} using htmlwidgets for performance and portability.\n\nlangevitour: HTML widget that shows tours projections of a high-dimensional dataset with an animated scatterplot.\n\nwoylier: alternative method for generating a tour path by interpolating between d-D frames in p-D space rather than d-D planes.\n\nspinifex: manual control of dynamic projections of numeric multivariate data.\n\nferrn: extracts key components in the data object collected by the guided tour optimisation, and produces diagnostic plots.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Toolbox</span>"
    ]
  },
  {
    "objectID": "A1-toolbox.html#supporting-software",
    "href": "A1-toolbox.html#supporting-software",
    "title": "Appendix A — Toolbox",
    "section": "\nA.4 Supporting software",
    "text": "A.4 Supporting software\n\n\nclassifly: This package is used heavily for supervised classification.\n\nThe explore() function is used to explore the classification model. It will predict the class of a sample of points in the predictor space (.TYPE=simulated), and return this in a data frame with the observed data (.TYPE=actual). The variable .BOUNDARY indicates that a point is within a small distance of the classification boundary, when the value is FALSE. The variable .ADVANTAGE gives an indication of the confidence with which an observation is predicted, so can also be used to select simulated points near the boundary.\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan den Boogaart, K. G., Tolosana-Delgado, R., & Bren, M. (2024). Compositions: Compositional data analysis. http://www.stat.boogaart.de/compositions/\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Toolbox</span>"
    ]
  },
  {
    "objectID": "A2-data.html",
    "href": "A2-data.html",
    "title": "Appendix B — Data",
    "section": "",
    "text": "B.1 Australian Football League Women\nThis chapter describes the datasets used throughout the book as listed in Table B.1.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#australian-football-league-women",
    "href": "A2-data.html#australian-football-league-women",
    "title": "Appendix B — Data",
    "section": "",
    "text": "Description\nThe aflw data is from the 2021 Women’s Australian Football League. These are average player statistics across the season, with game statistics provided by the fitzRoy package. If you are new to the game of AFL, there is a nice explanation on Wikipedia.\nVariables\n\n\nRows: 381\nColumns: 35\n$ id              &lt;chr&gt; \"CD_I1001678\", \"CD_I1001679\", \"CD_I1001681\", \"CD_I1001…\n$ given_name      &lt;chr&gt; \"Jordan\", \"Brianna\", \"Jodie\", \"Ebony\", \"Emma\", \"Pepa\",…\n$ surname         &lt;chr&gt; \"Zanchetta\", \"Green\", \"Hicks\", \"Antonio\", \"King\", \"Ran…\n$ number          &lt;int&gt; 2, 3, 5, 12, 60, 21, 22, 23, 35, 14, 3, 8, 16, 12, 19,…\n$ team            &lt;chr&gt; \"Brisbane Lions\", \"West Coast Eagles\", \"GWS Giants\", \"…\n$ position        &lt;chr&gt; \"INT\", \"INT\", \"HFFR\", \"WL\", \"RK\", \"BPL\", \"INT\", \"INT\",…\n$ time_pct        &lt;dbl&gt; 63.00000, 61.25000, 76.50000, 74.90000, 85.10000, 77.4…\n$ goals           &lt;dbl&gt; 0.0000000, 0.0000000, 0.0000000, 0.1000000, 0.6000000,…\n$ behinds         &lt;dbl&gt; 0.0000000, 0.0000000, 0.5000000, 0.4000000, 0.4000000,…\n$ kicks           &lt;dbl&gt; 5.000000, 2.500000, 3.750000, 8.800000, 4.100000, 3.22…\n$ handballs       &lt;dbl&gt; 2.500000, 3.750000, 3.000000, 3.600000, 2.700000, 2.22…\n$ disposals       &lt;dbl&gt; 7.500000, 6.250000, 6.750000, 12.400000, 6.800000, 5.4…\n$ marks           &lt;dbl&gt; 1.5000000, 0.2500000, 1.0000000, 3.7000000, 2.2000000,…\n$ bounces         &lt;dbl&gt; 0.0000000, 0.0000000, 0.0000000, 0.6000000, 0.1000000,…\n$ tackles         &lt;dbl&gt; 3.000000, 2.250000, 2.250000, 3.900000, 2.000000, 1.77…\n$ contested       &lt;dbl&gt; 3.500000, 2.250000, 3.500000, 5.700000, 4.400000, 2.66…\n$ uncontested     &lt;dbl&gt; 3.500000, 4.500000, 3.000000, 7.000000, 2.800000, 1.77…\n$ possessions     &lt;dbl&gt; 7.000000, 6.750000, 6.500000, 12.700000, 7.200000, 4.4…\n$ marks_in50      &lt;dbl&gt; 1.0000000, 0.0000000, 0.2500000, 0.5000000, 0.9000000,…\n$ contested_marks &lt;dbl&gt; 1.0000000, 0.0000000, 0.0000000, 0.4000000, 1.2000000,…\n$ hitouts         &lt;dbl&gt; 0.0000000, 0.0000000, 0.0000000, 0.0000000, 19.4000000…\n$ one_pct         &lt;dbl&gt; 0.0000000, 1.5000000, 0.5000000, 1.2000000, 2.6000000,…\n$ disposal        &lt;dbl&gt; 60.25000, 67.15000, 37.20000, 65.96000, 61.72000, 66.8…\n$ clangers        &lt;dbl&gt; 2.000000, 0.500000, 2.500000, 3.100000, 2.400000, 1.33…\n$ frees_for       &lt;dbl&gt; 1.0000000, 0.5000000, 0.2500000, 2.5000000, 0.5000000,…\n$ frees_against   &lt;dbl&gt; 1.0000000, 0.5000000, 1.2500000, 1.3000000, 1.1000000,…\n$ rebounds_in50   &lt;dbl&gt; 0.0000000, 0.5000000, 0.2500000, 1.1000000, 0.0000000,…\n$ assists         &lt;dbl&gt; 0.00000000, 0.00000000, 0.00000000, 0.20000000, 0.2000…\n$ accuracy        &lt;dbl&gt; 0.00000, 0.00000, 0.00000, 5.00000, 30.00000, 0.00000,…\n$ turnovers       &lt;dbl&gt; 1.500000, 1.000000, 2.500000, 4.000000, 1.700000, 1.22…\n$ intercepts      &lt;dbl&gt; 2.0000000, 2.0000000, 0.5000000, 5.3000000, 1.3000000,…\n$ tackles_in50    &lt;dbl&gt; 0.5000000, 0.0000000, 0.7500000, 0.5000000, 0.5000000,…\n$ shots           &lt;dbl&gt; 0.5000000, 0.0000000, 0.7500000, 1.0000000, 1.2000000,…\n$ metres          &lt;dbl&gt; 72.50000, 58.50000, 76.00000, 225.90000, 89.80000, 76.…\n$ clearances      &lt;dbl&gt; 0.5000000, 0.2500000, 1.2500000, 0.4000000, 0.9000000,…\n\n\nPurpose\nThe primary analysis is to summarise the variation using principal component analysis, which gives information about relationships between the statistics or skills sets common in players. One also might be tempted to cluster the players, but there are no obvious clusters so it could be frustrating. At best one could partition the players into groups, while recognising there are no absolutely distinct and separated groups.\nSource\nSee the information provided with the fitzRoy package.\nPre-processing\nThe code for downloading and pre-processing the data is available at the mulgar website in the data-raw folder. The data provided by the fitzRoy package was pre-processed to reduce the variables to only those that relate to player skills and performance. It is possible that using some transformations on the variables would be useful to make them less skewed.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#bushfires",
    "href": "A2-data.html#bushfires",
    "title": "Appendix B — Data",
    "section": "\nB.2 Bushfires",
    "text": "B.2 Bushfires\nDescription\nThis data was collated by Weihao (Patrick) Li as part of his Honours research at Monash University. It contains fire ignitions as detected from satellite hotspots, and processed using the spotoroo package, augmented with measurements on weather, vegetation, proximity to human activity. The cause variable is predicted based on historical fire ignition data collected by County Fire Authority personnel.\nVariables\n\n\nRows: 1,021\nColumns: 60\n$ id            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ lon           &lt;dbl&gt; 141.1300, 141.3000, 141.4800, 147.1600, 148.1050, 144.18…\n$ lat           &lt;dbl&gt; -37.13000, -37.65000, -37.35000, -37.85000, -37.57999, -…\n$ time          &lt;date&gt; 2019-10-01, 2019-10-01, 2019-10-02, 2019-10-02, 2019-10…\n$ FOR_CODE      &lt;dbl&gt; 41, 41, 91, 44, 0, 44, 0, 102, 0, 91, 45, 41, 45, 45, 45…\n$ FOR_TYPE      &lt;chr&gt; \"Eucalypt Medium Woodland\", \"Eucalypt Medium Woodland\", …\n$ FOR_CAT       &lt;chr&gt; \"Native forest\", \"Native forest\", \"Commercial plantation…\n$ COVER         &lt;dbl&gt; 1, 1, 4, 2, 6, 2, 6, 5, 6, 4, 2, 1, 2, 2, 2, 2, 6, 6, 6,…\n$ HEIGHT        &lt;dbl&gt; 2, 2, 4, 2, 6, 2, 6, 5, 6, 4, 3, 2, 3, 3, 3, 2, 6, 6, 6,…\n$ FOREST        &lt;dbl&gt; 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,…\n$ rf            &lt;dbl&gt; 0.0, 0.0, 15.4, 4.8, 6.0, 11.6, 11.6, 0.6, 0.2, 0.6, 0.0…\n$ arf7          &lt;dbl&gt; 5.0857143, 2.4000000, 2.4000000, 0.7142857, 0.8571429, 1…\n$ arf14         &lt;dbl&gt; 2.8142857, 1.7428571, 1.8000000, 1.6714286, 1.5714286, 1…\n$ arf28         &lt;dbl&gt; 1.9785714, 1.5357143, 1.5357143, 3.7857143, 1.9000000, 1…\n$ arf60         &lt;dbl&gt; 2.3033333, 1.7966667, 1.7966667, 4.0000000, 2.5333333, 1…\n$ arf90         &lt;dbl&gt; 1.2566667, 1.0150000, 1.0150000, 2.9600000, 2.1783333, 1…\n$ arf180        &lt;dbl&gt; 0.9355556, 0.8444444, 0.8444444, 2.3588889, 1.7866667, 1…\n$ arf360        &lt;dbl&gt; 1.3644444, 1.5255556, 1.5255556, 1.7272222, 1.4716667, 1…\n$ arf720        &lt;dbl&gt; 1.3011111, 1.5213889, 1.5213889, 1.7111111, 1.5394444, 1…\n$ se            &lt;dbl&gt; 3.8, 4.6, 14.2, 23.7, 23.8, 16.8, 18.0, 12.9, 14.7, 12.9…\n$ ase7          &lt;dbl&gt; 18.02857, 18.50000, 21.41429, 23.08571, 23.11429, 22.014…\n$ ase14         &lt;dbl&gt; 17.03571, 17.44286, 18.03571, 19.17143, 18.45714, 18.628…\n$ ase28         &lt;dbl&gt; 19.32857, 18.47500, 19.33929, 18.23571, 16.86071, 19.375…\n$ ase60         &lt;dbl&gt; 20.38644, 19.99153, 20.39492, 19.90847, 19.26780, 20.449…\n$ ase90         &lt;dbl&gt; 22.54118, 21.93193, 22.04370, 20.59328, 20.04538, 21.809…\n$ ase180        &lt;dbl&gt; 20.79106, 19.93966, 19.99385, 19.11006, 18.66760, 19.810…\n$ ase360        &lt;dbl&gt; 15.55153, 14.83259, 14.87883, 14.69276, 14.44318, 14.755…\n$ ase720        &lt;dbl&gt; 15.52350, 14.75049, 14.77427, 14.53463, 14.32656, 14.540…\n$ maxt          &lt;dbl&gt; 21.3, 17.8, 15.4, 20.8, 19.8, 15.8, 19.5, 12.6, 18.8, 12…\n$ amaxt7        &lt;dbl&gt; 22.38571, 20.44286, 22.21429, 24.21429, 23.14286, 21.671…\n$ amaxt14       &lt;dbl&gt; 21.42857, 19.72857, 19.86429, 21.80000, 20.89286, 19.578…\n$ amaxt28       &lt;dbl&gt; 20.71071, 19.10000, 19.18929, 19.75000, 19.05714, 18.885…\n$ amaxt60       &lt;dbl&gt; 24.02667, 22.28000, 22.38667, 22.93167, 22.12000, 21.031…\n$ amaxt90       &lt;dbl&gt; 27.07750, 25.77667, 25.89833, 24.93667, 23.93750, 23.164…\n$ amaxt180      &lt;dbl&gt; 26.92000, 25.92722, 25.98500, 24.84056, 23.95389, 23.343…\n$ amaxt360      &lt;dbl&gt; 21.55389, 20.79778, 20.81333, 20.21972, 19.99389, 19.505…\n$ amaxt720      &lt;dbl&gt; 21.47750, 20.57222, 20.57694, 20.13153, 20.03875, 19.650…\n$ mint          &lt;dbl&gt; 9.6, 9.0, 7.3, 7.7, 8.3, 8.3, 6.1, 5.9, 7.4, 5.9, 6.9, 7…\n$ amint7        &lt;dbl&gt; 9.042857, 7.971429, 9.171429, 10.328571, 11.200000, 10.6…\n$ amint14       &lt;dbl&gt; 9.928571, 9.235714, 9.421429, 10.007143, 10.900000, 10.7…\n$ amint28       &lt;dbl&gt; 8.417857, 7.560714, 7.353571, 8.671429, 9.575000, 10.060…\n$ amint60       &lt;dbl&gt; 11.156667, 9.903333, 9.971667, 10.971667, 11.975000, 12.…\n$ amint90       &lt;dbl&gt; 11.96667, 10.81250, 10.87833, 12.49000, 13.46167, 13.638…\n$ amint180      &lt;dbl&gt; 11.96778, 11.01056, 11.02000, 12.41944, 13.42500, 13.695…\n$ amint360      &lt;dbl&gt; 9.130556, 8.459722, 8.448333, 9.588611, 10.456389, 11.03…\n$ amint720      &lt;dbl&gt; 8.854861, 8.266250, 8.254028, 9.674861, 10.517083, 10.96…\n$ dist_cfa      &lt;dbl&gt; 9442.206, 6322.438, 7957.374, 7790.785, 10692.055, 6054.…\n$ dist_camp     &lt;dbl&gt; 50966.485, 6592.893, 31767.235, 8816.272, 15339.702, 941…\n$ ws            &lt;dbl&gt; 1.263783, 1.263783, 1.456564, 5.424445, 4.219751, 4.1769…\n$ aws_m0        &lt;dbl&gt; 2.644795, 2.644795, 2.644795, 5.008369, 3.947659, 5.2316…\n$ aws_m1        &lt;dbl&gt; 2.559202, 2.559202, 2.559202, 5.229680, 4.027398, 4.9704…\n$ aws_m3        &lt;dbl&gt; 2.446211, 2.446211, 2.446211, 5.386005, 3.708622, 5.3045…\n$ aws_m6        &lt;dbl&gt; 2.144843, 2.144843, 2.144843, 5.132617, 3.389890, 5.0355…\n$ aws_m12       &lt;dbl&gt; 2.545008, 2.545008, 2.548953, 5.045297, 3.698736, 5.2341…\n$ aws_m24       &lt;dbl&gt; 2.580671, 2.580671, 2.584047, 5.081100, 3.745286, 5.2522…\n$ dist_road     &lt;dbl&gt; 498.75145, 102.22032, 1217.22446, 281.69151, 215.56176, …\n$ log_dist_cfa  &lt;dbl&gt; 9.152945, 8.751860, 8.981854, 8.960697, 9.277256, 8.7084…\n$ log_dist_camp &lt;dbl&gt; 10.838924, 8.793748, 10.366191, 9.084354, 9.638200, 9.15…\n$ log_dist_road &lt;dbl&gt; 6.212108, 4.627130, 7.104329, 5.640813, 5.373247, 5.0047…\n$ cause         &lt;chr&gt; \"lightning\", \"lightning\", \"lightning\", \"lightning\", \"lig…\n\n\nPurpose\nThe primary goal is to predict the cause of the bushfire using the weather and distance from human activity variables provided.\nSource\nCollated data was part of Weihao Li’s Honours thesis, which is not publicly available. The hotspots data was collected from P-Tree System (2020), climate data was taken from the Australian Bureau of Meteorology using the bomrang package (Sparks et al., 2020), wind data from McVicar (2011) and Iowa State University (2020), vegetation data from Australian Bureau of Agricultural and Resource Economics and Sciences (2018), distance from roads calculated using OpenStreetMap contributors (2020), CFA stations from Department of Environment, Land, Water & Planning (2020a), and campsites from Department of Environment, Land, Water & Planning (2020b). The cause was predicted from training data provided by Department of Environment, Land, Water & Planning (2019).\nPre-processing\nThe 60 variables are too many to view with a tour, so it should be pre-processed using principal component analysis. The categorical variables of FOR_TYPE and FOR_CAT are removed. It would be possible to keep these if they are converted to dummy (binary variables).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#australian-election-data",
    "href": "A2-data.html#australian-election-data",
    "title": "Appendix B — Data",
    "section": "\nB.3 Australian election data",
    "text": "B.3 Australian election data\nDescription\nThis is data from a study on the relationship between voting patterns and socio-demographic characteristics of Australian electorates reported in Forbes et al. (2020). These are the predictor variables upon which voting percentages are modelled. There are two years of data in oz_election_2001 and oz_election_2016.\nVariables\n\nload(\"data/oz_election_2001.rda\")\nload(\"data/oz_election_2016.rda\")\nglimpse(oz_election_2001)\n\nPurpose\nThe tour is used to check for multicollinearity between predictors, that might adversely affect the linear model fit.\nSource\nThe data was compiled from Australian Electoral Commission (AEC) and the Australian 38 Bureau of Statistics (ABS). Code to construct the data, and the original data are available at https://github.com/jforbes14/eechidna-paper.\nPre-processing\nConsiderable pre-processing was done to produce these data sets. The original data was wrangled into tidy form, some variables were log transformed to reduce skewness, and a subset of variables was chosen.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#palmer-penguins",
    "href": "A2-data.html#palmer-penguins",
    "title": "Appendix B — Data",
    "section": "\nB.4 Palmer penguins",
    "text": "B.4 Palmer penguins\nDescription\nThis data measure four physical characteristics of three species of penguins.\nVariables\n\n\n\n\n\n\nName\nDescription\n\n\n\nbl\na number denoting bill length (millimeters)\n\n\nbd\na number denoting bill depth (millimeters)\n\n\nfl\nan integer denoting flipper length (millimeters)\n\n\nbm\nan integer denoting body mass (grams)\n\n\nspecies\na factor denoting penguin species (Adélie, Chinstrap and Gentoo)\n\n\nPurpose\nThe primary goal is to find a combination of the four variables where the three species are distinct. This is also a useful data set to illustrate cluster analysis.\nSource\nDetails of the penguins data can be found at https://allisonhorst.github.io/palmerpenguins/, and A. Horst et al. (2022) is the package source.\nPre-processing\nThe data is loaded from the palmerpenguins package. The four physical measurement variables and the species are selected, and the penguins with missing values are removed. Variables are standardised, and their names are shortened.\n\nlibrary(palmerpenguins)\npenguins &lt;- penguins %&gt;%\n  na.omit() # 11 observations out of 344 removed\n# use only vars of interest, and standardise\n# them for easier interpretation\npenguins_sub &lt;- penguins[,c(3:6, 1)] %&gt;% \n  mutate(across(where(is.numeric),  ~ scale(.)[,1])) %&gt;%\n  rename(bl = bill_length_mm,\n         bd = bill_depth_mm,\n         fl = flipper_length_mm,\n         bm = body_mass_g) %&gt;%\n  as.data.frame()\nsave(penguins_sub, file=\"data/penguins_sub.rda\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#program-for-international-student-assessment",
    "href": "A2-data.html#program-for-international-student-assessment",
    "title": "Appendix B — Data",
    "section": "\nB.5 Program for International Student Assessment",
    "text": "B.5 Program for International Student Assessment\nDescription\nThe pisa data contains plausible scores for math, reading and science of Australian and Indonesian students from the 2018 testing cycle. The plausible scores are simulated from a model fitted to the original data, to preserve privacy of the students.\nVariables\n\n\nName\nDescription\n\n\n\nCNT\ncountry, either AUS for Australia or IDN for Indonesia\n\n\n\nPV1MATH-PV10MATH\n\nplausible scores for math\n\n\n\nPV1READ-PV10READ\n\nplausible scores for reading\n\n\n\nPV1SCIE-PV10SCIE\n\nplausible scores for science\n\n\nPurpose\nPrimarily this data is useful as an example for dimension reduction.\nSource\nThe full data is available from https://www.oecd.org/pisa/. There are records of the student test scores, along with survey data from the students, their households and their schools.\nPre-processing\nThe data was reduced to country and the plausible scores, and filtered to the two countries. It may be helpful to know that the SPSS format data was used, and was read into R using the read_sav() function in the haven package.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#sketches",
    "href": "A2-data.html#sketches",
    "title": "Appendix B — Data",
    "section": "\nB.6 Sketches",
    "text": "B.6 Sketches\nDescription\nThis data is a subset of images from https://quickdraw.withgoogle.com. The subset was created using the quickdraw R package at https://huizezhang-sherry.github.io/quickdraw/. It has 6 different groups: banana, boomerang, cactus, crab, flip flops, kangaroo. Each image is 28x28 pixels. The sketches_train data would be used to train a classification model, and the unlabelled sketches_test can be used for prediction.\nVariables\n\n\nName\nDescription\n\n\n\nV1-V784\ngrey scale 0-255\n\n\nword\nwhat the person was asked to draw, NA in the test data\n\n\nid\nunique id for each sketch\n\n\nPurpose\nPrimarily this data is useful as an example for supervised classification, and also dimension reduction.\nSource\nThe full data is available from https://quickdraw.withgoogle.com.\nPre-processing\nIt is typically useful to pre-process this data into principal components. This code can also be useful for plotting one of the sketches in a recognisable form:\n\nlibrary(mulgar)\nlibrary(ggplot2)\ndata(\"sketches_train\")\nset.seed(77)\nx &lt;- sketches_train[sample(1:nrow(sketches_train), 1), ]\nxm &lt;- data.frame(gry=t(as.matrix(x[,1:784])),\n        x=rep(1:28, 28),\n        y=rep(28:1, rep(28, 28)))\nggplot(xm, aes(x=x, y=y, fill=gry)) +\n  geom_tile() +\n  scale_fill_gradientn(colors = gray.colors(256, \n                                     start = 0, \n                                     end = 1, \n                                     rev = TRUE )) +\n  ggtitle(x$word) +\n  theme_void() + \n    theme(legend.position=\"none\")\n\n\n\n\n\n\nFigure B.1: One of the sketches in the subset of training data.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#multicluster",
    "href": "A2-data.html#multicluster",
    "title": "Appendix B — Data",
    "section": "\nB.7 multicluster\n",
    "text": "B.7 multicluster\n\n\nCodelibrary(mulgar)\ndata(\"multicluster\")\n\n\nDescription\nThis data has 10 numeric variables, and a class variable labelling groups.\nVariables\n\n\nName\nDescription\n\n\n\ngroup\ncluster label\n\n\nx1-x10\nnumeric variables\n\n\nPurpose\nThe primary goal is to find the different clusters.\nSource\nThis data is originally from http://ifs.tuwien.ac.at/dm/download/multiChallenge-matrix.txt, and provided as a challenge for non-linear dimension reduction. It was used as an example in Lee, Laa, Cook (2023) https://doi.org/10.52933/jdssv.v2i3.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#clusters-clusters_nonlin-simple_clusters",
    "href": "A2-data.html#clusters-clusters_nonlin-simple_clusters",
    "title": "Appendix B — Data",
    "section": "\nB.8 clusters, clusters_nonlin, simple_clusters\n",
    "text": "B.8 clusters, clusters_nonlin, simple_clusters\n\n\nCodelibrary(mulgar)\ndata(\"clusters\")\ndata(\"clusters_nonlin\")\ndata(\"simple_clusters\")\n\n\nDescription\nThis data has a various number of numeric variables, and a class variable labelling the clusters.\nVariables\n\n\nName\nDescription\n\n\n\nx1-x5\nnumeric variables\n\n\ncl\ncluster label\n\n\nPurpose\nThe primary goal is to find the different clusters.\nSource\nSimulated using the code in the simulate.R file of the data-raw directory of the mulgar package.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#plane-plane_nonlin-box",
    "href": "A2-data.html#plane-plane_nonlin-box",
    "title": "Appendix B — Data",
    "section": "\nB.9 plane, plane_nonlin, box\n",
    "text": "B.9 plane, plane_nonlin, box\n\n\nCodelibrary(mulgar)\ndata(\"plane\")\ndata(\"plane_nonlin\")\ndata(\"box\")\n\n\nDescription\nThis data has a varying number of numeric variables.\nVariables\n\n\nName\nDescription\n\n\nx1-x5\nnumeric variables\n\nPurpose\nThe primary goal is to understand how many dimensions the data spreads out.\nSource\nSimulated using the code in the simulate.R file of the data-raw directory of the mulgar package.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#additional-data-used-in-the-book",
    "href": "A2-data.html#additional-data-used-in-the-book",
    "title": "Appendix B — Data",
    "section": "\nB.10 Additional data used in the book",
    "text": "B.10 Additional data used in the book\nTable C.1 lists additional data available on the book web site at https://dicook.github.io/mulgar_book/data.\n\n\n\nTable B.2: Links to other data sets used on the book.\n\n\n\n\n\n\nDescription\nLink\n\n\n\nSaved 2D tour path for the aflw data\n&lt;a href='https://dicook.github.io/mulgar_book/data/aflw_pct.rda'&gt; aflw_pct.rda &lt;/a&gt;\n\n\nSaved clusters of the penguins data from detourr\n&lt;a href='https://dicook.github.io/mulgar_book/data/detourr_penguins.csv'&gt; detourr_penguins.csv &lt;/a&gt;\n\n\nSaved clusters of the fake trees data from detourr\n&lt;a href='https://dicook.github.io/mulgar_book/data/fake_trees_sb.csv'&gt; fake_trees_sb.csv &lt;/a&gt;\n\n\nTidied penguins data\n&lt;a href='https://dicook.github.io/mulgar_book/data/penguins_sub.rda'&gt; penguins_sub.rda &lt;/a&gt;\n\n\nSaved 2D tour path for penguins data\n&lt;a href='https://dicook.github.io/mulgar_book/data/penguins_tour_path.rda'&gt; penguins_tour_path.rda &lt;/a&gt;\n\n\nrisk survey\n&lt;a href='https://dicook.github.io/mulgar_book/data/risk_MSA.rds'&gt; risk_MSA.rds &lt;/a&gt;\n\n\npenguins NN model\n&lt;a href='https://dicook.github.io/mulgar_book/data/penguins_cnn&gt; penguins_cnn &lt;/a&gt;\n\n\nfashion MNST NN model\n&lt;a href='https://dicook.github.io/mulgar_book/data/fashion_cnn&gt; fashion_cnn &lt;/a&gt;\n\n\npenguins SHAP values\n&lt;a href='https://dicook.github.io/mulgar_book/data/p_exp_sv.rda&gt; p_exp_sv.rda &lt;/a&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A3-book-code-and-data.html",
    "href": "A3-book-code-and-data.html",
    "title": "Appendix C — Links to Book Code and Additional Data",
    "section": "",
    "text": "C.1 Additional data\nThe code and data and an RStudio project can be downloaded with\nAlternatively, individual files can be downloaded from the links below.\nTable C.1 lists additional data available on the book web site at https://github.com/dicook/mulgar_book.\nTable C.1: Links to other data sets used in the book.\n\n\n\n\n\n\nDescription\nLink\n\n\n\nSaved 2D tour path for the aflw data\n&lt;a href='https://dicook.github.io/mulgar_book/data/aflw_pct.rda'&gt; aflw_pct.rda &lt;/a&gt;\n\n\nSaved clusters of the penguins data from detourr\n&lt;a href='https://dicook.github.io/mulgar_book/data/detourr_penguins.csv'&gt; detourr_penguins.csv &lt;/a&gt;\n\n\nSaved clusters of the fake trees data from detourr\n&lt;a href='https://dicook.github.io/mulgar_book/data/fake_trees_sb.csv'&gt; fake_trees_sb.csv &lt;/a&gt;\n\n\nTidied penguins data\n&lt;a href='https://dicook.github.io/mulgar_book/data/penguins_sub.rda'&gt; penguins_sub.rda &lt;/a&gt;\n\n\nSaved 2D tour path for penguins data\n&lt;a href='https://dicook.github.io/mulgar_book/data/penguins_tour_path.rda'&gt; penguins_tour_path.rda &lt;/a&gt;\n\n\nrisk survey\n&lt;a href='https://dicook.github.io/mulgar_book/data/risk_MSA.rds'&gt; risk_MSA.rds &lt;/a&gt;\n\n\npenguins NN model\n&lt;a href='https://dicook.github.io/mulgar_book/data/penguins_cnn&gt; penguins_cnn &lt;/a&gt;\n\n\nfashion MNST NN model\n&lt;a href='https://dicook.github.io/mulgar_book/data/fashion_cnn&gt; fashion_cnn &lt;/a&gt;\n\n\npenguins SHAP values\n&lt;a href='https://dicook.github.io/mulgar_book/data/p_exp_sv.rda&gt; p_exp_sv.rda &lt;/a&gt;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Links to Book Code and Additional Data</span>"
    ]
  },
  {
    "objectID": "A3-book-code-and-data.html#code-files",
    "href": "A3-book-code-and-data.html#code-files",
    "title": "Appendix C — Links to Book Code and Additional Data",
    "section": "\nC.2 Code files",
    "text": "C.2 Code files\nTable C.2 lists additional data available on the book web site at https://dicook.github.io/mulgar_book/code.\n\n\n\nTable C.2: Links to code used on the book.\n\n\n\n\n\n\nChapter\nLink\nFilename\n\n\n\n1 Picturing high dimensions\n1-intro.R\n1-intro.R\n\n\n2 Notation conventions and R objects\n2-notation.R\n2-notation.R\n\n\n3 Overview of dimension reduction\n3-overview-dimred.R\n3-overview-dimred.R\n\n\n4 Principal component analysis\n4-pca.R\n4-pca.R\n\n\n5 Non-linear dimension reduction\n5-nldr.R\n5-nldr.R\n\n\n6 Overview of clustering\n6-overview-clust.R\n6-overview-clust.R\n\n\n7 Spin-and-brush approach\n7-spin-and-brush.R\n7-spin-and-brush.R\n\n\n8 Hierarchical clustering\n8-hierarchical.R\n8-hierarchical.R\n\n\n9 k-means clustering\n9-kmeans.R\n9-kmeans.R\n\n\n10 Model-based clustering\n10-model-based.R\n10-model-based.R\n\n\n11 Self-organizing maps\n11-som.R\n11-som.R\n\n\n12 Summarising and comparing clustering results\n12-summary-clust.R\n12-summary-clust.R\n\n\n13 Overview of supervised classification\n13-intro-class.R\n13-intro-class.R\n\n\n14 Linear discriminant analysis\n14-lda.R\n14-lda.R\n\n\n15 Trees and forests\n15-forests.R\n15-forests.R\n\n\n16 Support vector machines\n16-svm.R\n16-svm.R\n\n\n17 Neural networks and deep learning\n17-nn.R\n17-nn.R\n\n\n18 Exploring misclassifications\n18-summary-class.R\n18-summary-class.R\n\n\nA Toolbox\nA-toolbox.R\nA-toolbox.R\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan den Boogaart, K. G., Tolosana-Delgado, R., & Bren, M. (2024). Compositions: Compositional data analysis. http://www.stat.boogaart.de/compositions/\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Links to Book Code and Additional Data</span>"
    ]
  },
  {
    "objectID": "A4-glossary.html",
    "href": "A4-glossary.html",
    "title": "Appendix D — Glossary",
    "section": "",
    "text": "Table D.1: List of common terms used in the book and their synonyms used elsewhere.\n\n\n\n\n\n\nTerm\nSynonyms\nDescription\n\n\n\nvariable\nfeature, attribute\na characteristic, number or quantity that can be measured\n\n\nobservations\ncases, items, experimental units, observational units, records, statistical units, instances, examples\nindividuals on which the observations are made\n\n\ndata set\ndata, file\ncollection of observations made on one or more variables\n\n\nresponse\ntarget\nvariable that one wishes to predict\n\n\npredictor\nindependent variable, feature\nvariables used to produce a mode to predict the response\n\n\nsimilarity\ncorrelation\na measure ranging between 0 and 1, with 1 indicating that the cases are closer\n\n\ndissimilarity\ndistance\na measure where a smaller number means the cases are closer\n\n\nprincipal component analysis (PCA)\nempirical orthogonal functions, eigenvalue decomposition\nsummarise a high-dimensional variance-covariance using an orthonormal matrix and set of variances. Related methods include factor analysis, multidimensional scaling.\n\n\nlinear discriminant analysis (LDA)\nFisher's linear discriminant\nreduce the dimension to the space where the classes are most separated relative to the class means and pooled variance-covariance.\n\n\nself-organising map (SOM)\nKohonen map\nuse a grid-constrained set of means to cluster high-dimensional data, and also provide a 2D view of the clusters\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan den Boogaart, K. G., Tolosana-Delgado, R., & Bren, M. (2024). Compositions: Compositional data analysis. http://www.stat.boogaart.de/compositions/\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "1-intro.html#reading-the-axes",
    "href": "1-intro.html#reading-the-axes",
    "title": "1  Picturing high dimensions",
    "section": "\n1.2 Reading the axes",
    "text": "1.2 Reading the axes\nThe coefficients of the projection are important to matching the variables with the patterns detected. For example, in the 2D data used in Figure 1.2 the primary structure to detect is the clustering. It is when a positive, equal combination of the two variables x1 and x2 are used that the two clusters can be observed in a projection.\nWhen the projection dimension is 2, as in the example data used in Figure 1.3, there are two sets of projection coefficients. These are represented in the plot by the circle and line segments. The direction and length of the line segments indicate how the variable contributes to the view seen. Lining these up with any patterns in the data helps to understand how the variables contribute to making the pattern. In this data, the interesting feature is the hole in the donut, which can be seen in certain combinations of x1 and x3 plotted against x2.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#an-illustration-of-the-benefits",
    "href": "1-intro.html#an-illustration-of-the-benefits",
    "title": "1  Picturing high dimensions",
    "section": "\n1.6 An illustration of the benefits",
    "text": "1.6 An illustration of the benefits\nThe Palmer penguins data (A. M. Horst et al., 2022) is available in the R package palmerpenguins (A. Horst et al., 2022). These are measurements on three species of penguins, recording the bill length (bl) and depth (bd), flipper length (fl) and body mass (bm), along with the sex, island location and year of recording. Of interest here are the four physical measurements and the species. There are two penguins with missing values on these measurements which are removed from the analysis below. The variables have also been standardised. \n\n\n\n\n\n\n\nFigure 1.9: Scatterplot matrix of the penguins, with colour indicating the three species, Adelie, Chinstrap, Gentoo. The clusters for each species are similarly shaped in each scatterplot, and centred at different locations in some plots.\n\n\n\n\nFigure 1.9 shows the data as a scatterplot matrix, as produced by the ggscatmat function in the R package GGally (Emerson et al., 2013), a common way to examine multivariate data with low-dimensional plots: pairwise scatterplots and univariate density plots. A lot of information can be gained from viewing this plot:\n\nthe three species form three clusters, indicating that the physical characteristics of the three are different.\nthe Gentoo species forms a separated cluster when bd is plotted with bm.\nthere is one anomaly, a Chinstrap penguin that has a very low value of fl relative to it’s bl measurement.\n\nAlthough one cannot see it in this plot clearly, making the plot larger also reveals that fl values appear to have been often rounded because there is some discreteness in the plots.\n\n\n\n\n\n\nNice view\n\n\n\n\n\nChinstrap anomaly\n\n\n\n\n\n\n\nGentoo anomaly\n\n\n\n\n\nMultiple anomalies\n\n\n\n\n\nFigure 1.10: Four projections from a tour, showing the data from more sides. We can see that the separation between clusters is larger and that there are more unusually shaped penguins.\n\n\nIn Figure 1.10 there are four 2D projections from a grand tour of the penguins data. Projection (a) reveals a 2D projection where all three species are distinct. It’s quite a nice view where all species have circular spread, the Gentoo are separated, and the other two are very slightly overlapped. There is also one Adelie penguin that is a little different from the others here, primarily due to having large flippers but small bill depth. Projection (b) shows the anomalous Chinstrap penguin, and reveals that the gap between it and the other penguins is bigger than was seen in the scatterplot matrix. Projection (c) shows that there is an unusual Gentoo penguin, and projection (d) shows possibly a few more anomalous Gentoo, with relatively small bl and larger bm.\nIn terms of understanding how the variables contribute to the patterns observed, we need to study the axes display on each plot. In projection (a) showing the nice view of the clusters, all four variables contribute in an interesting way. The variables operate in pairs of what we might call contrasts in statistics: bl and bm combine in the top left to bottom right direction, while fl and bd combine in the top right to bottom left direction. Because the axes are pointing in opposite directions, in each pair one variable contributes in the opposite way to the other. That is, one coefficient in the pair will be positive and the other negative. We can also infer that fl and bd contribute most to distinguishing Gentoo from the other species, and also that bl and bm contribute primarily to distinguishing Chinstrap from Adelie penguins.\nInterpretations can be checked against plots of the individual variables, like the scatterplot matrix in Figure 1.9. Here, can see that, yes, bl is primarily distinguishing Chinstrap from Adelie, and fl strongly contributes to distinguishing Gentoo from the others. The plot of bl against fl has a reasonably good view of the three species as different from each other. This view gets even better when bm is combined with bl, and bd is combined with fl, to produce what we see with the tour.\nThe penguins data is relatively simple, and well-studied. Despite this, examining this data with a tour of linear projections provides a few more details that may have gone unobserved.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#common-choices-of-tours",
    "href": "1-intro.html#common-choices-of-tours",
    "title": "1  Picturing high dimensions",
    "section": "\n1.7 Common choices of tours",
    "text": "1.7 Common choices of tours\nThere are many different types of tours, all generated by different ways of choosing the sequence of linear projections to show. There are three main ones we commonly use, grand tour, guided tour and manual or radial tour. The grand tour is designed to show as many projections of the data as fast as possible with the goal being to give an overview or big picture of the data. The guided tour is used when particular patterns, such as clusters or anomalies, need to be discovered. It steers the choice of projections towards those that have these patterns. The radial tour a variable (or combination of two) from the projection, then puts it back, with the specific intent to learn if the pattern depends on this variable’s contribution. If the pattern disappears when the variable disappears it means that this variable is vital or very important for defining the pattern.\nThe Appendix A contains details on running tours, primarily using the tourr package but other software is listed. A grand tour making 2D projections uses the animate_xy() function, which implicitly uses the algorithm created by the grand_tour() function. The guided tour is created using the guided_tour() function as an argument, and the radial/manual tour is created using the radial_tour() function as an argument. It is also useful to use the save_history() function to pre-compute the set of projections to show, and then use the planned_tour() function to play the sequence. All the different algorithms for generating paths of projections can be used with save_history(). For saving an animation to include in an HTML document the render_gif() can be used. It will save a set of images to a file that will be recognised as an animated gif. It is also possible to extract any of the individual images from this file. All the gifs accompanying this book are created using the render_gif() function.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#do-you-really-have-high-dimensional-data",
    "href": "1-intro.html#do-you-really-have-high-dimensional-data",
    "title": "1  Picturing high dimensions",
    "section": "\n1.8 Do you really have high-dimensional data?",
    "text": "1.8 Do you really have high-dimensional data?\nEven though, you have multiple numeric variables, there may not be any need to use high-dimensional data visualisation. The purpose of using high-dimensional visualisation is to learn about the associations between variables. If there is no association between variables everything we need to learn can be done with univariate data visualisation methods. Chapter 3 focuses on this dimensionality, finding associations, and reducing dimensionality.\n\n\n\n\nExamples of 2D data that lack association, for which univariate methods are sufficient: (a) points spread uniformly in the square, (b) points spread in a circle with higher density in the middle, (c) points conentrated in the centre vertically and skewed to the right.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#solutions-to-exercises",
    "href": "1-intro.html#solutions-to-exercises",
    "title": "1  Picturing high dimensions",
    "section": "\n1.9 Solutions to exercises",
    "text": "1.9 Solutions to exercises",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#project",
    "href": "1-intro.html#project",
    "title": "1  Picturing high dimensions",
    "section": "Project",
    "text": "Project\nThe data set nigeria-water-imputed.csv contains water availability data recorded for Nigeria, obtained from https://www.waterpointdata.org. Examining this data is motivated by an analysis by Julia Silge “Predict availability in #TidyTuesday water sources with random forest models”. The data has been cleaned, and a small number of missing values have been imputed using the variable means. Variables with _NA at the end indicate values that are imputed, and can be ignored for this exercise.\n\nThere are 86684 observations. To do an initial examination of the the data we will start with a small subset. Make a 1% sample to work with. Note, that generally when sampling one should sample the same fraction within strata that are important for the analysis. Here we will examine the type of water source as indicated by the water_tech_category variable. You can do the sampling with this code:\n\n\nCodelibrary(tidyverse)\nlibrary(tourr)\nwater &lt;- read_csv(\"data/nigeria-water-imputed.csv\")\nset.seed(113)\nwater_sub &lt;- water |&gt;\n  group_by(water_tech_category) |&gt;\n  sample_frac(size = 0.01)\n\n\n\nTake a look at the variables starting with distance_. This can be done more easily by making a smaller subset of variables (see code below, and using shorter variable names). What are the patterns you can see? Does it look like there is much association between variables, or clustering?\n\n\nCodewater_dist &lt;- water_sub |&gt;\n  select(water_tech_category, starts_with(\"distance\")) |&gt;\n  select(!contains(\"_NA\")) |&gt;\n  mutate(water_tech_category = factor(water_tech_category)) |&gt;\n  rename(dpr = distance_to_primary_road,\n         dsr = distance_to_secondary_road,\n         dtr = distance_to_tertiary_road,\n         dc = distance_to_city,\n         dt = distance_to_town)\nanimate_xy(water_dist[,2:6], rescale=TRUE)\n\n\n\nNow let’s see how the type of water source might vary by distance. Colour the points by the water_tech_category and examine this in a grand tour. Would you expect that the water source is different depending on the distance from populated areas?\n\n\nCodeanimate_xy(water_dist[,2:6], rescale=TRUE,\n           col=water_dist$water_tech_category)\n\n\n\nNow try using a guided tour to find the best combination to see the differences between the type of water sources. Interpret which variable combination yields this difference.\n\n\nCodeset.seed(324)\nanimate_xy(water_dist[,2:6],\n           guided_tour(lda_pp(water_dist$water_tech_category)),\n           rescale=TRUE,\n           col=water_dist$water_tech_category)\n\n\n\nAnswers. 1. It is worth checking that the proportions of the groups remain the same with the sampling, so the 1% is applied in each group, eg\n\ntable(water$water_tech_category)/nrow(water)\ntable(water_dist$water_tech_category)/nrow(water_dist)\n\n\nThere is not so much association between the variables. There is no clustering of the data. Most of the observations are concentrated in a central area and spread thinner further away from the centre. There are a few locations that are possibly considered to be outliers.\n\nDistances are often skewed, so this may not be different from what is expected. Often it is useful to take log transformations of skewed data, but for perceiving differences between the types of water sources is easier on the original variables. Because the data is skewed it might not be appropriate to interpret observations as outliers, unless they are very different from the other points.\n\nMany Hand Pump’s tend to be larger distances than the Motorized Pumps, on most of the distance variables. There are too few Public Tapstand observations to say much.\nThe biggest difference between the types of water sources is in a combination of most of the variables. Distance to town, distance to city, and distance to tertiary roads have the largest contribution.\n\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936b). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936a). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan den Boogaart, K. G., Tolosana-Delgado, R., & Bren, M. (2024). Compositions: Compositional data analysis. http://www.stat.boogaart.de/compositions/\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "2-notation.html#notation-conventions-and-r-objects",
    "href": "2-notation.html#notation-conventions-and-r-objects",
    "title": "2  Technical details",
    "section": "",
    "text": "Having notation is helpful for concise explanations of different methods, to explain how data is scaled, processed and projected for various tasks, and how different quantities are calculated from the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe notation convention used throughout the book is:\nn = number of observationsp = number of variables, dimension of datad = dimension of the projectiong = number of groups, in classificationX = data matrix",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical details</span>"
    ]
  },
  {
    "objectID": "2-notation.html#mechanics-of-tours",
    "href": "2-notation.html#mechanics-of-tours",
    "title": "2  Technical details",
    "section": "\n2.2 Mechanics of tours",
    "text": "2.2 Mechanics of tours\n\n2.2.1 Different ways to choose target bases\nAlthough there are a variety of different tour types, they are (almost) all composed of three core building blocks: a set of target projection bases, a method for interpolating between them and the method to display the projected data. The manner that the target planes are chosen primarily determines the type of tour. Figure 2.1 illustrates three main tour types: grand, guided and radial. The appendix has a list of the many others.\n\nTours are composed from three elements: - a set of target projection bases - an interpolation method - the method to display the projected data\n\nThe original tour was called the grand tour (Asimov, 1985). In a grand tour, the target bases are chosen randomly from all possible projections. The reason to use a grand tour is to get an overview of the data quickly - it is possible to discover relationships between variables that were not pre-conceived. The particular grand tour available in the tourr package also has the feature that all projections are equally likely to be viewed, and it efficiently covers the space of all projections. The tour in the langevitour (Harrison, 2023a) software is similar to a grand tour but uses a different dynamic to choose the tour path, based on jostling particles. It doesn’t need to do interpolation because changes are incremental.\n \nBecause space gets large as dimension increases, the wait for seeing interesting structure in projections when using a grand tour can be long. So if you have an idea of the types of structure that would be interesting to observe using a guided tour (Cook et al., 1995a) may help. A guided tour chooses target bases according to some function describing interesting, and the tour path follows an optimisation of this function. For example, the LDA index (E.-K. Lee et al., 2005) is a function that describes the separation between known classes in a projection, and is defined as follows:\n\\[\\begin{eqnarray*}\nI_{\\rm LDA}(A) = 1- \\frac{|A'WA|}{|A'(W+B)A|}\n\\end{eqnarray*}\\]\nwhere \\(B = \\sum_{i=1}^g\nn_i(\\bar{y}_{i.}-\\bar{y}_{..})(\\bar{y}_{i.}-\\bar{y}_{..})',\nW=\\sum_{i=1}^g\\sum_{j=1}^{n_i}\n(y_{ij}-\\bar{y}_{i.})(y_{ij}-\\bar{y}_{i.})'\\) are the between- and within-group sum of squares matrices in a linear discriminant analysis, with \\(g=\\)number of groups, and \\(n_i, i=1, ....g\\) is the number of cases in each group.\nThe radial tour (Ursula Laa & Valencia, 2023) provides a way to assess the importance of any variable or combination of variables. The target basis is chosen by zeroing out a variable (or multiple variables) and the interpolation runs from the initial projection to the target and back to the initial. If the structure observed in the initial plot doesn’t change much when the variable(s) is removed, then the variable is not important. This is often best combined with the guided tour, where the radial tour would start from the best projection (as done in Figure 2.1 c), the most structured projection, and each of the variables can be tested for their importance in producing the structure.\nEach of these tour types can be run in the tourr package by setting the tour_path parameter of the animate_XXX() functions. The paths of projection bases can also be generated and saved to be used later with the save_history() function. This is the manner with which to save a particular data projection, or to generate sequences of projections to pass to external software.\n\n\n\n\n\n\ngrand tour\n\n\n\n\n\nguided tour\n\n\n\n\n\nradial\n\n\n\n\n\nFigure 2.1: Three main tour types for examining multivariate data: (a) grand tour for obtaining an overview, (b) guided tour to explore for particular structure, (c) radial tour to assess the importance of a variable. The guided tour does show the separations between the three groups better, but will miss unexpected features like the several anomalies. The radial tour shows that fl is not contributing much to the separation of the Gentoo (red) penguins from the others.\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.2: Two different types of interpolation to a target: (a) geodesic plane-to-plane, (b) basis-to-basis using Givens rotations. The geodesic interpolation follows the shortest paths between planes. Givens respects the orientation of the basis when plotting or calculating projection pursuit indexes. Both methods maintain orthonormality of the bases for each step.\n\n\n\n2.2.2 Interpolating between targets\nInterpolating from the current basis to the target basis is most commonly achieved using geodesic interpolation. This type of interpolation (described in Buja et al. (2005)) has especially important properties: (1) it is plane-to-plane so follows the shortest path, and (2) maintains orthonormality of the basis at each step when \\(d&gt;1\\). The plane-to-plane movement operates like video stabilisation, by removing the within-plane spin, so you can focus on structure without distracting movement. However, when using the guided tour if the index is not rotationally invariant, for example, if based on correlation or splines, it can be important respect a particular orientation. For this rare situation, using Givens interpolation, available in the woylier package (Batsaikan et al., 2024) can be helpful. Figure 2.2 illustrates the difference.\n\n2.2.3 Displaying the projected data\nBased on the dimension of the projection basis there are natural ways to display the projected data. If \\(d=2\\) it is most common that we would use a scatterplot, as shown in (as done in Figure 2.1.\nIf \\(d=1\\) there are many choices of display - histogram, density plot, dotplot, boxplot - any method commonly used to display univariate continuous data (see animate_dist()). If \\(d=1\\) but a second (set of) variable(s) is available, such as a time index, a categorical variable index (animate_idx()), or spatial coordinates (animate_image()), then the display might reserve one axis for the projected data and another for the additional variables. Figure 2.3 shows two different display choices for \\(d=1\\), a histogram of the projected data (a) and an ordered dotplot of an index created by combining values of several ranking variables. In each display the box with horizontal lines at the bottom represents the projection coefficients. In (a) there are six variables contributing to the projection, four with negative coefficients, which reveals some bimodality and a potential anomaly in this data. In (b), nine ranking variables on the liveability of 10 US cities are combined to give an overall rank for each city. This combination is a projection, and a tour is used to assess how the city ranks would change if the combination of these measures changed. That is, the use case, is how robust is the ranking to small changes in its construction.\nWhen \\(d&gt;2\\), even though it primarily academic, some possible choices are to use stereo to simulate 3D, scatterplot matrices or parallel coordinates.\n\n\n\n\n\n\nhistogram\n\n\n\n\n\ndotplot\n\n\n\n\n\nFigure 2.3: Different choices for displaying projected data: (a) histogram, (b) ordered dotplot. In each case the projected data is 1D. In the histogram, the lines at the bottom of the display correspond to the projection basis. For the ordered dotplot each point corresponds to a US city, which has been measured on several criteria such as housing, climate, crime, and education. The lines at the bottom correspond the coefficients for each of these ratings in the projection basis.\n\n\nAdjustments to the display are useful for some problems. The crowding problem where points concentrate as dimension increases can be alleviated with a transformation of the projected data documented in Laa et al. (2022) and available with the animate_sage() function. When the data is particularly dense, for example, simulated data filling out a full \\(p\\)-dimensional cube from a fitted model generated to understand the fit, it can be useful to use slicing (Laa et al., 2020a). Slicing will fade out observations beyond a given distance from the centre of the data, relative to the projection. Figure 2.4 illustrates the slice display available using the animate_slice() function.\n\n\n\n\n\n\nprojection\n\n\n\n\n\nslice\n\n\n\n\n\nFigure 2.4: Slicing can cut through high density is useful to find hollowness in high-dimensional data, or understand limitations of fitted models. Here points on the surface of a 3D torus are shown using (a) projections, and (b) slices. The slicing reveals the hollowness of this data with the circular cuts to the donut shape.\n\n\nIt can also be useful to add layers to the data, such as summary statistics, labels for selected observations, or connecting points with lines to represent model fits. Figure 2.5 illustrates two use cases. In (a) labels for specific players are shown when examining player statistics in the aflw data. All three were named best players in the 2021 AFLW season, Bowers and Davey were equal best and fairest, and Vescio was awarded best goal kicker. All three have quite different player statistics profiles. The play of Bowers and Davey differs in the number of handballs and kicks - Davey tends to distribute the ball with handballs, while Bowers tends to kick. In (b) the lines indicate constraints. This is compositional data where each row adds to 1. It is the Fireworks data from the compositions (van den Boogaart et al., 2024) package, and measures the mixtures of five different ingredients. We can see that it is relatively equal mixtures because all are very centred within the constraints. We can also see points banding into stripes, suggesting that there are just a small number of firework recipes.\n \n\n\n\n\n\n\nlabelling\n\n\n\n\n\nconstraints\n\n\n\n\n\nFigure 2.5: It is sometimes useful to overlay additional information, such as labels for a few points (a) or representing constraints (b). The labels in (a) correspond to players that won awards in the 2021 AFLW season. The lines in (b) correspond to constraints - this is compositional data where each 5D observation is constrained to sum to 1.\n\n\nIt is often asked why isn’t the data display using solid shapes, or provide depth cues with point size or colour. But the nature of high-dimensions is that comprehensive research on lighting models and perspective conducted for 3D graphics, does not extend to more than 3D. For example, a light source, like a lamp, is a point object, and in 4D the shadows would be 3D. A surface in 4D is 3D. So the choice of using points to represent objects, and lines to indicate geometric features is because these are meaningful in any dimension.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical details</span>"
    ]
  },
  {
    "objectID": "2-notation.html#solutions-to-exercises",
    "href": "2-notation.html#solutions-to-exercises",
    "title": "2  Technical details",
    "section": "\n2.3 Solutions to exercises",
    "text": "2.3 Solutions to exercises",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical details</span>"
    ]
  },
  {
    "objectID": "A2-data.html#clusterchallenges-c1---c7",
    "href": "A2-data.html#clusterchallenges-c1---c7",
    "title": "Appendix B — Data",
    "section": "\nB.10 clusterchallenges: c1 - c7\n",
    "text": "B.10 clusterchallenges: c1 - c7\n\nDescription\nThis data has a varying number of numeric variables, and a variety of cluster shapes.\nVariables\n\n\nName\nDescription\n\n\n\nx1, x2, …\nnumeric variables\n\nPurpose\nThe primary goal is to detect the different clusters.\nSource\nThese are challenge data sets, so the code to simulate them is not made available.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#anomalies-anomaly1---anomaly5",
    "href": "A2-data.html#anomalies-anomaly1---anomaly5",
    "title": "Appendix B — Data",
    "section": "\nB.11 anomalies: anomaly1 - anomaly5\n",
    "text": "B.11 anomalies: anomaly1 - anomaly5\n\nDescription\nThese dataset have four numeric variables, and a variety of anomalies.\nVariables\n\n\nName\nDescription\n\n\n\nx1, …, x4\n\nnumeric variables\n\nPurpose\nThe primary goal is to detect the anomalies.\nSource\nThese are challenge data sets, so the code to simulate them is not made available.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#associations-assoc1---assoc3",
    "href": "A2-data.html#associations-assoc1---assoc3",
    "title": "Appendix B — Data",
    "section": "\nB.12 associations: assoc1 - assoc3\n",
    "text": "B.12 associations: assoc1 - assoc3\n\nDescription\nThese dataset have four numeric variables, and a variety of types of association.\nVariables\n\n\nName\nDescription\n\n\n\nx1, …, x4\n\nnumeric variables\n\nPurpose\nThe primary goal is to detect the associations.\nSource\nThese are challenge data sets, so the code to simulate them is not made available.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#fashion-mnist",
    "href": "A2-data.html#fashion-mnist",
    "title": "Appendix B — Data",
    "section": "\nB.13 Fashion MNIST",
    "text": "B.13 Fashion MNIST\nDescription\nThis data is a subset of images from https://github.com/zalandoresearch/fashion-mnist. Each image is 28x28 grayscale image. The training set has 60,000 images, and the test set has 10,000 images.\nVariables\n\n\n\n\n\n\nName\nDescription\n\n\n\nx\narrays of grey scale values 0-255\n\n\ny\nlabel 0-9, corresponding to T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n\n\nPurpose\nPrimarily this data is useful as an example for neural network modeling, following the tutorial at https://tensorflow.rstudio.com/tutorials/keras/classification.\nSource\nThe data is available from https://github.com/zalandoresearch/fashion-mnist.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#risk_msa",
    "href": "A2-data.html#risk_msa",
    "title": "Appendix B — Data",
    "section": "\nB.14 risk_MSA\n",
    "text": "B.14 risk_MSA\n\nDescription\nThe data was collected in Australia in 2015 (Hajibaba et al., 2016) and includes six types of risks (recreational, health, career, financial, safety and social) with responses on a scale from 1 (never) to 5 (very often).\nVariables\n\n\nRows: 563\nColumns: 6\n$ Recreational &lt;int&gt; 3, 1, 2, 1, 5, 5, 1, 5, 1, 3, 1, 5, 2, 5, 2, 2, 2, 1, 2, …\n$ Health       &lt;int&gt; 2, 1, 2, 1, 4, 2, 1, 5, 1, 5, 1, 5, 2, 5, 1, 1, 4, 2, 2, …\n$ Career       &lt;int&gt; 1, 1, 1, 1, 1, 5, 1, 5, 1, 2, 1, 5, 2, 3, 3, 1, 2, 1, 1, …\n$ Financial    &lt;int&gt; 2, 1, 1, 1, 3, 3, 1, 5, 1, 1, 1, 5, 2, 4, 3, 2, 2, 1, 2, …\n$ Safety       &lt;int&gt; 2, 1, 2, 1, 5, 2, 1, 5, 1, 4, 1, 5, 1, 5, 2, 3, 2, 1, 2, …\n$ Social       &lt;int&gt; 4, 1, 3, 1, 5, 3, 1, 5, 1, 5, 1, 5, 1, 4, 2, 1, 1, 1, 2, …\n\n\nPurpose\nThis data is useful for the demonstration of clustering methods, it was also used in Dolnicar et al. (2018).\nSource\nThe data is available from https://homepage.boku.ac.at/leisch/MSA/.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "A2-data.html#peripheral-blood-mononuclear-cells",
    "href": "A2-data.html#peripheral-blood-mononuclear-cells",
    "title": "Appendix B — Data",
    "section": "\nB.15 Peripheral Blood Mononuclear Cells",
    "text": "B.15 Peripheral Blood Mononuclear Cells\nDescription\nThe data was described in Z. Chen et al. (2024), which is available through the R package Seurat (Hao et al. (2021), Stuart et al. (2019), Butler et al. (2018), Satija et al. (2015)). Here the data has been pre-processed following the tutorial at https://satijalab.org/seurat/articles/pbmc3k_tutorial.html, and the first 50 PCs are made available in the data file pbmc_pca_50.rds which is read into R using the readRDS() function.\nVariables\n\n\nName\nDescription\n\n\n\nPC_1-PC_50\n\nPrincipal component scores\n\nPurpose\nThe purpose is to understand the clustering of cell types, relative to clustering in the gene expression. Here, our purpose is to determine if the low-dimensional representation provided by NLDR is an accurate representation of the clustering, as understood from using the tour on the PCs. We ignore the cell type labels, and focus on the geometric shapes of clumps and clusters in the high dimensions.\nSource\nThe data can be downloaded and pre-processed following https://satijalab.org/seurat/articles/pbmc3k_tutorial.html.\n\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan den Boogaart, K. G., Tolosana-Delgado, R., & Bren, M. (2024). Compositions: Compositional data analysis. http://www.stat.boogaart.de/compositions/\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "5-nldr.html#assessing-reliability-of-the-nldr-representation",
    "href": "5-nldr.html#assessing-reliability-of-the-nldr-representation",
    "title": "\n5  Non-linear dimension reduction\n",
    "section": "\n5.2 Assessing reliability of the NLDR representation",
    "text": "5.2 Assessing reliability of the NLDR representation\nNLDR can produce useful low-dimensional summaries of structure in high-dimensional data, like those shown in Figure 5.1. However, there are numerous pitfalls. The fitting procedure can produce very different representations depending on the parameter choices, and even the random number seeding the fit. (You can check this by changing the set.seed in the code above, and by changing from the default parameters.) Also, it may not be possible to represent the high-dimensional structures faithfully in low dimensions. For these reasons, one needs to connect the NLDR view with a tour of the data, to help assess its usefulness and accuracy. For example, with this data, we would want to know which of the two curved clusters in the UMAP representation correspond to the sine wave cluster.\n\n5.2.1 Using liminal\n\n\nFigure 5.3 shows how the NLDR plot can be linked to a tour view, using the liminal package, to better understand how well the structure of the data is represented. Here we learn that the smile in the UMAP embedding is the small bent rod cluster, and that the unibrow is the sine wave.\n\nlibrary(liminal)\numap_df &lt;- data.frame(umapX = cnl_umap[, 1],\n                      umapY = cnl_umap[, 2])\nlimn_tour_link(\n  umap_df,\n  clusters_nonlin,\n  cols = x1:x4\n)\n\n\n\n\n\n\n\n\n\n\n(a) Smile matches bent rod.\n\n\n\n\n\n\n\n\n\n\n\n(b) Unibrow matches sine wave.\n\n\n\n\n\n\nFigure 5.3: Two screenshots from liminal showing which clusters match between the UMAP representation and the tour animation. The smile corresponds to the small bent rod cluster. The unibrow matches to the sine wave cluster.\n\n\n\n5.2.2 Using detourr\n\n\nFigure 5.4 shows how the linking is achieved using detourr. It uses a shared data object, as made possible by the crosstalk package, and the UMAP view is made interactive using plotly.\n\nlibrary(detourr)\nlibrary(dplyr)\nlibrary(crosstalk)\nlibrary(plotly)\numap_df &lt;- data.frame(umapX = cnl_umap[, 1],\n                      umapY = cnl_umap[, 2])\ncnl_df &lt;- bind_cols(clusters_nonlin, umap_df)\nshared_cnl &lt;- SharedData$new(cnl_df)\n\ndetour_plot &lt;- detour(shared_cnl, tour_aes(\n  projection = starts_with(\"x\"))) |&gt;\n    tour_path(grand_tour(2), \n                    max_bases=50, fps = 60) |&gt;\n       show_scatter(alpha = 0.7, axes = FALSE,\n                    width = \"100%\", height = \"450px\")\n\numap_plot &lt;- plot_ly(shared_cnl,\n                    x = ~umapX, \n                    y = ~umapY,\n                    color = I(\"black\"),\n                    height = 450) %&gt;%\n    highlight(on = \"plotly_selected\", \n              off = \"plotly_doubleclick\") %&gt;%\n    add_trace(type = \"scatter\", \n              mode = \"markers\")\n\nbscols(\n     detour_plot, umap_plot,\n     widths = c(5, 6)\n )\n\n\n\n\n\n\nFigure 5.4: Screenshot from detourr showing which clusters match between the UMAP representation and the tour animation. The smile corresponds to the small bent rod cluster.",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-linear dimension reduction</span>"
    ]
  },
  {
    "objectID": "5-nldr.html#example-fake_trees",
    "href": "5-nldr.html#example-fake_trees",
    "title": "\n5  Non-linear dimension reduction\n",
    "section": "\n5.3 Example: fake_trees\n",
    "text": "5.3 Example: fake_trees\n\n\nFigure 5.5 shows a more complex example, using the fake_trees data. We know that the 10D data has a main branch, and 9 branches (clusters) attached to it, based on our explorations in the earlier chapters. The t-SNE view, where points are coloured by the known branch ids, is very helpful for seeing the linear branch structure.\nWhat we can’t tell is that there is a main branch from which all of the others extend. We also can’t tell which of the clusters corresponds to this branch. Linking the plot with a tour helps with this. Although, not shown in the sequence of snapshots in Figure 5.5, the main branch is actually the dark blue cluster, which is separated into three pieces by t-SNE.\n\nCode to run liminal on the fake trees datalibrary(liminal)\nlibrary(Rtsne)\ndata(fake_trees)\nset.seed(2020)\ntsne &lt;- Rtsne::Rtsne(\n  dplyr::select(fake_trees,\n                dplyr::starts_with(\"dim\")))\ntsne_df &lt;- data.frame(tsneX = tsne$Y[, 1],\n                      tsneY = tsne$Y[, 2])\nlimn_tour_link(\n  tsne_df,\n  fake_trees,\n  cols = dim1:dim10,\n  color = branches\n)\n\n\n\n\n\n\n\n\n\n\n\n(a) Linked views of t-SNE dimension reduction with a tour of the fake trees data. The t-SNE view clearly shows ten 1D non-linear clusters, while the tour of the full 100 variables suggests a lot more variation in the data, and less difference between clusters.\n\n\n\n\n\n\n\n\n\n\n\n(b) Focus on the green cluster which is split by t-SNE. The shape as viewed in many linear projections shown by the tour shows that it is a single curved cluster. The split is an artifact of the t-SNE mapping.\n\n\n\n\n\n\n\n\n\n\n\n(c) Focus on the purple cluster which splits the green cluster in the t-SNE view. The tour shows that these two clusters are distinct, but are close in one neighbourhood of the 100D space. The close proximity in the t-SNE view is reasonable, though.\n\n\n\n\n\n\nFigure 5.5: Three snapshots of using the liminal linked views to explore how t-SNE has summarised the fake_trees data in 2D.\n\n\n\nThe t-SNE representation clearly shows the linear structures of the data, but viewing this 10D data with the tour shows that t-SNE makes several inaccurate breaks of some of the branches.",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-linear dimension reduction</span>"
    ]
  },
  {
    "objectID": "5-nldr.html#exercises",
    "href": "5-nldr.html#exercises",
    "title": "\n5  Non-linear dimension reduction\n",
    "section": "Exercises",
    "text": "Exercises\n\nThis question uses the penguins_sub data\n\n\nGenerate a 2D representation using t-SNE. Plot the points mapping the colour to species. What is most surprising? (Hint: Are the three species represented by three distinct clusters?)\nRe-do the t-SNE representation with different parameter choices, including using different random seeds. Are the results different each time, or do you think that they could be considered to be equivalent?\nUse liminal or detourr to link the t-SNE representation to a tour of the penguins. Highlight the points that have been placed in an awkward position by t-SNE from others in their species. Watch them relative to the others in their species in the tour view, and think about whether there is any rationale for the awkward placement.\nTry again using UMAP to make the 2D representation, and use liminal or detourr to link with a tour to explore the result.\n\n\nConduct your best t-SNE and UMAP representations of the aflw data. Compare and contrast what is learned relative to a tour or the principal component analysis.",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-linear dimension reduction</span>"
    ]
  },
  {
    "objectID": "5-nldr.html#project",
    "href": "5-nldr.html#project",
    "title": "\n5  Non-linear dimension reduction\n",
    "section": "Project",
    "text": "Project\nGene expressions measured as scRNA-Seq of 2622 human peripheral blood mononuclear cells data is available from the Seurat R package Satija et al. (2015). The paper web site has code to extract and pre-process the data, which follow the tutorial at https://satijalab.org/seurat/articles/pbmc3k_tutorial.html. The processed data, containing the first 50 PCs is provided with the book, as pbmc_pca_50.rds.\nThe original paper (Z. Chen et al., 2024) used UMAP on the first 15 PCs to find a representation of the data to illustrate the clustering. They used the default settings of the RunUMAP() function in Seurat, without setting a seed.\nGenerate the t-SNE and UMAP representations of the first 9 PCs of data, using their default settings. They should be quite different. (We use 9 PCs because the scree plot in the data pre-processing suggests that 15 is too many.) Based on your examination of the data in a tour, which method yields the more accurate representation? Explain what the structure in the 2D is relative to that seen in the tour.\n\n\n\n\n(2015). [Computer software]. Chapman; Hall/CRC. https://doi.org/https://doi.org/10.1201/b19706\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2024). Ggthemes: Extra themes, scales and geoms for ggplot2. https://jrnold.github.io/ggthemes/\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBatsaikan, Z., Cook, D., & Laa, U. (2024). Woylier: Alternative tour frame interpolation method. https://numbats.github.io/woylier/\n\n\nBatsaikhan, Z., Cook, D., & Laa, U. (2023). Frame to frame interpolation for high-dimensional data visualisation using the woylier package. https://doi.org/10.48550/arXiv.2311.08181\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with R (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nButler, A., Hoffman, P., Smibert, P., Papalexi, E., & Satija, R. (2018). Integrating single-cell transcriptomic data across different conditions, technologies, and species. Nature Biotechnology, 36, 411–420. https://doi.org/10.1038/nbt.4096\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nChen, Z., Wang, C., Huang, S., Shi, Y., & Xi, R. (2024). Directly selecting cell-type marker genes for single-cell clustering analyses. Cell Reports Methods, 4, 100810. https://doi.org/10.1016/j.crmeth.2024.100810\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2023). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2025). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer. https://doi.org/10.1007/978-3-540-33037-0\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2024). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://andrie.github.io/ggdendro/\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDolnicar, S., Grün, B., & Leisch, F. (2018). Market segmentation analysis: Understanding it, doing it, and making it useful (pp. 11–22). https://doi.org/10.1007/978-981-10-8818-6_2\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEmerson, J. W., Green, W. A., Schloerke, B., Crowley, J., Cook, D., Hofmann, H., & Wickham, H. (2013). The generalized pairs plot. Journal of Computational and Graphical Statistics, 22(1), 79–91. https://doi.org/10.1080/10618600.2012.694762\n\n\nEveritt, B. S., Landau, S., Leese, M., & Stahel, D. (2011). Cluster Analysis (5th ed). John Wiley & Sons, Ltd.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631. http://www.stat.washington.edu/mclust\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2024). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with R. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nGruen, B. (2024). CRAN task view: Cluster analysis & finite mixture models (Version 2024-08-20). https://cran.r-project.org/web/views/Cluster.html.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHao, Y., Hao, S., Andersen-Nissen, E., III, W. M. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby, C., Zagar, M., Hoffman, P., Stoeckius, M., Papalexi, E., Mimitou, E. P., Jain, J., Srivastava, A., Stuart, T., Fleming, L. B., Yeung, B., … Satija, R. (2021). Integrated analysis of multimodal single-cell data. Cell. https://doi.org/10.1016/j.cell.2021.04.048\n\n\nHarrison, P. (2023a). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15, 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHarrison, P. (2024). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHart, C., & Wang, E. (2024). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2024). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2022). Palmer archipelago penguins data in the palmerpenguins r package - an alternative to anderson’s irises. The R Journal, 14, 244–254. https://doi.org/10.32614/RJ-2022-020\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2024). Gt: Easily create presentation-ready display tables. https://gt.rstudio.com\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2024). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://colorspace.R-Forge.R-project.org/\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKandanaarachchi, S., & Hyndman, R. J. (2021). Dimension reduction for outlier detection using DOBIN. Journal of Computational and Graphical Statistics, 30(1), 204–219. https://doi.org/https://doi.org/10.1080/10618600.2020.1807353\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in R: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2023). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2024). Tidymodels: Easily install and load the tidymodels packages. https://tidymodels.tidymodels.org\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An R package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://github.com/sa-lee/liminal/\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F. (2008). Visualizing cluster analysis and finite mixture models. In Handbook of data visualization (pp. 561–587). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_22\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using R - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2024). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2024). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2023). gtExtras: Extending gt for beautiful HTML tables. https://github.com/jthomasmock/gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2024). Patchwork: The composer of plots. https://patchwork.data-imaginist.com\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B., & Venables, B. (2024). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSatija, R., Farrell, J. A., Gennert, D., Schier, A. F., & Regev, A. (2015). Spatial reconstruction of single-cell gene expression data. Nature Biotechnology, 33, 495–502. https://doi.org/10.1038/nbt.3192\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. http://schloerke.github.io/geozoo/\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2024). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nSchloerke, B., Wickham, H., Cook, D., & Hofmann, H. (2016). Escape from boxland. The R Journal, 8, 243–257.\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023a). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nScrucca, L., Fraley, C., Murphy, T. B., & Raftery, A. E. (2023b). Model-based clustering, classification, and density estimation using mclust in R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003277965\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2024). Plotly: Create interactive web graphics via plotly.js. https://plotly-r.com\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2024). Gtsummary: Presentation-ready data summary and analytic result tables. https://github.com/ddsjoberg/gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2024). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://ggrepel.slowkow.com/\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nStuart, T., Butler, A., Hoffman, P., Hafemeister, C., Papalexi, E., III, W. M. M., Hao, Y., Stoeckius, M., Smibert, P., & Satija, R. (2019). Comprehensive integration of single-cell data. Cell, 177, 1888–1902. https://doi.org/10.1016/j.cell.2019.05.031\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://github.com/bethatkinson/rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2024). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nUrsula Laa, D. C., Alex Aumann, & Valencia, G. (2023). New and simplified manual controls for projection and slice tours, with application to exploring classification boundaries in high dimensions. Journal of Computational and Graphical Statistics, 32(3), 1229–1236. https://doi.org/10.1080/10618600.2023.2206459\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan den Boogaart, K. G., Tolosana-Delgado, R., & Bren, M. (2024). Compositions: Compositional data analysis. http://www.stat.boogaart.de/compositions/\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWang, Y., Huang, H., Rudin, C., & Shaposhnik, Y. (2021). Understanding how dimension reduction tools work: An empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data visualization. Journal of Machine Learning Research, 22(201), 1–73. http://jmlr.org/papers/v22/20-1061.html\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & van den Brand, T. (2024). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nWickham, H., & Cook, D. (2025). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Hester, J., & Bryan, J. (2024). Readr: Read rectangular text data. https://readr.tidyverse.org\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2024). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2024). kableExtra: Construct complex table with kable and pipe syntax. http://haozhu233.github.io/kableExtra/",
    "crumbs": [
      "Dimension reduction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-linear dimension reduction</span>"
    ]
  }
]