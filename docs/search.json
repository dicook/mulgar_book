[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Interactive and dynamic graphics for high-dimensional data using R",
    "section": "",
    "text": "Although there are many resources available for data visualization, there are few comprehensive resources on high-dimensional data visualisation. This book fills this gap by providing a comprehensive and up-to-date guide to visualising high-dimensional data and models, with R.\nHigh-dimensional data spaces are fascinating places. You may think that there’s a lot of ways to plot one or two variables, and a lot of types of patterns that can be found. You might use a density plot and see skewness or a dot plot to find outliers. A scatterplot of two variables might reveal a non-linear relationship or a barrier beyond which no observations exist. We don’t as yet have so many different choices of plot types for high-dimensions, but these types of patterns are also what we seek in scatterplots of high-dimensional data. The additional dimensions can clarify these patterns, that clusters are likely to be more distinct. Observations that did not appear to be very different can be seen to be lonely anomalies in high-dimensions, that no other observations have quite the same combination of values."
  },
  {
    "objectID": "index.html#audience",
    "href": "index.html#audience",
    "title": "Interactive and dynamic graphics for high-dimensional data using R",
    "section": "Audience",
    "text": "Audience\nHigh-dimensional data arises in many fields such as biology, social sciences, finance, and more. Anyone who is doing exploratory data analysis and model fitting for more than two variables will benefit from learning how to effectively visualise high-dimensions. This book will be useful for students and teachers of mulitvariate data analysis and machine learning, and researchers, data analysts, and industry professionals who work in these areas."
  },
  {
    "objectID": "index.html#how-to-use-the-book",
    "href": "index.html#how-to-use-the-book",
    "title": "Interactive and dynamic graphics for high-dimensional data using R",
    "section": "How to use the book?",
    "text": "How to use the book?\nThe book is written with explanations followed by examples with R code. The toolbox chapter provides an overview of the primary high-dimensional visualisation methods. The remaining chapters focus on different application areas and how to use the high-dimensional visualisation to complement commonly used analytical methods."
  },
  {
    "objectID": "index.html#setting-up-your-workflow",
    "href": "index.html#setting-up-your-workflow",
    "title": "Interactive and dynamic graphics for high-dimensional data using R",
    "section": "Setting up your workflow",
    "text": "Setting up your workflow\nTo get started set up your computer with the current versions of R and Rstudio Desktop.\nIn addition, we have made an R package to share the data and functions used in this book, called mulgar.12\n\ninstall.packages(\"mulgar\", dependencies=TRUE)\n#| or the development version\ndevtools::install_github(\"dicook/mulgar\")"
  },
  {
    "objectID": "intro.html#notation-conventions-and-r-objects",
    "href": "intro.html#notation-conventions-and-r-objects",
    "title": "Introduction",
    "section": "Notation conventions and R objects",
    "text": "Notation conventions and R objects\nThe data can be considered to be a matrix of numbers with the columns corresponding to variables, and the rows correspond to observations. It can be helpful to write this in mathematical notation, like:\n\\[\\begin{eqnarray*}\nX_{n\\times p} =\n[X_1~X_2~\\dots~X_p]_{n\\times p} = \\left[ \\begin{array}{cccc}\nX_{11} & X_{12} & \\dots & X_{1p} \\\\\nX_{21} & X_{22} & \\dots & X_{2p}\\\\\n\\vdots & \\vdots &  & \\vdots \\\\\nX_{n1} & X_{n2} & \\dots & X_{np} \\end{array} \\right]_{n\\times p}\n\\end{eqnarray*}\\]\nwhere \\(X\\) indicates the the \\(n\\times p\\) data matrix, \\(X_j\\) indicates variable \\(j, j=1, \\dots, p\\) and \\(X_{ij}\\) indicates the value \\(j^{th}\\) variable of the \\(i^{th}\\) observation. (It can be confusing to distinguish whether one is referring to the observation or a variable, because \\(X_i\\) is used to indicate observation also. When this is done it is usually accompanied by qualifying words such as observation \\(X_3\\), or variable \\(X_3\\).)\nWhen there is a response variable(s), it is common to consider \\(X\\) to be the predictors, and use \\(Y\\) to indicate the response variable(s). \\(Y\\) could be a matrix, also, and would be \\(n\\times q\\), where commonly \\(q=1\\). \\(Y\\) could be numeric or categorical, and this would change how it is handled with visualisation.\nTo make a low-dimensional projection (shadow) of the data, we need a projection matrix:\n\\[\\begin{eqnarray*}\nA_{p\\times d} = \\left[ \\begin{array}{cccc}\nA_{11} & A_{12} & \\dots & A_{1d} \\\\\nA_{21} & A_{22} & \\dots & A_{2d}\\\\\n\\vdots & \\vdots &  & \\vdots \\\\\nA_{p1} & A_{p2} & \\dots & A_{pd} \\end{array} \\right]_{p\\times d}\n\\end{eqnarray*}\\]\n\\(A\\) should be an orthonormal matrix, which means that the \\(\\sum_{j=1}^p A_{jk}^2=1, k=1, \\dots, d\\) (columns represent vectors of length 1) and \\(\\sum_{j=1}^p A_{jk}A_{jl}=0, k,l=1, \\dots, d\\) (columns represent vectors that are orthogonal to each other).\nThen the projected data is written as:\n\\[\\begin{eqnarray*}\nY_{n\\times d} = XA = \\left[ \\begin{array}{cccc}\ny_{11} & y_{12} & \\dots & y_{1d} \\\\\ny_{21} & y_{22} & \\dots & y_{2d}\\\\\n\\vdots & \\vdots &  & \\vdots \\\\\ny_{n1} & y_{n2} & \\dots & y_{nd} \\end{array} \\right]_{n\\times d}\n\\end{eqnarray*}\\]\nwhere \\(y_{ij} = \\sum_{k=1}^p X_{ik}A_{kj}\\). Note that we are using \\(Y\\) as the projected data here, as well as it possibly being used for a response variable. Where necessary, this will be clarified with words in the text, when notation is used in explanations later.\nWhen using R, if we only have the data corresponding to \\(X\\) it makes sense to use a matrix object. However, if the response variable is included and it is categorical, then we might use a data.frame or a tibble which can accommodate non-numerical values. Then to work with the data, we can use the base R methods:\n\nX <- matrix(c(1.1, 1.3, 1.4, 1.2, 2.7, 2.6, 2.4, 2.5, 3.5, 3.4, 3.2, 3.6), ncol=4, byrow=TRUE)\nX\n\n     [,1] [,2] [,3] [,4]\n[1,]  1.1  1.3  1.4  1.2\n[2,]  2.7  2.6  2.4  2.5\n[3,]  3.5  3.4  3.2  3.6\n\n\nwhich is a data matrix with \\(n=3, p=4\\) and to extract a column (variable):\n\nX[,2]\n\n[1] 1.3 2.6 3.4\n\n\nor a row (observation):\n\nX[2,]\n\n[1] 2.7 2.6 2.4 2.5\n\n\nor an individual cell (value):\n\nX[3,2]\n\n[1] 3.4\n\n\nTo make a projection we need an orthonormal matrix:\n\nA <- matrix(c(0.707,0.707,0,0,0,0,0.707,0.707), ncol=2, byrow=FALSE)\nA\n\n      [,1]  [,2]\n[1,] 0.707 0.000\n[2,] 0.707 0.000\n[3,] 0.000 0.707\n[4,] 0.000 0.707\n\n\nYou can check that it is orthonormal by\n\nsum(A[,1]^2)\n\n[1] 0.999698\n\nsum(A[,1]*A[,2])\n\n[1] 0\n\n\nand make a projection using matrix multiplication:\n\nX %*% A\n\n       [,1]   [,2]\n[1,] 1.6968 1.8382\n[2,] 3.7471 3.4643\n[3,] 4.8783 4.8076\n\n\nThe seemingly magical number 0.707 used above and to create the projection in Figure 2 arises from normalising a vector with equal contributions from each variable, (1, 1). Dividing by sqrt(2) gives (0.707, 0.707)."
  },
  {
    "objectID": "intro.html#whats-different-about-space-beyond-2d",
    "href": "intro.html#whats-different-about-space-beyond-2d",
    "title": "Introduction",
    "section": "What’s different about space beyond 2D?",
    "text": "What’s different about space beyond 2D?\nThe term “high-dimensional” in this book refers to the dimensionality of the Euclidean space. Figure 4 shows a way to imagine this. It shows a sequence of cube wireframes, ranging from one-dimensional (1D) through to five-dimensional (5D), where beyond 2D is a linear projection of the cube. As the dimension increases, a new orthogonal axis is added. For cubes, this is achieved by doubling the cube: a 2D cube consists of two 1D cubes, a 3D cube consists of two 2D cubes, and so forth. This is a great way to think about the space being examined by the visual methods, and also all of the machine learning methods mentioned, in this book.\n\n\n\n\n\nFigure 4: Space can be considered to be a high-dimensional cube. Here we have pictured a sequence of increasing dimension cubes, from 1D to 5D, as wireframes, it can be seen that as the dimension increase by one, the cube doubles.\n\n\n\n\nInterestingly, the struggle with imagining high-dimensions this way is described in a novel published in 1884 [Abbott (1884)]1. Yes, more than 100 years ago! This is a story about characters living in a 2D world, being visited by an alien 3D character. It also is a social satire, serving the reader strong messages about gender inequity, although this provides the means to explain more intricacies in perceiving dimensions. There have been several movies made based on the book in recent decades (e.g. Martin (1965), D. Johnson and Travis (2007)). Although purchasing the movies may be prohibitive, watching the trailers available for free online is sufficient to gain enough geometric intuition on the nature of understanding high-dimensional spaces while living in a low-dimensional world.\nWhen we look at high-dimensional spaces from a low-dimensional space, we meet the “curse of dimensionality”, a term introduced by Bellman (1961) to express the difficulty of doing optimization in high dimensions because of the exponential growth in space as dimension increases. A way to imagine this is look at the cubes in Figure 4: As you go from 1D to 2D, 2D to 3D, the space expands a lot, and imagine how vast space might get as more dimensions are added2. The volume of the space grows exponentially with dimension, which makes it infeasible to sample enough points – any sample will be less densely covering the space as dimension increases. The effect is that most points will be far from the sample mean, on the edge of the sample space.\nFor visualisation, the curse manifests in an opposite manner. Projecting from high to low dimensions creates a crowding or piling of points near the center of the distribution. This was noted by Persi Diaconis and Freedman (1984). Figure 5 illustrates this phenomenon. As dimension increases, the points crowd the centre, even with as few as ten dimensions. This is something that we may need to correct for when exploring high dimensions with low-dimensional projections.\n\n\n\n\n\nFigure 5: Illustration of data crowding in the low-dimensional projection as dimension increases, here from 3, 10, 100. Colour shows the number of points in each hexagon bin (pink is large, navy is small). As dimension increases the points concentrate near the centre."
  },
  {
    "objectID": "intro.html#interactive-and-dynamic-graphics-literature",
    "href": "intro.html#interactive-and-dynamic-graphics-literature",
    "title": "Introduction",
    "section": "Interactive and dynamic graphics literature",
    "text": "Interactive and dynamic graphics literature\nA short history of the literature, how does that stat graphics literature differ from info vis?"
  },
  {
    "objectID": "intro.html#an-opening-case-study",
    "href": "intro.html#an-opening-case-study",
    "title": "Introduction",
    "section": "An opening case study",
    "text": "An opening case study\nTo give a taste of the approach used in the book"
  },
  {
    "objectID": "intro.html#the-big-picture-of-the-book",
    "href": "intro.html#the-big-picture-of-the-book",
    "title": "Introduction",
    "section": "The big picture of the book",
    "text": "The big picture of the book\nThe book is divided into four parts:\n\nDimension reduction: This part covers linear and non-linear dimension reduction. It includes ways to help decide on the number of dimensions needed to summarise the high dimensional data, whether linear dimension reduction is appropriate, detecting problems that might affect the dimension reduction, and examining how well or badly a non-linear dimension reduction is representing the data.\nCluster analysis: This part described methods for finding groups in data. Although it includes an explanation of a purely graphical approach, it is mostly on using graphics in association with numerical clustering algorithms. There are explanations of assessing the suitability of different numerical techniques for extracting clusters, based on the data shapes, evaluating the clustering result, and showing the solutions in high dimensions.\nClassification: This part describes methods for exploring known groups in the data. You’ll learn how to check model assumptions, to help decide if a method is suited to the data, examine classification boundaries and explore where errors arise.\nMiscellaneous: The material in this part focuses on examining data from different contexts. This includes multiple time series, longitudinal data. A key pre-processing step is to convert the data into Euclidean space.\n\nIn each of these parts an emphasis is also showing your model with your data in the high dimensional space.\nOur hopes are that you will come away with understanding the importance of plotting your high dimensional data as a regular step in your statistical or machine learning analyses. There are many examples of what you might miss if you don’t plot the data. Effective use of graphics goes hand-in-hand with analytical techniques. With high dimensions visualisation is a challenge but it is fascinating, and leads to many surprising moments.\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create Interactive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "dimension.html",
    "href": "dimension.html",
    "title": "Dimension reduction",
    "section": "",
    "text": "Shadows of Mulga in the Great Victoria Desert at Sunset"
  },
  {
    "objectID": "pca.html#exercises",
    "href": "pca.html#exercises",
    "title": "2  Principal component analysis",
    "section": "2.4 Exercises",
    "text": "2.4 Exercises\n\nMake a scatterplot matrix of the first four PCs. Is the branch pattern visible in any pair?\nConstruct five new variables to measure these skills offense, defense, playing time, ball movement, errors. Using the tour, examine the relationship between these variables. Map out how a few players could be characterised based on these directions of skills.\nSymmetrise any aflw variables that have skewed distributions using a log or square root transformation. Then re-do the PCA. What do we learn that is different about associations between the skill variables?\nExamine the bushfires data using a grand tour on the numeric variables, ignoring the cause (class) variable. Would it be important to transform any variables to remove skewness? Do so, if necessary. How many principal components would be recommended? Examine the PCA model with the data.\n\n\n\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBoelaert, Julien, Etienne Ollion, and Jan Sodoge. 2022. aweSOM: Interactive Self-Organizing Maps. https://CRAN.R-project.org/package=aweSOM.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nde Vries, Andrie, and Brian D. Ripley. 2022. Ggdendro: Create Dendrograms and Tree Diagrams Using Ggplot2. https://github.com/andrie/ggdendro.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2023. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2023. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIannone, Richard, Joe Cheng, Barret Schloerke, Ellis Hughes, and JooYoung Seo. 2022. Gt: Easily Create Presentation-Ready Display Tables. https://CRAN.R-project.org/package=gt.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2023. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2022. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMock, Thomas. 2022. gtExtras: Extending Gt for Beautiful HTML Tables. https://CRAN.R-project.org/package=gtExtras.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2022. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2023. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2023. Plotly: Create Interactive Web Graphics via Plotly.js.\n\n\nSjoberg, Daniel D., Joseph Larmarange, Michael Curry, Jessica Lavery, Karissa Whiting, and Emily C. Zabor. 2023. Gtsummary: Presentation-Ready Data Summary and Analytic Result Tables. https://CRAN.R-project.org/package=gtsummary.\n\n\nSjoberg, Daniel D., Karissa Whiting, Michael Curry, Jessica A. Lavery, and Joseph Larmarange. 2021. “Reproducible Summary Tables with the Gtsummary Package.” The R Journal 13: 570–80. https://doi.org/10.32614/RJ-2021-053.\n\n\nSlowikowski, Kamil. 2023. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2023. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2023. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "nldr.html",
    "href": "nldr.html",
    "title": "3  Non-linear dimension reduction",
    "section": "",
    "text": "Non-linear dimension reduction aims to find a low-dimensional representation of the high-dimensional data that shows the main features of the data. In statistics, it dates back to Kruskal (1964a)’s work on multidimensional scaling. Some techniques only require an interpoint similarity or distance matrix as the main ingredient, rather than the full data.\nShow a small simple example here.\nDiscuss contemporary methods (t-SNE, UMAP, PHATE, trimap, pacmap), and references to MDS literature.\nBorg and Groenen (2005)\n\nlibrary(liminal)\nlibrary(Rtsne)\ndata(fake_trees)\nset.seed(2020)\ntsne <- Rtsne::Rtsne(dplyr::select(fake_trees, dplyr::starts_with(\"dim\")))\ntsne_df <- data.frame(tsneX = tsne$Y[, 1],\n                      tsneY = tsne$Y[, 2])\n\n\nlimn_tour_link(\n  tsne_df,\n  fake_trees,\n  cols = dim1:dim10,\n  color = branches\n)\n\n\n\n\nFigure 3.1: Linked views of t-SNE dimension reduction with a tour of the fake trees data. The t-SNE view clearly shows ten 1D non-linear clusters, while the tour of the full 100 variables suggests a lot more variation in the data, and less difference between clusters.\n\n\n \n\n\n\nFigure 3.2: The t-SNE mapping of the penguins data inaccurately splits one of the clusters. The three clusters are clearly distinct when viewed with the tour.\n\n\n\n\nCode\nload(\"data/penguins_sub.rda\")\n\nset.seed(2022)\np_tsne <- Rtsne::Rtsne(penguins_sub[,2:5])\np_tsne_df <- data.frame(tsneX = p_tsne$Y[, 1], tsneY = p_tsne$Y[, 2])\nlimn_tour_link(\n  p_tsne_df,\n  penguins_sub,\n  cols = bl:bm,\n  color = species\n)\n\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBoelaert, Julien, Etienne Ollion, and Jan Sodoge. 2022. aweSOM: Interactive Self-Organizing Maps. https://CRAN.R-project.org/package=aweSOM.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nde Vries, Andrie, and Brian D. Ripley. 2022. Ggdendro: Create Dendrograms and Tree Diagrams Using Ggplot2. https://github.com/andrie/ggdendro.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2023. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2023. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIannone, Richard, Joe Cheng, Barret Schloerke, Ellis Hughes, and JooYoung Seo. 2022. Gt: Easily Create Presentation-Ready Display Tables. https://CRAN.R-project.org/package=gt.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2023. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2022. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMock, Thomas. 2022. gtExtras: Extending Gt for Beautiful HTML Tables. https://CRAN.R-project.org/package=gtExtras.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2022. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2023. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2023. Plotly: Create Interactive Web Graphics via Plotly.js.\n\n\nSjoberg, Daniel D., Joseph Larmarange, Michael Curry, Jessica Lavery, Karissa Whiting, and Emily C. Zabor. 2023. Gtsummary: Presentation-Ready Data Summary and Analytic Result Tables. https://CRAN.R-project.org/package=gtsummary.\n\n\nSjoberg, Daniel D., Karissa Whiting, Michael Curry, Jessica A. Lavery, and Joseph Larmarange. 2021. “Reproducible Summary Tables with the Gtsummary Package.” The R Journal 13: 570–80. https://doi.org/10.32614/RJ-2021-053.\n\n\nSlowikowski, Kamil. 2023. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2023. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2023. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "supervised.html",
    "href": "supervised.html",
    "title": "Classification",
    "section": "",
    "text": "This chapter will methods for visualising data and models when there is a response variable.\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create Interactive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "regression.html#support-vector-machine",
    "href": "regression.html#support-vector-machine",
    "title": "5  Regression methods",
    "section": "5.1 Support vector machine",
    "text": "5.1 Support vector machine\n% http://www.support-vector-machines.org/SVM_osh.html % wikipedia\nA support vector machine (SVM) (Vapnik 1999) is a binary classification method. An SVM looks for gaps between clusters in the data, based on the extreme observations in each class. In this sense it mirrors the graphical approach described at the start of this chapter, in which we searched for gaps between groups. We describe this method more fully than we did the other algorithms for two reasons: first, because of its apparent similarity to the graphical approach, and second, because it is difficult to find a simple explanation of the method in the literature.\nThe algorithm takes an \\(n \\times p\\) data matrix, where each column is scaled to \\([-1,1]\\) and each row is labeled as one of two classes (\\(y_i=+1\\) or \\(-1\\)), and finds a hyperplane that separates the two groups, if they are separable. Each row of the data matrix is a vector in \\(p\\)-dimensional space, denoted as\n% Should this be represented as a row instead of a column? dfs\n\\[\nX=\\left[ \\begin{array}{c}\n  x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_p \\end{array} \\right]\n\\]\nand the separating hyperplane can be written as\n\\[\nW'X + b = 0\n\\]\nwhere \\(W = [ w_1~~ w_2 ~~ \\dots ~~ w_p]'\\) is the normal vector to the separating hyperplane and \\(b\\) is a constant. The best separating hyperplane is found by maximizing the margin of separation between the two classes as defined by two parallel hyperplanes:\n\\[\nW'X + b = 1, ~~~~~ W'X + b = -1.\n\\]\nThese hyperplanes should maximize the distance from the separating hyperplane and have no points between them, capitalizing on any gap between the two classes. The distance from the origin to the separating hyperplane is \\(|b|/||W||\\), so the distance between the two parallel margin hyperplanes is \\(2/||W||=2/\\sqrt{w_1^2+\\dots +w_p^2}\\). Maximizing this is the same as minimizing \\(||W||/2\\). To ensure that the two classes are separated, and that no points lie between the margin hyperplanes we need:\n\\[\nW'X_i + b \\geq 1, ~~~\\mbox{  or  } ~~~W'X_i + b \\leq -1 ~~~\\forall i=1, ..., n\n\\]\nwhich corresponds to\n\\[\\begin{eqnarray}\ny_i(W'X_i+b)\\geq 1 ~~~\\forall i=1, ..., n\n\\label{svm-crit}\n\\end{eqnarray}\\]\nThus the problem corresponds to\n\nInterestingly, only the points closest to the margin hyperplanes are needed to define the separating hyperplane. We might think of these points as lying on or close to the convex hull of each cluster in the area where the clusters are nearest to each other. These points are called support vectors, and the coefficients of the separating hyperplane are computed from a linear combination of the support vectors \\(W = \\sum_{i=1}^{s} y_i\\alpha_iX_i\\), where \\(s\\) is the number of support vectors. We could also use \\(W = \\sum_{i=1}^n y_i\\alpha_iX_i\\), where \\(\\alpha_i=0\\) if \\(X_i\\) is not a support vector. For a good fit the number of support vectors \\(s\\) should be small relative to \\(n\\). Fitting algorithms can achieve gains in efficiency by using only samples of the cases to find suitable support vector candidates; this approach is used in the SVMLight (Joachims 1999) software.\nIn practice, the assumption that the classes are completely separable is unrealistic. Classification problems rarely present a gap between the classes, such that there are no misclassifications. Cortes and Vapnik (1995) relaxed the separability condition to allow some misclassified training points by adding a tolerance value \\(\\epsilon_i\\) to Equation \\(\\ref{svm-crit}\\), which results in the modified criterion \\(y_i(W'X_i+b)>1-\\epsilon_i, \\epsilon_i\\geq 0\\). Points that meet this criterion but not the stricter one are called slack vectors.\nNonlinear classifiers can be obtained by using nonlinear transformations of \\(X_i\\), \\(\\phi(X_i)\\) (Boser, Guyon, and Vapnik 1992), which is implicitly computed during the optimization using a kernel function \\(K\\). Common choices of kernels are linear \\(K(x_i,x_j)=x_i'x_j\\), polynomial \\(K(x_i,x_j)=(\\gamma x_i'x_j+r)^d\\), radial basis \\(K(x_i,x_j)=\\exp(-\\gamma ||x_i-x_j||^2)\\), or sigmoid functions \\(K(x_i,x_j)=\\mbox{tanh}(\\gamma x_i'x_j+r)\\), where \\(\\gamma>0, r,\\) and \\(d\\) are kernel parameters.\n% She didn’t say to delete the terminating colon here, but by % analogy with these rest, I will. dfs\nThe ensuing minimization problem is formulated as\n\\[\n\\mbox{ minimizing } \\frac{1}{2}||W|| + C\\sum_{i=1}^n \\epsilon_i ~~ \\mbox{ subject to }\ny_i(W'\\phi(X)+b)>1-\\epsilon_i\n\\]\nwhere \\(\\epsilon_i\\geq 0\\), \\(C>0\\) is a penalty parameter guarding against over-fitting the training data and \\(\\epsilon\\) controls the tolerance for misclassification. The normal to the separating hyperplane \\(W\\) can be written as \\(\\sum_{i=1}^{n} y_i\\alpha_i{\\phi(X_i)}\\), where points other than the support and slack vectors will have \\(\\alpha_i=0\\). Thus the optimization problem becomes\n\\[\\begin{eqnarray*}\n\\mbox{ minimizing } \\frac{1}{2} \\sum_{i=1}^n\\sum_{j=1}^n y_iy_j\\alpha_i\\alpha_jK(X_i,X_j)+C\\sum_{i=1}^n \\epsilon_i \\\\ ~~~~~~~~~~~\\mbox{ subject to }\ny_i(W'\\phi(X)+b)>1-\\epsilon_i\n\\end{eqnarray*}\\]\n \nWe use the svm function in the e1071 package (Dimitriadou et al. 2006) of R, which uses libsvm (Chang and Lin 2006), to classify the oils of the four areas in the Southern region. SVM is a binary classifier, but this algorithm overcomes that limitation by comparing classes in pairs, fitting six separate classifiers, and then using a voting scheme to make predictions. To fit the SVM we also need to specify a kernel, or rely on the internal tuning tools of the algorithm to choose this for us. Automatic tuning in the algorithm chooses a radial basis, but we found that a linear kernel performed better, so that is what we used. (This accords with our earlier visual inspection of the data in ?sec-class-plots.) Here is the R code used to fit the model:\n> library(e1071)\n> olive.svm <- best.svm(factor(area) ~ ., data=d.olive.train)\n> olive.svm <- svm(factor(area) ~ ., data=d.olive.sth.train, \n  type=\"C-classification\", kernel=\"linear\")\n> table(d.olive.sth.train[,1], predict(olive.svm, \n  d.olive.sth.train))\n   \n      1   2   3   4\n  1  19   0   0   0\n  2   0  42   0   0\n  3   0   0 155   3\n  4   1   2   3  21\n> table(d.olive.sth.test[,1], predict(olive.svm, \n  d.olive.sth.test))\n   \n     1  2  3  4\n  1  6  0  0  0\n  2  1 12  1  0\n  3  0  0 46  2\n  4  1  1  0  7\n> support.vectors <- olive.svm$index[\n    abs(olive.svm$coefs[,1])<1 &\n    abs(olive.svm$coefs[,2])<1 & abs(olive.svm$coefs[,3])<1]\n> pointtype <- rep(0,323) # training\n> pointtype[247:323] <- 1 # test\n> pointtype[olive.svm$index] <- 2 # slack vectors\n> pointtype[support.vectors] <- 3 # support vectors\n> parea <- c(predict(olive.svm, d.olive.sth.train),\n    predict(olive.svm, d.olive.sth.test))\n> d.olive.svm <- cbind(rbind(d.olive.sth.train, \n    d.olive.sth.test), parea, pointtype)\n> gd <- ggobi(d.olive.svm)[1]\n> glyph_color(gd) <- c(6,3,2,9)[d.olive.svm$area]\nThese are our misclassification tables:\n\n\nThe training error is \\(9/246=0.037\\), and the test error is \\(6/77=0.078\\). (The training error is the same as that of the neural network classifier, but the test error is lower.) Most error is associated with Sicily, which we have seen repeatedly to be an especially difficult class to separate. In the training data there are no other errors, and in the test data there are just two samples from Calabria mistakenly classified. ?fig-olive-svm illustrates our examination of the misclassified cases, one in each row of the figure. (Points corresponding to Sicily were removed from all four plots.) Each of the two cases is brushed (using a filled red circle) in the plot of misclassification table and viewed in a linked 2D tour. Both of these cases are on the edge of their clusters so the confusion of classes is reasonable.\n% Figure 14\n% Figure 15\nThe linear SVM classifier uses 20 support vectors and 29 slack vectors to define the separating planes between the four areas. It is interesting to examine which points are selected as support vectors, and where they are located in the data space. For each pair of classes, we expect to find some projection in which the support vectors line up on either side of the margin of separation, whereas the slack vectors lie closer to the boundary, perhaps mixed in with the points of other classes.\n The plots in ?fig-olive-svm2 represent our use of the 2D tour, augmented by manual manipulation,~to look for these projections. (The Sicilian points are again removed.) The support vectors are represented by open circles and the slack vectors by open rectangles, and we have been able to find a number of projections in which the support vectors are on the opposing outer edge of the point clouds for each cluster.\nThe linear SVM does a very nice job with this difficult classification. The accuracy is almost perfect on three classes, and the misclassifications are quite reasonable mistakes, being points that are on the extreme edges of their clusters. However, this method joins the list of those defeated by the difficult problem of distinguishing the Sicilian oils from the rest.\n\n5.1.1 Examining boundaries\n\nFor some classification problems, it is possible to get a good picture of the boundary between two classes. With LDA and SVM classifiers the boundary is described by the equation of a hyperplane. For others the boundary can be determined by evaluating the classifier on points sampled in the data space, using either a regular grid or some more efficient sampling scheme.\n% Figure 16\n We use the R package classifly (Wickham 2006) to generate points illustrating boundaries, add those points to the original data, and display them in GGobi. ?fig-olive-classifly shows projections of boundaries between pairs of classes in the . In each example, we used the 2D tour with manual control~to focus the view on a projection that revealed the boundary between two groups.\n% Needs to be checked\nThe top two plots show tour projections of the North (purple) and Sardinia (green) oils where the two classes are separated and the boundary appears in gray. The LDA boundary (shown at left) slices too close to the Northern oils. This might be due to the violation of the LDA assumption that the two groups have equal variance; since that is not true here, it places the boundary too close to the group with the larger variance. The SVM boundary (at right) is a bit closer to the Sardinian oils than the LDA boundary is, yet it is still a tad too close to the oils from the North.\nThe bottom row of plots examines the more difficult classification of the areas of the South, focusing on separating the South Apulian oils (in pink), which is the largest sample, from the oils of the other areas (all in orange). Perfect separation between the classes does not occur. Both plots are tour projections showing SVM boundaries, the left plot generated by a linear kernel and the right one by a radial kernel. Recall that the radial kernel was selected automatically by the SVM software we used, whereas we actually chose to use a linear kernel. These pictures illustrate that the linear basis yields a more reasonable boundary between the two groups. The shape of the clusters of the two groups is approximately the same, and there is only a small overlap of the two. The linear boundary fits this structure neatly. The radial kernel wraps around the South Apulian oils.\n\n\n\n\nBoser, Bernhard E., Isabelle M. Guyon, and Vladimir N. Vapnik. 1992. “A Training Algorithm for Optimal Margin Classifiers.” In COLT ’92: Proceedings of the Fifth Annual Workshop on Computational Learning Theory, 144–52. New York: ACM Press. https://doi.org/http://doi.acm.org/10.1145/130385.130401.\n\n\nChang, C.-C., and C.-J. Lin. 2006. “LIBSVM: A Library for Support Vector Machines.” http://www.csie.ntu.edu.tw/\\(\\sim\\)cjlin/libsvm.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nDimitriadou, E., K. Hornik, F. Leisch, D. Meyer, and A. Weingessel. 2006. “e1071: Misc Functions of the Department of Statistics, TU Wien.” http://www.R-project.org.\n\n\nJoachims, T. 1999. “Making Large-Scale SVM Learning Practical.” In Advances in Kernel Methods-Support Vector Learning, edited by B. Schölkopf, C. Burges, and A. Smola. Cambridge, MA: MIT Press.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nWickham, H. 2006. “classifly: Classify and Explore a Data Set.” http://www.R-project.org."
  },
  {
    "objectID": "LDA.html#definition",
    "href": "LDA.html#definition",
    "title": "11  Linear discriminant analysis",
    "section": "11.1 Definition",
    "text": "11.1 Definition\nFisher’s linear discriminant (Fisher 1936) computes a linear combination of the variables that separates two classes by comparing the differences between class means with the variance of values within each class. It makes no assumptions about the distribution of the data.\nLinear discriminant analysis (LDA), as proposed by Rao (1948), formalizes Fisher’s approach, by recognising that it arises from making the assumption that the data values for each class arise from a \\(p\\)-dimensional multivariate normal distribution, sharing a common variance-covariance matrix with data from other classes. When this assumption holds, Fisher’s linear discriminant gives the optimal separation between the two groups.\nFor two equally weighted groups, where \\(Y\\) is coded as \\(\\{0, 1\\}\\), the LDA rule is:\nAllocate a new observation \\(X_0\\) to group 1 if\n\\[(\\bar{X}_1-\\bar{X}_2)'S^{-1}_{\\rm pooled}X_0 \\geq\n  \\frac{1}{2}(\\bar{X}_1-\\bar{X}_2)'S^{-1}_{\\rm pooled}\n  (\\bar{X}_1+\\bar{X}_2)\\]\nelse allocate it to group 2,\nwhere \\(\\bar{X}_k\\) are the class mean vectors of an \\(n\\times p\\) data matrix \\(X_k ~~(k=1,2)\\),\n\\[S_{\\rm pooled} = \\frac{(n_1-1) S_1}{(n_1-1)+(n_2-1)} + \\frac{(n_2-1) S_2}{(n_1-1)+(n_2-1)}\\]\nis the pooled variance-covariance matrix, and\n\\[S_k = \\frac{1}{n-1}\\sum_{i=1}^{n}\n(X_{ki}-\\bar{X}_k)(X_{ki}-\\bar{X}_k)', ~~k=1,2\\]\nis the class variance–covariance matrix. The linear discriminant part of this rule is \\((\\bar{X}_1-\\bar{X}_2)'S^{-1}_{\\rm pooled}\\), which defines the linear combination of variables that best separates the two groups. To define a classification rule, we compute the value of the new observation \\(X_0\\) on this line and compare it with the value of the average of the two class means \\((\\bar{X}_1+\\bar{X}_2)/2\\) on the same line.\nFor multiple \\((g)\\) classes, the rule and the discriminant space are constructed using the between-group sum-of-squares matrix,\n\\[B=\\sum_{k=1}^g n_k(\\bar{X}_k-\\bar{X})(\\bar{X}_k-\\bar{X})'\\]\nwhich measures the differences between the class means, compared with the overall data mean \\(\\bar{X}\\) and the within-group sum-of-squares matrix,\n\\[W =\n\\sum_{k=1}^g\\sum_{i=1}^{n_k}\n(X_{ki}-\\bar{X}_k)(X_{ki}-\\bar{X}_k)'\\]\nwhich measures the variation of values around each class mean. The linear discriminant space is generated by computing the eigenvectors (canonical coordinates) of \\(W^{-1}B\\), and this is the space where the group means are most separated with respect to the pooled variance–covariance. The resulting classification rule is to allocate a new observation to the class with the highest value of\n\\[\\bar{X}_k'S^{-1}_{\\rm pooled}X_0 -\n\\frac{1}{2}\\bar{X}_k'S^{-1}_{\\rm pooled}\\bar{X}_k ~~~k=1,...,g\\]\nwhich results in allocating the new observation into the class with the closest mean.\n\nBecause LDA is a parametric model it is important to check that the assumptions are reasonable:\n\nshape of clusters are elliptical\ncluster sizes are the same."
  },
  {
    "objectID": "LDA.html#checking-assumptions",
    "href": "LDA.html#checking-assumptions",
    "title": "11  Linear discriminant analysis",
    "section": "11.2 Checking assumptions",
    "text": "11.2 Checking assumptions\nThis LDA approach is widely applicable, but it is useful to check the underlying assumptions on which it depends: (1) that the cluster structure corresponding to each class forms an ellipse, showing that the class is consistent with a sample from a multivariate normal distribution, and (2) that the variance of values around each mean is nearly the same. Figure 11.2 and Figure 11.3 illustrates two datasets, of which only one is consistent with these assumptions. Other parametric models, such as quadratic discriminant analysis or logistic regression, also depend on assumptions about the data which should be validated. \n\nlda1 <- ggplot(penguins_sub, aes(x=bl, \n                         y=bd, \n                         colour=species)) +\n  geom_point() +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  xlim(-2.5, 3) + ylim(-2.5, 2.5) +\n  ggtitle(\"(a)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1) \np_ell <- NULL\nfor (i in unique(penguins_sub$species)) {\n  x <- penguins_sub %>% dplyr::filter(species == i)\n  e <- gen_xvar_ellipse(x[,1:2], n=150, nstd=1.5)\n  e$species <- i\n  p_ell <- bind_rows(p_ell, e)\n}\nlda2 <- ggplot(p_ell, aes(x=bl, \n                         y=bd, \n                         colour=species)) +\n  geom_point() +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  xlim(-2.5, 3) + ylim(-2.5, 2.5) +\n  ggtitle(\"(b)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\nggarrange(lda1, lda2, ncol=2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\nFigure 11.2: Scatterplot of flipper length by bill length of the penguins data, and corresponding variance-covariance ellipses. There is a small amount of difference between the ellipses, but they are similar enough to be confident in assuming the population variance-covariances are equal.\n\n\n\n\n\n\nCode\n# Now repeat for a data set that violates assumptions\ndata(bushfires)\nlda3 <- ggplot(bushfires, aes(x=log_dist_cfa, \n                         y=log_dist_road, \n                         colour=cause)) +\n  geom_point() +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  xlim(6, 11) + ylim(-1, 10.5) +\n  ggtitle(\"(a)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\nb_ell <- NULL\nfor (i in unique(bushfires$cause)) {\n  x <- bushfires %>% dplyr::filter(cause == i)\n  e <- gen_xvar_ellipse(x[,c(57, 59)], n=150, nstd=2)\n  e$cause <- i\n  b_ell <- bind_rows(b_ell, e)\n}\nlda4 <- ggplot(b_ell, aes(x=log_dist_cfa, \n                         y=log_dist_road, \n                         colour=cause)) +\n  geom_point() +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  xlim(6, 11) + ylim(-1, 10.5) +\n  ggtitle(\"(b)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\nggarrange(lda3, lda4, ncol=2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nFigure 11.3: Scatterplot of distance to cfa and road for the bushfires data, and corresponding variance-covariance ellipses. There is a lot of difference between the ellipses, so it cannot be assumed that the population variance-covariances are equal.\n\n\n\n\nThis approach extends to any dimension. We would use the same projection sequence to view both the data and the variance-covariance ellipses, as in Figure 11.5. It can be seen that there is some difference in the shape and size of the ellipses in some projections, as there is with the spread of points in the projected data. However,\n\nlibrary(tourr)\np_ell <- NULL\nfor (i in unique(penguins_sub$species)) {\n  x <- penguins_sub %>% dplyr::filter(species == i)\n  e <- gen_xvar_ellipse(x[,1:4], n=150, nstd=1.5)\n  e$species <- i\n  p_ell <- bind_rows(p_ell, e)\n}\np_ell$species <- factor(p_ell$species)\nload(\"data/penguins_tour_path.rda\")\nanimate_xy(p_ell[,1:4], col=factor(p_ell$species))\nrender_gif(penguins_sub[,1:4], \n           planned_tour(pt1), \n           display_xy(half_range=0.9, axes=\"off\", col=penguins_sub$species),\n           gif_file=\"gifs/penguins_lda1.gif\",\n           frames=500,\n           loop=FALSE)\nrender_gif(p_ell[,1:4], \n           planned_tour(pt1), \n           display_xy(half_range=0.9, axes=\"off\", col=p_ell$species),\n           gif_file=\"gifs/penguins_lda2.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n(a) Data\n\n\n\n\n\n\n\n(b) Variance-covariance ellipses\n\n\n\n\nFigure 11.4: Checking the assumption of equal variance-covariance matrices for the 4D penguins data.\n\n\nAs a further check, we could generate three ellipses corresponding to the pooled variance-covariance matrix, as would be used in the model, centered at each of the means. Overlay this with the data. Now you will compare the spread of the observations in the data, with the elliptical shape of the pooled variance-covariance. If it matches reasonably we can safely use LDA. This can also be done group by group when multiple groups make it difficult to view all together.\n\nlibrary(tourr)\n# Create an ellipse corresponding to pooled vc\npool_ell <- gen_vc_ellipse(p_vc_pool, xm=rep(0, ncol(p_vc_pool)))\n\n# Add means to produce ellipses for each species\np_lda_pool <- data.frame(rbind(pool_ell +\n                                 matrix(rep(p_lda$means[1,],\n                                            each=nrow(pool_ell)),\n                                        ncol=4),\n                        pool_ell +\n                                 matrix(rep(p_lda$means[2,],\n                                            each=nrow(pool_ell)),\n                                        ncol=4),\n                        pool_ell +\n                                 matrix(rep(p_lda$means[3,],\n                                            each=nrow(pool_ell)),\n                                        ncol=4)))\n# Create one data set with means, data, ellipses\np_lda_pool$species <- factor(rep(levels(penguins_sub$species),\n                          rep(nrow(pool_ell), 3)))\np_lda_pool$type <- \"ellipse\"\np_lda_means <- data.frame(p_lda$means,\n                          species=factor(rownames(p_lda$means)),\n                          type=\"mean\")\np_data <- data.frame(penguins_sub[,1:5], type=\"data\")\np_lda_all <- bind_rows(p_lda_means,\n                       p_data,\n                       p_lda_pool)\np_lda_all$type <- factor(p_lda_all$type, \n                         levels=c(\"mean\", \"data\", \"ellipse\"))\nshapes <- c(3, 4, 20)\np_pch <- shapes[p_lda_all$type]\n\n\n\nCode\n# Code to run the tour\nanimate_xy(p_lda_all[,1:4], col=p_lda_all$species, pch=p_pch)\nload(\"data/penguins_tour_path.rda\")\nrender_gif(p_lda_all[,1:4], \n           planned_tour(pt1), \n           display_xy(col=p_lda_all$species, pch=p_pch, \n                      axes=\"off\", half_range = 0.7),\n           gif_file=\"gifs/penguins_lda_pooled1.gif\",\n           frames=500,\n           loop=FALSE)\n\n# Focus on one species\nrender_gif(p_lda_all[p_lda_all$species == \"Gentoo\",1:4], \n           planned_tour(pt1), \n           display_xy(col=\"#F5191C\", \n                      pch=p_pch[p_lda_all$species == \"Gentoo\"], \n                      axes=\"off\", half_range = 0.7),\n           gif_file=\"gifs/penguins_lda_pooled2.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n(a) All species\n\n\n\n\n\n\n\n(b) Gentoo\n\n\n\n\nFigure 11.5: Tour of penguins data, pooled variance-covariance ellipse overlaid. We can see that the pooled variance-covariance is a reasonable estimate of the spread of the data."
  },
  {
    "objectID": "LDA.html#examining-results",
    "href": "LDA.html#examining-results",
    "title": "11  Linear discriminant analysis",
    "section": "11.3 Examining results",
    "text": "11.3 Examining results\nThe boundaries for a classification model can be examined by:\n\ngenerating a large number of observations in the domain of the data\npredicting the class for each\n\nWe’ll look at this for 2D using the LDA model fitted to bl, and bd of the penguins data.\n\nlibrary(classifly)\n\nload(\"data/penguins_sub.rda\")\np_bl_bd_lda <- lda(species~bl+bd, data=penguins_sub, \n                                  prior = c(1/3, 1/3, 1/3))\n\nThe fitted model parameters are the means: \\(\\bar{x}_{Adelie} = (\\) -0.95, 0.6\\()^\\top\\), \\(\\bar{x}_{Chinstrap} = (\\) 0.89, 0.64\\()^\\top\\), and \\(\\bar{x}_{Gentoo} = (\\) 0.65, -1.1\\()^\\top\\).\nThe boundaries can be examined using the explore() function from the classifly package, which generates observations in the range of all values ofbl and bd and predicts their class. We can overlay the sample means and an ellipse corresponding to the variance-covariance also, by extracting these from the model object.\n\np_bl_bd_lda_boundaries <- explore(p_bl_bd_lda, penguins_sub)\np_bl_bd_lda_m1 <- ggplot(p_bl_bd_lda_boundaries) +\n  geom_point(aes(x=bl, y=bd, colour=species, shape=.TYPE)) + \n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  scale_shape_manual(values=c(46, 16)) +\n  theme_minimal() +\n  theme(aspect.ratio = 1, legend.position = \"none\")\n\np_bl_bd_lda_means <- data.frame(p_bl_bd_lda$means, species=rownames(p_bl_bd_lda$means))\n\n\np_lda <- lda(species ~ ., penguins_sub[,1:5], prior = c(1/3, 1/3, 1/3))\np_lda_boundaries <- explore(p_lda, penguins_sub)\n\n\n\nCode\n# Code to run the tour\np_lda_boundaries$species\nanimate_slice(p_lda_boundaries[p_lda_boundaries$.TYPE == \"simulated\",1:4], col=p_lda_boundaries$species[p_lda_boundaries$.TYPE == \"simulated\"], v_rel=0.02, axes=\"bottomleft\")\nrender_gif(p_lda_boundaries[p_lda_boundaries$.TYPE == \"simulated\",1:4],\n           planned_tour(pt1),\n           display_slice(v_rel=0.02, \n             col=p_lda_boundaries$species[p_lda_boundaries$.TYPE == \"simulated\"], \n             axes=\"bottomleft\"),                     gif_file=\"gifs/penguins_lda_boundaries.gif\",\n           frames=500,\n           loop=FALSE\n           )\n\n\n\n# Project the boundaries into the 2D discriminant space\np_lda_b_sub <- p_lda_boundaries[\n  p_lda_boundaries$.TYPE == \"simulated\", \n  c(1:4, 6)]\np_lda_b_sub_ds <- data.frame(as.matrix(p_lda_b_sub[,1:4]) %*%\n  p_lda$scaling)\np_lda_b_sub_ds$species <- p_lda_b_sub$species\np_lda_b_sub_ds_p <- ggplot(p_lda_b_sub_ds, \n       aes(x=LD1, y=LD2, \n           colour=species)) +\n  geom_point(alpha=0.2) +  \n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, \n        legend.position = \"bottom\",\n        legend.title = element_blank()) \n\n\n\n\n\n\n\n\n(a) 4D\n\n\n\n\n\n\n\n\n(b) Discriminant space\n\n\n\n\n\nFigure 11.6: Examining the boundaries produced by the LDA model in the full 4D with a slice tour and in the discriminant space.\n\n\n\nThe LDA boundaries divide the classes in the discriminant space, and the remaining directions are irrelevant."
  },
  {
    "objectID": "forests.html#trees",
    "href": "forests.html#trees",
    "title": "13  Trees and forests",
    "section": "13.1 Trees",
    "text": "13.1 Trees\nThe tree algorithm Breiman et al. (1984) is a simple and versatile algorithmic method for supervised classification. The basic tree algorithm generates a classification rule by sequentially splitting the data into two buckets. Splits are made between sorted data values of individual variables, with the goal of obtaining pure classes on each side of the split. The inputs for a simple tree classifier commonly include (1) an impurity measure, an indication of the relative diversity among the cases in the terminal nodes; (2) a parameter that sets the minimum number of cases in a node, or the minimum number of observations in a terminal node of the tree; and (3) a complexity measure that controls the growth of a tree, balancing the use of a simple generalizable tree against a more accurate tree tailored to the sample. When applying tree methods, exploring the effects of the input parameters on the tree is instructive; for example, it helps us to assess the stability of the tree model.\nAlthough algorithmic models do not depend on distributional assumptions, that does not mean that every algorithm is suitable for all data. For example, the tree model works best when all variables are independent within each class, because it does not take such dependencies into account. Visualization can help us to determine whether a particular model should be applied. In classification problems, it is useful to explore the cluster structure, comparing the clusters with the classes and looking for evidence of correlation within each class. The plots in Figure 5.1 and Figure 5.3 shows a strong correlation between the variables within each species, which indicates that the tree model may not give good results for the penguins data. We’ll show how this is the case with two variables initially, and then extend to the four variables.\n\n\n\n\n\nCode\nlibrary(mulgar)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(colorspace)\nlibrary(classifly)\nlibrary(ggplot2)\n\nload(\"data/penguins_sub.rda\")\np_bl_bd_tree <- rpart(species~bl+bd, data=penguins_sub)\nrpart.plot(p_bl_bd_tree, box.palette=\"Grays\")\n\n\n\n\n\n(a) Default tree fit\n\n\n\n\n\n\nCode\np_bl_bd_tree_boundaries <- explore(p_bl_bd_tree, penguins_sub)\nggplot(p_bl_bd_tree_boundaries) +\n  geom_point(aes(x=bl, y=bd, colour=species, shape=.TYPE)) + \n  scale_color_discrete_qualitative(\"Dark 3\") +\n  scale_shape_manual(values=c(46, 16)) +\n  theme_minimal() +\n  theme(aspect.ratio = 1, legend.position = \"none\")\n\n\n\n\n\n(b) Boundaries of tree fit\n\n\n\n\n\nFigure 13.1: The correlation between variables causes problems for using a tree model on the penguins data.\n\n\nThe plots in Figure 13.1 show the inadequacies of the tree fit. The background color indicates the class predictions, and thus boundaries produced by the tree fit. They can be seen to be boxy, and missing the elliptical nature of the penguin clusters. This produces errors in the classification of observations which are indefensible. One could always force the tree to fit the data more closely by adjusting the parameters, but the main problem persists: that one is trying to fit elliptical data using boxes.\nThe boundaries for the tree model on all four variables of the penguins data can be viewed similarly using the tour. The default fitted tree is delightfully simple, with just six splits of the data.\n\n\nCode\np_tree <- rpart(species~., data=penguins_sub)\nrpart.plot(p_tree, box.palette=\"Grays\")\n\np_tree_boundaries <- explore(p_tree, penguins_sub)\nanimate_slice(p_tree_boundaries[p_tree_boundaries$.TYPE == \"simulated\",1:4], col=p_tree_boundaries[p_tree_boundaries$.TYPE == \"simulated\",6], v_rel=0.02, axes=\"bottomleft\")\nload(\"data/penguins_tour_path.rda\")\nrender_gif(p_tree_boundaries[p_tree_boundaries$.TYPE == \"simulated\",1:4],\n           planned_tour(pt1),\n           display_slice(v_rel=0.02, \n             col=p_tree_boundaries[p_tree_boundaries$.TYPE == \"simulated\",6], \n             axes=\"bottomleft\"),                     gif_file=\"gifs/penguins_tree_boundaries.gif\",\n           frames=500,\n           loop=FALSE\n           )\n\n\n\n\n\n\n\n\n\n(a) Boundaries produced by the LDA model.\n\n\n\n\n\n\n\n(b) Boundaries produced by the tree model.\n\n\n\n\nFigure 13.2: Comparison of the boundaries produced by the LDA model and the tree models."
  },
  {
    "objectID": "forests.html#random-forests",
    "href": "forests.html#random-forests",
    "title": "12  Trees and forests",
    "section": "12.2 Random forests",
    "text": "12.2 Random forests\nA random forest L. Breiman and Cutler (2004) is a classifier that is built from multiple trees generated by randomly sampling the cases and the variables. The random sampling (with replacement) of cases has the fortunate effect of creating a training (“in-bag”) and a test (“out-of-bag”) sample for each tree computed. The class of each case in the out-of-bag sample for each tree is predicted, and the predictions for all trees are combined into a vote for the class identity.\nA random forest is a computationally intensive method, a “black box” classifier, but it produces several diagnostics that make the outcome less mysterious. Some diagnostics that help us to assess the model are the votes, the measure of variable importance, and the proximity matrix.\n\n12.2.1 Examining the votes matrix\nHere we show how to use the randomForest (Li06?) votes matrix for the penguins data to investigate confusion between classes, and observations which are problematic to classify. With only three classes the votes matrix is only a 2D object, and thus easy to examine. With four or more classes the votes matrix needs to be examined in a tour.\n\nlibrary(randomForest)\nlibrary(dplyr)\npenguins_rf <- randomForest(species~.,\n                             data=penguins_sub[,1:5],\n                             importance=TRUE)\npenguins_rf\n\n\nCall:\n randomForest(formula = species ~ ., data = penguins_sub[, 1:5],      importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 2.4%\nConfusion matrix:\n          Adelie Chinstrap Gentoo class.error\nAdelie       143         3      0 0.020547945\nChinstrap      4        64      0 0.058823529\nGentoo         0         1    118 0.008403361\n\n\nTo examine the votes matrix, we extract the votes element from the random forest model object. This will have three columns corresponding to the three species, but because each row is a set of proportions it is only a 2D object, as seen in Figure 12.3 (a). To reduce the dimension from 3D to the 2D we use a Helmert matrix (Lancaster 1965). Helmert matrices are orthogonal matrices, where the first row is all 1’s, and then subsequent rows sequentially replace one element with a 0. The rows are usually normalised to have length 1. They are used to create contrasts to test combinations of factor levels for post-testing after Analysis of Variance (ANOVA). For compositional data, like the votes matrix, when the first row is removed a Helmert matrix can be used to reduce the dimension appropriately. For three classes, this will generate the common 2D ternary diagram, but for higher dimensions it will reduce to a \\((g-1)\\)-dimensional simplex. For the penguins data, the Helmert matrix for 3D is\n\n\nCode\ngeozoo::f_helmert(3)\n\n\n             [,1]       [,2]       [,3]\nhelmert 0.5773503  0.5773503  0.5773503\nx       0.7071068 -0.7071068  0.0000000\nx       0.4082483  0.4082483 -0.8164966\n\n\nWe drop the first row, transpose it, and use matrix multiplication with the votes matrix to get the ternary diagram.\n\n# Project 4D into 3D\nlibrary(geozoo)\nproj <- t(geozoo::f_helmert(3)[-1,])\np_rf_v_p <- as.matrix(penguins_rf$votes) %*% proj\ncolnames(p_rf_v_p) <- c(\"x1\", \"x2\")\np_rf_v_p <- p_rf_v_p %>%\n  as.data.frame() %>%\n  mutate(species = penguins_sub$species)\n\nWe can use the geozoo package to generate the surrounding simplex, which is a triangle for 2D.\n\n# Add simplex\nsimp <- simplex(p=2)\nsp <- data.frame(cbind(simp$points), simp$points[c(2,3,1),])\ncolnames(sp) <- c(\"x1\", \"x2\", \"x3\", \"x4\")\nsp$species = sort(unique(penguins_sub$species))\nlibrary(ggthemes)\np_ternary <- ggplot() +\n  geom_segment(data=sp, aes(x=x1, y=x2, xend=x3, yend=x4)) +\n  geom_text(data=sp, aes(x=x1, y=x2, label=species),\n            nudge_x=c(-0.06, 0.07, 0),\n            nudge_y=c(0.05, 0.05, -0.05)) +\n  geom_point(data=p_rf_v_p, aes(x=x1, y=x2, colour=species), size=2, alpha=0.5) +\n  scale_color_discrete_divergingx(palette=\"Zissou 1\") +\n  theme_map() +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n\n\nCode\n# Look at the votes matrix, in its 3D space\nanimate_xy(penguins_rf$votes, col=penguins_sub$species)\n\n# Save an animated gif\nrender_gif(penguins_rf$votes,\n           grand_tour(),\n           display_xy(v_rel=0.02, \n             col=penguins_sub$species, \n             axes=\"bottomleft\"), \n           gif_file=\"gifs/penguins_rf_votes.gif\",\n           frames=500,\n           loop=FALSE\n)\n\n\n\n\n\n\n\n\n\n(a) Votes matrix in a tour.\n\n\n\n\n\n\n\n\n(b) Votes matrix in its 2D space, a ternary diagram.\n\n\n\n\n\nFigure 12.3: Examining the votes matrix from a random forest fit to the penguins.\n\n\nThe votes matrix, reports the proportion of trees each observation is classified as each class. From the tour of the votes matrix, it can be seen to be 2D in 3D space. This is due to the constraint that the three proportions for each observation sum to 1. Using a Helmert matrix, this data can be projected into the 2D space, or more generally the \\((g-1)\\)-dimensional space where it resides. In 2D this is called a ternary diagram, and in higher dimensions the bounding shapes might be considered to be a simplex. The vertices of this shape correspond to \\((1,0,0), (0,1,0), (0,0,1)\\) (and analogously for higher dimensions), which represent perfect confidence, that an observation is classified into that group all the time.\nWhat we can see here is a concentration of points in the corners of the triangle indicates that most of the penguins are confidently classified into their correct class. Then there is more separation between the Gentoo and the others, than between Chinstrap and Adelie. That means that as a group Gentoo are more distinguishable. Only one of the Gentoo penguins has substantial confusion, mostly confused as a Chinstrap, but occasionally confused as an Adelie – if it was only ever confused as a Chinstrap it would fall on the edge between Gentoo and Chinstrap. There are quite a few Chinstrap and Adelie penguins confused as each other, with a couple of each more confidently predicted to be the other class. This can be seen because there are points of the wrong colour close to those vertices.\nThe votes matrix is useful for investigating the fit, but one should remember that there are some structural elements of this data that don’t lend themselves to tree models. Although a forest has the capacity to generate non-linear boundaries by combining predictions from multiple trees, it is still based on the boxy boundaries of trees. This makes it less suitable for the penguins data with elliptical classes. You could use the techniques from the previous section to explore the boundaries produced by the forest, and you will find that the are more boxy than the LDA models.\nTo examine a vote matrix for a problem with more classes, we will examine the 10 class fake_trees data example. The full data has 100 variables, and we have seen from ?sec-clust-graphics that reducing to 10 principal components allows the linear branching structure in the data to be seen. Given that the branches correspond to the classes, it will be interesting to see how well the random forest model performs.\n\nlibrary(mulgar)\nlibrary(dplyr)\nlibrary(liminal)\nft_pca <- prcomp(fake_trees[,1:100], \n                 scale=TRUE, retx=TRUE)\nft_pc <- as.data.frame(ft_pca$x[,1:10])\nft_pc$branches <- fake_trees$branches\nlibrary(randomForest)\nft_rf <- randomForest(branches~., data=ft_pc, \n                            importance=TRUE)\nft_rf\n\n\nCall:\n randomForest(formula = branches ~ ., data = ft_pc, importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 3\n\n        OOB estimate of  error rate: 4.1%\nConfusion matrix:\n    0   1   2   3   4   5   6   7   8   9 class.error\n0 271   4   2   2   3   2   4   3   6   3  0.09666667\n1  13 287   0   0   0   0   0   0   0   0  0.04333333\n2  10   0 288   0   2   0   0   0   0   0  0.04000000\n3   6   0   0 289   0   0   0   4   0   1  0.03666667\n4  12   0   0   0 288   0   0   0   0   0  0.04000000\n5  10   0   0   0   0 290   0   0   0   0  0.03333333\n6  13   0   0   0   0   0 286   0   1   0  0.04666667\n7   6   0   0   3   0   0   0 291   0   0  0.03000000\n8   8   0   0   0   0   0   0   0 292   0  0.02666667\n9   5   0   0   0   0   0   0   0   0 295  0.01666667\n\n\n\nft_rf_votes <- ft_rf$votes %>%\n  as_tibble() %>%\n  mutate(branches = fake_trees$branches)\n\nproj <- t(geozoo::f_helmert(10)[-1,])\nf_rf_v_p <- as.matrix(ft_rf_votes[,1:10]) %*% proj\ncolnames(f_rf_v_p) <- c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\")\nf_rf_v_p <- f_rf_v_p %>%\n  as.data.frame() %>%\n  mutate(branches = fake_trees$branches)\n\nsimp <- geozoo::simplex(p=9)\nsp <- data.frame(simp$points)\ncolnames(sp) <- c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\")\nsp$branches = \"\"\nf_rf_v_p_s <- bind_rows(sp, f_rf_v_p) %>%\n  mutate(branches = factor(branches))\nlabels <- c(\"0\" , \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\",\n                rep(\"\", 3000))\nanimate_xy(f_rf_v_p_s[,1:9], col = f_rf_v_p_s$branches, \n           axes = \"off\", half_range = 0.8,\n           edges = as.matrix(simp$edges),\n           obs_labels = labels, palette = \"Viridis\")\n\nrender_gif(f_rf_v_p_s[,1:9],\n           grand_tour(),\n           display_xy(col = f_rf_v_p_s$branches, \n           axes = \"off\", half_range = 0.8,\n           edges = as.matrix(simp$edges),\n           obs_labels = labels, palette=\"Viridis\"),\n           gif_file=\"gifs/ft_votes.gif\",\n           frames=500) \n\n\n\n\n\n\n\n\n(a) The 9D votes matrix for the 10 class fake_trees data in a tour.\n\n\n\n\n\n\n\n(b) Several static views from the tour revealing how clusters connect.\n\n\n\n\nFigure 12.4: The votes matrix for the fake_trees data has a very striking geometric shape. The branching nature of the clusters is very clear. Most classes are distinct except for a connection with class 0.\n\n\nThe votes matrix is 9D, but the structure of it is easy to read, and very interesting. The observations are coloured by class. There is one vertex (0) which has connections to all other vertexes. That is, there are points stretching without big breaks from this vertex to every other. It means that some observations in every other class can be confused with class 0, and class 0 observations can be confused with every other class. All of the other vertexes have a string of points almost entirely along one edge, the edge leading to vertex 0. This shows the lack of confusion with any other class, except 0. Cluster 0 could be considered the trunk of the tree, from which the other clusters grow.\nThis pattern is what can be inferred from the confusion matrix, but we can’t determine whether the clusters are mostly separated except for a few observations, or some other clustering shape. The visual pattern in the votes matrix is so striking, and gives additional information about the clustering distribution, and shapes of clusters. It reinforces the clusters are linear extending into different dimensions in the 100D space, but really only into about 8D (as we’ll see from the variable importance explanation below). We also see that 9 of the clusters are all connected to one cluster.\n\n\n\n12.2.2 Using variable importance\nThe variable importance score across all classes, and for each class is useful for choosing variables to enter into a tour, to explore class differences. This is particularly so when there are many variables, as in the fake_trees data. We would also expect that this data will have a difference between importance for some classes.\n\nlibrary(gt)\nft_rf$importance %>% \n  as_tibble(rownames=\"Variable\") %>% \n  rename(Accuracy=MeanDecreaseAccuracy,\n         Gini=MeanDecreaseGini) %>%\n  #arrange(desc(Gini)) %>%\n  gt() %>%\n  fmt_number(columns = c(`0`,`1`,`2`,`3`,`4`,`5`,`6`,`7`,`8`,`9`, Accuracy),\n             decimals = 2) %>%\n  fmt_number(columns = Gini,\n             decimals = 0)\n\n\n\n\n\nTable 12.1:  Variable importance from the random forest fit to the fake_trees data. \n  \n    \n    \n      Variable\n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      Accuracy\n      Gini\n    \n  \n  \n    PC1\n0.10\n0.34\n0.44\n0.28\n0.20\n0.49\n0.39\n0.19\n0.32\n0.30\n0.31\n470\n    PC2\n0.13\n0.24\n0.22\n0.52\n0.28\n0.30\n0.16\n0.41\n0.23\n0.29\n0.28\n378\n    PC3\n0.09\n0.06\n0.11\n0.13\n0.52\n0.15\n0.09\n0.14\n0.18\n0.16\n0.16\n315\n    PC4\n0.09\n0.48\n0.07\n0.04\n0.10\n0.04\n0.36\n0.14\n0.09\n0.10\n0.15\n358\n    PC5\n0.12\n0.10\n0.34\n0.07\n0.17\n0.25\n0.09\n0.10\n0.28\n0.20\n0.17\n325\n    PC6\n0.10\n0.24\n0.26\n0.17\n0.05\n0.12\n0.04\n0.28\n0.15\n0.18\n0.16\n293\n    PC7\n0.07\n0.03\n0.14\n0.04\n0.05\n0.06\n0.12\n0.32\n0.11\n0.15\n0.11\n243\n    PC8\n0.05\n0.06\n0.01\n0.23\n0.06\n0.09\n0.02\n0.04\n0.08\n0.26\n0.09\n214\n    PC9\n0.08\n0.01\n0.01\n0.01\n0.01\n0.01\n0.01\n0.03\n0.06\n0.02\n0.02\n60\n    PC10\n0.04\n0.01\n0.01\n0.01\n0.01\n0.02\n0.01\n0.00\n0.01\n0.01\n0.01\n44\n  \n  \n  \n\n\n\n\n\nFrom the variable importance, we can see that PC9 and PC10 do not substantially contribute. That means the 100D data can be reduced to 8 PCs while maintaining the information about the clustering. PC1 is most important overall, but each cluster has a different set of variables that are important. For example, the variables important for distinguishing cluster 1 are PC1, PC2, PC4 and PC6, and for cluster 7 they are PC2, PC6, PC7. We can use this information to choose variables to provide to the tour. It can be helpful to reduce the class variable to focus on a particular class, by creating a new class variable, as follows.\n\nft_pc <- ft_pc %>%\n  mutate(cl1 = factor(case_when(\n                 branches == \"0\" ~ \"0\",\n                 branches == \"1\" ~ \"1\",\n                 .default = \"other\"\n  )))\n\n\n\nCode\nanimate_xy(ft_pc[,c(\"PC1\", \"PC2\", \"PC4\", \"PC6\")], col=ft_pc$cl1, palette=\"Viridis\")\nrender_gif(ft_pc[,c(\"PC1\", \"PC2\", \"PC4\", \"PC6\")],\n           grand_tour(),\n           display_xy(col=ft_pc$cl1, palette=\"Viridis\"),\n           gif_file=\"gifs/ft_cl1.gif\",\n           frames=500)\n\n\n\n\nCode\nft_pc_cl1 <- ggplot(ft_pc, aes(x=PC4, y=PC2, col=cl1)) +\n  geom_point(alpha=0.7, size=1) +\n  scale_color_discrete_sequential(palette=\"Viridis\", rev=FALSE) +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\n\n\nFrom Figure 12.5 we can see how cluster 1 is distinct from all of the other observations, albeit with a close connection to the trunk of the tree (cluster 0). The distinction is visible in PC1, PC2, PC4, PC6, but can be seen clearly with just two of these.\n\n\n\n\n\n\n\n(a) Tour of most important variables for class 1.\n\n\n\n\n\n\n\n\n(b) PC2 and PC4 together reveal cluster 1.\n\n\n\n\n\nFigure 12.5: Focusing on class 1 in the fake_trees data. The most important variables were PC1, PC2, PC4, PC6. A combination of PC2 and PC4 reveals the difference between cluster 1 and all the other clusters.\n\n\nFor a problem with this many classes it can be useful to focus on several groups together. We’ve chosen cluster 8, because it appears to have less of a connection with cluster 0. See the light green cluster in bottom right static plot of Figure 12.4 (b) is connected more to a different vertex, which is cluster 6 when carefully viewed. This is also suggested by the confusion matrix, where there is one observation from cluster 8 confused with cluster 6, although somewhat contradictory information, most are confused with cluster 0. We have also added cluster 1 to the investigation because it is closely connected to 6 and 8.\n\nft_pc <- ft_pc %>%\n  mutate(cl8 = factor(case_when(\n                 branches == \"0\" ~ \"0\",\n                 branches == \"6\" ~ \"6\",\n                 branches == \"1\" ~ \"1\",\n                 branches == \"8\" ~ \"8\",\n                 .default = \"other\"\n  )))\n\n\n\nCode\nanimate_xy(ft_pc[,c(\"PC1\", \"PC2\", \"PC4\", \"PC5\", \"PC6\")], col=ft_pc$cl8, palette=\"Viridis\")\nrender_gif(ft_pc[,c(\"PC1\", \"PC2\", \"PC4\", \"PC5\", \"PC6\")],\n           grand_tour(),\n           display_xy(col=ft_pc$cl8, palette=\"Viridis\"),\n           gif_file=\"gifs/ft_cl8.gif\",\n           frames=500)\n\n\n\n\nCode\nft_pc_cl8 <- ggplot(ft_pc, aes(x=PC1, y=PC5, col=cl8)) +\n  geom_point(alpha=0.7, size=1) +\n  scale_color_discrete_sequential(palette=\"Viridis\", rev=FALSE) +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\n\n\nFrom Figure 12.6 we can see that clusters 1, 6, and 8 share one end of the trunk (cluster 0). Cluster 8 is almost more closely connected with cluster 6, though, than cluster 0. PC1 and PC5 mostly show the distinction between cluster 8 and the rest of the points, but it is clearer if more variables are used.\n\n\n\n\n\n\n\n(a) Tour of most important variables for class 1.\n\n\n\n\n\n\n\n\n(b) PC1 and PC5 together mostly reveal cluster 8.\n\n\n\n\n\nFigure 12.6: Focusing on class 8 in the fake_trees data, relative to nearby clusters 1 and 6. The most important variables for cluster 8 are PC1, PC2, PC5, but to explore in association with clusters 1 and 6, we include PC4 and PC6. A combination of PC1 and PC5 reveals the difference between cluster 8, 6, 1 and 0."
  },
  {
    "objectID": "forests.html#exercises",
    "href": "forests.html#exercises",
    "title": "12  Trees and forests",
    "section": "Exercises",
    "text": "Exercises\n\nUsing a grand tour compare the boundaries from the random forest model on the penguins data to that of (a) a default tree model, (b) an LDA model. Is it less boxy than the tree model, but still more boxy than that of the LDA model?\nTinker with the parameters of the tree model to force it to fit a tree more closely to the data. Compare the boundaries from this with the default tree, and with the forest model. Is it less boxy than the default tree, but more boxy than the forest model?\nFit a random forest model to the bushfires data using the cause variable as the class. It is a highly imbalanced classification problem. What is the out-of-bag error rate for the forest? Are there some classes that have lower error rate than others? Examine the 4D votes matrix with a tour, and describe the confusion between classes. This is interesting because it is difficult to accurately classify the fire ignition cause, and only some groups are often confused with each other. You should be able to see this from the 3D votes matrix.\nExplore the 5D votes matrix for a random forest on the sketches data. Why does it look star-shaped?\nChoose a cluster (or group of clusters) from the fake_trees data (2, 3, 4, 5, 7, 9) to explore in detail like done in Section 12.2.2. Be sure to choose which PCs are the most useful using a tour, and follow-up by making a scatterplot showing the best distinction between your chosen cluster and the other observations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create Interactive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "nn.html",
    "href": "nn.html",
    "title": "14  Neural networks and deep learning",
    "section": "",
    "text": "Abbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create Interactive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "unsupervised.html#sec-clust-bg",
    "href": "unsupervised.html#sec-clust-bg",
    "title": "Unsupervised learning",
    "section": "Background",
    "text": "Background\nBefore we can begin finding groups of cases that are similar, we need to decide on a definition of similarity. How is similarity defined? Consider a dataset with three cases \\((a_1, a_2, a_3)\\) and four variables \\((V_1, V_2, V_3, V_4)\\), described in matrix format as\n\n\\[\n\\require{mathtools}\n\\definecolor{grey}{RGB}{192, 192, 192}\n\\]\n\n\\[\\begin{align*}\nX = \\begin{bmatrix}\n& {\\color{grey} V_1} & {\\color{grey} V_2} & {\\color{grey} V_3} & {\\color{grey} V_4} \\\\\\hline\n{\\color{grey} a_1} | & x_{11} & x_{12} & x_{13} & x_{14} \\\\\n{\\color{grey} a_2} | & x_{21} & x_{22} & x_{23} & x_{24} \\\\\n{\\color{grey} a_3} | & x_{31} & x_{32} & x_{33} & x_{34}    \n\\end{bmatrix}\n=  \\begin{bmatrix}\n& {\\color{grey} V_1} & {\\color{grey} V_2} & {\\color{grey} V_3} & {\\color{grey} V_4} \\\\\\hline\n{\\color{grey} a_1} | & 7.3 & 7.6 & 7.7 & 8.0 \\\\\n{\\color{grey} a_2} | & 7.4 & 7.2 & 7.3 & 7.2 \\\\\n{\\color{grey} a_3} | & 4.1 & 4.6 & 4.6 & 4.8\n\\end{bmatrix}\n\n\\end{align*}\\]\nwhich is plotted in Figure 2. The Euclidean distance between two cases (rows of the matrix) with \\(p\\) elements is defined as\n\\[\\begin{align*}\nd_{\\rm Euc}(a_i,a_j) &=& ||a_i-a_j|| %\\\\\n% &=& \\sqrt{(x_{i1}-x_{j1})^2+\\dots + (x_{ip}-x_{jp})^2},\n~~~~~~i,j=1,\\dots, n,\n\\end{align*}\\]\nwhere \\(||x_i||=\\sqrt{x_{i1}^2+x_{i2}^2+\\dots +x_{ip}^2}\\). For example, the Euclidean distance between cases 1 and 2 in the above data, is\n\\[\\begin{align*}\nd_{\\rm Euc}(a_1,a_2) &= \\sqrt{(7.3-7.4)^2+(7.6-7.2)^2+ (7.7-7.3)^2+(8.0-7.2)^2} \\\\\n&= 1.0\n\\end{align*}\\]\n\nFor the three cases, the interpoint Euclidean distance matrix is\n\\[\\begin{align*}\nd_{\\rm Euc} =\n\\left[ \\begin{array}{ccc}\n0.0  ~&     &   \\\\\n1.0 ~&  0.0 ~  &  \\\\\n6.3 ~& 5.5 ~&  0.0 ~ \\\\\n\\end{array} \\right]\n\\begin{array}{r}\na_1 \\\\ a_2 \\\\ a_3 \\\\\n\\end{array}\n\\end{align*}\\]\n\n\n\n\n\nCode\nx <- tibble::tibble(V1 = c(7.3, 7.4, 4.1),\n                    V2 = c(7.6, 7.2, 4.6),\n                    V3 = c(7.7, 7.3, 4.6),\n                    V4 = c(8.0, 7.2, 4.8),\n                    point = factor(c(\"a1\", \"a2\", \"a3\")))\nlibrary(GGally)\nlibrary(colorspace)\nlibrary(gridExtra)\npscat <- ggpairs(x, columns=1:4,\n                 upper=list(continuous=\"points\"),\n                 diag=list(continuous=\"blankDiag\"),\n                 axisLabels=\"internal\",\n                 ggplot2::aes(colour=point)) +\n    scale_colour_discrete_qualitative(\n      palette = \"Dark 3\") +\n    theme(aspect.ratio=1)\npscat\n\n\n\n\n\n\n\nCode\nppar <- ggparcoord(x, columns=1:4, \n                   groupColumn = 5, \n                   scale = \"globalminmax\") +\n          scale_colour_discrete_qualitative(\n            palette = \"Dark 3\") +\n  xlab(\"\") + ylab(\"\") + \n  theme(axis.ticks.y = element_blank(),\n        axis.text.y = element_blank(),\n        legend.title = element_blank())\nppar\n\n\n\n\n\n\nFigure 2: The scatterplot matrix (left) shows that cases \\(a_1\\) and \\(a_2\\) have similar values. The parallel coordinate plot (right) allows a comparison of other structure, which shows the similarity in the trend of the profiles on cases \\(a_1\\) and \\(a_3\\).\n\n\nCases \\(a_1\\) and \\(a_2\\) are more similar to each other than they are to case \\(a_3\\), because the Euclidean distance between cases \\(a_1\\) and \\(a_2\\) is much smaller than the distance between cases \\(a_1\\) and \\(a_3\\) and between cases \\(a_2\\) and \\(a_3\\).\nThere are many different ways to calculate similarity. Similarity measures based on correlation distance have become common. Correlation distance is typically used where similarity of structure is more important than similarity in magnitude.\n\nAs an example, see the parallel coordinate plot of the sample data at the right of Figure 2. Cases \\(a_1\\) and \\(a_3\\) are widely separated, but their shapes are similar (low, medium, medium, high). Case \\(a_2\\), although overlapping with Case \\(a_1\\), has a very different shape (high, medium, medium, low). The correlation between two cases is defined as\n\\[\\begin{align*}\n\\rho(a_i,a_j) = \\frac{(a_i-c_i)'(a_j-c_j)}\n{\\sqrt{(a_i-c_i)'(a_i-c_i)} \\sqrt{(a_j-c_j)'(a_j-c_j)}}\n\\label{corc}\n\\end{align*}\\]\nWhen \\(c_i, c_j\\) are the sample means \\(\\bar{a}_i,\\bar{a}_j\\), then \\(\\rho\\) is the Pearson correlation coefficient. If, indeed, they are set at 0, as is commonly done, \\(\\rho\\) is a generalized correlation that describes the angle between the two data vectors. The correlation is then converted to a distance metric; one equation for doing so is as follows:\n\\[\\begin{align*}\nd_{\\rm Cor}(a_i,a_j) = \\sqrt{2(1-\\rho(a_i,a_j))}\n\\end{align*}\\]\nThe above distance metric will treat cases that are strongly negatively correlated as the most distant.\nThe interpoint distance matrix for the sample data using \\(d_{\\rm Cor}\\) and the Pearson correlation coefficient is\n\\[\\begin{align*}\nd_{\\rm Cor} =\n\\left[ \\begin{array}{rrrrrrrrr}\n0.0  ~&     &  \\\\\n3.6 ~ & 0.0 ~ &  \\\\\n0.1 ~ & 3.8 ~ &  0.0 ~\\\\\n\\end{array} \\right]\n\\begin{array}{r}\na_1 \\\\ a_2 \\\\ a_3 \\\\\n\\end{array}\n\\end{align*}\\]\nBy this metric, cases \\(a_1\\) and \\(a_3\\) are the most similar, because the correlation distance is smaller between these two cases than the other pairs of cases. \nNote that these interpoint distances differ dramatically from those for Euclidean distance. As a consequence, the way the cases would be clustered is also be very different. Choosing the appropriate distance measure is an important part of a cluster analysis.\nAfter a distance metric has been chosen and a cluster analysis has been performed, the analyst must evaluate the results, and this is actually a difficult task. A cluster analysis does not generate \\(p\\)-values or other numerical criteria, and the process tends to produce hypotheses rather than testing them. Even the most determined attempts to produce the “best” results using modeling and validation techniques may result in clusters that, although seemingly significant, are useless for practical purposes. As a result, cluster analysis is best thought of as an exploratory technique, and it can be quite useful despite the lack of formal validation because of its power in data simplification.\nThe context in which the data arises is the key to assessing the results. If the clusters can be characterized in a sensible manner, and they increase our knowledge of the data, then we are on the right track. To use an even more pragmatic criterion, if a company can gain an economic advantage by using a particular clustering method to carve up their customer database, then that is the method they should use.\n\n\n\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nVenables, W. N., and B. Ripley. 2002. Modern Applied Statistics with S. New York: Springer-Verlag."
  },
  {
    "objectID": "brush-and-spin.html#exercises",
    "href": "brush-and-spin.html#exercises",
    "title": "5  Spin and brush approach",
    "section": "Exercises",
    "text": "Exercises\n\nUse the spin and brush approach to identify the three clusters in the mulgar::clusters data set.\nUse the spin and brush approach to identify the six clusters in the mulgar::multicluster data set. (The code below using detourr could be useful.)\n\n\nlibrary(detourr)\n\n# Use a random starting basis because the first two variables make it too easy\nstrt <- tourr::basis_random(10, 2)\ndetour(multicluster, \n       tour_aes(projection = -group)) |>\n       tour_path(grand_tour(2), start=strt, fps = 60) |>\n       show_scatter(alpha = 0.7, axes = FALSE)\n\n\nUse the spin and brush technique to identify the branches of the fake_trees data available in the liminal package (originally from PHATE). The result should look something like this:\n\n\n\n\nFigure 5.3: Example solution after spin and brush on fake_trees data.\n\n\nYou can use the download button to save the data with the colours. Tabulate the branches id variable in the original data with the colour groups created from brushing, to see how closely you have recovered the original classes.\n\n\nCode\nlibrary(detourr)\nlibrary(liminal)\nlibrary(mulgar)\ndata(\"fake_trees\")\n\n# Original data is 100D, so need to reduce dimension using PCA first\nft_pca <- prcomp(fake_trees[,1:100], \n                 scale=TRUE, retx=TRUE)\nggscree(ft_pca)\ndetour(as.data.frame(ft_pca$x[,1:10]), \n       tour_aes(projection = PC1:PC10)) |>\n       tour_path(grand_tour(2), fps = 60, max_bases=50) |>\n       show_scatter(alpha = 0.7, axes = FALSE)\n\nft_sb <- read_csv(\"data/fake_trees_sb.csv\")\ntable(fake_trees$branches, ft_sb$colour)\n\n\n\n\n\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46."
  },
  {
    "objectID": "hierarchical-clustering.html#explanation-of-the-algorithm",
    "href": "hierarchical-clustering.html#explanation-of-the-algorithm",
    "title": "6  Hierarchical clustering",
    "section": "6.1 Explanation of the algorithm",
    "text": "6.1 Explanation of the algorithm\nHierarchical cluster algorithms sequentially fuse neighboring points to form ever-larger clusters, starting from a full interpoint distance matrix. Figure 6.1 illustrates the hierarchical clustering approach for a simple simulated data set (a) with two well-separated clusters in 2D. The dendrogram (b) is a representation of the order that points are joined into clusters. The dendrogram strongly indicates two clusters because there are two branches branches representing the last join are much longer than all of the other branches. Although, the dendrogram is usually a good summary of the steps taken by the algorithm, it can be misleading. The dendrogram might strongly suggest a clustering but it might be a terrible solution. To check this we need to show the model with the data, as shown in plot (c). The segments show how the points and clusters are joined. Note that once points are joined into a cluster, the centroid of that cluster is used as the join location with other points or other clusters, and this is represented by a “+”. We can see that the longest edge is the one stretching across the gap between the two clusters, which is the location where the dendrogram would be cut to produce the two-cluster solution. This two-cluster solution is shown in plot (d).\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(mulgar)\nlibrary(ggdendro)\nlibrary(dplyr)\nlibrary(patchwork)\nlibrary(tourr)\nlibrary(plotly)\nlibrary(htmlwidgets)\nlibrary(colorspace)\nlibrary(GGally)\n\n\n\ndata(simple_clusters)\n# Data has two well-separated clusters\npd <- ggplot(simple_clusters, aes(x=x1, y=x2)) +\n  geom_point(colour=\"#3B99B1\", size=2, alpha=0.8) +\n  ggtitle(\"(a)\") +\n  theme(aspect.ratio=1) \n\n# Compute hierarchical clustering with Ward's linkage\ncl_hw <- hclust(dist(simple_clusters[,1:2]),\n                method=\"ward.D2\")\ncl_ggd <- dendro_data(cl_hw, type = \"triangle\")\nph <- ggplot() +\n  geom_segment(data=cl_ggd$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=cl_ggd$labels, aes(x=x, y=y),\n             colour=\"#3B99B1\", alpha=0.8) +\n  ggtitle(\"(b)\") +\n  theme_dendro()\n\n# Compute dendrogram in data\ncl_hfly <- hierfly(simple_clusters, cl_hw, scale=FALSE)\n\npdh <- ggplot() +\n  geom_segment(data=cl_hfly$segments, \n                aes(x=x, xend=xend,\n                    y=y, yend=yend)) +\n  geom_point(data=cl_hfly$data, \n             aes(x=x1, y=x2,\n                 shape=factor(node),\n                 colour=factor(node),\n                 size=1-node), alpha=0.8) +\n  scale_shape_manual(values = c(16, 3)) +\n  scale_colour_manual(values = c(\"#3B99B1\", \"black\")) +\n  scale_size(limits=c(0,17)) +\n  ggtitle(\"(c)\") +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Show result\nsimple_clusters <- simple_clusters %>%\n  mutate(clw = factor(cutree(cl_hw, 2)))\npc <- ggplot(simple_clusters) +\n  geom_point(aes(x=x1, y=x2, colour=clw), \n             size=2, alpha=0.8) +\n  scale_colour_discrete_divergingx(palette = \"Zissou 1\",\n                                   nmax=5, rev=TRUE) +\n  ggtitle(\"(d)\") +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\npd + ph + pdh + pc + plot_layout(ncol=2)\n\n\n\n\nFigure 6.1: Hierarchical clustering on simulated data: (a) data, (b) dendrogram, (c) dendrogram on the data, and (d) two cluster solution. Nodes of the dendrogram indicated by + when it is drawn on the data.\n\n\n\n\nClustering algorithms are all prone to being confused by different problems occurring in data. For hierarchical clustering, plotting the dendrogram on the data provides another way to assess the solution. For hierarchical clustering additional the complications arise from a range of choices for defining distance once points have been joined into clusters.\nDistance between clusters is described by a “linkage method”, of which there are many. For example, single linkage measures the distance between clusters by the smallest interpoint distance between the members of the two clusters clusters, complete linkage uses the maximum interpoint distance, and average linkage uses the average of the interpoint distances. Wards linkage, which usually produces the best clustering solutions, defines the distance as the reduction in the within-group variance. A good discussion on cluster analysis and linkage can be found in Boehmke and Greenwell (2019), on Wikipedia or any multivariate textbook."
  },
  {
    "objectID": "hierarchical-clustering.html#why-you-should-look-at-the-dendrogram-on-the-data",
    "href": "hierarchical-clustering.html#why-you-should-look-at-the-dendrogram-on-the-data",
    "title": "6  Hierarchical clustering",
    "section": "6.2 Why you should look at the dendrogram on the data",
    "text": "6.2 Why you should look at the dendrogram on the data\n\n\nCode\n# Nuisance observations\nset.seed(20190514)\nx <- (runif(20)-0.5)*4\ny <- x\nd1 <- data.frame(x1 = c(rnorm(50, -3), \n                            rnorm(50, 3), x),\n                 x2 = c(rnorm(50, -3), \n                            rnorm(50, 3), y),\n                 cl = factor(c(rep(\"A\", 50), \n                             rep(\"B\", 70))))\nd1 <- d1 %>% \n  mutate_if(is.numeric, function(x) (x-mean(x))/sd(x))\npd1 <- ggplot(data=d1, aes(x=x1, y=x2)) + \n  geom_point() +\n    ggtitle(\"Nuisance observations\") +\n    theme(aspect.ratio=1) \n\n# Nuisance variables\nset.seed(20190512)\nd2 <- data.frame(x1=c(rnorm(50, -4), \n                            rnorm(50, 4)),\n                 x2=c(rnorm(100)),\n                 cl = factor(c(rep(\"A\", 50), \n                             rep(\"B\", 50))))\nd2 <- d2 %>% \n  mutate_if(is.numeric, function(x) (x-mean(x))/sd(x))\npd2 <- ggplot(data=d2, aes(x=x1, y=x2)) + \n  geom_point() +\n    ggtitle(\"Nuisance variables\") +\n    theme(aspect.ratio=1)\n\npd1 + pd2 + plot_layout(ncol=2)\n\n\n\n\n\nFigure 6.2: Two examples of data structure that causes problems for hierarchical clustering. Nuisance observations can cause problems because the close observations between the two clusters can cause some chaining in the hierarchical joining of observations. Nuisance variables can cause problems because observations across the gap can seem closer than observations at the end of each cluster.\n\n\n\n\n\n\nCode\n# Compute single linkage\nd1_hs <- hclust(dist(d1[,1:2]),\n                method=\"single\")\nd1_ggds <- dendro_data(d1_hs, type = \"triangle\")\npd1s <- ggplot() +\n  geom_segment(data=d1_ggds$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=d1_ggds$labels, aes(x=x, y=y),\n             colour=\"#3B99B1\", alpha=0.8) +\n  ggtitle(\"(a) Single linkage dendrogram\") +\n  theme_dendro()\n\n# Compute dendrogram in data\nd1_hflys <- hierfly(d1, d1_hs, scale=FALSE)\n\npd1hs <- ggplot() +\n  geom_segment(data=d1_hflys$segments, \n                aes(x=x, xend=xend,\n                    y=y, yend=yend)) +\n  geom_point(data=d1_hflys$data, \n             aes(x=x1, y=x2,\n                 shape=factor(node),\n                 colour=factor(node),\n                 size=1-node), alpha=0.8) +\n  scale_shape_manual(values = c(16, 3)) +\n  scale_colour_manual(values = c(\"#3B99B1\", \"black\")) +\n  scale_size(limits=c(0,17)) +\n  ggtitle(\"(b) Dendrogram in data\") +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Show result\nd1 <- d1 %>%\n  mutate(cls = factor(cutree(d1_hs, 2)))\npc_d1s <- ggplot(d1) +\n  geom_point(aes(x=x1, y=x2, colour=cls), \n             size=2, alpha=0.8) +\n  scale_colour_discrete_divergingx(palette = \"Zissou 1\",\n                                   nmax=4, rev=TRUE) +\n  ggtitle(\"(c) Two-cluster solution\") +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Compute Wards linkage\nd1_hw <- hclust(dist(d1[,1:2]),\n                method=\"ward.D2\")\nd1_ggdw <- dendro_data(d1_hw, type = \"triangle\")\npd1w <- ggplot() +\n  geom_segment(data=d1_ggdw$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=d1_ggdw$labels, aes(x=x, y=y),\n             colour=\"#3B99B1\", alpha=0.8) +\n  ggtitle(\"(d) Ward's linkage dendrogram\") +\n  theme_dendro()\n\n# Compute dendrogram in data\nd1_hflyw <- hierfly(d1, d1_hw, scale=FALSE)\n\npd1hw <- ggplot() +\n  geom_segment(data=d1_hflyw$segments, \n                aes(x=x, xend=xend,\n                    y=y, yend=yend)) +\n  geom_point(data=d1_hflyw$data, \n             aes(x=x1, y=x2,\n                 shape=factor(node),\n                 colour=factor(node),\n                 size=1-node), alpha=0.8) +\n  scale_shape_manual(values = c(16, 3)) +\n  scale_colour_manual(values = c(\"#3B99B1\", \"black\")) +\n  scale_size(limits=c(0,17)) +\n  ggtitle(\"(e) Dendrogram in data\") +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Show result\nd1 <- d1 %>%\n  mutate(clw = factor(cutree(d1_hw, 2)))\npc_d1w <- ggplot(d1) +\n  geom_point(aes(x=x1, y=x2, colour=clw), \n             size=2, alpha=0.8) +\n  scale_colour_discrete_divergingx(palette = \"Zissou 1\",\n                                   nmax=4, rev=TRUE) +\n  ggtitle(\"(f) Two-cluster solution\") +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\npd1s + pd1hs + pc_d1s + \n  pd1w + pd1hw + pc_d1w +\n  plot_layout(ncol=3)\n\n\n\n\n\nFigure 6.3: Single linkage clustering on nuisance cases in comparison to Ward’s linkage.\n\n\n\n\n\n\nCode\n# Compute complete linkage\nd2_hc <- hclust(dist(d2[,1:2]),\n                method=\"complete\")\nd2_ggdc <- dendro_data(d2_hc, type = \"triangle\")\npd2c <- ggplot() +\n  geom_segment(data=d2_ggdc$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=d2_ggdc$labels, aes(x=x, y=y),\n             colour=\"#3B99B1\", alpha=0.8) +\n  ggtitle(\"(a) Complete linkage dendrogram\") +\n  theme_dendro()\n\n# Compute dendrogram in data\nd2_hflyc <- hierfly(d2, d2_hc, scale=FALSE)\n\npd2hc <- ggplot() +\n  geom_segment(data=d2_hflyc$segments, \n                aes(x=x, xend=xend,\n                    y=y, yend=yend)) +\n  geom_point(data=d2_hflyc$data, \n             aes(x=x1, y=x2,\n                 shape=factor(node),\n                 colour=factor(node),\n                 size=1-node), alpha=0.8) +\n  scale_shape_manual(values = c(16, 3)) +\n  scale_colour_manual(values = c(\"#3B99B1\", \"black\")) +\n  scale_size(limits=c(0,17)) +\n  ggtitle(\"(b) Dendrogram in data\") +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Show result\nd2 <- d2 %>%\n  mutate(clc = factor(cutree(d2_hc, 2)))\npc_d2c <- ggplot(d2) +\n  geom_point(aes(x=x1, y=x2, colour=clc), \n             size=2, alpha=0.8) +\n  scale_colour_discrete_divergingx(palette = \"Zissou 1\",\n                                   nmax=4, rev=TRUE) +\n  ggtitle(\"(c) Two-cluster solution\") +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Compute Wards linkage\nd2_hw <- hclust(dist(d2[,1:2]),\n                method=\"ward.D2\")\nd2_ggdw <- dendro_data(d2_hw, type = \"triangle\")\npd2w <- ggplot() +\n  geom_segment(data=d2_ggdw$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=d2_ggdw$labels, aes(x=x, y=y),\n             colour=\"#3B99B1\", alpha=0.8) +\n  ggtitle(\"(d) Ward's linkage dendrogram\") +\n  theme_dendro()\n\n# Compute dendrogram in data\nd2_hflyw <- hierfly(d2, d2_hw, scale=FALSE)\n\npd2hw <- ggplot() +\n  geom_segment(data=d2_hflyw$segments, \n                aes(x=x, xend=xend,\n                    y=y, yend=yend)) +\n  geom_point(data=d2_hflyw$data, \n             aes(x=x1, y=x2,\n                 shape=factor(node),\n                 colour=factor(node),\n                 size=1-node), alpha=0.8) +\n  scale_shape_manual(values = c(16, 3)) +\n  scale_colour_manual(values = c(\"#3B99B1\", \"black\")) +\n  scale_size(limits=c(0,17)) +\n  ggtitle(\"(e) Dendrogram in data\") +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\n# Show result\nd2 <- d2 %>%\n  mutate(clw = factor(cutree(d2_hw, 2)))\npc_d2w <- ggplot(d2) +\n  geom_point(aes(x=x1, y=x2, colour=clw), \n             size=2, alpha=0.8) +\n  scale_colour_discrete_divergingx(palette = \"Zissou 1\",\n                                   nmax=4, rev=TRUE) +\n  ggtitle(\"(f) Two-cluster solution\") +\n  theme(aspect.ratio=1, legend.position=\"none\")\n\npd2c + pd2hc + pc_d2c + \n  pd2w + pd2hw + pc_d2w +\n  plot_layout(ncol=3)\n\n\n\n\n\nFigure 6.4: Complete linkage clustering on nuisance variables in comparison to Ward’s linkage. The complete linkage dendrogram looks quite reasonably suggesting a two-cluster solution, but when it is plotted amongst the data that it is clearly not a good two-cluster solution."
  },
  {
    "objectID": "hierarchical-clustering.html#dendrograms-in-high-dimensions",
    "href": "hierarchical-clustering.html#dendrograms-in-high-dimensions",
    "title": "6  Hierarchical clustering",
    "section": "6.3 Dendrograms in high-dimensions",
    "text": "6.3 Dendrograms in high-dimensions\nCheck the data: pretend we don’t know the clusters. Think you can see three elliptical clusters. One is further from the others.\n\n\nCode\nload(\"data/penguins_sub.rda\")\n\n\n\n\nCode\nggscatmat(penguins_sub[,1:4]) \n\n\n\n\n\nScatterplot matrix of the penguins data, assuming we don’t know the species\n\n\n\n\n\nset.seed(20230329)\nb <- basis_random(4,2)\npt1 <- save_history(penguins_sub[,1:4], \n                    max_bases = 500, \n                    start = b)\nsave(pt1, file=\"data/penguins_tour_path.rda\")\nanimate_xy(penguins_sub[,1:4], \n           tour_path = planned_tour(pt1), \n           axes=\"off\", rescale=FALSE, \n           half_range = 3.5)\n\n\n\nCode\nload(\"data/penguins_tour_path.rda\")\nrender_gif(penguins_sub[,1:4], \n           planned_tour(pt1), \n           display_xy(half_range=0.9, axes=\"off\"),\n           gif_file=\"gifs/penguins_gt.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\nFigure 6.5: Grand tour of the penguins data\n\n\n\np_dist <- dist(penguins_sub[,1:4])\np_hcw <- hclust(p_dist, method=\"ward.D2\")\np_hcs <- hclust(p_dist, method=\"single\")\n\np_clw <- penguins_sub %>% \n  mutate(cl = factor(cutree(p_hcw, 3)))\np_cls <- penguins_sub %>% \n  mutate(cl = factor(cutree(p_hcs, 3)))\n\np_w_hfly <- hierfly(p_clw, p_hcw, scale=FALSE)\np_s_hfly <- hierfly(p_cls, p_hcs, scale=FALSE)\n\n\n\nCode\n# Generate the dendrograms in 2D\np_hcw_dd <- dendro_data(p_hcw)\npw_dd <- ggplot() +\n  geom_segment(data=p_hcw_dd$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=p_hcw_dd$labels, aes(x=x, y=y),\n             alpha=0.8) +\n  theme_dendro()\n\np_hcs_dd <- dendro_data(p_hcs)\nps_dd <- ggplot() +\n  geom_segment(data=p_hcs_dd$segments, \n               aes(x = x, y = y, \n                   xend = xend, yend = yend)) + \n  geom_point(data=p_hcs_dd$labels, aes(x=x, y=y),\n             alpha=0.8) +\n  theme_dendro()\n\n\n\n\nCode\nload(\"data/penguins_tour_path.rda\")\nglyphs <- c(16, 46)\npchw <- glyphs[p_w_hfly$data$node+1]\npchs <- glyphs[p_s_hfly$data$node+1]\n\nanimate_xy(p_w_hfly$data[,1:4], \n           #col=colw, \n           tour_path = planned_tour(pt1),\n           pch = pchw,\n           edges=p_w_hfly$edges, \n           axes=\"bottomleft\")\n\nanimate_xy(p_s_hfly$data[,1:4], \n           #col=colw, \n           tour_path = planned_tour(pt1),\n           pch = pchs,\n           edges=p_s_hfly$edges, \n           axes=\"bottomleft\")\n\nrender_gif(p_w_hfly$data[,1:4], \n           planned_tour(pt1),\n           display_xy(half_range=0.9,            \n                      pch = pchw,\n                      edges = p_w_hfly$edges,\n                      axes = \"off\"),\n           gif_file=\"gifs/penguins_hflyw.gif\",\n           frames=500,\n           loop=FALSE)\n\nrender_gif(p_s_hfly$data[,1:4], \n           planned_tour(pt1), \n           display_xy(half_range=0.9,            \n                      pch = pchs,\n                      edges = p_s_hfly$edges,\n                      axes = \"off\"),\n           gif_file=\"gifs/penguins_hflys.gif\",\n           frames=500,\n           loop=FALSE)\n\n# Show three cluster solutions\nclrs <- hcl.colors(3, \"Zissou 1\")\nw3_col <- clrs[p_w_hfly$data$cl[p_w_hfly$data$node == 0]]\nrender_gif(p_w_hfly$data[p_w_hfly$data$node == 0, 1:4], \n           planned_tour(pt1), \n           display_xy(half_range=0.9,   \n                      col=w3_col,\n                      axes = \"off\"),\n           gif_file=\"gifs/penguins_w3.gif\",\n           frames=500,\n           loop=FALSE)\n\ns3_col <- clrs[p_s_hfly$data$cl[p_w_hfly$data$node == 0]]\nrender_gif(p_s_hfly$data[p_w_hfly$data$node == 0,1:4], \n           planned_tour(pt1), \n           display_xy(half_range=0.9,   \n                      col=s3_col,\n                      axes = \"off\"),\n           gif_file=\"gifs/penguins_s3.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n\n(a) Wards linkage\n\n\n\n\n\n\n\n\n\n(b) single linkage\n\n\n\n\n\n\n\n\n\n\n(c) Wards linkage\n\n\n\n\n\n\n\n(d) Single linkage\n\n\n\n\n\n\n\n\n\n(e) Wards linkage\n\n\n\n\n\n\n\n(f) Single linkage\n\n\n\n\nFigure 6.6: Dendrograms for Wards and single linkage of the penguins data, shown in 2D (top) and in 4D (middle), and the three-cluster solution of each.\n\n\n\n\nCode\nload(\"data/penguins_tour_path.rda\")\n# Create a smaller one, for space concerns\npt1i <- interpolate(pt1[,,1:5], 0.1)\npw_anim <- render_anim(p_w_hfly$data,\n                       vars=1:4,\n                       frames=pt1i, \n                       edges = p_w_hfly$edges,\n             obs_labels=paste0(1:nrow(p_w_hfly$data),\n                               p_w_hfly$data$cl))\n\npw_gp <- ggplot() +\n     geom_segment(data=pw_anim$edges, \n                    aes(x=x, xend=xend,\n                        y=y, yend=yend,\n                        frame=frame)) +\n     geom_point(data=pw_anim$frames, \n                aes(x=P1, y=P2, \n                    frame=frame, \n                    shape=factor(node),\n                    label=obs_labels), \n                alpha=0.8, size=1) +\n     xlim(-1,1) + ylim(-1,1) +\n     scale_shape_manual(values=c(16, 46)) +\n     coord_equal() +\n     theme_bw() +\n     theme(legend.position=\"none\", \n           axis.text=element_blank(),\n           axis.title=element_blank(),\n           axis.ticks=element_blank(),\n           panel.grid=element_blank())\n\npwg <- ggplotly(pw_gp, width=450, height=500,\n                tooltip=\"label\") %>%\n       animation_button(label=\"Go\") %>%\n       animation_slider(len=0.8, x=0.5,\n                        xanchor=\"center\") %>%\n       animation_opts(easing=\"linear\", transition = 0)\nhtmlwidgets::saveWidget(pwg,\n          file=\"html/penguins_cl_ward.html\",\n          selfcontained = TRUE)\n\n# Single\nps_anim <- render_anim(p_s_hfly$data, vars=1:4,\n                         frames=pt1i, \n                       edges = p_s_hfly$edges,\n             obs_labels=paste0(1:nrow(p_s_hfly$data),\n                               p_s_hfly$data$cl))\n\nps_gp <- ggplot() +\n     geom_segment(data=ps_anim$edges, \n                    aes(x=x, xend=xend,\n                        y=y, yend=yend,\n                        frame=frame)) +\n     geom_point(data=ps_anim$frames, \n                aes(x=P1, y=P2, \n                    frame=frame, \n                    shape=factor(node),\n                    label=obs_labels), \n                alpha=0.8, size=1) +\n     xlim(-1,1) + ylim(-1,1) +\n     scale_shape_manual(values=c(16, 46)) +\n     coord_equal() +\n     theme_bw() +\n     theme(legend.position=\"none\", \n           axis.text=element_blank(),\n           axis.title=element_blank(),\n           axis.ticks=element_blank(),\n           panel.grid=element_blank())\n\npsg <- ggplotly(ps_gp, width=450, height=500,\n                tooltip=\"label\") %>%\n       animation_button(label=\"Go\") %>%\n       animation_slider(len=0.8, x=0.5,\n                        xanchor=\"center\") %>%\n       animation_opts(easing=\"linear\", transition = 0)\nhtmlwidgets::saveWidget(psg,\n          file=\"html/penguins_cl_single.html\",\n          selfcontained = TRUE)\n\n\n\n\n\n\n\n\nFigure 6.7: Animation of dendrogram from Wards (top) and single (bottom) linkage clustering of the penguins data.\n\n\n\n\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377."
  },
  {
    "objectID": "model-based-clustering.html#overview",
    "href": "model-based-clustering.html#overview",
    "title": "8  Model-based clustering",
    "section": "8.1 Overview",
    "text": "8.1 Overview\nModel-based clustering Fraley and Raftery (2002) fits a multivariate normal mixture model to the data. It uses the EM algorithm to fit the parameters for the mean, variance–covariance of each population, and the mixing proportion. The variance-covariance matrix is re-parametrized using an eigen-decomposition\n\\[\n\\Sigma_k = \\lambda_kD_kA_kD_k', ~~~k=1, \\dots, g ~~\\mbox{(number of clusters)}\n\\]\nresulting in several model choices, ranging from simple to complex, as shown in Table 8.1.\n\n\nCode\nlibrary(dplyr)\nlibrary(kableExtra)\nlibrary(ggplot2)\nlibrary(mclust)\nlibrary(mulgar)\nlibrary(patchwork)\nlibrary(colorspace)\nlibrary(tourr)\n\n\n\n\n\n\nTable 8.1:  Parameterizations of the covariance matrix. \n \n  \n    Model \n    Sigma \n    Family \n    Volume \n    Shape \n    Orientation \n  \n \n\n  \n    EII \n    $$\\lambda I$$ \n    Spherical \n    Equal \n    Equal \n    NA \n  \n  \n    VII \n    $$\\lambda_k I$$ \n    Spherical \n    Variable \n    Equal \n    NA \n  \n  \n    EEI \n    $$\\lambda A$$ \n    Diagonal \n    Equal \n    Equal \n    Coordinate axes \n  \n  \n    VEI \n    $$\\lambda_kA$$ \n    Diagonal \n    Variable \n    Equal \n    Coordinate axes \n  \n  \n    EVI \n    $$\\lambda A_k$$ \n    Diagonal \n    Equal \n    Variable \n    Coordinate axes \n  \n  \n    VVI \n    $$\\lambda_k A_k$$ \n    Diagonal \n    Variable \n    Variable \n    Coordinate axes \n  \n  \n    EEE \n    $$\\lambda DAD^T$$ \n    Diagonal \n    Equal \n    Equal \n    Equal \n  \n  \n    EVE \n    $$\\lambda DA_kD^T$$ \n    Ellipsoidal \n    Equal \n    Variable \n    Equal \n  \n  \n    VEE \n    $$\\lambda_k DAD^T$$ \n    Ellipsoidal \n    Variable \n    Equal \n    Equal \n  \n  \n    VVE \n    $$\\lambda_k DA_kD^T$$ \n    Ellipsoidal \n    Variable \n    Equal \n    Equal \n  \n  \n    EEV \n    $$\\lambda D_kAD_k^T$$ \n    Ellipsoidal \n    Equal \n    Variable \n    Variable \n  \n  \n    VEV \n    $$\\lambda_k D_kAD_k^T$$ \n    Ellipsoidal \n    Variable \n    Variable \n    Variable \n  \n  \n    EVV \n    $$\\lambda D_kA_kD_k^T$$ \n    Ellipsoidal \n    Equal \n    Variable \n    Variable \n  \n  \n    VVV \n    $$\\lambda_k D_kA_kD_k^T$$ \n    Ellipsoidal \n    Variable \n    Variable \n    Variable \n  \n\n\n\n\n\n\nNote the distribution descriptions “spherical” and “ellipsoidal”. These are descriptions of the shape of the variance-covariance for a multivariate normal distribution. A standard multivariate normal distribution has a variance-covariance matrix with zeros in the off-diagonal elements, which corresponds to spherically shaped data. When the variances (diagonals) are different or the variables are correlated, then the shape of data from a multivariate normal is ellipsoidal.\n\nThe models are typically scored using the Bayes Information Criterion (BIC), which is based on the log likelihood, number of variables, and number of mixture components. They should also be assessed using graphical methods, as we demonstrate using the data."
  },
  {
    "objectID": "model-based-clustering.html#two-variables",
    "href": "model-based-clustering.html#two-variables",
    "title": "8  Model-based clustering",
    "section": "8.2 Two variables",
    "text": "8.2 Two variables\nWe start with two of the four real-valued variables (bl, fl) and the three species. The goal is to determine whether model-based methods can discover clusters that closely correspond to the three species. Based on the scatterplot in Figure 8.1 we would expect it to do well, and suggest an elliptical variance-covariance of roughly equal sizes as the model.\n\n\nCode\nload(\"data/penguins_sub.rda\")\nggplot(penguins_sub, aes(x=bl, \n                         y=fl)) + #, \n                         #colour=species)) +\n  geom_point() +\n  geom_density2d(colour=\"#3B99B1\") +\n  theme(aspect.ratio = 1)\n\n\n\n\n\nFigure 8.1: Scatterplot of flipper length by bill length of the penguins data.\n\n\n\n\n\npenguins_BIC <- mclustBIC(penguins_sub[,c(1,3)])\nggmc <- ggmcbic(penguins_BIC, cl=2:9, top=4) + \n  scale_color_discrete_divergingx(palette = \"Roma\") +\n  ggtitle(\"(a)\")\npenguins_mc <- Mclust(penguins_sub[,c(1,3)], \n                      G=3, \n                      modelNames = \"EVE\")\npenguins_mce <- mc_ellipse(penguins_mc)\npenguins_cl <- penguins_sub[,c(1,3)]\npenguins_cl$cl <- factor(penguins_mc$classification)\nggell <- ggplot() +\n   geom_point(data=penguins_cl, aes(x=bl, y=fl,\n                                    colour=cl),\n              alpha=0.3) +\n   geom_point(data=penguins_mce$ell, aes(x=bl, y=fl,\n                                         colour=cl),\n              shape=16) +\n   geom_point(data=penguins_mce$mn, aes(x=bl, y=fl,\n                                        colour=cl),\n              shape=3, size=2) +\n  scale_color_discrete_divergingx(palette = \"Zissou 1\") +\n   theme(aspect.ratio=1, legend.position=\"none\") +\n  ggtitle(\"(b)\")\nggmc + ggell + plot_layout(ncol=2)\n\n\n\n\nFigure 8.2: Summary plots from model-based clustering: (a) BIC values for clusters 2-9 of top four models, (b) variance-covariance ellipses and cluster means (+) corresponding to the best model. The best model is three-cluster EVE, which has differently shaped variance-covariances albeit the same volume and orientation.\n\n\n\n\nFigure 8.2 summarises the results. All models agree that three clusters is the best. The different variance-covariance models for three clusters have similar BIC values with EVE (different shape, same volume and orientation) being slightly higher. These plots are made from the mclust package output using the ggmcbic and mc_ellipse functions fro the mulgar package."
  },
  {
    "objectID": "model-based-clustering.html#high-dimensions",
    "href": "model-based-clustering.html#high-dimensions",
    "title": "8  Model-based clustering",
    "section": "8.3 High-dimensions",
    "text": "8.3 High-dimensions\nNow we will examine how model-based clustering will group the penguins data using all four variables.\n\npenguins_BIC <- mclustBIC(penguins_sub[,1:4])\nggmc <- ggmcbic(penguins_BIC, cl=2:9, top=7) +  scale_color_discrete_divergingx(palette = \"Roma\") \nggmc\n\n\n\n\nFigure 8.3: BIC values for the top models for 2-9 clusters on the penguins data. The interpretation is mixed: if one were to choose three clusters any of the variance-covariance models would be equally as good, but the very best model is the four-cluster VEE.\n\n\n\n\n\npenguins_mc <- Mclust(penguins_sub[,1:4], \n                      G=4, \n                      modelNames = \"VEE\")\npenguins_mce <- mc_ellipse(penguins_mc)\npenguins_cl <- penguins_sub\npenguins_cl$cl <- factor(penguins_mc$classification)\n\npenguins_mc_data <- penguins_cl %>%\n  select(bl:bm, cl) %>%\n  mutate(type = \"data\") %>%\n  bind_rows(bind_cols(penguins_mce$ell,\n                      type=rep(\"ellipse\",\n                               nrow(penguins_mce$ell)))) %>%\n  mutate(type = factor(type))\n\nanimate_xy(penguins_mc_data[,1:4],\n           col=penguins_mc_data$cl,\n           pch=c(4, 20 )[as.numeric(penguins_mc_data$type)], \n           axes=\"off\")\n\n# \nload(\"data/penguins_tour_path.rda\")\nrender_gif(penguins_mc_data[,1:4], \n           planned_tour(pt1), \n           display_xy(col=penguins_mc_data$cl,\n               pch=c(4, 20)[\n                 as.numeric(penguins_mc_data$type)], \n                      axes=\"off\",\n               half_range = 0.7),\n           gif_file=\"gifs/penguins_best_mc.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\nCode\npenguins_mc <- Mclust(penguins_sub[,1:4], \n                      G=3, \n                      modelNames = \"EEE\")\npenguins_mce <- mc_ellipse(penguins_mc)\npenguins_cl <- penguins_sub\npenguins_cl$cl <- factor(penguins_mc$classification)\n\npenguins_mc_data <- penguins_cl %>%\n  select(bl:bm, cl) %>%\n  mutate(type = \"data\") %>%\n  bind_rows(bind_cols(penguins_mce$ell,\n                      type=rep(\"ellipse\",\n                               nrow(penguins_mce$ell)))) %>%\n  mutate(type = factor(type))\n\nanimate_xy(penguins_mc_data[,1:4],\n           col=penguins_mc_data$cl,\n           pch=c(4, 20)[as.numeric(penguins_mc_data$type)], \n           axes=\"off\")\n\n# Save the animated gif\nload(\"data/penguins_tour_path.rda\")\nrender_gif(penguins_mc_data[,1:4], \n           planned_tour(pt1), \n           display_xy(col=penguins_mc_data$cl,\n               pch=c(4, 20)[\n                 as.numeric(penguins_mc_data$type)], \n                      axes=\"off\",\n               half_range = 0.7),\n           gif_file=\"gifs/penguins_simpler_mc.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n(a) Best model: four-cluster VEE\n\n\n\n\n\n\n\n(b) Three-cluster EEE\n\n\n\n\nFigure 8.4: Examining the model-based clustering results for the penguins data: (a) best model according to BIC value, (b) simpler three-cluster model. Dots are ellipse points, and “x” are data points. It is important to note that the three cluster solution fits the data better, even though it has a lower BIC.\n\n\n\n\n\n\n\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31."
  },
  {
    "objectID": "som.html",
    "href": "som.html",
    "title": "9  Self-organizing maps",
    "section": "",
    "text": "A self-organizing map (SOM) is constructed using a constrained \\(k\\)-means algorithm. A 1D or 2D net is stretched through the data. The knots, in the net, form the cluster means, and the points closest to the knot are considered to belong to that cluster. The similarity of nodes (and their corresponding clusters) is defined as proportional to their distance from one another on the net. Unlike \\(k\\)-means one would normally choose a largish net, with more nodes than expected clusters. A well-separated cluster in the data would likely be split across multiple nodes in the net. Examining the net where nodes are empty of points we would interpret this as a gap in the original data.\n\nA self-organising map is like a fisherwoman’s net, as the net is pulled in it catches the fish near knots in the net. We would examine the net in\n\n2D to extract the fish.\nhigh-dimensions to see how it was woven through the space to catch fish.\n\n\nFigure 9.1 illustrates how the SOM fits the penguins data. SOM is not ideal for clustered data where there are gaps. It is better suited for data that lies on a non-linear low-dimensional manifold. To model data like the penguins the first step is to set up a net that will cover more than the three clusters. Here we have chosen to use a \\(5\\times 5\\) rectangular grid. (The option allows for a hexagonal grid, which would make for a better tiled 2D map, but this is not useful for viewing the model in high dimensions.) Like \\(k\\)-means clustering the fitted model can change substantially depending on the initialisation, so setting a seed will ensure a consistent result. We have also initialised the positions of the knots using PCA, which stretches the net in the main two directions of variance of the data, generally giving better results.\n\nlibrary(kohonen)\nlibrary(aweSOM)\nlibrary(mulgar)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(colorspace)\nload(\"data/penguins_sub.rda\")\n\nset.seed(947)\np_grid <- kohonen::somgrid(xdim = 5, ydim = 5,\n                           topo = 'rectangular')\np_init <- somInit(as.matrix(penguins_sub[,1:4]), 5, 5)\np_som <- som(as.matrix(penguins_sub[,1:4]), \n             rlen=2000,\n             grid = p_grid,\n             init = p_init)\n\nThe resulting model object is used to construct an object containing the original data, the 2D map, the map in \\(p\\)-D, with edges, and segments to connect points to represent the next using the f_som() function from mulgar. The 2D map shows a configuration of the data in 2D which best displays the clusters, much like how a PCA or LDA plot would eb used.\n\np_som_df_net <- f_som(p_som)\np_som_data <- p_som_df_net$data %>% \n  mutate(species = penguins_sub$species)\np_som_map_p <- ggplot() +\n  geom_segment(data=p_som_df_net$edges_s, \n               aes(x=x, xend=xend, y=y, \n                   yend=yend)) +\n  geom_point(data=p_som_data, \n             aes(x=map1, y=map2, \n                 colour=species), \n             size=3, alpha=0.5) +\n  xlab(\"map 1\") + ylab(\"map 2\") +\n  scale_color_discrete_divergingx(\n    palette=\"Zissou 1\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, \n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        axis.text = element_blank())\n\nThe object can also be modified into the pieces needed to show the net in \\(p\\)-D. You need the data, points marking the net, and edges indicating which points to connect to draw the net.\n\nlibrary(tourr)\n\n# Set up data\np_som_map <- p_som_df_net$net %>%\n  mutate(species = \"0\", type=\"net\")\np_som_data <- p_som_data %>% \n  select(bl:bm, species) %>%\n  mutate(type=\"data\", \n         species = as.character(species)) \np_som_map_data <- bind_rows(p_som_map, p_som_data)\np_som_map_data$type <- factor(p_som_map_data$type,\n  levels=c(\"net\", \"data\"))\np_som_map_data$species <- factor(p_som_map_data$species,\n  levels=c(\"0\",\"Adelie\",\"Chinstrap\",\"Gentoo\"))\np_pch <- c(46, 16)[as.numeric(p_som_map_data$type)]\np_col <- c(\"black\", hcl.colors(3, \"Zissou 1\"))[as.numeric(p_som_map_data$species)]\nanimate_xy(p_som_map_data[,1:4],\n           col=p_col, \n           pch=p_pch,\n           edges=as.matrix(p_som_df_net$edges), \n           edges.col = \"black\",\n           axes=\"bottomleft\")\n\n\n\n\n\n\n\n\n\n\n\n\n(a) 2D map\n\n\n\n\n\n\n\n\n(b) Map in 4D\n\n\n\n\nFigure 9.1: Examining the SOM map views in 2D and with the data in 4D. Points are coloured by species, which was not used for the modeling. The 2D map shows that the map 2 direction is primarily distinguishing the Gentoo from the others, and map 1 is imperfectly distinguishing the Chinstrap from Adelie. The map in the data space shows how it is woven into the shape of the data.\n\n\nThe SOM fit, with a \\(5\\times 5\\) grid, for the penguins has the data clustered into 25 groups. This doesn’t work as a clustering technique on its own, if we remember that the data has three clusters corresponding to three species of penguins. Using species to colour the points helps to see what SOM has done. It has used about seven nodes to capture the separated Gentoo group. These are mostly in the map 2 direction, which means that this direction (like a direction in PCA) is useful for distinguishing the Gentoo penguins from the others. The other two species are mixed on the map, but roughly spread out on the direction of map 1."
  },
  {
    "objectID": "unsupervised-summary.html#chap-clust-recap",
    "href": "unsupervised-summary.html#chap-clust-recap",
    "title": "10  Comparing methods",
    "section": "10.1 Recap",
    "text": "10.1 Recap\nGraphics are invaluable for cluster analysis, whether they are used to find clusters or to interpret and evaluate the results of a cluster analysis arrived at by other means.\nThe spin and brush approach can be used to get an initial look at the data and to find clusters, and occasionally, it is sufficient. When the clustering is the result of an algorithm, a very useful first step is to paint the points by cluster membership and to look at the data to see whether the clustering seems sensible. How many clusters are there, and how big are they? What shape are they, and do they overlap one another? Which variables have contributed most to the clustering? Can the clusters be qualitatively described? All the plots we have described can be useful: scatterplots, parallel coordinate plots, and area plots, as well as static plots like dendrograms.\nWhen the clusters have been generated by a model, we should also use graphics to help us assess the model. If the model makes distributional assumptions, we can generate ellipses and compare them with the clusters to see whether the shapes are consistent. For self-organizing maps the tour can assist in uncovering problems with the fit, such as when the map wraps in on itself through the data making it appear that some cases are far apart when they are truly close together. A confusion table can come alive with linked brushing, so that mismatches and agreements between methods can be explored. \n\n\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society."
  },
  {
    "objectID": "unsupervised-ex.html",
    "href": "unsupervised-ex.html",
    "title": "Exercises",
    "section": "",
    "text": "Using the spin and brush method, uncover three clusters in the data and confirm that these correspond to the three species. (Hint: Transform the data to principal components and enter these variables into the projection pursuit guided tour running the holes index. Also the species should not be identified by color or symbol, until the clusters have been uncovered.)\nRun hierarchical clustering with average linkage on the data (excluding ).\n\nCut the tree at three clusters and append a cluster id to the dataset. How well do the clusters correspond to the species? (Plot vs , and use jittering if necessary.) Using brushing in a plot of linked to a tour plot of the six variables, examine the beetles that are misclassified.\nNow cut the tree at four clusters, and repeat the last part.\nWhich is the better solution, three or four clusters? Why?\n\nFor the ,\n\nConsider the oils from the four areas of Southern Italy. What would you expect to be the result of model-based clustering on the eight fatty acid variables?\nRun model-based clustering on the Southern oils, with the goal of extracting clusters corresponding to the four areas. What is the best model? Create ellipsoids corresponding to the model and examine these in a tour. Do they match your expectations?\nCreate ellipsoids corresponding to alternative models and use these to decide on a best solution.\n\nThis question uses the data.\n\nExplore the patterns in expression level for the functional classes. Can you characterize the expression patterns for each class?\nHow well do the cluster analysis results match the functional classes? Where do they differ?\nCould you use the cluster analysis results to refine the classification of genes into functional classes? How would you do this?\n\nIn the data, make further comparisons of the five-cluster solutions of \\(k\\)-means and Ward’s hierarchical clustering.\n\nOn what tracks do the methods disagree?\nWhich track does \\(k\\)-means consider to be a singleton cluster, while Ward’s hierarchical clustering groups it with 12 other tracks?\nIdentify and characterize the tracks in the four clusters where both methods agree.\n\nIn the data, fit a \\(5\\times 5\\) grid SOM, and observe the results for 100, 200, 500, and 1,000 updates. How does the net change with the increasing number of updates?\nThere is a mystery dataset in the collection, called . How many clusters are in this dataset?"
  },
  {
    "objectID": "temporal.html",
    "href": "temporal.html",
    "title": "Miscellaneous",
    "section": "",
    "text": "computing features, and exploring feature space linked to individual time series plots\nprojection pursuit of multiple time series, 1D indexes against time\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create Interactive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "multivariate-time-series.html",
    "href": "multivariate-time-series.html",
    "title": "16  Multiple time series",
    "section": "",
    "text": "Potential topics:\n\ncomputing features, and exploring feature space linked to individual time series plots\nprojection pursuit of multiple time series, 1D indexes against time\nlongitudinal data\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create Interactive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Abbott, Edwin. 1884. Flatland: A Romance of Many Dimensions.\nDover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic\nQueries for Information\nExploration: An Implementation\nand Evaluation.” In ACM CHI ‘92 Conference\nProceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical\nMethod for the Analysis of\nComplex Problems.” In Proceedings\nof the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of\nHigh-Dimensional Data.”\nBiometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971.\n“Transformations of Multivariate\nData.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory\nSpatial Data Analysis\nLinking SpaceStat and\nArcView.” In Recent\nDevelopments in Spatial\nAnalysis, edited by M. M. Fischer and A. Getis, 35–59.\nBerlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms\nfor Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video\nLibrary.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand\nTour: A Tool for\nViewing Multidimensional\nData.” SIAM Journal of Scientific and\nStatistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for\n\"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences.\n2018. “Forests of Australia.”\nhttps://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing\nScatterplots.” In Dynamic Graphics for\nStatistics, edited by W. S. Cleveland and M. E. McGill, 201–24.\nMonterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996.\n“The Visual Design and\nControl of Trellis\nDisplays.” Journal of Computational and\nGraphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An\nEnvironment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of\nInformation Visualization: Readings and Reflections. San Diego, CA:\nMorgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided\nTour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection\nPursuit in High Dimensions.” Proceedings of the National\nAcademy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and\nMachine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning\nwith r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006.\nScientific Visualization: The Visual Extraction of Knowledge from\nData. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern\nMultidimensional Scaling. New York:\nSpringer.\n\n\nBreiman, L. 2001. “Random Forests.”\nMachine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random\nForests.”\nhttp://www.math.usu.edu/∼adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022.\nrandomForest: Breiman and Cutler’s Random Forests for Classification\nand Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984.\nClassification and Regression Trees.\nMonterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand\nTour Methods: An\nOutline.” Computing Science and Statistics\n17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988.\n“Elements of a Viewing\nPipeline for Data\nAnalysis.” In Dynamic Graphics for\nStatistics, edited by W. S. Cleveland and M. E. McGill, 277–308.\nMonterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic\nProjections in High-Dimensional\nVisualization: Theory and\nComputational Methods.” Florham Park,\nNJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for\nHigh-Dimensional Rotations in\nData Visualization.” In Handbook of\nStatistics: Data Mining and Visualization, edited by C. R. Rao, E.\nJ. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands:\nElsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive\nHigh-Dimensional Data\nVisualization.” Journal of Computational and\nGraphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical\nMethods in the Analysis of\nCustomer Panel Data:\nComment.” Journal of Business & Economic\nStatistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A\nData Viewer for Multivariate\nData.” Computing Science and Statistics 17\n(1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization\nMethodology for Multidimensional\nScaling.” Journal of Classification 19 (1):\n7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean,\nHeike Hofmann, and Lisha Chen. 2008. “Data Visualization with\nMultidimensional Scaling.” Journal of Computational and\nGraphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and\nGraphics in Statistics. New York:\nSpringer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999.\nReadings in Information Visualization. San Francisco, CA:\nMorgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996.\n“ExplorN: Design\nConsiderations Past and\nPresent.” Technical Report 129. Fairfax, VA: Center\nfor Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide.\nLondon: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of\nData Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006.\nHandbook of Computational Statistics (Volume III) Data\nVisualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural\nNetworks: A Review from a\nStatistical Perspective.”\nStatistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget\nInteractivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to\nRepresent Points in k-Dimensional Space\nGraphically.” Journal of the American\nStatistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy\nWeighted Regression and Smoothing\nScatterplots.” Journal of American Statistics\nAssociation 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart\nPress.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for\nStatistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual\nControls For\nHigh-Dimensional Data\nProjections.” Journal of Computational and\nGraphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection\nPursuit Indexes Based on\nOrthonormal Function\nExpansions.” Journal of Computational and\nGraphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand\nTour and Projection\nPursuit.” Journal of Computational and Graphical\nStatistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection\nPursuit.” Journal of Computational and Graphical\nStatistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele.\n2007. “Exploring Gene Expression\nData, Using Plots.”\nJournal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for\nMultivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic\nGraphics for Data Analysis: With R and\nGGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006.\n“Grand Tours, Projection\nPursuit Guided Tours and\nManual Controls.” In Handbook of\nData Visualization, edited by C.-H. Chen,\nW. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996.\n“Dynamic Graphics in a GIS:\nExploring and Analyzing\nMultivariate Spatial Data Using\nLinked Software.” Computational\nStatistics: Special Issue on Computer Aided Analyses of Spatial\nData 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003.\n“Computational Methods for Dynamic\nGraphs.” Journal of Computational &\nGraphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector\nNetworks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles\nEt Axiales: Méthode de Transformation\nGéométrique Et Procédé Nouveau de Calcul Graphique Déduits de La\nConsidération Des Coordonnées Paralléles. Paris, France:\nGauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with\nR. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping\nMultivariate Time Series: A\nCase Study.” In Proceedings of the\nIEEE Workshop on Temporal Data\nMining: Algorithms, Theory and\nApplications, in Conjunction with the Conference on Data\nMining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019.\n“Fire Origins - Current and\nHistorical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of\nGraphical Projection Pursuit.” Annals of Statistics 12\n(3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of\nGraphical Projection\nPursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring\nGeovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster\nAnalysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in\nStatistics.” Journal of American Statistical\nAssociation 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of\nMultiple Measurements in\nTaxonomic Problems.” Annals of\nEugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic\nProblems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization\nof Multiple Measurements.” Annals\nof Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973.\n“PRIM-9, an Interactive Multidimensional Data Display\nand Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional\nData Display and Analysis System.” In The Collected Works of\nJohn w. Tukey: Graphics 1965-1985, Volume v, edited by William S.\nCleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific\nIllustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency\nVersus Interpretability of Classification.” Biometrics\n21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust:\nGaussian Mixture Modelling for Model-Based Clustering, Classification,\nand Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based\nClustering, Discriminant\nAnalysis, Density\nEstimation.” Journal of the American Statistical\nAssociation 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory\nProjection Pursuit.” Journal of\nAmerican Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A\nProjection Pursuit Algorithm for\nExploratory Data\nAnalysis.” IEEE Transactions on Computing C\n23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of\nThematic Cartography, Statistical Graphics, and Data\nVisualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical\nMilestones.”\nhttp://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection\nViews: Dimensional Inference\nThrough Sections and\nProjections.” Journal of Computational and\nGraphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot\nGraphical Display of Matrices\nwith Applications to Principal\nComponent Analysis.”\nBiometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004.\nHandbook of Computational Statistics: Concepts and Methods. New\nYork: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020.\nAn Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of\nMultivariate Chemical Data by\nProjection Pursuit.” Chemometrics\nand Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and\nBootstrap Tests of\nHypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman;\nHall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization\nHandbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant\nTour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for\nContingency Tables.” In Computer\nScience and Statistics: Proceedings of the 13th Symposium on the\nInterface, 268–73. Fairfax Station, VA: Interface Foundation of\nNorth America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of\nTelevision Ratings.” The American\nStatistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991.\n“Dynamic Graphics for\nExploring Spatial Data with\nApplication to Locating Global\nand Local Anomalies.” The American\nStatistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The\nElements of Statistical\nLearning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds.\n2015. Handbook of Cluster Analysis. Chapman;\nHall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the\nExploration of Multivariate\nCategorical Data.\nhttp://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading\nMosaicplots.” Computational Statistics and Data\nAnalysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences\nin MANET.” Computational Statistics 13 (1):\n77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022.\nPalmerpenguins: Palmer Archipelago (Antarctica) Penguin Data.\nhttps://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical\nVariables into Principal Components.” Journal of Educational\nPsychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit\n(with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program\nfor Data Analysis.” PhD thesis, Seattle: University of\nWashington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A\nLanguage for Data Analysis and\nGraphics.” Journal of Computational and\nGraphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer,\nClaus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023.\nColorspace: A Toolbox for Manipulating and Assessing Colors and\nPalettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with\nParallel Coordinates.” The Visual\nComputer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data\nDownload.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The\nMovie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate\nStatistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component\nAnalysis: A Review and Recent Developments.” Phil. Trans. R.\nSoc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is\nProjection Pursuit? (With Discussion).”\nJournal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in\nr: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps\n(3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive\nGraphical Methods in the Analysis\nof Customer Panel Data (with\nDiscussion).” Journal of Business and Economic\nStatistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor\nEmbedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by\nOptimizing Goodness of Fit to a\nNonmetric Hypothesis.”\nPsychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional\nScaling: A Numerical\nMethod.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional\nScaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice\nTour for Finding Hollowness in High-Dimensional Data.”\nJournal of Computational and Graphical Statistics 29 (3):\n681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in\nHigh-Dimensional Data.” Journal of Computational and\nGraphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The\nAmerican Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection\nPursuit for Exploratory\nSupervised Classification.” Journal\nof Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing\nProjection Pursuit Classification Trees.” Journal of\nStatistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index\nfor Large p Small n Data.” Statistics and\nComputing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005.\n“Projection Pursuit for\nExploratory Supervised\nClassification.” Journal of Computational and\nGraphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with\nTours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas\nSpyrison, Earo Wang, and H. Sherry Zhang. 2022. “The\nState-of-the-Art on Tours for Dynamic Visualization of High-Dimensional\nData.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013.\n“PPtree: Projection pursuit classification\ntree.” Electronic Journal of Statistics 7 (none):\n1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View:\nCluster Analysis & Finite Mixture Models.”\nhttps://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and\nRegression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja.\n1992. “Visualizing the Embedding of\nObjects in Euclidean\nSpace.” In Computing Science and Statistics:\nProceedings of the 24th Symposium on the Interface, 208–17. Fairfax\nStation, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.”\nIEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005.\nGeographic Information Systems and Science. New York: John\nWiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A\nComputational Approach.” Computational Statistics & Data\nAnalysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and\nAnalysis of Multivariate Observations.” In Proc. Of the Fifth\nBerkeley Symposium on Mathematical Statistics and Probability,\nedited by L. M. Le Cam and J. Neyman, 1:281–97. University of California\nPress.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using\nr - an Example-Based Approach. Cambridge: Cambridge University\nPress.\n\n\nMartin, Eric. 1965. “Flatland.”\nhttp://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical\nSensitivity Analysis for\nMultidimensional Scaling.” Journal\nof Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data\nAnalysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data\nCollection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and\nFriedrich Leisch. 2023. E1071: Misc Functions of the Department of\nStatistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced\nVersion of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman &\nHall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet\ndump retrieved from https://planet.osm.org .”\nhttps://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to\nSystems of Points in Space.” The London, Edinburgh, and\nDublin Philosophical Magazine and Journal of Science 2 (11):\n559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots.\nhttps://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit\nIndices Based on the Empirical Distribution Function.”\nJournal of Computational and Graphical Statistics 14 (3):\n700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit\nDiscriminant Analysis.”\nComputational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit\nDiscriminant Analysis for Two\nGroups.” Communications in Statistics, Part A –\nTheory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional\nProjection Pursuit.” Journal of\nComputational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor -\nUser’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of\nMultiple Measurements in Problems\nof Biological Classification (with\nDiscussion).” Journal of the Royal Statistical Society,\nSeries B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics,\nVol. 9. Amsterdam, The Netherlands: Elsevier Science\nPublishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of\nStatistics: Data Mining and\nVisualization. Amsterdam, The Netherlands:\nElsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and\nNeural Networks. Cambridge: Cambridge\nUniversity Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for\nVenables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of\nStimulus Similarity and Errors in\nSome Paired-Associate Learning\nTasks.” Journal of Experimental Psychology\n53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz\nMarbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally:\nExtension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery.\n2016. “mclust 5: Clustering,\nClassification and Density Estimation Using Gaussian Finite\nMixture Models.” The R Journal 8 (1):\n289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of\nProximities: Multidimensional\nScaling with an Unknown Distance\nFunction, I and II.”\nPsychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with\nr, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik\nRam, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create\nInteractive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position\nNon-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul\nMelloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020.\nbomrang: Australian Government Bureau of\nMeteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for\nInteraction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009.\n“Somewhere over the Rainbow: How to Make Effective Use of Colors\nin Meteorological Visualizations.” Bulletin of the American\nMeteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh,\nJulie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A\nVisualization Toolkit for High-Dimensional Data.” Journal of\nComputational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z.\nCox, and D. Cook. 2000. “Orca: A\nVisualization Toolkit for\nHigh-Dimensional Data.”\nJournal of Computational and Graphical Statistics 9 (3):\n509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004.\n“Exploratory Visual Analysis of Graphs in\nGGobi.” In CompStat: Proceedings in\nComputational Statistics, 16th Symposium, edited by Jaromir Antoch.\nPhysica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.”\nComputational Statistics: Special Issue on The Use of Interactive\nGraphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing\nData in Interactive\nHigh-Dimensional Data\nVisualization.” Computational Statistics 13\n(1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992.\n“XGobi: Interactive Dynamic\nGraphics in the X Window\nSystem with a Link to S.”\nIn American Statistical Association 1991 Proceedings of the Section\non Statistical Graphics, 1–8. Alexandria, VA: American Statistical\nAssociation.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x\nWindow System.” Journal of Computational and Graphical\nStatistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook.\n2003. “GGobi: Evolving from\nXGobi into an Extensible\nFramework for Interactive Data\nVisualization.” Computational Statistics &\nData Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand\nTour.” In Computing Science and Statistics, 34:500--512.\nhttps://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic\nGraphics.” In Handbook of Computational\nStatistics: Concepts and Methods, edited by James E. Gentle,\nWolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA\nStudio: A Codeless Visual\nProgramming Environment for\nGeoscientific Data Analysis and\nVisualization.” The Journal of Computers and\nGeosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and\nSelf–Consistent Points of Elliptical Distributions.” The\nAnnals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006.\n“rggobi: An\nInterface Between R and\nGGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive\nPartitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data\nVisualization Using\nMondrian.” Journal of Statistical Software\n7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection\nSequences – Interactive Analysis\nof Massive Data Sets.”\nComputing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation\nPolytopes and Exploratory\nGraphical Methods for Ranked\nData.” The Annals of Statistics 21:\n1401–30.\n\n\nTierney, L. 1991. LispStat:\nAn Object-Orientated\nEnvironment for Statistical\nComputing and Dynamic\nGraphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1.\nTheory and Method.”\nPsychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative\nInformation. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics\nPress.\n\n\nTukey, J. W. 1965. “The Technical Tools\nof Statistics.” The American Statistician\n19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996.\n“Interactive Graphics for\nData Sets with Missing\nValues - MANET.” Journal of\nComputational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct\nManipulation Graphics for Data\nMining.” Journal of Image and Graphics 2\n(1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of\nLarge Datasets: Visualizing a\nMillion. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel\nCoordinates for Exploratory\nModelling Analysis.” Comput. Stat.\nData Anal. 43 (4): 553–64. https://doi.org/{\\tt\nhttp://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction\nGraphics for R.” In Proceedings of\nthe 3rd International Workshop on Distributed Statistical Computing (DSC\n2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis.\nhttp://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert,\nand Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using\nTree-Based Algorithms.” Journal of Machine Learning\nResearch 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing\nHigh-Dimensional Data Using t-SNE.” Journal of Machine\nLearning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of\nStatistical Learning Theory.\nNew York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook.\nIthaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied\nStatistics with S. New York:\nSpringer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics\nwith s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed).\nHillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial\nand Political Atlas,\nRepresenting, by Means of Stained\nCopper-Plate Charts,\nThe Progress of the Commerce,\nRevenues, Expenditure, and Debts\nof England, During the Whole of the Eighteenth\nCentury, by William\nPlayfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary;\nShewing on a Principle Entirely New, the\nResources of Every State and Kingdom in Europe; Illustrated\nwith Stained Copper-Plate\nCharts, Representing the Physical Powers of Each Distinct\nNation with Ease and Perspicuity by William\nPlayfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical\nRepresentation of Multivariate\nData. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data\nAnalysis Using Parallel\nCoordinates.” Journal of American Statistics\nAssociation 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in\nk-Dimensions.”\nTechnical Report 68. Center for Computational Statistics, George Mason\nUniversity.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical\nGraphics and Visualization.” In, edited\nby C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science\nPublishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image\nGrand Tour.” In Automatic Target\nRecognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham,\nWA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and\nSuper-Organizing Maps in R: The kohonen Package.” Journal of\nStatistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible\nSelf-Organizing Maps in kohonen 3.0.”\nJournal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising\nMaps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data\nAnalysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High\nDimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen,\nKohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey\nDunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using\nthe Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for\nMultivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a.\n“Tourr: An R Package for\nExploring Multivariate Data with\nProjections.” Journal of Statistical\nSoftware 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R\nPackage for Exploring Multivariate Data with Projections.”\nJournal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis\nVaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read\nRectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual\nClustering and Classification:\nThe Oronsay Particle\nSize Data Set\nRevisited.” Computational Statistics: Special\nIssue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York:\nSpringer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive\nVisualization of Very Large\nGraphs.” Journal of Computational and Graphical\nStatistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive\nGraphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006.\nVisual Statistics: Seeing\nData with Dynamic Interactive\nGraphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D.\nMcWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020.\n“colorspace: A Toolbox for\nManipulating and Assessing Colors and Palettes.” Journal of\nStatistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping\nRGBland: Selecting Colors for Statistical Graphics.”\nComputational Statistics & Data Analysis 53 (9): 3259–70.\nhttps://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A\nComputational Perspective on Projection Pursuit in High Dimensions:\nFeasible or Infeasible Feature Extraction.” International\nStatistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and\nPipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "toolbox.html",
    "href": "toolbox.html",
    "title": "Appendix A — Toolbox",
    "section": "",
    "text": "Description and explanation of primary methods used throughout the book. Mostly focusing on tour methods.\nWe need a really nice friendly introduction to tour methods:\n\n2D to 1D projections as basic explanation\nmaybe 3D to 2D, or even 4D to 2D illustration\n\nShow examples of what can be gained from looking at combinations as opposed to pairs plots, for example. Clusters is a good situation, but also collinearity and outliers\nExplain data needed for input, what happens if discrete data is included, or time series\nWorking with many dimensions, how to adapt\nGrand tour, and show paths on the space, starting with 1D. How more time gives more coverage of the sphere. Then the torus and paths on torus.\nDifferent types of tours, and when to use them.\nAnd finally how to save tours, and make plot of single projection\nNeed to include - half_range - standardizing variables\nAlso include other software now available\n\ndetourr\nlangevitour\nwoylier\nspinifex"
  },
  {
    "objectID": "data.html#australian-football-league-women",
    "href": "data.html#australian-football-league-women",
    "title": "Appendix B — Data",
    "section": "B.1 Australian Football League Women",
    "text": "B.1 Australian Football League Women\n\nDescription\nThe aflw data is from the 2021 Women’s Australian Football League. These are average player statistics across the season, with game statistics provided by the fitzRoy package. If you are new to the game of AFL, there is a nice explanation on Wikipedia.\n\n\nVariables\n\n\n\n\n\nRows: 381\nColumns: 35\n$ id              <chr> \"CD_I1001678\", \"CD_I1001679\", \"CD_I1001681\", \"CD_I1001…\n$ given_name      <chr> \"Jordan\", \"Brianna\", \"Jodie\", \"Ebony\", \"Emma\", \"Pepa\",…\n$ surname         <chr> \"Zanchetta\", \"Green\", \"Hicks\", \"Antonio\", \"King\", \"Ran…\n$ number          <int> 2, 3, 5, 12, 60, 21, 22, 23, 35, 14, 3, 8, 16, 12, 19,…\n$ team            <chr> \"Brisbane Lions\", \"West Coast Eagles\", \"GWS Giants\", \"…\n$ position        <chr> \"INT\", \"INT\", \"HFFR\", \"WL\", \"RK\", \"BPL\", \"INT\", \"INT\",…\n$ time_pct        <dbl> 63.00000, 61.25000, 76.50000, 74.90000, 85.10000, 77.4…\n$ goals           <dbl> 0.0000000, 0.0000000, 0.0000000, 0.1000000, 0.6000000,…\n$ behinds         <dbl> 0.0000000, 0.0000000, 0.5000000, 0.4000000, 0.4000000,…\n$ kicks           <dbl> 5.000000, 2.500000, 3.750000, 8.800000, 4.100000, 3.22…\n$ handballs       <dbl> 2.500000, 3.750000, 3.000000, 3.600000, 2.700000, 2.22…\n$ disposals       <dbl> 7.500000, 6.250000, 6.750000, 12.400000, 6.800000, 5.4…\n$ marks           <dbl> 1.5000000, 0.2500000, 1.0000000, 3.7000000, 2.2000000,…\n$ bounces         <dbl> 0.0000000, 0.0000000, 0.0000000, 0.6000000, 0.1000000,…\n$ tackles         <dbl> 3.000000, 2.250000, 2.250000, 3.900000, 2.000000, 1.77…\n$ contested       <dbl> 3.500000, 2.250000, 3.500000, 5.700000, 4.400000, 2.66…\n$ uncontested     <dbl> 3.500000, 4.500000, 3.000000, 7.000000, 2.800000, 1.77…\n$ possessions     <dbl> 7.000000, 6.750000, 6.500000, 12.700000, 7.200000, 4.4…\n$ marks_in50      <dbl> 1.0000000, 0.0000000, 0.2500000, 0.5000000, 0.9000000,…\n$ contested_marks <dbl> 1.0000000, 0.0000000, 0.0000000, 0.4000000, 1.2000000,…\n$ hitouts         <dbl> 0.0000000, 0.0000000, 0.0000000, 0.0000000, 19.4000000…\n$ one_pct         <dbl> 0.0000000, 1.5000000, 0.5000000, 1.2000000, 2.6000000,…\n$ disposal        <dbl> 60.25000, 67.15000, 37.20000, 65.96000, 61.72000, 66.8…\n$ clangers        <dbl> 2.000000, 0.500000, 2.500000, 3.100000, 2.400000, 1.33…\n$ frees_for       <dbl> 1.0000000, 0.5000000, 0.2500000, 2.5000000, 0.5000000,…\n$ frees_against   <dbl> 1.0000000, 0.5000000, 1.2500000, 1.3000000, 1.1000000,…\n$ rebounds_in50   <dbl> 0.0000000, 0.5000000, 0.2500000, 1.1000000, 0.0000000,…\n$ assists         <dbl> 0.00000000, 0.00000000, 0.00000000, 0.20000000, 0.2000…\n$ accuracy        <dbl> 0.00000, 0.00000, 0.00000, 5.00000, 30.00000, 0.00000,…\n$ turnovers       <dbl> 1.500000, 1.000000, 2.500000, 4.000000, 1.700000, 1.22…\n$ intercepts      <dbl> 2.0000000, 2.0000000, 0.5000000, 5.3000000, 1.3000000,…\n$ tackles_in50    <dbl> 0.5000000, 0.0000000, 0.7500000, 0.5000000, 0.5000000,…\n$ shots           <dbl> 0.5000000, 0.0000000, 0.7500000, 1.0000000, 1.2000000,…\n$ metres          <dbl> 72.50000, 58.50000, 76.00000, 225.90000, 89.80000, 76.…\n$ clearances      <dbl> 0.5000000, 0.2500000, 1.2500000, 0.4000000, 0.9000000,…\n\n\n\n\nPurpose\nThe primary analysis is to summarise the variation using principal component analysis, which gives information about relationships between the statistics or skills sets common in players. One also might be tempted to cluster the players, but there are no obvious clusters so it could be frustrating. At best one could partition the players into groups, while recognising there are no absolutely distinct and separated groups.\n\n\nSource\nSee the information provided with the fitzRoy package.\n\n\nPre-processing\nThe code for downloading and pre-processing the data is available at the mulgar website in the data-raw folder. The data provided by the fitzRoy package was pre-processed to reduce the variables to only those that relate to player skills and performance. It is possible that using some transformations on the variables would be useful to make them less skewed."
  },
  {
    "objectID": "data.html#palmer-penguins",
    "href": "data.html#palmer-penguins",
    "title": "Appendix B — Data",
    "section": "B.2 Palmer penguins",
    "text": "B.2 Palmer penguins\n\n\nCode\nlibrary(palmerpenguins)\npenguins <- penguins %>%\n  na.omit() # 11 observations out of 344 removed\n# use only vars of interest, and standardise\n# them for easier interpretation\npenguins_sub <- penguins %>% \n  select(bill_length_mm,\n         bill_depth_mm,\n         flipper_length_mm,\n         body_mass_g,\n         species, \n         sex) %>% \n  mutate(across(where(is.numeric),  ~ scale(.)[,1])) %>%\n  rename(bl = bill_length_mm,\n         bd = bill_depth_mm,\n         fl = flipper_length_mm,\n         bm = body_mass_g)\nsave(penguins_sub, file=\"data/penguins_sub.rda\")\n\n\n\nDescription\nThis data measure four physical characteristics of three species of penguins.\n\n\nVariables\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nbl\na number denoting bill length (millimeters)\n\n\nbd\na number denoting bill depth (millimeters)\n\n\nfl\nan integer denoting flipper length (millimeters)\n\n\nbm\nan integer denoting body mass (grams)\n\n\nspecies\na factor denoting penguin species (Adélie, Chinstrap and Gentoo)\n\n\n\n\n\nPurpose\nThe primary goal is to find a combination of the four variables where the three species are distinct. This is also a useful data set to illustrate cluster analysis.\n\n\nSource\nDetails of the penguins data can be found at https://allisonhorst.github.io/palmerpenguins/, and Horst, Hill, and Gorman (2020) is the package source.\n\n\nPre-processing\nThe data is loaded from the palmerpenguins package. The four physical measurement variables and the species are selected, and the penguins with missing values are removed. Variables are standardised, and their names are shortened.\n\nlibrary(palmerpenguins)\npenguins <- penguins %>%\n  na.omit() # 11 observations out of 344 removed\n# use only vars of interest, and standardise\n# them for easier interpretation\npenguins_sub <- penguins[,c(3:6, 1)] %>% \n  mutate(across(where(is.numeric),  ~ scale(.)[,1])) %>%\n  rename(bl = bill_length_mm,\n         bd = bill_depth_mm,\n         fl = flipper_length_mm,\n         bm = body_mass_g) %>%\n  as.data.frame()\nsave(penguins_sub, file=\"data/penguins_sub.rda\")"
  },
  {
    "objectID": "data.html#bushfires",
    "href": "data.html#bushfires",
    "title": "Appendix B — Data",
    "section": "B.3 Bushfires",
    "text": "B.3 Bushfires\n\nDescription\nThis data was collated by Weihao (Patrick) Li as part of his Honours research at Monash University. It contains fire ignitions as detected from satellite hotspots, and processed using the spotoroo package, augmented with measurements on weather, vegetation, proximity to human activity. The cause variable is predicted based on historical fire ignition data collected by County Fire Authority personnel.\n\n\nVariables\n\n\nRows: 1,021\nColumns: 60\n$ id            <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ lon           <dbl> 141.1300, 141.3000, 141.4800, 147.1600, 148.1050, 144.18…\n$ lat           <dbl> -37.13000, -37.65000, -37.35000, -37.85000, -37.57999, -…\n$ time          <date> 2019-10-01, 2019-10-01, 2019-10-02, 2019-10-02, 2019-10…\n$ FOR_CODE      <dbl> 41, 41, 91, 44, 0, 44, 0, 102, 0, 91, 45, 41, 45, 45, 45…\n$ FOR_TYPE      <chr> \"Eucalypt Medium Woodland\", \"Eucalypt Medium Woodland\", …\n$ FOR_CAT       <chr> \"Native forest\", \"Native forest\", \"Commercial plantation…\n$ COVER         <dbl> 1, 1, 4, 2, 6, 2, 6, 5, 6, 4, 2, 1, 2, 2, 2, 2, 6, 6, 6,…\n$ HEIGHT        <dbl> 2, 2, 4, 2, 6, 2, 6, 5, 6, 4, 3, 2, 3, 3, 3, 2, 6, 6, 6,…\n$ FOREST        <dbl> 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,…\n$ rf            <dbl> 0.0, 0.0, 15.4, 4.8, 6.0, 11.6, 11.6, 0.6, 0.2, 0.6, 0.0…\n$ arf7          <dbl> 5.0857143, 2.4000000, 2.4000000, 0.7142857, 0.8571429, 1…\n$ arf14         <dbl> 2.8142857, 1.7428571, 1.8000000, 1.6714286, 1.5714286, 1…\n$ arf28         <dbl> 1.9785714, 1.5357143, 1.5357143, 3.7857143, 1.9000000, 1…\n$ arf60         <dbl> 2.3033333, 1.7966667, 1.7966667, 4.0000000, 2.5333333, 1…\n$ arf90         <dbl> 1.2566667, 1.0150000, 1.0150000, 2.9600000, 2.1783333, 1…\n$ arf180        <dbl> 0.9355556, 0.8444444, 0.8444444, 2.3588889, 1.7866667, 1…\n$ arf360        <dbl> 1.3644444, 1.5255556, 1.5255556, 1.7272222, 1.4716667, 1…\n$ arf720        <dbl> 1.3011111, 1.5213889, 1.5213889, 1.7111111, 1.5394444, 1…\n$ se            <dbl> 3.8, 4.6, 14.2, 23.7, 23.8, 16.8, 18.0, 12.9, 14.7, 12.9…\n$ ase7          <dbl> 18.02857, 18.50000, 21.41429, 23.08571, 23.11429, 22.014…\n$ ase14         <dbl> 17.03571, 17.44286, 18.03571, 19.17143, 18.45714, 18.628…\n$ ase28         <dbl> 19.32857, 18.47500, 19.33929, 18.23571, 16.86071, 19.375…\n$ ase60         <dbl> 20.38644, 19.99153, 20.39492, 19.90847, 19.26780, 20.449…\n$ ase90         <dbl> 22.54118, 21.93193, 22.04370, 20.59328, 20.04538, 21.809…\n$ ase180        <dbl> 20.79106, 19.93966, 19.99385, 19.11006, 18.66760, 19.810…\n$ ase360        <dbl> 15.55153, 14.83259, 14.87883, 14.69276, 14.44318, 14.755…\n$ ase720        <dbl> 15.52350, 14.75049, 14.77427, 14.53463, 14.32656, 14.540…\n$ maxt          <dbl> 21.3, 17.8, 15.4, 20.8, 19.8, 15.8, 19.5, 12.6, 18.8, 12…\n$ amaxt7        <dbl> 22.38571, 20.44286, 22.21429, 24.21429, 23.14286, 21.671…\n$ amaxt14       <dbl> 21.42857, 19.72857, 19.86429, 21.80000, 20.89286, 19.578…\n$ amaxt28       <dbl> 20.71071, 19.10000, 19.18929, 19.75000, 19.05714, 18.885…\n$ amaxt60       <dbl> 24.02667, 22.28000, 22.38667, 22.93167, 22.12000, 21.031…\n$ amaxt90       <dbl> 27.07750, 25.77667, 25.89833, 24.93667, 23.93750, 23.164…\n$ amaxt180      <dbl> 26.92000, 25.92722, 25.98500, 24.84056, 23.95389, 23.343…\n$ amaxt360      <dbl> 21.55389, 20.79778, 20.81333, 20.21972, 19.99389, 19.505…\n$ amaxt720      <dbl> 21.47750, 20.57222, 20.57694, 20.13153, 20.03875, 19.650…\n$ mint          <dbl> 9.6, 9.0, 7.3, 7.7, 8.3, 8.3, 6.1, 5.9, 7.4, 5.9, 6.9, 7…\n$ amint7        <dbl> 9.042857, 7.971429, 9.171429, 10.328571, 11.200000, 10.6…\n$ amint14       <dbl> 9.928571, 9.235714, 9.421429, 10.007143, 10.900000, 10.7…\n$ amint28       <dbl> 8.417857, 7.560714, 7.353571, 8.671429, 9.575000, 10.060…\n$ amint60       <dbl> 11.156667, 9.903333, 9.971667, 10.971667, 11.975000, 12.…\n$ amint90       <dbl> 11.96667, 10.81250, 10.87833, 12.49000, 13.46167, 13.638…\n$ amint180      <dbl> 11.96778, 11.01056, 11.02000, 12.41944, 13.42500, 13.695…\n$ amint360      <dbl> 9.130556, 8.459722, 8.448333, 9.588611, 10.456389, 11.03…\n$ amint720      <dbl> 8.854861, 8.266250, 8.254028, 9.674861, 10.517083, 10.96…\n$ dist_cfa      <dbl> 9442.206, 6322.438, 7957.374, 7790.785, 10692.055, 6054.…\n$ dist_camp     <dbl> 50966.485, 6592.893, 31767.235, 8816.272, 15339.702, 941…\n$ ws            <dbl> 1.263783, 1.263783, 1.456564, 5.424445, 4.219751, 4.1769…\n$ aws_m0        <dbl> 2.644795, 2.644795, 2.644795, 5.008369, 3.947659, 5.2316…\n$ aws_m1        <dbl> 2.559202, 2.559202, 2.559202, 5.229680, 4.027398, 4.9704…\n$ aws_m3        <dbl> 2.446211, 2.446211, 2.446211, 5.386005, 3.708622, 5.3045…\n$ aws_m6        <dbl> 2.144843, 2.144843, 2.144843, 5.132617, 3.389890, 5.0355…\n$ aws_m12       <dbl> 2.545008, 2.545008, 2.548953, 5.045297, 3.698736, 5.2341…\n$ aws_m24       <dbl> 2.580671, 2.580671, 2.584047, 5.081100, 3.745286, 5.2522…\n$ dist_road     <dbl> 498.75145, 102.22032, 1217.22446, 281.69151, 215.56176, …\n$ log_dist_cfa  <dbl> 9.152945, 8.751860, 8.981854, 8.960697, 9.277256, 8.7084…\n$ log_dist_camp <dbl> 10.838924, 8.793748, 10.366191, 9.084354, 9.638200, 9.15…\n$ log_dist_road <dbl> 6.212108, 4.627130, 7.104329, 5.640813, 5.373247, 5.0047…\n$ cause         <chr> \"lightning\", \"lightning\", \"lightning\", \"lightning\", \"lig…\n\n\n\n\nPurpose\nThe primary goal is to predict the cause of the bushfire using the weather and distance from human activity variables provided.\n\n\nSource\nCollated data was part of Weihao Li’s Honours thesis, which is not publicly available. The hotspots data was collected from P-Tree System (2020), climate data was taken from the Australian Bureau of Meteorology using the bomrang package (Sparks et al. 2020), wind data from McVicar (2011) and Iowa State University (2020), vegetation data from Australian Bureau of Agricultural and Resource Economics and Sciences (2018), distance from roads calculated using OpenStreetMap contributors (2020), CFA stations from Department of Environment, Land, Water & Planning (2020a), and campsites from Department of Environment, Land, Water & Planning (2020b). The cause was predicted from training data provided by Department of Environment, Land, Water & Planning (2019).\n\n\nPre-processing\nThe 60 variables are too many to view with a tour, so it should be pre-processed using principal component analysis. The categorical variables of FOR_TYPE and FOR_CAT are removed. It would be possible to keep these if they are converted to dummy (binary variables)."
  },
  {
    "objectID": "data.html#notes-to-self",
    "href": "data.html#notes-to-self",
    "title": "Appendix B — Data",
    "section": "B.6 Notes to self",
    "text": "B.6 Notes to self\nThere were fifteen datasets listed in chapter 7 of the first edition. Several of these were related to networks which we are not including this time. I have tried to give a mix of things on a variety of topics. It would be nice to see if there’s updated versions of the “tips” (there seems to be a lot of noise in the literature here and no open datasets) and Di’s music data (perhaps we could scrape our own spotify accounts to get an equivalent), there are also a few audio challenge datasets like FSD50K . I think it would be useful to have more unstructured data sets like natural text that we have used for 1010.\n\nOther possible sources for data\nThere are now many search engines available for datasets that originate from research contexts that list licensing information and DOIs:\n\nhttps://zenodo.org (mostly ecology/biology)\nhttps://datadryad.org/stash (mostly biology)\nhttps://dataverse.harvard.edu/dataverse/harvard/ (mostly social sciences, but has a mixture of things)\nThere’s also a big list of datasets here: https://docs.google.com/spreadsheets/d/1ejOJTNTL5ApCuGTUciV0REEEAqvhI2Rd2FCoj7afops/edit#gid=0 (all psychology related)\nTidyTuesday\n\nhttps://github.com/rfordatascience/tidytuesday/blob/master/data/2022/2022-03-29/readme.md Would need to rearrange data to look at count, participation, revenue, expenditure\n\ngapminder\naccounting records\nLyn’s ecology data\nlearningtower, yowie\n\n\n\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://doi.org/10.5281/zenodo.3960218.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang."
  },
  {
    "objectID": "dimension-overview.html",
    "href": "dimension-overview.html",
    "title": "1  Overview",
    "section": "",
    "text": "This chapter will focus on methods for reducing dimension, and how the tour can be used to assist with the common methods such as principal component analysis (PCA), multidimensional scaling (MDS), t-stochastic neighbour embedding (t-SNE), and factor analysis.\nDimension is perceived in a tour using the spread of points. When the points are spread far apart, then the data is filling the space. Conversely when the points “collapse” into a sub-region then the data is only partially filling the space, and some dimension reduction to reduce to this smaller dimensional space may be worthwhile.\n\nWhen points do not fill the plotting canvas fully, it means that it lives in a lower dimension.\n\nLet’s start with some 2D examples. You need at least two variables to be able to talk about association between variables. Figure 1.1 shows three plots of two variables. Plot (a) shows two variables that are strongly linearly associated1, because when x1 is low, x2 is low also, and conversely when x1 is high, x2 is also high. This can also be seen by the reducton in spread of points (or “collapse”) in one direction making the data fill less than the full square of the plot. So from this we can conclude that the data is not fully 2D. The second step is to infer which variables contribute to this reduction in dimension. The axes for x1 and x2 are drawn extending from \\((0,0)\\) and because they both extend out of the cloud of points, in the direction away from the collapse of points we can say that they are jointly responsible for the dimension reduction.\nFigure 1.1 (b) shows a pair of variables that are not linearly associated. Variable x1 is more varied than x3 but knowing the value on x1 tells us nothing about possible values on x3. Before running a tour all variables are typically scaled to have equal spread. The purpose of the tour is to capture association and relationships between the variables, so any univariate differences should be removed ahead of time. Figure 1.1 (c) shows what this would look like when x3 is scaled - the points are fully spread in the full square of the plot.\n\n\nCode\nlibrary(ggplot2)\nlibrary(tibble)\nset.seed(6045)\nx1 <- runif(123)\nx2 <- x1 + rnorm(123, sd=0.1)\nx3 <- rnorm(123, sd=0.2)\ndf <- tibble(x1 = (x1-mean(x1))/sd(x1), \n             x2 = (x2-mean(x2))/sd(x2),\n             x3, \n             x3scaled = (x3-mean(x3))/sd(x3))\ndp1 <- ggplot(df) + \n  geom_point(aes(x=x1, y=x2)) +\n  xlim(-2.5, 2.5) + ylim(-2.5, 2.5) +\n  annotate(\"segment\", x=0, xend=2, y=0, yend=0) +\n  annotate(\"segment\", x=0, xend=0, y=0, yend=2) +\n  annotate(\"text\", x=2.1, y=0, label=\"x1\") +\n  annotate(\"text\", x=0, y=2.1, label=\"x2\") +\n  theme(aspect.ratio=1)\ndp2 <- ggplot(df) + \n  geom_point(aes(x=x1, y=x3)) +\n  xlim(-2.5, 2.5) + ylim(-2.5, 2.5) +\n  annotate(\"segment\", x=0, xend=2, y=0, yend=0) +\n  annotate(\"segment\", x=0, xend=0, y=0, yend=2) +\n  annotate(\"text\", x=2.1, y=0, label=\"x1\") +\n  annotate(\"text\", x=0, y=2.1, label=\"x3\") +\n  theme(aspect.ratio=1)\ndp3 <- ggplot(df) + \n  geom_point(aes(x=x1, y=x3scaled)) +\n  xlim(-2.5, 2.5) + ylim(-2.5, 2.5) +\n  annotate(\"segment\", x=0, xend=2, y=0, yend=0) +\n  annotate(\"segment\", x=0, xend=0, y=0, yend=2) +\n  annotate(\"text\", x=2.1, y=0, label=\"x1\") +\n  annotate(\"text\", x=0, y=2.1, label=\"x3\") +\n  theme(aspect.ratio=1)\n\n\n\n\n\n\n\n\n\n\n(a) Two variables with strong linear association. Both variables contribute to the association, as indicated by their axes extending out from the “collapsed” direction of the points.\n\n\n\n\n\n\n\n\n\n(b) Two variables with no linear association. But x3 has less variation, so points collapse in this direction.\n\n\n\n\n\n\n\n\n\n(c) The situation in plot (b) does not arise in a tour because all variables are (usually) scaled.\n\n\n\n\n\nFigure 1.1: Explanation of how dimension reduction is perceived in 2D, relative to variables. When an axes extends out of a direction where the points are collapsed, it means that this variable is partially responsible for the reduced dimension.\n\n\nNow let’s think about what this looks like with five variables. Figure 1.2 shows a grand tour on five variables, with (a) showing data that is primarily 2D, (b) has data that is primarily 3D and (c) is fully 5D. You can see that both (a) and (b) the spread of points collapse in some projections, with it happening more in (a). In (c) the data is always spread out in the square, although it does seem to concentrate or pile in the centre. This piling is typical when projecting from high dimensions to low dimensions. The sage tour (Laa, Cook, and Valencia 2020a) makes a correction for this.\n\n\nCode\nlibrary(mulgar)\ndata(plane)\ndata(box)\nrender_gif(plane,\n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/plane.gif\",\n           frames=500,\n           width=200,\n           height=200)\nrender_gif(box,\n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/box.gif\",\n           frames=500,\n           width=200,\n           height=200)\n# Simulate full cube\nlibrary(geozoo)\ncube5d <- data.frame(cube.solid.random(p=5, n=300)$points)\ncolnames(cube5d) <- paste0(\"x\", 1:5)\ncube5d <- data.frame(apply(cube5d, 2, function(x) (x-mean(x))/sd(x)))\nrender_gif(cube5d,\n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/cube5d.gif\",\n           frames=500,\n           width=200,\n           height=200)\n\n\n\n\n\n\n\n\n\n2D plane in 5D\n\n\n\n\n\n\n\n3D plane in 5D\n\n\n\n\n\n\n\n5D plane in 5D\n\n\n\n\nFigure 1.2: Different dimensional planes - 2D, 3D, 5D - displayed in a grand tour projecting into 2D. Notice that the 5D in 5D always fills out the box (although it does concentrate some in the middle which is typical when projecting from high to low dimensions). Also you can see that the 2D in 5D, concentrates into a line more than the 3D in 5D. This suggests that it is lower dimensional.\n\n\nThe next step is to determine which variables contribute. In the examples just provided, all variables are linearly associated in the 2D and 2D data. You can check this by making a scatterplot matrix.\n\n\nCode\nlibrary(GGally)\nlibrary(mulgar)\ndata(plane)\nggscatmat(plane)\n\n\n\n\n\nFigure 1.3: Scatterplot matrix of plane data. You can see that x1-x3 are strongly linearly associated, and also x4 and x5. When you watch the tour of this data, any time the data collapses into a line you should see only (x1, x2, x3) or (x4, x5). When combinations of x1 and x4 or x5 show, the data should be spread out.\n\n\n\n\nTo make an example where not all variables contribute, we have added two additional variables to the plane data set, which are purely noise.\n\n# Add two pure noise dimensions to the plane\nplane_noise <- plane\nplane_noise$x6 <- rnorm(100)\nplane_noise$x7 <- rnorm(100)\nplane_noise <- data.frame(apply(plane_noise, 2, function(x) (x-mean(x))/sd(x)))\nggduo(plane_noise, columnsX = 1:5, columnsY = 6:7, \n      types = list(continuous = \"points\")) +\n  theme(aspect.ratio=1, axis.text = element_blank())\n\n\n\n\nFigure 1.4: Additional noise variables are not associated with any of the first five variables.\n\n\n\n\nNow we have 2D structure in 7D, but only five of the variables contribute to the 2D structure, that is, five of the variables are linearly related with each other. The other two variables (x6, x7) are not linearly related to any of the others.\nWe can still see the concentration of points along a line in some dimensions, which tells us that the data is not fully 7D. Then if you look closely at the variable axes you will see that the collapsing to a line only occurs when any of x1-x5 contribute strongly in the direction orthogonal to this. This does not happen when x6 or x7 contribute strongly to a projection - the data is always expanded to fill much of the space. That tells us that x6 and x7 don’t substantially contribute to the dimension reduction, that is, they are not linearly related to the other variables.\n\n\nCode\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(htmlwidgets)\n\nset.seed(78)\nb <- basis_random(7, 2)\npn_t <- tourr::save_history(plane_noise, \n                    tour_path = grand_tour(),\n                    start = b,\n                    max_bases = 8)\npn_t <- interpolate(pn_t, 0.1)\npn_anim <- render_anim(plane_noise,\n                         frames=pn_t)\n\npn_gp <- ggplot() +\n     geom_path(data=pn_anim$circle, \n               aes(x=c1, y=c2,\n                   frame=frame), linewidth=0.1) +\n     geom_segment(data=pn_anim$axes, \n                  aes(x=x1, y=y1, \n                      xend=x2, yend=y2, \n                      frame=frame), \n                  linewidth=0.1) +\n     geom_text(data=pn_anim$axes, \n               aes(x=x2, y=y2, \n                   frame=frame, \n                   label=axis_labels), \n               size=5) +\n     geom_point(data=pn_anim$frames, \n                aes(x=P1, y=P2, \n                    frame=frame), \n                alpha=0.8) +\n     xlim(-1,1) + ylim(-1,1) +\n     coord_equal() +\n     theme_bw() +\n     theme(axis.text=element_blank(),\n         axis.title=element_blank(),\n         axis.ticks=element_blank(),\n         panel.grid=element_blank())\npn_tour <- ggplotly(pn_gp,\n                        width=500,\n                        height=550) %>%\n       animation_button(label=\"Go\") %>%\n       animation_slider(len=0.8, x=0.5,\n                        xanchor=\"center\") %>%\n       animation_opts(easing=\"linear\", \n                      transition = 0)\n\nhtmlwidgets::saveWidget(pn_tour,\n          file=\"html/plane_noise.html\",\n          selfcontained = TRUE)\n\n\n\n\n\n\nFigure 1.5: Grand tour of the plane with two additional dimensions of pure noise. The collapsing of the points indicates that this is not fully 7D. This only happens when any of x1-x5 are contributing strongly (frame 49 x4, x5; frame 79 x1; frame 115 x2, x3). If x6 or x7 are contributing strongly the data is spread out fully. This tells us that x6 and x7 are not linearly associated, but other variables are.\n\n\n\nTo determine which variables are responsible for the reduced dimension look for the axes that extend out of the point cloud.\n\nThe simulated data here is very simple, and what we have learned from the tour could also be learned from principal component analysis. However, if there are small complications, such as outliers or nonlinear relationships, that might not be visible from principal component analysis, the tour can help you to see them.\nFigure 1.6 and Figure 1.7 (a) show example data with an outlier and Figure 1.7 (b) shows data with non-linear relationships.\n\n\nCode\n# Add several outliers to the plane_noise data\nplane_noise_outliers <- plane_noise\nplane_noise_outliers[101,] <- c(2, 2, -2, 0, 0, 0, 0)\nplane_noise_outliers[102,] <- c(0, 0, 0,-2, -2, 0, 0)\n\nggscatmat(plane_noise_outliers, columns = 1:5) +\n  theme(aspect.ratio=1, axis.text = element_blank())\n\n\n\n\n\nFigure 1.6: Outliers added to the plane with noise data.\n\n\n\n\n\n\nCode\nrender_gif(plane_noise_outliers,          \n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/pn_outliers.gif\",\n           frames=500,\n           width=200,\n           height=200)\n\ndata(plane_nonlin)\nrender_gif(plane_nonlin,          \n           grand_tour(), \n           display_xy(),\n           gif_file=\"gifs/plane_nonlin.gif\",\n           frames=500,\n           width=200,\n           height=200)\n\n\n\n\n\n\n\n\n\n(a) Outliers in addition to 2D plane.\n\n\n\n\n\n\n\n(b) Non-linear relationship between several variables, primarily x3.\n\n\n\n\nFigure 1.7: Examples of different types of dimensionality issues: outliers and nonlinearity. In the left plot, you can see two points far from the others in some projections. Also the two can be seen with different movement patterns, moving faster that other points during the tour. Outliers will affect detection of reduced dimension, but it is easy to ignore with the tour. Non-linear relationships may not be captured by other techniques but are visible with the tour.\n\n\n\n\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create Interactive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra.\n\n\n\n\n\nIt is generally better to use associated than correlated. Correlated is a statistical quantity, measuring linear association. The term associated can be prefaced with the type of association, such as linear or non-linear.↩︎"
  },
  {
    "objectID": "unsupervised-overview.html#sec-clust-bg",
    "href": "unsupervised-overview.html#sec-clust-bg",
    "title": "4  Overview",
    "section": "4.2 The importance of defining similar",
    "text": "4.2 The importance of defining similar\nBefore we can begin finding groups of cases that are similar1, we need to decide how to define or measure whether they are close together or far apart. Consider a dataset with three cases \\((a_1, a_2, a_3)\\) and four variables \\((V_1, V_2, V_3, V_4)\\), described in matrix format as\n\n\\[\n\\require{mathtools}\n\\definecolor{grey}{RGB}{192, 192, 192}\n\\]\n\n\\[\\begin{align*}\nX = \\begin{bmatrix}\n& {\\color{grey} V_1} & {\\color{grey} V_2} & {\\color{grey} V_3} & {\\color{grey} V_4} \\\\\\hline\n{\\color{grey} a_1} | & x_{11} & x_{12} & x_{13} & x_{14} \\\\\n{\\color{grey} a_2} | & x_{21} & x_{22} & x_{23} & x_{24} \\\\\n{\\color{grey} a_3} | & x_{31} & x_{32} & x_{33} & x_{34}    \n\\end{bmatrix}\n=  \\begin{bmatrix}\n& {\\color{grey} V_1} & {\\color{grey} V_2} & {\\color{grey} V_3} & {\\color{grey} V_4} \\\\\\hline\n{\\color{grey} a_1} | & 7.3 & 7.6 & 7.7 & 8.0 \\\\\n{\\color{grey} a_2} | & 7.4 & 7.2 & 7.3 & 7.2 \\\\\n{\\color{grey} a_3} | & 4.1 & 4.6 & 4.6 & 4.8\n\\end{bmatrix}\n\n\\end{align*}\\]\nwhich is plotted in Figure 4.2. The Euclidean distance between two cases (rows of the matrix) with \\(p\\) elements is defined as\n\\[\\begin{align*}\nd_{\\rm Euc}(a_i,a_j) &=& ||a_i-a_j|| %\\\\\n% &=& \\sqrt{(x_{i1}-x_{j1})^2+\\dots + (x_{ip}-x_{jp})^2},\n~~~~~~i,j=1,\\dots, n,\n\\end{align*}\\]\nwhere \\(||x_i||=\\sqrt{x_{i1}^2+x_{i2}^2+\\dots +x_{ip}^2}\\). For example, the Euclidean distance between cases 1 and 2 in the above data, is\n\\[\\begin{align*}\nd_{\\rm Euc}(a_1,a_2) &= \\sqrt{(7.3-7.4)^2+(7.6-7.2)^2+ (7.7-7.3)^2+(8.0-7.2)^2} \\\\\n&= 1.0\n\\end{align*}\\]\n\nFor the three cases, the interpoint Euclidean distance matrix is\n\\[\\begin{align*}\nd_{\\rm Euc} =\n\\left[ \\begin{array}{ccc}\n0.0  ~&     &   \\\\\n1.0 ~&  0.0 ~  &  \\\\\n6.3 ~& 5.5 ~&  0.0 ~ \\\\\n\\end{array} \\right]\n\\begin{array}{r}\na_1 \\\\ a_2 \\\\ a_3 \\\\\n\\end{array}\n\\end{align*}\\]\n\n\n\n\n\nCode\nx <- tibble::tibble(V1 = c(7.3, 7.4, 4.1),\n                    V2 = c(7.6, 7.2, 4.6),\n                    V3 = c(7.7, 7.3, 4.6),\n                    V4 = c(8.0, 7.2, 4.8),\n                    point = factor(c(\"a1\", \"a2\", \"a3\")))\nlibrary(GGally)\nlibrary(colorspace)\nlibrary(gridExtra)\npscat <- ggpairs(x, columns=1:4,\n                 upper=list(continuous=\"points\"),\n                 diag=list(continuous=\"blankDiag\"),\n                 axisLabels=\"internal\",\n                 ggplot2::aes(colour=point)) +\n    scale_colour_discrete_divergingx(\n      palette = \"Zissou 1\", nmax=4) +\n    xlim(3.7, 8.5) + ylim(3.7, 8.5) +\n    theme(aspect.ratio=1)\npscat\n\n\n\n\n\n\n\n\n\n\n\nCode\nppar <- ggparcoord(x, columns=1:4, \n                   groupColumn = 5, \n                   scale = \"globalminmax\") +\n    scale_colour_discrete_divergingx(\n      palette = \"Zissou 1\", nmax=4) +\n  xlab(\"\") + ylab(\"\") + \n  theme(axis.ticks.y = element_blank(),\n        axis.text.y = element_blank(),\n        legend.title = element_blank())\nppar\n\n\n\n\n\n\nFigure 4.2: The scatterplot matrix (left) shows that cases \\(a_1\\) and \\(a_2\\) have similar values. The parallel coordinate plot (right) allows a comparison of other structure, which shows the similarity in the trend of the profiles on cases \\(a_1\\) and \\(a_3\\).\n\n\nCases \\(a_1\\) and \\(a_2\\) are more similar to each other than they are to case \\(a_3\\), because the Euclidean distance between cases \\(a_1\\) and \\(a_2\\) is much smaller than the distance between cases \\(a_1\\) and \\(a_3\\) and between cases \\(a_2\\) and \\(a_3\\).\nThere are many different ways to calculate similarity. Similarity measures based on correlation distance have become common. Correlation distance is typically used where similarity of structure is more important than similarity in magnitude.\n\nAs an example, see the parallel coordinate plot of the sample data at the right of Figure 4.2. Cases \\(a_1\\) and \\(a_3\\) are widely separated, but their shapes are similar (low, medium, medium, high). Case \\(a_2\\), although overlapping with Case \\(a_1\\), has a very different shape (high, medium, medium, low). The correlation between two cases is defined as\n\\[\\begin{align*}\n\\rho(a_i,a_j) = \\frac{(a_i-c_i)'(a_j-c_j)}\n{\\sqrt{(a_i-c_i)'(a_i-c_i)} \\sqrt{(a_j-c_j)'(a_j-c_j)}}\n\\label{corc}\n\\end{align*}\\]\nWhen \\(c_i, c_j\\) are the sample means \\(\\bar{a}_i,\\bar{a}_j\\), then \\(\\rho\\) is the Pearson correlation coefficient. If, indeed, they are set at 0, as is commonly done, \\(\\rho\\) is a generalized correlation that describes the angle between the two data vectors. The correlation is then converted to a distance metric; one equation for doing so is as follows:\n\\[\\begin{align*}\nd_{\\rm Cor}(a_i,a_j) = \\sqrt{2(1-\\rho(a_i,a_j))}\n\\end{align*}\\]\nThe above distance metric will treat cases that are strongly negatively correlated as the most distant.\nThe interpoint distance matrix for the sample data using \\(d_{\\rm Cor}\\) and the Pearson correlation coefficient is\n\\[\\begin{align*}\nd_{\\rm Cor} =\n\\left[ \\begin{array}{rrrrrrrrr}\n0.0  ~&     &  \\\\\n3.6 ~ & 0.0 ~ &  \\\\\n0.1 ~ & 3.8 ~ &  0.0 ~\\\\\n\\end{array} \\right]\n\\begin{array}{r}\na_1 \\\\ a_2 \\\\ a_3 \\\\\n\\end{array}\n\\end{align*}\\]\nBy this metric, cases \\(a_1\\) and \\(a_3\\) are the most similar, because the correlation distance is smaller between these two cases than the other pairs of cases. \nNote that these interpoint distances differ dramatically from those for Euclidean distance. As a consequence, the way the cases would be clustered is also be very different. Choosing the appropriate distance measure is an important part of a cluster analysis.\nAfter a distance metric has been chosen and a cluster analysis has been performed, the analyst must evaluate the results, and this is actually a difficult task. A cluster analysis does not generate \\(p\\)-values or other numerical criteria, and the process tends to produce hypotheses rather than testing them. Even the most determined attempts to produce the “best” results using modeling and validation techniques may result in clusters that, although seemingly significant, are useless for practical purposes. As a result, cluster analysis is best thought of as an exploratory technique, and it can be quite useful despite the lack of formal validation because of its power in data simplification.\n\nDefining an appropriate distance metric is a vitally important decision.\n\nThe context in which the data arises is the key to assessing the results. If the clusters can be characterized in a sensible manner, and they increase our knowledge of the data, then we are on the right track. To use an even more pragmatic criterion, if a company can gain an economic advantage by using a particular clustering method to carve up their customer database, then that is the method they should use."
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Appendix C — Glossary",
    "section": "",
    "text": "Term\n      Synonyms\n      Description\n    \n  \n  \n    variable\nfeature, attribute\na characteristic, number or quantity that can be measured\n    observations\ncases, items, experimental units, observational units, records, statistical units, instances, examples\nindividuals on which the observations are made\n    data set\n-\ncollection of observations made on one or more variables\n    response\ntarget\nvariable that one wishes to predict\n    predictor\nindependent variable, feature\nvariables used to produce a mode to predict the response\n    similarity\ncorrelation\na measure ranging between 0 and 1, with 1 indicating that the cases are closer\n    dissimilarity\ndistance\na measure where a smaller number means the cases are closer\n    PCA\n-\nprincipal component analysis\n    LDA\n-\nlinear discriminant analysis\n    SOM\n-\nself-organising map\n  \n  \n  \n\n\n\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBoelaert, Julien, Etienne Ollion, and Jan Sodoge. 2022. aweSOM: Interactive Self-Organizing Maps. https://CRAN.R-project.org/package=aweSOM.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nde Vries, Andrie, and Brian D. Ripley. 2022. Ggdendro: Create Dendrograms and Tree Diagrams Using Ggplot2. https://github.com/andrie/ggdendro.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2023. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2023. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIannone, Richard, Joe Cheng, Barret Schloerke, Ellis Hughes, and JooYoung Seo. 2022. Gt: Easily Create Presentation-Ready Display Tables. https://CRAN.R-project.org/package=gt.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2023. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2022. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMock, Thomas. 2022. gtExtras: Extending Gt for Beautiful HTML Tables. https://CRAN.R-project.org/package=gtExtras.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2022. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2023. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2023. Plotly: Create Interactive Web Graphics via Plotly.js.\n\n\nSjoberg, Daniel D., Joseph Larmarange, Michael Curry, Jessica Lavery, Karissa Whiting, and Emily C. Zabor. 2023. Gtsummary: Presentation-Ready Data Summary and Analytic Result Tables. https://CRAN.R-project.org/package=gtsummary.\n\n\nSjoberg, Daniel D., Karissa Whiting, Michael Curry, Jessica A. Lavery, and Joseph Larmarange. 2021. “Reproducible Summary Tables with the Gtsummary Package.” The R Journal 13: 570–80. https://doi.org/10.32614/RJ-2021-053.\n\n\nSlowikowski, Kamil. 2023. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2023. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2023. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "svm.html",
    "href": "svm.html",
    "title": "14  Support vector machine",
    "section": "",
    "text": "A support vector machine (SVM) (Vapnik 1999) looks for gaps between clusters in the data, based on the extreme observations in each class. In this sense it mirrors the graphical approach described Chapter 6, in which we searched for gaps between groups. It can be viewed as similar to LDA, in that the boundary between classes is a hyper-plane. The difference between LDA and SVM is the placement of the boundary. LDA uses the means and covariance matrices of the classes to place the boundary, but SVM uses extreme observations.\nTo illustrate the approach, we use two simple simulated data examples. Both have only two variables, and two classes. Explaining SVM is easier when there are just two groups. In the first data set the two classes have different covariances matrices, which will cause trouble for LDA, but SVM should see the gap between the two clusters and place the separating hyper-plane in the middle of the gap. In the second data set the two groups are concentric circles, with the inner one solid. A non-linear SVM should be fitted to this data, which should see circular gap between the two classes.\nNote that the svm function in the e1071 package will automatically scale observations into the range \\([0,1]\\). To make it easier to examine the fitted model, it is best to scale your data first, and then fit the model.\n\n\nCode\n# Toy examples\nlibrary(mulgar)\nlibrary(ggplot2)\nset.seed(1071)\nn1 <- 162\nvc1 <- matrix(c(1, -0.7, -0.7, 1), ncol=2, byrow=TRUE)\nc1 <- rmvn(n=n1, p=2, mn=c(-2, -2), vc=vc1)\nvc2 <- matrix(c(1, -0.4, -0.4, 1)*2, ncol=2, byrow=TRUE)\nn2 <- 138\nc2 <- rmvn(n=n2, p=2, mn=c(2, 2), vc=vc2)\ndf1 <- data.frame(x1=mulgar:::rescale01(c(c1[,1], c2[,1])), \n                 x2=mulgar:::rescale01(c(c1[,2], c2[,2])), \n                 cl = factor(c(rep(\"A\", n1), \n                               rep(\"B\", n2))))\nlibrary(geozoo)\nc1 <- sphere.hollow(p=2, n=n1)$points*3 + \n  c(rnorm(n1, sd=0.3), rnorm(n1, sd=0.3))\nc2 <- sphere.solid.random(p=2, n=n2)$points\ndf2 <- data.frame(x1=mulgar:::rescale01(c(c1[,1], c2[,1])), \n                  x2=mulgar:::rescale01(c(c1[,2], c2[,2])), \n                  cl = factor(c(rep(\"A\", n1), \n                               rep(\"B\", n2))))\n\n\n\nlibrary(classifly)\nlibrary(e1071)\ndf1_svm <- svm(cl~., data=df1, \n                     probability=TRUE, \n                     kernel=\"linear\")\n#df1_svm <- ksvm(cl~., data=df1, \n#                     probability=TRUE,\n#                     kernel=\"vanilladot\")\ndf1_svm_e <- explore(df1_svm, df1)\n\ns1 <- ggplot() + \n  geom_point(data=df1, aes(x=x1, y=x2, colour=cl),\n             shape=20) +\n  scale_colour_viridis_d(\"\", begin=0.3, end=0.8) +\n  geom_point(data=df1_svm_e[(!df1_svm_e$.BOUNDARY)&(df1_svm_e$.TYPE==\"simulated\"),], \n             aes(x=x1, y=x2, colour=cl), shape=3) +\n  geom_point(data=df1[df1_svm$index,], \n             aes(x=x1, y=x2, colour=cl), \n             shape=4, size=4) +\n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position = \"none\") +\n  ggtitle(\"(a)\")\n\ndf2_svm <- svm(cl~., data=df2,  \n                     probability=TRUE, \n                     kernel=\"radial\")\ndf2_svm_e <- explore(df2_svm, df2)\ns2 <- ggplot() + \n  geom_point(data=df2, aes(x=x1, y=x2, colour=cl), shape=20) +\n  scale_colour_viridis_d(\"\", begin=0.3, end=0.8) +\n  geom_point(data=df2_svm_e[(!df2_svm_e$.BOUNDARY)&(df2_svm_e$.TYPE==\"simulated\"),], \n             aes(x=x1, y=x2, colour=cl), \n             shape=3) +\n  geom_point(data=df2[df2_svm$index,], \n             aes(x=x1, y=x2, colour=cl), \n             shape=4, size=4) +\n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position = \"none\") +\n  ggtitle(\"(b)\")\n\nlibrary(patchwork)\ns1+s2\n\n\n\n\nFigure 14.1: SVM classifier fit overlaid on two simulated data examples: (a) groups with different variance-covariance, fitted using a linear kernel, (b) groups with non-linear separation, fitted using a radial kernel. The band of points shown as ‘+’ mark the SVM boundary, and points marked by ‘x’ are the support vectors used to define the boundary.\n\n\n\n\nFigure 14.1 shows the two data sets and the important aspects of the fitted SVM model for each. The observations are represented by dots, the separating hyper-plane (just a line for 2D) is represented by ‘+’. Where the two colours merge is the actual location of the boundary between classes. It can be seen that this is located right down the middle of the gap, for both data sets. Even though the boundary is circular for the second data set, in a transformed high-dimensional space it would be linear.\nSVMs use a subset of the observations to define the boundary, and these are called the support vectors. For each of the data sets these are marked with ‘x’. For the linear boundary, there are nine support vectors, five in one group and four in the other. There is one interesting observation in the green group, which falls far from its group and on the other side of the boundary with the blue points. It is marked as a support vector, but its contribution to the fitted hyper-plane is limited by a control parameter in the model fitting process. \nObservations 15, 45, 123, 135, 155, 180, 202, 239, 292 are the support vectors. All but 15, 45 and 180 are actually bounded support vectors, which means their coefficients are bounded to magnitude 1. \n\nThe key elements of the SVM model to examine are:\n\nsupport vectors\nseparating hyper-plane.\n\n\nFor higher dimensions,\n\n\n\n\n\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer."
  },
  {
    "objectID": "pca.html#example-aflw",
    "href": "pca.html#example-aflw",
    "title": "3  Principal component analysis (PCA)",
    "section": "3.2 Example: AFLW",
    "text": "3.2 Example: AFLW\nWe’ll use the AFLW data as the example. This data has player statistics for all the matches in the 2021 season. We would be interested to know which variables contain similar information, and thus might be combined into single variables. We would expect that many statistics to group into a few small sets, such as offensive and defensive skills. We might also expect that some of the statistics are skewed, most players have low values and just a handful of players are stellar. It is also possible that there are some extreme values. These are interesting features, but they will distract from the main purpose of grouping the statistics. Thus the tour is used to check for potential problems with the data prior to conducting PCA.\n\nlibrary(tourr)\ndata(aflw)\naflw_std <- aflw %>%\n  mutate_if(is.numeric, function(x) (x-\n      mean(x, na.rm=TRUE))/\n      sd(x, na.rm=TRUE))\n\nTo look at all of the 29 player statistics in a grand tour use the animate_xy() function as follows:\n\nanimate_xy(aflw_std[,7:35], half_range=0.9)\n\n\n\nCode\nrender_gif(aflw_std[,7:35], \n           grand_tour(), \n           display_xy(half_range=0.9),\n           gif_file=\"gifs/aflw_gt.gif\",\n           frames=500,\n           loop=FALSE)\n\n\nThe gif here is the saved version of the grand tour, made using the render_gif() function.\n\n\n\nFigure 3.3: Grand tour of the AFLW player statistics\n\n\nNo major surprises! There is a small amount of skewness, and there are no major outliers. Skewness indicates that most players have reasonably similar skills (bunching of points), except for some key players (the moderate outliers). The skewness could be reduced by applying a log or square root transformation to some variables prior to running the PCA. However, we elect not to do this because the moderate outliers are of interest. These correspond to talented players that we’d like to explore further with the analysis.\nBelow we have the conventional summary of the PCA, a scree plot showing the reduction in variance to be explained when each additional PC is considered. It is also conventional to look at a table summarising the proportions of variance explained by PCs, but with 30 variables it is easier to make some decision on the number of PCs needed based on the scree plot.\n\n\nCode\naflw_pca <- prcomp(aflw_std[,7:35], \n               scale = FALSE, \n               retx=TRUE)\n\nggscree(aflw_pca)\n\n\n\n\n\nFigure 3.4: Scree plot showing decay in variance of PCs.\n\n\n\n\nFrom the scree plot in Figure 3.4, we see a sharp drop from one to two, two to three and then smaller drops. After four PCs the variance drops again at six PCs and then gradually decays. We will choose four PCs to examine more closely. This explains 67.2% of the variance.\n\n\nCode\nlibrary(gt)\naflw_pca$rotation[,1:4] %>%\n  as_tibble(rownames=\"Variable\") %>% \n  arrange(desc(PC1), desc(PC2), desc(PC3)) %>%\n  gt() %>%\n  fmt_number(columns = c(PC1, PC2, PC3, PC4),\n             decimals = 2)\n\n\n\n\n\n\nTable 3.4:  Coefficients for the first four PCs. \n  \n  \n    \n      Variable\n      PC1\n      PC2\n      PC3\n      PC4\n    \n  \n  \n    disposals\n0.31\n−0.05\n−0.03\n0.07\n    possessions\n0.31\n−0.03\n−0.07\n0.09\n    kicks\n0.29\n−0.04\n0.09\n−0.12\n    metres\n0.28\n−0.03\n0.10\n−0.15\n    contested\n0.28\n0.01\n−0.12\n0.23\n    uncontested\n0.28\n−0.06\n−0.01\n−0.05\n    turnovers\n0.27\n−0.01\n−0.01\n−0.29\n    clearances\n0.23\n0.00\n−0.29\n0.19\n    clangers\n0.23\n−0.02\n−0.06\n−0.33\n    handballs\n0.23\n−0.04\n−0.19\n0.31\n    frees_for\n0.21\n0.02\n−0.13\n0.18\n    marks\n0.21\n0.03\n0.32\n0.02\n    tackles\n0.20\n0.01\n−0.28\n0.09\n    time_pct\n0.16\n−0.04\n0.35\n−0.02\n    intercepts\n0.13\n−0.28\n0.24\n0.03\n    rebounds_in50\n0.13\n−0.28\n0.24\n−0.06\n    frees_against\n0.13\n0.03\n−0.16\n−0.23\n    assists\n0.09\n0.23\n0.00\n0.05\n    bounces\n0.09\n0.03\n0.02\n−0.28\n    behinds\n0.09\n0.32\n0.08\n−0.02\n    shots\n0.08\n0.38\n0.12\n−0.03\n    tackles_in50\n0.07\n0.27\n−0.18\n0.03\n    marks_in50\n0.06\n0.34\n0.18\n0.04\n    contested_marks\n0.05\n0.16\n0.34\n0.15\n    goals\n0.04\n0.37\n0.16\n0.03\n    accuracy\n0.04\n0.34\n0.10\n0.06\n    one_pct\n0.03\n−0.21\n0.33\n0.08\n    disposal\n0.02\n−0.13\n0.20\n0.50\n    hitouts\n−0.04\n0.00\n−0.03\n0.32\n  \n  \n  \n\n\n\n\n\nWhen there are as many variables as this, it can be hard to digest the combinations of variables most contributing to each PC. Rearranging the table by sorting on a selected PC can help. Table 3.4 has been sorted according to the PC 1 coefficients.\nPC 1 is primarily composed of disposals, possessions, kicks, metres, uncontested, contested, …. Actually almost all variables positively contribute, albeit in different amounts! It is quite common in PCA for the first PC to be a combination of all variables, although it might commonly be a closer to equal contribution, and it tells us that there is one main direction of variation in the data. For PC 1 in the AFLW data, PCA is telling us that the primary variation is through a combination of skills, and this maps to basic football playing skills, where some skills (e.g. disposals, possessions, kicks, …) are more important.\nThus the second PC might be the more interesting. PC 2 is primarily a combination of shots, goals, marks_in50, accuracy, and behinds contrasted against rebounds_in50 and intercepts. The negative coefficients are primary offensive skills and the positive coefficients are defensive skills. This PC is reasonable measure of the offensive vs defensive skills of a player.\nWe would continue to interpret each PC by examining large coefficients to help decide how many PCs are a suitable summary of the information in the data. Briefly, PC 3 is a measure of worth of the player because time_pct has a large coefficient, so players that are on the field longer will contribute strongly to this new variable. It also has large (and opposite) contributions from clearances, tackles, contested_marks. PC 4 appears to be related to aggressive play with clangers, turnovers, bounces and frees_against featuring. So all four PCs have useful information. (Note, if we had continued to examine large coefficients on PC 5 we would find that all variables already have had reasonably large coefficients on PC 1-4, which supports restricting attention to the first four.)\n\nIdeally, when we tour the four PCs, we’d like to be able to stop and identify players. This involves creating a pre-computed animation, with additional mouse-over. This is only feasible with a small number of observations, like the AFLW data, because all of the animation frames are constructed in a single object and passed to plotly. This object gets large very quickly!\n\n\nCode\nlibrary(plotly)\nlibrary(htmlwidgets)\nset.seed(20)\nb <- basis_random(4, 2)\naflw_pct <- tourr::save_history(aflw_pca$x[,1:4], \n                    tour_path = grand_tour(),\n                    start = b,\n                    max_bases = 5)\n# To reconstruct projected data plots, later\nsave(aflw_pct, file=\"data/aflw_pct.rda\") \naflw_pcti <- interpolate(aflw_pct, 0.1)\naflw_anim <- render_anim(aflw_pca$x[,1:4],\n                         frames=aflw_pcti, \n             obs_labels=paste0(aflw$surname,\n                               aflw$given_name))\n\naflw_gp <- ggplot() +\n     geom_path(data=aflw_anim$circle, \n               aes(x=c1, y=c2,\n                   frame=frame), linewidth=0.1) +\n     geom_segment(data=aflw_anim$axes, \n                  aes(x=x1, y=y1, \n                      xend=x2, yend=y2, \n                      frame=frame), \n                  linewidth=0.1) +\n     geom_text(data=aflw_anim$axes, \n               aes(x=x2, y=y2, \n                   frame=frame, \n                   label=axis_labels), \n               size=5) +\n     geom_point(data=aflw_anim$frames, \n                aes(x=P1, y=P2, \n                    frame=frame, \n                    label=obs_labels), \n                alpha=0.8) +\n     xlim(-1,1) + ylim(-1,1) +\n     coord_equal() +\n     theme_bw() +\n     theme(axis.text=element_blank(),\n         axis.title=element_blank(),\n         axis.ticks=element_blank(),\n         panel.grid=element_blank())\naflw_pctour <- ggplotly(aflw_gp,\n                        width=500,\n                        height=550) %>%\n       animation_button(label=\"Go\") %>%\n       animation_slider(len=0.8, x=0.5,\n                        xanchor=\"center\") %>%\n       animation_opts(easing=\"linear\", transition = 0)\n\nhtmlwidgets::saveWidget(aflw_pctour,\n          file=\"html/aflw_pca.html\",\n          selfcontained = TRUE)\n\n\n\n\n\n\nFigure 3.5: Animation of AFLW four PCs with interactive labelling.\n\n\n\n\n\nFrom Figure 3.5 the shape of the four PCs is similar to that of all the variables, bunching of points in the centre with a lot of moderate outliers.\n\n\nCode\nlibrary(plotly)\nload(\"data/aflw_pct.rda\")\naflw_pcti <- interpolate(aflw_pct, 0.1)\nf18 <- matrix(aflw_pcti[,,18], ncol=2)\np18 <- render_proj(aflw_pca$x[,1:4], f18, \n                   obs_labels=paste0(aflw$surname,\n                               aflw$given_name))\npg18 <- ggplot() +\n  geom_path(data=p18$circle, aes(x=c1, y=c2)) +\n  geom_segment(data=p18$axes, aes(x=x1, y=y1, xend=x2, yend=y2)) +\n  geom_text(data=p18$axes, aes(x=x2, y=y2, label=rownames(p18$axes))) +\n  geom_point(data=p18$data_prj, aes(x=P1, y=P2, label=obs_labels)) +\n  xlim(-1,1) + ylim(-1, 1) +\n  ggtitle(\"Frame 18\") +\n  theme_bw() +\n  theme(aspect.ratio=1,\n    axis.text=element_blank(),\n    axis.title=element_blank(),\n    axis.ticks=element_blank(),\n    panel.grid=element_blank())\nggplotly(pg18, width=650, height=650)\n\n\n\n\n\nFigure 3.6: Frame 18 replotted so that players can be identified on mouseover.\n\n\n\nFor any particular frame, like 18 re-plotted in Figure 3.6, we can investigate further. Here there is a branching pattern, where the branch points in the direction of PC 1. Mouseover the players at the tip of this branch and we find players like Alyce Parker, Brittany Bonnici, Dana Hooker, Kiara Bowers. If you look up the bios of these players you’ll find they all have generally good player descriptions like “elite disposals”, “powerful left foot”, “hard-running midfielder”, “best and fairest”.\nIn the direction of PC 2, you’ll find players like Lauren Ahrens, Stacey Livingstone who are star defenders. Players in this end of PC 1, have high scores on intercepts and rebounds_in50.\nAnother interesting frame for inspecting PC 2 is 59. PC 2 at one end has players with high goal scoring skills, and the other good defending skills. So mousing over the other end of PC 2 finds players like Gemma Houghton and Katie Brennan who are known for their goal scoring. The branch pattern is an interesting one, because it tells us there is some combination of skills that are lacking among all players, primarily this appears to be there some distinction between defenders skills and general playing skills. It’s not as simple as this because the branching is only visible when PC 1 and PC 2 are examined with PC 3.\nPCA is useful for getting a sense of the variation in a high-dimensional data set. Interpreting the principal components is often useful, but it can be discombobulating. For the AFLW data it would be good to think about it as a guide to the main directions of variation and to follow with a more direct engineering of variables into interesting player characteristics. For example, calculate offensive skill as an equal combination of goals, accuracy, shots, behinds. A set of new variables specifically computed to measure particular skills would make explaining an analysis easier.\n\n3.2.1 Model in the data space\n\n\nCode\ndata(pisa)\npisa_std <- apply(pisa[,-1], 2, function(x) (x-mean(x))/sd(x))[sample(1:nrow(pisa), 1000),c(1:5, 11:15, 21:25)]\npisa_pca <- prcomp(pisa_std)\nggscree(pisa_pca)\nanimate_xy(pisa_std, half_range=1)\n\npisa_model <- pca_model(pisa_pca, d=1, s=2)\n\npisa_all <- rbind(pisa_model$points, pisa_std)\nanimate_xy(pisa_all, edges=pisa_model$edges, edges.col=\"orange\")\nrender_gif(pisa_all, \n           grand_tour(), \n           display_xy(half_range=0.9,\n                      edges=pisa_model$edges, \n                      edges.col=\"orange\"),\n           gif_file=\"gifs/pisa_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\n\n\n\n\nFigure 3.7: PCA model of the PISA data"
  },
  {
    "objectID": "pca.html#introduction-to-pca-analysis",
    "href": "pca.html#introduction-to-pca-analysis",
    "title": "2  Principal component analysis",
    "section": "2.1 Introduction to PCA analysis",
    "text": "2.1 Introduction to PCA analysis\nWe would start by examining the data using a grand tour. The goal is to check whether there might be potential issues for PCA, such as skewness, outliers or clustering, or even non-linear dependencies.\nWe’ll start be showing PCA on the simulated from Chapter 1. The scree plots show that PCA supports that the data are 2D, 3D and 5D respectively.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(mulgar)\ndata(plane)\ndata(box)\nlibrary(geozoo)\ncube5d <- data.frame(cube.solid.random(p=5, n=300)$points)\ncolnames(cube5d) <- paste0(\"x\", 1:5)\ncube5d <- data.frame(apply(cube5d, 2, function(x) (x-mean(x))/sd(x)))\np_pca <- prcomp(plane)\nb_pca <- prcomp(box)\nc_pca <- prcomp(cube5d)\np_scree <- ggscree(p_pca)\nb_scree <- ggscree(b_pca)\nc_scree <- ggscree(c_pca)\n\n\n\n\n\n\n\n\n\n(a) 2D in 5D\n\n\n\n\n\n\n\n\n\n(b) 3D in 5D\n\n\n\n\n\n\n\n\n\n(c) fully 5D\n\n\n\n\n\nFigure 2.1: Scree plots for the three simulated data sets. The 2D in 5D is clearly recognised by PCA to be 2D because the variance drops substantially between 2-3 principal components. The 3D in 5D is possibly 3D because the variance drops from 3-4 principal components. The fully 5D data has no drop in variance, and all values are close to the typical value one would observe if the data was fully 5D.\n\n\nThe next step is to look at the coefficients for the selected number of PCs. Table 2.1 shows the coefficients for the first two PCs of the plane data. All five variables contribute, with x1, x2, x3 contributing more to PC1, and x4, x5 contributing more to PC2. Table 2.2 shows the coefficients for the first three PCs. Variables x1, x2, x3 contribute strongly to PC1, PC2 has contributions from all variables except x3 and variables x4 and x5 contribute strongly to PC3.\n\n\nCode\nlibrary(gt)\np_pca$rotation[,1:2] %>%\n  as_tibble(rownames=\"Variable\") %>% \n  gt() %>%\n  fmt_number(columns = c(PC1, PC2),\n             decimals = 2)\n\n\n\n\n\n\nTable 2.1:  Coefficients for the first two PCs for the plane data. \n  \n  \n    \n      Variable\n      PC1\n      PC2\n    \n  \n  \n    x1\n0.58\n−0.06\n    x2\n−0.55\n0.21\n    x3\n0.47\n−0.41\n    x4\n0.25\n0.64\n    x5\n−0.29\n−0.62\n  \n  \n  \n\n\n\n\n\n\n\nCode\nb_pca$rotation[,1:3] %>%\n  as_tibble(rownames=\"Variable\") %>% \n  gt() %>%\n  fmt_number(columns = c(PC1, PC2, PC3),\n             decimals = 2)\n\n\n\n\n\n\nTable 2.2:  Coefficients for the first three PCs for the box data. \n  \n  \n    \n      Variable\n      PC1\n      PC2\n      PC3\n    \n  \n  \n    x1\n−0.51\n0.46\n−0.11\n    x2\n0.51\n0.46\n0.00\n    x3\n−0.65\n−0.09\n−0.23\n    x4\n−0.22\n0.36\n0.87\n    x5\n0.02\n0.66\n−0.43\n  \n  \n  \n\n\n\n\n\nIn each of these simulated data sets, all five variables contributed to the dimension reduction. If we added two purely noise variables to the plane data, as done in Chapter 1, the scree plot would indicate that the data is now 4D, and we would get a different interpretation of the coefficients from the PCA. We see that PC1 and PC2 are approximately the same as before, with main variables being (x1, x2, x3) and (x4, x5) respectively. PC3 and PC4 are both x6 and x7.\n\nplane_noise <- plane\nplane_noise$x6 <- rnorm(100)\nplane_noise$x7 <- rnorm(100)\nplane_noise <- data.frame(apply(plane_noise, 2, function(x) (x-mean(x))/sd(x)))\n\npn_pca <- prcomp(plane_noise)\nggscree(pn_pca)\n\n\n\n\nFigure 2.2: Additional noise variables expands the data to 4D.\n\n\n\n\n\n\nCode\npn_pca$rotation[,1:4] %>%\n  as_tibble(rownames=\"Variable\") %>% \n  gt() %>%\n  fmt_number(columns = c(PC1, PC2, PC3, PC4),\n             decimals = 2)\n\n\n\n\n\n\nTable 2.3:  Coefficients for the first four PCs for the box data. \n  \n  \n    \n      Variable\n      PC1\n      PC2\n      PC3\n      PC4\n    \n  \n  \n    x1\n0.57\n−0.06\n−0.03\n0.05\n    x2\n−0.55\n0.22\n0.03\n−0.05\n    x3\n0.46\n−0.41\n0.03\n0.10\n    x4\n0.25\n0.63\n−0.07\n0.05\n    x5\n−0.29\n−0.61\n0.05\n−0.05\n    x6\n−0.14\n−0.05\n−0.55\n0.82\n    x7\n−0.02\n0.06\n0.83\n0.55\n  \n  \n  \n\n\n\n\n\n\n2.1.1 Example: aflw\nWe’ll use the aflw data as the example. This data has player statistics for all the matches in the 2021 season. We would be interested to know which variables contain similar information, and thus might be combined into single variables. We would expect that many statistics to group into a few small sets, such as offensive and defensive skills. We might also expect that some of the statistics are skewed, most players have low values and just a handful of players are stellar. It is also possible that there are some extreme values. These are interesting features, but they will distract from the main purpose of grouping the statistics. Thus the tour is used to check for potential problems with the data prior to conducting PCA.\n\nlibrary(tourr)\ndata(aflw)\naflw_std <- aflw %>%\n  mutate_if(is.numeric, function(x) (x-\n      mean(x, na.rm=TRUE))/\n      sd(x, na.rm=TRUE))\n\nTo look at all of the 29 player statistics in a grand tour use the animate_xy() function as follows:\n\nanimate_xy(aflw_std[,7:35], half_range=0.9)\n\n\n\nCode\nrender_gif(aflw_std[,7:35], \n           grand_tour(), \n           display_xy(half_range=0.9),\n           gif_file=\"gifs/aflw_gt.gif\",\n           frames=500,\n           loop=FALSE)\n\n\nThe gif here is the saved version of the grand tour, made using the render_gif() function.\n\n\n\nFigure 2.3: Grand tour of the AFLW player statistics\n\n\nNo major surprises! There is a small amount of skewness, and there are no major outliers. Skewness indicates that most players have reasonably similar skills (bunching of points), except for some key players (the moderate outliers). The skewness could be reduced by applying a log or square root transformation to some variables prior to running the PCA. However, we elect not to do this because the moderate outliers are of interest. These correspond to talented players that we’d like to explore further with the analysis.\nBelow we have the conventional summary of the PCA, a scree plot showing the reduction in variance to be explained when each additional PC is considered. It is also conventional to look at a table summarising the proportions of variance explained by PCs, but with 30 variables it is easier to make some decision on the number of PCs needed based on the scree plot.\n\n\nCode\naflw_pca <- prcomp(aflw_std[,7:35], \n               scale = FALSE, \n               retx=TRUE)\n\nggscree(aflw_pca)\n\n\n\n\n\nFigure 2.4: Scree plot showing decay in variance of PCs.\n\n\n\n\nFrom the scree plot in Figure 2.4, we see a sharp drop from one to two, two to three and then smaller drops. After four PCs the variance drops again at six PCs and then gradually decays. We will choose four PCs to examine more closely. This explains 67.2% of the variance.\n\n\nCode\nlibrary(gt)\naflw_pca$rotation[,1:4] %>%\n  as_tibble(rownames=\"Variable\") %>% \n  arrange(desc(PC1), desc(PC2), desc(PC3)) %>%\n  gt() %>%\n  fmt_number(columns = c(PC1, PC2, PC3, PC4),\n             decimals = 2)\n\n\n\n\n\n\nTable 2.4:  Coefficients for the first four PCs. \n  \n  \n    \n      Variable\n      PC1\n      PC2\n      PC3\n      PC4\n    \n  \n  \n    disposals\n0.31\n−0.05\n−0.03\n0.07\n    possessions\n0.31\n−0.03\n−0.07\n0.09\n    kicks\n0.29\n−0.04\n0.09\n−0.12\n    metres\n0.28\n−0.03\n0.10\n−0.15\n    contested\n0.28\n0.01\n−0.12\n0.23\n    uncontested\n0.28\n−0.06\n−0.01\n−0.05\n    turnovers\n0.27\n−0.01\n−0.01\n−0.29\n    clearances\n0.23\n0.00\n−0.29\n0.19\n    clangers\n0.23\n−0.02\n−0.06\n−0.33\n    handballs\n0.23\n−0.04\n−0.19\n0.31\n    frees_for\n0.21\n0.02\n−0.13\n0.18\n    marks\n0.21\n0.03\n0.32\n0.02\n    tackles\n0.20\n0.01\n−0.28\n0.09\n    time_pct\n0.16\n−0.04\n0.35\n−0.02\n    intercepts\n0.13\n−0.28\n0.24\n0.03\n    rebounds_in50\n0.13\n−0.28\n0.24\n−0.06\n    frees_against\n0.13\n0.03\n−0.16\n−0.23\n    assists\n0.09\n0.23\n0.00\n0.05\n    bounces\n0.09\n0.03\n0.02\n−0.28\n    behinds\n0.09\n0.32\n0.08\n−0.02\n    shots\n0.08\n0.38\n0.12\n−0.03\n    tackles_in50\n0.07\n0.27\n−0.18\n0.03\n    marks_in50\n0.06\n0.34\n0.18\n0.04\n    contested_marks\n0.05\n0.16\n0.34\n0.15\n    goals\n0.04\n0.37\n0.16\n0.03\n    accuracy\n0.04\n0.34\n0.10\n0.06\n    one_pct\n0.03\n−0.21\n0.33\n0.08\n    disposal\n0.02\n−0.13\n0.20\n0.50\n    hitouts\n−0.04\n0.00\n−0.03\n0.32\n  \n  \n  \n\n\n\n\n\nWhen there are as many variables as this, it can be hard to digest the combinations of variables most contributing to each PC. Rearranging the table by sorting on a selected PC can help. Table 2.4 has been sorted according to the PC 1 coefficients.\nPC 1 is primarily composed of disposals, possessions, kicks, metres, uncontested, contested, …. Actually almost all variables positively contribute, albeit in different amounts! It is quite common in PCA for the first PC to be a combination of all variables, although it might commonly be a closer to equal contribution, and it tells us that there is one main direction of variation in the data. For PC 1 in the AFLW data, PCA is telling us that the primary variation is through a combination of skills, and this maps to basic football playing skills, where some skills (e.g. disposals, possessions, kicks, …) are more important.\nThus the second PC might be the more interesting. PC 2 is primarily a combination of shots, goals, marks_in50, accuracy, and behinds contrasted against rebounds_in50 and intercepts. The negative coefficients are primary offensive skills and the positive coefficients are defensive skills. This PC is reasonable measure of the offensive vs defensive skills of a player.\nWe would continue to interpret each PC by examining large coefficients to help decide how many PCs are a suitable summary of the information in the data. Briefly, PC 3 is a measure of worth of the player because time_pct has a large coefficient, so players that are on the field longer will contribute strongly to this new variable. It also has large (and opposite) contributions from clearances, tackles, contested_marks. PC 4 appears to be related to aggressive play with clangers, turnovers, bounces and frees_against featuring. So all four PCs have useful information. (Note, if we had continued to examine large coefficients on PC 5 we would find that all variables already have had reasonably large coefficients on PC 1-4, which supports restricting attention to the first four.)\n\nIdeally, when we tour the four PCs, we’d like to be able to stop and identify players. This involves creating a pre-computed animation, with additional mouse-over. This is only feasible with a small number of observations, like the AFLW data, because all of the animation frames are constructed in a single object and passed to plotly. This object gets large very quickly!\n\n\nCode\nlibrary(plotly)\nlibrary(htmlwidgets)\nset.seed(20)\nb <- basis_random(4, 2)\naflw_pct <- tourr::save_history(aflw_pca$x[,1:4], \n                    tour_path = grand_tour(),\n                    start = b,\n                    max_bases = 5)\n# To reconstruct projected data plots, later\nsave(aflw_pct, file=\"data/aflw_pct.rda\") \naflw_pcti <- interpolate(aflw_pct, 0.1)\naflw_anim <- render_anim(aflw_pca$x[,1:4],\n                         frames=aflw_pcti, \n             obs_labels=paste0(aflw$surname,\n                               aflw$given_name))\n\naflw_gp <- ggplot() +\n     geom_path(data=aflw_anim$circle, \n               aes(x=c1, y=c2,\n                   frame=frame), linewidth=0.1) +\n     geom_segment(data=aflw_anim$axes, \n                  aes(x=x1, y=y1, \n                      xend=x2, yend=y2, \n                      frame=frame), \n                  linewidth=0.1) +\n     geom_text(data=aflw_anim$axes, \n               aes(x=x2, y=y2, \n                   frame=frame, \n                   label=axis_labels), \n               size=5) +\n     geom_point(data=aflw_anim$frames, \n                aes(x=P1, y=P2, \n                    frame=frame, \n                    label=obs_labels), \n                alpha=0.8) +\n     xlim(-1,1) + ylim(-1,1) +\n     coord_equal() +\n     theme_bw() +\n     theme(axis.text=element_blank(),\n         axis.title=element_blank(),\n         axis.ticks=element_blank(),\n         panel.grid=element_blank())\naflw_pctour <- ggplotly(aflw_gp,\n                        width=500,\n                        height=550) %>%\n       animation_button(label=\"Go\") %>%\n       animation_slider(len=0.8, x=0.5,\n                        xanchor=\"center\") %>%\n       animation_opts(easing=\"linear\", transition = 0)\n\nhtmlwidgets::saveWidget(aflw_pctour,\n          file=\"html/aflw_pca.html\",\n          selfcontained = TRUE)\n\n\n\n\n\n\nFigure 2.5: Animation of AFLW four PCs with interactive labelling.\n\n\n\n\n\nFrom Figure 2.5 the shape of the four PCs is similar to that of all the variables, bunching of points in the centre with a lot of moderate outliers.\n\n\nCode\nlibrary(plotly)\nload(\"data/aflw_pct.rda\")\naflw_pcti <- interpolate(aflw_pct, 0.1)\nf18 <- matrix(aflw_pcti[,,18], ncol=2)\np18 <- render_proj(aflw_pca$x[,1:4], f18, \n                   obs_labels=paste0(aflw$surname,\n                               aflw$given_name))\npg18 <- ggplot() +\n  geom_path(data=p18$circle, aes(x=c1, y=c2)) +\n  geom_segment(data=p18$axes, aes(x=x1, y=y1, xend=x2, yend=y2)) +\n  geom_text(data=p18$axes, aes(x=x2, y=y2, label=rownames(p18$axes))) +\n  geom_point(data=p18$data_prj, aes(x=P1, y=P2, label=obs_labels)) +\n  xlim(-1,1) + ylim(-1, 1) +\n  ggtitle(\"Frame 18\") +\n  theme_bw() +\n  theme(aspect.ratio=1,\n    axis.text=element_blank(),\n    axis.title=element_blank(),\n    axis.ticks=element_blank(),\n    panel.grid=element_blank())\nggplotly(pg18, width=650, height=650)\n\n\n\n\n\nFigure 2.6: Frame 18 replotted so that players can be identified on mouseover.\n\n\n\nFor any particular frame, like 18 re-plotted in Figure 2.6, we can investigate further. Here there is a branching pattern, where the branch points in the direction of PC 1. Mouseover the players at the tip of this branch and we find players like Alyce Parker, Brittany Bonnici, Dana Hooker, Kiara Bowers. If you look up the bios of these players you’ll find they all have generally good player descriptions like “elite disposals”, “powerful left foot”, “hard-running midfielder”, “best and fairest”.\nIn the direction of PC 2, you’ll find players like Lauren Ahrens, Stacey Livingstone who are star defenders. Players in this end of PC 1, have high scores on intercepts and rebounds_in50.\nAnother interesting frame for inspecting PC 2 is 59. PC 2 at one end has players with high goal scoring skills, and the other good defending skills. So mousing over the other end of PC 2 finds players like Gemma Houghton and Katie Brennan who are known for their goal scoring. The branch pattern is an interesting one, because it tells us there is some combination of skills that are lacking among all players, primarily this appears to be there some distinction between defenders skills and general playing skills. It’s not as simple as this because the branching is only visible when PC 1 and PC 2 are examined with PC 3.\nPCA is useful for getting a sense of the variation in a high-dimensional data set. Interpreting the principal components is often useful, but it can be discombobulating. For the AFLW data it would be good to think about it as a guide to the main directions of variation and to follow with a more direct engineering of variables into interesting player characteristics. For example, calculate offensive skill as an equal combination of goals, accuracy, shots, behinds. A set of new variables specifically computed to measure particular skills would make explaining an analysis easier.\n\n\n2.1.2 Example: pisa\nThe PISA data contains simulated data from math, reading nd science scores. PCA is used here to examine the association between the 30 scores. We might expect that it is 3D, but the result suggests it is primarily 1D. This means that a student that scores well in math, will also score well in reading and science.\n\n\nCode\ndata(pisa)\npisa_std <- pisa %>%\n  filter(CNT == \"Australia\") %>%\n  select(-CNT) %>%\n  mutate_all(mulgar:::scale2)\npisa_pca <- prcomp(pisa_std)\npisa_scree <- ggscree(pisa_pca)\n\n\n\n\nCode\nanimate_xy(pisa_std, half_range=1)\nrender_gif(pisa_std, \n           grand_tour(), \n           display_xy(half_range=0.9),\n           gif_file=\"gifs/pisa_gt.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n\n(a) Scree plot for the PCA on the pisa data suggests that the data is 1D.\n\n\n\n\n\n\n\n\n(b) Grand tour of the pisa data.\n\n\n\n\nFigure 2.7: Scree plot and tour of the pisa data, with 30 variables being the plausible scores for Australian students."
  },
  {
    "objectID": "data.html#program-for-international-student-assessment",
    "href": "data.html#program-for-international-student-assessment",
    "title": "Appendix B — Data",
    "section": "B.4 Program for International Student Assessment",
    "text": "B.4 Program for International Student Assessment\n\nDescription\nThe pisa data contains plausible scores for math, reading and science of Australian and Indonesian students from the 2018 testing cycle. The plausible scores are simulated from a model fitted to the original data, to preserve privacy of the students.\n\n\nVariables\n\n\n\nName\nDescription\n\n\n\n\nCNT\ncountry, either AUS for Australia or IDN for Indonesia\n\n\nPV1MATH-PV10MATH\nplausible scores for math\n\n\nPV1READ-PV10READ\nplausible scores for reading\n\n\nPV1SCIE-PV10SCIE\nplausible scores for science\n\n\n\n\n\nPurpose\nPrimarily this data is useful as an example for dimension reduction.\n\n\nSource\nThe full data is available from https://www.oecd.org/pisa/. There are records of the student test scores, along with survey data from the students, their households and their schools.\n\n\nPre-processing\nThe data was reduced to country and the plausible scores, and filtered to the two countries. It may be helpful to know that the SPSS format data was used, and was read into R using the read_sav() function in the haven package."
  },
  {
    "objectID": "pca.html#examining-the-pca-model-in-the-data-space",
    "href": "pca.html#examining-the-pca-model-in-the-data-space",
    "title": "2  Principal component analysis",
    "section": "2.2 Examining the PCA model in the data space",
    "text": "2.2 Examining the PCA model in the data space\nWhen you choose a smaller number of PCs \\((k)\\) than the number of original variables, this is essentially producing a model for the data. The model is the lower dimensional space. It is analogous to a linear regression model, except that the residuals from the model are \\((p-k)\\)-D. The model is \\(k\\)-D. It can be useful to examine this model using the tour.\nWe’ll start with the simulated data examples used at the beginning of this chapter. The function pca_model() from the mulgar package can be used to represent the model as a \\(k\\)-D wireframe plane.\n\nplane_pca <- prcomp(plane)\nplane_m <- pca_model(plane_pca)\nplane_m_d <- rbind(plane_m$points, plane)\nanimate_xy(plane_m_d, edges=plane_m$edges,\n           axes=\"bottomleft\",\n           edges.col=\"#E7950F\",\n           edges.width=3)\nrender_gif(plane_m_d, \n           grand_tour(), \n           display_xy(half_range=0.9,\n                      edges=plane_m$edges, \n                      edges.col=\"#E7950F\",\n                      edges.width=3),\n           gif_file=\"gifs/plane_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\nbox_pca <- prcomp(box)\nbox_m <- pca_model(box_pca, d=3)\nbox_m_d <- rbind(box_m$points, box)\nanimate_xy(box_m_d, edges=box_m$edges, \n           axes=\"bottomleft\", edges.col=\"#E7950F\", edges.width=3)\nrender_gif(box_m_d, \n           grand_tour(), \n           display_xy(half_range=0.9,\n                      edges=box_m$edges, \n                      edges.col=\"#E7950F\",\n                      edges.width=3),\n           gif_file=\"gifs/box_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n(a) Model for the 2D in 5D data.\n\n\n\n\n\n\n\n(b) Model for the 3D in 5D data.\n\n\n\n\nFigure 2.8: PCA model overlaid on the data for the 2D in 5D, and 3D in 5D simulated data.\n\n\n\n2.2.1 Example: pisa\nThe model for the pisa data is a 1D vector, shown in Figure 2.9.\n\npisa_model <- pca_model(pisa_pca, d=1, s=2)\n\npisa_all <- rbind(pisa_model$points, pisa_std)\nanimate_xy(pisa_all, edges=pisa_model$edges,\n           edges.col=\"#E7950F\", edges.width=3)\nrender_gif(pisa_all, \n           grand_tour(), \n           display_xy(half_range=0.9,\n                      edges=pisa_model$edges, \n                      edges.col=\"#E7950F\", \n                      edges.width=5),\n           gif_file=\"gifs/pisa_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\n\n\n\nFigure 2.9: PCA model of the pisa data. The 1D model captures the primary variation in the data and there is a small amount of spread in all directions away from the model.\n\n\n\n\n2.2.2 Example: aflw\nIt is less useful to examine the PCA model for the aflw data, because the main patterns that were of interest were the exceptional players. However, we will do it anyway! Figure 2.10 shows the 4D PCA model overlain on the data. Even though the distribution of points is not as symmetric and balanced as the other examples, we can see that the cube structure mirrors the variation. We can see that the relationships between variables are not strictly linear, because the spread extends unevenly away fro the box.\n\naflw_model <- pca_model(aflw_pca, d=4, s=1)\n\naflw_all <- rbind(aflw_model$points, aflw_std[,7:35])\nanimate_xy(aflw_all, edges=aflw_model$edges,\n           edges.col=\"#E7950F\", \n           edges.width=3, \n           half_range=0.8, \n           axes=\"off\")\nrender_gif(aflw_all, \n           grand_tour(), \n           display_xy(half_range=0.8,\n                      edges=aflw_model$edges, \n                      edges.col=\"#E7950F\", \n                      edges.width=3, \n                      axes=\"off\"),\n           gif_file=\"gifs/aflw_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\n\n\n\nFigure 2.10: PCA model of the aflw data. The linear model is not ideal for this data, which has other patterns like outliers, and some branching. However, the model roughly captures the linear associations, and leaves unequal variation in different directions."
  },
  {
    "objectID": "forests.html#examining-misclassifications",
    "href": "forests.html#examining-misclassifications",
    "title": "13  Trees and forests",
    "section": "13.3 Examining misclassifications",
    "text": "13.3 Examining misclassifications\nTo examine misclassifications, we can create a separate variable that identifies the errors or not. Constructing this for each class, and exploring in small steps is helpful. Let’s do this using the random forest model for the penguins fit. There are four Adelie penguins confused with Chinstrap, and similarly four Chinstrap confused with Adelie. There is one Gentoo penguin confused with a Chinstrap. This is interesting, because the Gentoo cluster is well separated from the clusters of the other two penguin species.\n\n\nCode\npenguins_rf\n\n\n\nCall:\n randomForest(formula = species ~ ., data = penguins_sub, importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 2.7%\nConfusion matrix:\n          Adelie Chinstrap Gentoo class.error\nAdelie       142         3      1 0.027397260\nChinstrap      4        64      0 0.058823529\nGentoo         0         1    118 0.008403361\n\n\n\npenguins_errors <- penguins_sub %>%\n  mutate(err = ifelse(penguins_rf$predicted != penguins_rf$y, 1, 0))\n\n\n\nCode\nsymbols <- c(20, 8)\np_pch <- symbols[penguins_errors$err+1]\nanimate_xy(penguins_errors[,1:4],\n           col=penguins_errors$species,\n           pch=pch)\nrender_gif(penguins_errors[,1:4],\n           grand_tour(),\n           display_xy(col=penguins_errors$species,\n                      pch=p_pch),\n           gif_file=\"gifs/p_rf_errors.gif\",\n           frames=500)\n\nanimate_xy(penguins_errors[,1:4],\n           guided_tour(lda_pp(penguins_errors$species)),\n           col=penguins_errors$species,\n           pch=pch)\n\nrender_gif(penguins_errors[,1:4],\n           guided_tour(lda_pp(penguins_errors$species)),\n           display_xy(col=penguins_errors$species,\n                      pch=p_pch),\n           gif_file=\"gifs/p_rf_errors_guided.gif\",\n           frames=500,\n           loop=FALSE)\n\n\nFigure 13.7 shows a grand tour, and a guided tour, of the penguins data, where the misclassifications are marked by an asterisk. (If these gifs are too small to see the different glyphs, zoom in to make the figures larger.) It can be seen that the one Gentoo penguin that is mistaken for a Chinstrap by the forest model is always moving with its other Gentoo (yellow) family. It can occasionally be seen to be on the edge of the group, closer to the Chinstraps, in some projections in the grand tour. But in the final projection from the guided tour it is hiding well among the other Gentoos. This is an observation where a mistake has been made because of the inadequacies of the forest algorithm. Forests are only as good as the trees they are constructed from, and we have seen from Section 13.1 that the splits only on single variables done by trees does not adequately utilise the covariance structure in each class. They make mistakes based on the boxy nature of the boundaries. This can carry through to the forests model. Even though many trees are combined to generate smoother boundaries, forests do not effectively utilise covariance in clusters either. The other mistakes, where Chinstrap are predicted to be Adelie, and vice versa, are more sensible. These mistaken observations can be seen to lie in the border region between the two clusters, and reflect genuine uncertainty about the classification of penguins in these two species.\n\n\n\n\n\n\n\n(a) Exploring misclassifications using a grand tour.\n\n\n\n\n\n\n\n(b) Exploring misclassifications using a guided tour.\n\n\n\n\nFigure 13.7: Examining the misclassified cases (marked as asterisks) from a random forest fit to the penguins data. The one Gentoo penguin mistaken for a Chinstrap is a mistake made because the forest method suffers from the same problems as trees - cutting on single variables rather than effectively using covariance structure. The mistakes between the Adelie and Chinstrap penguins are more sensible because all of these observations lie is the bordering regions between the two clusters."
  },
  {
    "objectID": "forests.html#sec-trees",
    "href": "forests.html#sec-trees",
    "title": "12  Trees and forests",
    "section": "12.1 Trees",
    "text": "12.1 Trees\nThe tree algorithm L. Breiman et al. (1984) is a simple and versatile algorithmic method for supervised classification. The basic tree algorithm generates a classification rule by sequentially splitting the data into two buckets. Splits are made between sorted data values of individual variables, with the goal of obtaining pure classes on each side of the split. The inputs for a simple tree classifier commonly include (1) an impurity measure, an indication of the relative diversity among the cases in the terminal nodes; (2) a parameter that sets the minimum number of cases in a node, or the minimum number of observations in a terminal node of the tree; and (3) a complexity measure that controls the growth of a tree, balancing the use of a simple generalizable tree against a more accurate tree tailored to the sample. When applying tree methods, exploring the effects of the input parameters on the tree is instructive; for example, it helps us to assess the stability of the tree model.\nAlthough algorithmic models do not depend on distributional assumptions, that does not mean that every algorithm is suitable for all data. For example, the tree model works best when all variables are independent within each class, because it does not take such dependencies into account. Visualization can help us to determine whether a particular model should be applied. In classification problems, it is useful to explore the cluster structure, comparing the clusters with the classes and looking for evidence of correlation within each class. The plots in ?fig-lda-assumptions1 and ?fig-penguins-lda-ellipses shows a strong correlation between the variables within each species, which indicates that the tree model may not give good results for the penguins data. We’ll show how this is the case with two variables initially, and then extend to the four variables.\n\n\n\n\n\nCode\nlibrary(mulgar)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(colorspace)\nlibrary(classifly)\nlibrary(ggplot2)\n\nload(\"data/penguins_sub.rda\")\np_bl_bd_tree <- rpart(species~bl+bd, data=penguins_sub)\nrpart.plot(p_bl_bd_tree, box.palette=\"Grays\")\n\n\n\n\n\n(a) Default tree fit\n\n\n\n\n\n\nCode\np_bl_bd_tree_boundaries <- explore(p_bl_bd_tree, penguins_sub)\nggplot(p_bl_bd_tree_boundaries) +\n  geom_point(aes(x=bl, y=bd, colour=species, shape=.TYPE)) + \n  scale_color_discrete_divergingx(palette=\"Zissou 1\") +\n  scale_shape_manual(values=c(46, 16)) +\n  theme_minimal() +\n  theme(aspect.ratio = 1, legend.position = \"none\")\n\n\n\n\n\n(b) Boundaries of tree fit\n\n\n\n\n\nFigure 12.1: The correlation between variables causes problems for using a tree model on the penguins data.\n\n\nThe plots in Figure 12.1 show the inadequacies of the tree fit. The background color indicates the class predictions, and thus boundaries produced by the tree fit. They can be seen to be boxy, and missing the elliptical nature of the penguin clusters. This produces errors in the classification of observations which are indefensible. One could always force the tree to fit the data more closely by adjusting the parameters, but the main problem persists: that one is trying to fit elliptical data using boxes.\nThe boundaries for the tree model on all four variables of the penguins data can be viewed similarly using the tour. The default fitted tree is delightfully simple, with just six splits of the data.\n\n\nCode\np_tree <- rpart(species~., data=penguins_sub[,1:5])\nrpart.plot(p_tree, box.palette=\"Grays\")\n\np_tree_boundaries <- explore(p_tree, penguins_sub)\nanimate_slice(p_tree_boundaries[p_tree_boundaries$.TYPE == \"simulated\",1:4], col=p_tree_boundaries[p_tree_boundaries$.TYPE == \"simulated\",6], v_rel=0.02, axes=\"bottomleft\")\nload(\"data/penguins_tour_path.rda\")\nrender_gif(p_tree_boundaries[p_tree_boundaries$.TYPE == \"simulated\",1:4],\n           planned_tour(pt1),\n           display_slice(v_rel=0.02, \n             col=p_tree_boundaries[p_tree_boundaries$.TYPE == \"simulated\",6], \n             axes=\"bottomleft\"),                     gif_file=\"gifs/penguins_tree_boundaries.gif\",\n           frames=500,\n           loop=FALSE\n           )\n\n\n\n\n\n\n\n\n\n(a) Boundaries produced by the LDA model.\n\n\n\n\n\n\n\n(b) Boundaries produced by the tree model.\n\n\n\n\nFigure 12.2: Comparison of the boundaries produced by the LDA model and the tree models."
  },
  {
    "objectID": "forests.html#sec-forest-errors",
    "href": "forests.html#sec-forest-errors",
    "title": "12  Trees and forests",
    "section": "12.3 Examining misclassifications",
    "text": "12.3 Examining misclassifications\nTo examine misclassifications, we can create a separate variable that identifies the errors or not. Constructing this for each class, and exploring in small steps is helpful. Let’s do this using the random forest model for the penguins fit. There are four Adelie penguins confused with Chinstrap, and similarly four Chinstrap confused with Adelie. There is one Gentoo penguin confused with a Chinstrap. This is interesting, because the Gentoo cluster is well separated from the clusters of the other two penguin species.\n\n\nCode\npenguins_rf\n\n\n\nCall:\n randomForest(formula = species ~ ., data = penguins_sub[, 1:5],      importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 2.7%\nConfusion matrix:\n          Adelie Chinstrap Gentoo class.error\nAdelie       142         4      0 0.027397260\nChinstrap      4        64      0 0.058823529\nGentoo         0         1    118 0.008403361\n\n\n\npenguins_errors <- penguins_sub %>%\n  mutate(err = ifelse(penguins_rf$predicted != penguins_rf$y, 1, 0))\n\n\n\nCode\nsymbols <- c(1, 16)\np_pch <- symbols[penguins_errors$err+1]\np_cex <- rep(1, length(p_pch))\np_cex[penguins_errors$err==1] <- 2\nanimate_xy(penguins_errors[,1:4],\n           col=penguins_errors$species,\n           pch=p_pch, cex=p_cex)\nrender_gif(penguins_errors[,1:4],\n           grand_tour(),\n           display_xy(col=penguins_errors$species,\n                      pch=p_pch, cex=p_cex),\n           gif_file=\"gifs/p_rf_errors.gif\",\n           frames=500,\n           width=400,\n           height=400)\n\nanimate_xy(penguins_errors[,1:4],\n           guided_tour(lda_pp(penguins_errors$species)),\n           col=penguins_errors$species,\n           pch=pch)\n\nrender_gif(penguins_errors[,1:4],\n           guided_tour(lda_pp(penguins_errors$species)),\n           display_xy(col=penguins_errors$species,\n                      pch=p_pch, cex=p_cex),\n           gif_file=\"gifs/p_rf_errors_guided.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\n\nFigure 12.7 shows a grand tour, and a guided tour, of the penguins data, where the misclassifications are marked by an asterisk. (If these gifs are too small to see the different glyphs, zoom in to make the figures larger.) It can be seen that the one Gentoo penguin that is mistaken for a Chinstrap by the forest model is always moving with its other Gentoo (yellow) family. It can occasionally be seen to be on the edge of the group, closer to the Chinstraps, in some projections in the grand tour. But in the final projection from the guided tour it is hiding well among the other Gentoos. This is an observation where a mistake has been made because of the inadequacies of the forest algorithm. Forests are only as good as the trees they are constructed from, and we have seen from Section 12.1 that the splits only on single variables done by trees does not adequately utilise the covariance structure in each class. They make mistakes based on the boxy nature of the boundaries. This can carry through to the forests model. Even though many trees are combined to generate smoother boundaries, forests do not effectively utilise covariance in clusters either. The other mistakes, where Chinstrap are predicted to be Adelie, and vice versa, are more sensible. These mistaken observations can be seen to lie in the border region between the two clusters, and reflect genuine uncertainty about the classification of penguins in these two species.\n\n\n\n\n\n\n\n(a) Exploring misclassifications using a grand tour.\n\n\n\n\n\n\n\n(b) Exploring misclassifications using a guided tour.\n\n\n\n\nFigure 12.7: Examining the misclassified cases (marked as asterisks) from a random forest fit to the penguins data. The one Gentoo penguin mistaken for a Chinstrap is a mistake made because the forest method suffers from the same problems as trees - cutting on single variables rather than effectively using covariance structure. The mistakes between the Adelie and Chinstrap penguins are more sensible because all of these observations lie is the bordering regions between the two clusters."
  },
  {
    "objectID": "data.html#google-quick-draw",
    "href": "data.html#google-quick-draw",
    "title": "Appendix B — Data",
    "section": "B.5 Google Quick Draw",
    "text": "B.5 Google Quick Draw\n\nDescription\nThis data is a subset of images from https://quickdraw.withgoogle.com The subset was created using the quickdraw R package at https://huizezhang-sherry.github.io/quickdraw/. It has 6 different groups: banana, boomerang, cactus, flip flops, kangaroo. Each image is 28x28 pixels. The sketches_train data would be used to train a classification model, and the unlabelled sketches_test can be used for prediction.\n\n\nVariables\n\n\n\nName\nDescription\n\n\n\n\nV1-V784\ngrey scale 0-255\n\n\nword\nwhat the person was asked to draw, NA in the test data\n\n\nid\nunique id for each sketch\n\n\n\n\n\nPurpose\nPrimarily this data is useful as an example for supervised classification, and also dimension reduction.\n\n\nSource\nThe full data is available from https://quickdraw.withgoogle.com.\n\n\nPre-processing\nIt is typically useful to pre-process this data into principal components. This code can also be useful for plotting one of the sketches in a recognisable form:\n\nlibrary(mulgar)\nlibrary(ggplot2)\ndata(\"sketches_train\")\nset.seed(77)\nx <- sketches_train[sample(1:nrow(sketches_train), 1), ]\nxm <- data.frame(gry=t(as.matrix(x[,1:784])),\n        x=rep(1:28, 28),\n        y=rep(28:1, rep(28, 28)))\nggplot(xm, aes(x=x, y=y, fill=gry)) +\n  geom_tile() +\n  scale_fill_gradientn(colors = gray.colors(256, start = 0, end = 1, rev = TRUE )) +\n  ggtitle(x$word) +\n  theme_void() + \n    theme(legend.position=\"none\")\n\n\n\n\nFigure B.1: One of the sketches in the subset of training data."
  },
  {
    "objectID": "svm.html#example-simple-2d",
    "href": "svm.html#example-simple-2d",
    "title": "13  Support vector machines",
    "section": "13.1 Example: simple 2D",
    "text": "13.1 Example: simple 2D\nTo illustrate the approach, we use two simple simulated data examples. Both have only two variables, and two classes. Explaining SVM is easier when there are just two groups. In the first data set the two classes have different covariances matrices, which will cause trouble for LDA, but SVM should see the gap between the two clusters and place the separating hyper-plane in the middle of the gap. In the second data set the two groups are concentric circles, with the inner one solid. A non-linear SVM should be fitted to this data, which should see circular gap between the two classes.\nNote that the svm function in the e1071 package will automatically scale observations into the range \\([0,1]\\). To make it easier to examine the fitted model, it is best to scale your data first, and then fit the model.\n\n\nCode\n# Toy examples\nlibrary(mulgar)\nlibrary(ggplot2)\nset.seed(1071)\nn1 <- 162\nvc1 <- matrix(c(1, -0.7, -0.7, 1), ncol=2, byrow=TRUE)\nc1 <- rmvn(n=n1, p=2, mn=c(-2, -2), vc=vc1)\nvc2 <- matrix(c(1, -0.4, -0.4, 1)*2, ncol=2, byrow=TRUE)\nn2 <- 138\nc2 <- rmvn(n=n2, p=2, mn=c(2, 2), vc=vc2)\ndf1 <- data.frame(x1=mulgar:::rescale01(c(c1[,1], c2[,1])), \n                 x2=mulgar:::rescale01(c(c1[,2], c2[,2])), \n                 cl = factor(c(rep(\"A\", n1), \n                               rep(\"B\", n2))))\nlibrary(geozoo)\nc1 <- sphere.hollow(p=2, n=n1)$points*3 + \n  c(rnorm(n1, sd=0.3), rnorm(n1, sd=0.3))\nc2 <- sphere.solid.random(p=2, n=n2)$points\ndf2 <- data.frame(x1=mulgar:::rescale01(c(c1[,1], c2[,1])), \n                  x2=mulgar:::rescale01(c(c1[,2], c2[,2])), \n                  cl = factor(c(rep(\"A\", n1), \n                               rep(\"B\", n2))))\n\n\n\nlibrary(classifly)\nlibrary(e1071)\nlibrary(colorspace)\ndf1_svm <- svm(cl~., data=df1, \n                     probability=TRUE, \n                     kernel=\"linear\")\n#df1_svm <- ksvm(cl~., data=df1, \n#                     probability=TRUE,\n#                     kernel=\"vanilladot\")\ndf1_svm_e <- explore(df1_svm, df1)\n\ns1 <- ggplot() + \n  geom_point(data=df1, aes(x=x1, y=x2, colour=cl),\n             shape=20) +\n  scale_colour_discrete_divergingx(palette=\"Zissou 1\") +\n  geom_point(data=df1_svm_e[(!df1_svm_e$.BOUNDARY)&(df1_svm_e$.TYPE==\"simulated\"),], \n             aes(x=x1, y=x2, colour=cl), shape=3) +\n  geom_point(data=df1[df1_svm$index,], \n             aes(x=x1, y=x2, colour=cl), \n             shape=4, size=4) +\n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position = \"none\") +\n  ggtitle(\"(a)\")\n\ndf2_svm <- svm(cl~., data=df2,  \n                     probability=TRUE, \n                     kernel=\"radial\")\ndf2_svm_e <- explore(df2_svm, df2)\ns2 <- ggplot() + \n  geom_point(data=df2, aes(x=x1, y=x2, colour=cl), shape=20) +\n  scale_colour_discrete_divergingx(palette=\"Zissou 1\") +\n  geom_point(data=df2_svm_e[(!df2_svm_e$.BOUNDARY)&(df2_svm_e$.TYPE==\"simulated\"),], \n             aes(x=x1, y=x2, colour=cl), \n             shape=3) +\n  geom_point(data=df2[df2_svm$index,], \n             aes(x=x1, y=x2, colour=cl), \n             shape=4, size=4) +\n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position = \"none\") +\n  ggtitle(\"(b)\")\n\nlibrary(patchwork)\ns1+s2\n\n\n\n\nFigure 13.1: SVM classifier fit overlaid on two simulated data examples: (a) groups with different variance-covariance, fitted using a linear kernel, (b) groups with non-linear separation, fitted using a radial kernel. The band of points shown as ‘+’ mark the SVM boundary, and points marked by ‘x’ are the support vectors used to define the boundary.\n\n\n\n\nFigure 13.1 shows the two data sets and the important aspects of the fitted SVM model for each. The observations are represented by dots, the separating hyper-plane (just a line for 2D) is represented by ‘+’. Where the two colours merge is the actual location of the boundary between classes. It can be seen that this is located right down the middle of the gap, for both data sets. Even though the boundary is circular for the second data set, in a transformed high-dimensional space it would be linear.\nSVMs use a subset of the observations to define the boundary, and these are called the support vectors. For each of the data sets these are marked with ‘x’. For the linear boundary, there are nine support vectors, five in one group and four in the other. There is one interesting observation in the green group, which falls far from its group and on the other side of the boundary with the blue points. It is marked as a support vector, but its contribution to the fitted hyper-plane is limited by a control parameter in the model fitting process. \nObservations 15, 45, 123, 135, 155, 180, 202, 239, 292 are the support vectors. All but 15, 45 and 180 are actually bounded support vectors, which means their coefficients are bounded to magnitude 1."
  },
  {
    "objectID": "svm.html#example-penguins",
    "href": "svm.html#example-penguins",
    "title": "13  Support vector machines",
    "section": "13.2 Example: penguins",
    "text": "13.2 Example: penguins\nFor higher dimensions, the procedures are similar, with the hyper-plane and support vectors being examined using a tour.\n\nlibrary(dplyr)\nload(\"data/penguins_sub.rda\")\nchinstrap <- penguins_sub %>%\n  filter(species == \"Chinstrap\") %>%\n  select(-species)\nchinstrap_svm <- svm(sex~., data=chinstrap, \n                     kernel=\"linear\",\n                     probability=TRUE)\nchinstrap_svm_e <- explore(chinstrap_svm, chinstrap)\n\n\n\nCode\n# Tour raw data\nlibrary(tourr)\nanimate_xy(chinstrap[,1:4], col=chinstrap$sex)\n# Add all SVs, including bounded\nc_pch <- rep(20, nrow(chinstrap))\nc_pch[chinstrap_svm$index] <- 4\nanimate_xy(chinstrap[,1:4], col=chinstrap$sex, pch=c_pch)\n# Only show the SVs with |coefs| < 1\nc_pch <- rep(20, nrow(chinstrap))\nc_pch[chinstrap_svm$index[abs(chinstrap_svm$coefs)<1]] <- 4\nc_cex <- rep(1, nrow(chinstrap))\nc_cex[chinstrap_svm$index[abs(chinstrap_svm$coefs)<1]] <- 2\nanimate_xy(chinstrap[,1:4], col=chinstrap$sex, \n           pch=c_pch, cex=c_cex)\nrender_gif(chinstrap[,1:4],\n           grand_tour(),\n           display_xy(col=chinstrap$sex, pch=c_pch, cex=c_cex),\n           gif_file=\"gifs/chinstrap_svs.gif\",\n           width=400,\n           height=400,\n           frames=500)\n\n# Tour the separating hyper-plane also\nsymbols <- c(3, 20)\nc_pch <- symbols[as.numeric(chinstrap_svm_e$.TYPE[!chinstrap_svm_e$.BOUNDARY])]\nanimate_xy(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4], \n           col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY],\n           pch=c_pch)\nrender_gif(chinstrap_svm_e[!chinstrap_svm_e$.BOUNDARY,1:4],\n           grand_tour(),\n           display_xy(col=chinstrap_svm_e$sex[!chinstrap_svm_e$.BOUNDARY], pch=c_pch),\n           gif_file=\"gifs/chinstrap_svm.gif\",\n           width=400,\n           height=400,\n           frames=500)\n\n\n\n\n\n\n\n\n\n(a) Exploring which points are support vectors.\n\n\n\n\n\n\n\n(b) Exploring SVM boundary.\n\n\n\n\nFigure 13.2: SVM model for distinguishing the sexes of the Chinstrap penguins. The separating hyper-plane is 3D, and separates primarily on variables bl and bd, as seen because these two axes extend out from the plane when it is seen on its side, separating the two groups.\n\n\nThis is a good place to show manual tour also, to find the separation.\n\n\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create Interactive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "index.html#how-do-i-report-an-error",
    "href": "index.html#how-do-i-report-an-error",
    "title": "Interactive and dynamic graphics for high-dimensional data using R",
    "section": "How do I report an error?",
    "text": "How do I report an error?\nIf you encounter an error, you can report it as an issue at the Github repo for this book.\nPlease make a small reproducible example and report the error encountered. Reproducible examples have these components:\n\na small amount of data\nsmall amount of code that generates the error\ncopy of the error message that was generated"
  },
  {
    "objectID": "index.html#what-should-i-know-before-reading-this-book",
    "href": "index.html#what-should-i-know-before-reading-this-book",
    "title": "Interactive and dynamic graphics for high-dimensional data using R",
    "section": "What should I know before reading this book?",
    "text": "What should I know before reading this book?\nThe examples assume that you already use R, and have a working knowledge of base R and tidyverse way of thinking about data analysis. It also assumes that you have some knowledge of statistical methods, and some experience with machine learning methods.\nIf you feel like you need build up your skills in these areas in preparation for working through this book, these are our recommended resources:\n\nR for Data Science by Wickham and Grolemund for learning about data wrangling and visualisation.\nIntroduction to Modern Statistics by Çetinkaya-Rundel and Hardin to learn about introductory statistics.\nHands-On Machine Learning with R by Boehmke and Greenwell to learn about machine learning."
  },
  {
    "objectID": "unsupervised-overview.html#what-are-clusters",
    "href": "unsupervised-overview.html#what-are-clusters",
    "title": "4  Overview",
    "section": "4.1 What are clusters?",
    "text": "4.1 What are clusters?\nOrganizing objects into groups is a common task to help make sense of the world around us. Perhaps this is why it is an appealing method of data analysis. However, cluster analysis is more complex than it initially appears. Many people imagine that it will produce neatly separated clusters like those in Figure 4.1(a), but it almost never does. Such ideal clusters are rarely encountered in real data, so we often need to modify our objective from find the natural clusters in this data. Instead, we need to organize the cases into groups that are similar in some way. Even though this may seem disappointing when compared with the ideal, it is still often an effective means of simplifying and understanding a dataset.\n\nKnowing what shapes are in your data helps with clustering it.\n\n\n\n\n\n\nFigure 4.1: Different structures in data impact cluster analysis. When there are well-separated groups (a), it is simple to group similar observations. Even when there are not, partitioning observations into groups may still be useful. There may be nuisance observations or (b) nuisance variables (c) that affect the interpoint distance calculations and distract the clustering algorithm, and there may oddly shaped clusters (d) which are hard to numerically describe.\n\n\n\n\nAt the heart of the clustering process is the work of discovering which variables are most important for defining the groups. It is often true that we only require a subset of the variables for finding clusters, whereas another subset (called ) has no impact. In the bottom left plot of Figure 4.1, it is clear that the variable plotted horizontally is important for splitting this data into two clusters, whereas the variable plotted vertically is a nuisance variable. Nuisance is an apt term for these variables, because they can radically change the interpoint distances and impair the clustering process. \nDynamic graphical methods help us to find and understand the cluster structure in high dimensions. With the tools in our toolbox, primarily tours, along with linked scatterplots and parallel coordinate plots, we can see clusters in high-dimensional spaces. We can detect gaps between clusters, the shape and relative positions of clusters, and the presence of nuisance variables. We can even find unusually shaped clusters, like those in the bottom right plot in Figure 4.1. In simple situations we can use graphics alone to group observations into clusters, using a “spin and brush” method. In more difficult data problems, we can assess and refine numerical solutions using graphics. \nThis part of the book discusses the use of interactive and dynamic graphics in the clustering of data. Section 4.2 introduces cluster analysis, focusing on interpoint distance measures. Chapter 5 describes an example of a purely graphical approach to cluster analysis, the spin and brush method. In the example shown in that section, we were able to find simplifications of the data that had not been found using numerical clustering methods, and to find a variety of structures in high-dimensional space. Chapter 6 describes methods for reducing the interpoint distance matrix to an intercluster distance matrix using hierarchical algorithms, Chapter 8 covers model-based clustering, and Chapter 9 described clustering with self-organising maps. Each of these chapters shows how graphical tools can be used to assess the results of numerical methods. Chapter 10 summarizes the chapter and revisits the data analysis strategies used in the examples. Additional references that provide good companions to the material presented in these chapters are Venables and Ripley (2002), Boehmke and Greenwell (2019), Hennig et al. (2015), Giordani, Ferraro, and Martella (2020), Kassambara (2017), and the CRAN Task View (Leisch and Gruen 2023). Chapter 10 summarizes the chapter and revisits the data analysis strategies used in the examples."
  },
  {
    "objectID": "unsupervised-overview.html#exercises",
    "href": "unsupervised-overview.html#exercises",
    "title": "4  Overview",
    "section": "Exercises",
    "text": "Exercises\nUse the following data to answer these questions:\n\n\n     x1   x2   x3\na1 0.13 0.21 0.09\na2 0.91 0.95 0.85\na3 0.62 0.73 0.65\na4 0.21 0.92 0.43\n\n\n\nCompute the Euclidean distance between cases a1, a2, a3, a4.\nCompute the correlation distance (as defined above) between cases a1, a2, a3, a4.\nWhich two points have the (a) biggest (b) smallest Mahalanobis (statistical) distance, assuming that the covariance matrix is:\n\n\n\n    x1  x2  x3\nx1 1.0 0.8 0.8\nx2 0.8 1.0 0.8\nx3 0.8 0.8 1.0\n\n\n(The function mahalanobis will calculate this in R. Technically this gives distance between each case and the mean vector.)\n\nIs the ordering of distance between cases the same if Manhattan distance is used instead of Euclidean?\nCompute the Chebychev distance between cases a1, a2, a3, a4.\nCompute Bray-Curtis distance between cases a1, a2, a3, a4.\nMake a plot of the data, and write a paragraph describing how the different distance metrics agree and disagree on how close or far the cases are from each other.\n\n\n\n\n\n\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nVenables, W. N., and B. Ripley. 2002. Modern Applied Statistics with S. New York: Springer-Verlag."
  },
  {
    "objectID": "intro.html#background-literature",
    "href": "intro.html#background-literature",
    "title": "Introduction",
    "section": "Background literature",
    "text": "Background literature\nViewing high-dimensional data based on low-dimensional projections can probably be traced back to the early work on principal component analysis by Pearson (1901) and Hotelling (1933), which was extended to known classes as part of discriminant analysis by Fisher (1936).\nWith computer graphics, the capability of animating plots to show more than a single best projection became possible. The video library (ASA Statistical Graphics Section 2023) is the best place to see the earliest work. Kruskal’s 1962 animation of multidimensional scaling showed the process of finding a good 2D representation of high dimensional data, although the views are not projections. Chang’s 1970 video shows her rotating a high dimensional point cloud along coordinate axes to find a special projection where all the numbers align. The classic video that must be watched is PRIM9 (Fisherkeller, Friedman, and Tukey 1973) where a variety of interactive and dynamic tools are used together to explore high dimensional physics data, documented in Fisherkeller, Friedman, and Tukey (1974).\nCook and Swayne (2007)\nEarly history Asimov (1985)\nMaybe not too extensive? Definitely need to point to some videos.\nWhy new tools? Explain change of technology, need to be part of a workflow."
  },
  {
    "objectID": "intro.html#a-little-history",
    "href": "intro.html#a-little-history",
    "title": "Introduction",
    "section": "A little history",
    "text": "A little history\nViewing high-dimensional data based on low-dimensional projections can probably be traced back to the early work on principal component analysis by Pearson (1901) and Hotelling (1933), which was extended to known classes as part of discriminant analysis by Fisher (1936a).\nWith computer graphics, the capability of animating plots to show more than a single best projection became possible. The video library (ASA Statistical Graphics Section 2023) is the best place to experience the earliest work. Kruskal’s 1962 animation of multidimensional scaling showed the process of finding a good 2D representation of high dimensional data, although the views are not projections. Chang’s 1970 video shows her rotating a high dimensional point cloud along coordinate axes to find a special projection where all the numbers align. The classic video that must be watched is PRIM9 (Fisherkeller, Friedman, and Tukey 1973) where a variety of interactive and dynamic tools are used together to explore high dimensional physics data, documented in Fisherkeller, Friedman, and Tukey (1974).\nThe methods in this book primarily emerge from Asimov (1985)’s grand tour method. The algorithm provided the first smooth and continuous sequence of low dimensional projections, and guaranteed that all possible low dimensional projections were likely to be shown. The algorithm was refined in A. Buja and Asimov (1986) (and documented in detail in A. Buja et al. (2005)) to make it efficiently show all possible projections. Since then there have been numerous varieties of tour algorithms developed to focus on specific tasks in exploring high dimensional data, and these are recently documented in S. Lee et al. (2022).\nThis book is an evolution from Dianne Cook and Swayne (2007). One of the difficulties in working on interactive and dynamic graphics research has been the rapid change in technology. Programming languages have changed a little (fortran to C to java to python) but graphics toolkits and display devices have changed a lot! The tour software used in this book evolved from XGobi, which was written in C and used the X Window System, which was then rewritten in GGobi using gtk. The video library has engaging videos of these software systems There have been several other short-lived implementations, including orca (Peter Sutherland et al. 2000), written in java, and cranvas (Xie, Hofmann, and Cheng 2014), written in R with a back-end provided by wrapper functions to qt libraries.\nAlthough attempts were made with these ancestor systems to connect the data plots to a statistical analysis system, these were always limited. With the emergence of R, having graphics in the data analysis workflow has been much easier, albeit at the cost of the interactivity with graphics that matches the old systems. We are mostly using the R package, tourr (Wickham et al. 2011a) for examples in this book. It provides the machinery for running a tour, and has the flexibility that it can be ported, modified, and used as a regular element of data analysis."
  },
  {
    "objectID": "pca.html#determining-how-many-dimensions",
    "href": "pca.html#determining-how-many-dimensions",
    "title": "2  Principal component analysis",
    "section": "2.1 Determining how many dimensions",
    "text": "2.1 Determining how many dimensions\nWe would start by examining the data using a grand tour. The goal is to check whether there might be potential issues for PCA, such as skewness, outliers or clustering, or even non-linear dependencies.\nWe’ll start be showing PCA on the simulated from Chapter 1. The scree plots show that PCA supports that the data are 2D, 3D and 5D respectively.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(mulgar)\ndata(plane)\ndata(box)\nlibrary(geozoo)\ncube5d <- data.frame(cube.solid.random(p=5, n=300)$points)\ncolnames(cube5d) <- paste0(\"x\", 1:5)\ncube5d <- data.frame(apply(cube5d, 2, function(x) (x-mean(x))/sd(x)))\np_pca <- prcomp(plane)\nb_pca <- prcomp(box)\nc_pca <- prcomp(cube5d)\np_scree <- ggscree(p_pca)\nb_scree <- ggscree(b_pca)\nc_scree <- ggscree(c_pca)\n\n\n\n\n\n\n\n\n\n(a) 2D in 5D\n\n\n\n\n\n\n\n\n\n(b) 3D in 5D\n\n\n\n\n\n\n\n\n\n(c) fully 5D\n\n\n\n\n\nFigure 2.1: Scree plots for the three simulated data sets. The 2D in 5D is clearly recognised by PCA to be 2D because the variance drops substantially between 2-3 principal components. The 3D in 5D is possibly 3D because the variance drops from 3-4 principal components. The fully 5D data has no drop in variance, and all values are close to the typical value one would observe if the data was fully 5D.\n\n\nThe next step is to look at the coefficients for the selected number of PCs. Table 2.1 shows the coefficients for the first two PCs of the plane data. All five variables contribute, with x1, x2, x3 contributing more to PC1, and x4, x5 contributing more to PC2. Table 2.2 shows the coefficients for the first three PCs. Variables x1, x2, x3 contribute strongly to PC1, PC2 has contributions from all variables except x3 and variables x4 and x5 contribute strongly to PC3.\n\n\nCode\nlibrary(gt)\np_pca$rotation[,1:2] %>%\n  as_tibble(rownames=\"Variable\") %>% \n  gt() %>%\n  fmt_number(columns = c(PC1, PC2),\n             decimals = 2)\n\n\n\n\n\n\nTable 2.1:  Coefficients for the first two PCs for the plane data. \n  \n  \n    \n      Variable\n      PC1\n      PC2\n    \n  \n  \n    x1\n0.58\n−0.06\n    x2\n−0.55\n0.21\n    x3\n0.47\n−0.41\n    x4\n0.25\n0.64\n    x5\n−0.29\n−0.62\n  \n  \n  \n\n\n\n\n\n\n\nCode\nb_pca$rotation[,1:3] %>%\n  as_tibble(rownames=\"Variable\") %>% \n  gt() %>%\n  fmt_number(columns = c(PC1, PC2, PC3),\n             decimals = 2)\n\n\n\n\n\n\nTable 2.2:  Coefficients for the first three PCs for the box data. \n  \n  \n    \n      Variable\n      PC1\n      PC2\n      PC3\n    \n  \n  \n    x1\n−0.51\n0.46\n−0.11\n    x2\n0.51\n0.46\n0.00\n    x3\n−0.65\n−0.09\n−0.23\n    x4\n−0.22\n0.36\n0.87\n    x5\n0.02\n0.66\n−0.43\n  \n  \n  \n\n\n\n\n\nIn each of these simulated data sets, all five variables contributed to the dimension reduction. If we added two purely noise variables to the plane data, as done in Chapter 1, the scree plot would indicate that the data is now 4D, and we would get a different interpretation of the coefficients from the PCA. We see that PC1 and PC2 are approximately the same as before, with main variables being (x1, x2, x3) and (x4, x5) respectively. PC3 and PC4 are both x6 and x7.\n\nset.seed(5143)\nplane_noise <- plane\nplane_noise$x6 <- rnorm(100)\nplane_noise$x7 <- rnorm(100)\nplane_noise <- data.frame(apply(plane_noise, 2, function(x) (x-mean(x))/sd(x)))\n\npn_pca <- prcomp(plane_noise)\nggscree(pn_pca)\n\n\n\n\nFigure 2.2: Additional noise variables expands the data to 4D.\n\n\n\n\n\n\nCode\npn_pca$rotation[,1:4] %>%\n  as_tibble(rownames=\"Variable\") %>% \n  gt() %>%\n  fmt_number(columns = c(PC1, PC2, PC3, PC4),\n             decimals = 2)\n\n\n\n\n\n\nTable 2.3:  Coefficients for the first four PCs for the box data. \n  \n  \n    \n      Variable\n      PC1\n      PC2\n      PC3\n      PC4\n    \n  \n  \n    x1\n0.58\n0.04\n−0.01\n0.00\n    x2\n−0.55\n−0.18\n0.03\n0.07\n    x3\n0.47\n0.37\n−0.05\n−0.20\n    x4\n0.24\n−0.62\n0.06\n0.17\n    x5\n−0.28\n0.60\n−0.07\n−0.14\n    x6\n0.05\n0.29\n0.58\n0.76\n    x7\n−0.02\n−0.08\n0.81\n−0.58\n  \n  \n  \n\n\n\n\n\n\n2.1.1 Example: pisa\nThe pisa data contains simulated data from math, reading and science scores, totalling 30 variables. PCA is used here to examine the association. We might expect that it is 3D, but what we see suggests it is primarily 1D. This means that a student that scores well in math, will also score well in reading and science.\n\ndata(pisa)\npisa_std <- pisa %>%\n  filter(CNT == \"Australia\") %>%\n  select(-CNT) %>%\n  mutate_all(mulgar:::scale2)\npisa_pca <- prcomp(pisa_std)\npisa_scree <- ggscree(pisa_pca)\n\nThe scree plot in Figure 2.3 (a) shows a big drop from one to two PCs in the amount of variance explained. A grand tour on the 30 variables can be run using animate_xy():\n\nanimate_xy(pisa_std, half_range=1)\n\nor rendered as an animated gif using render_gif():\n\nrender_gif(pisa_std, \n           grand_tour(), \n           display_xy(half_range=0.9),\n           gif_file=\"gifs/pisa_gt.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\nand we can see that the data is elliptical in most projections, sometimes shrinking to be a small circle. This pattern strongly indicates that there is one primary direction of variation in the data, with only small variation in any direction away from it. Shrinking to the small circle is analogous to to how a pencil or cigar or water bottle in 3D looks from some angles.\n\n\n\n\n\n\n\n\n(a) Scree plot for the PCA on the pisa data suggests that the data is 1D.\n\n\n\n\n\n\n\n\n(b) Grand tour of the pisa data.\n\n\n\n\nFigure 2.3: Scree plot and tour of the pisa data, with 30 variables being the plausible scores for Australian students.\n\n\nThe coefficients of the first PC (first eigenvector) are roughly equal in magnitude (as shown below), which tells us that all variables roughly contribute. Interestingly, they are all negative, which is not actually meaningful. With different software these could easily have been all positive. The sign of the coefficients can be reversed, as long as all are reversed, which is the same as an arrow pointing one way, changing and pointing the other way.\n\n\nCode\nround(pisa_pca$rotation[,1], 2)\n\n\n PV1MATH  PV2MATH  PV3MATH  PV4MATH  PV5MATH  PV6MATH  PV7MATH  PV8MATH \n   -0.18    -0.18    -0.18    -0.18    -0.18    -0.18    -0.18    -0.18 \n PV9MATH PV10MATH  PV1READ  PV2READ  PV3READ  PV4READ  PV5READ  PV6READ \n   -0.18    -0.18    -0.19    -0.18    -0.19    -0.19    -0.19    -0.19 \n PV7READ  PV8READ  PV9READ PV10READ  PV1SCIE  PV2SCIE  PV3SCIE  PV4SCIE \n   -0.19    -0.19    -0.19    -0.19    -0.18    -0.18    -0.19    -0.18 \n PV5SCIE  PV6SCIE  PV7SCIE  PV8SCIE  PV9SCIE PV10SCIE \n   -0.19    -0.18    -0.19    -0.18    -0.19    -0.18 \n\n\n\nThe 1D structure of the pisa data means that a student that scores well in math, tends to score well in reading and science too.\n\n\n\n2.1.2 Example: aflw\nThis data has player statistics for all the matches in the 2021 season. We would be interested to know which variables contain similar information, and thus might be combined into single variables. We would expect that many statistics to group into a few small sets, such as offensive and defensive skills. We might also expect that some of the statistics are skewed, most players have low values and just a handful of players are stellar. It is also possible that there are some extreme values. These are interesting features, but they will distract from the main purpose of grouping the statistics. Thus the tour is used to check for potential problems with the data prior to conducting PCA.\n\nlibrary(tourr)\ndata(aflw)\naflw_std <- aflw %>%\n  mutate_if(is.numeric, function(x) (x-\n      mean(x, na.rm=TRUE))/\n      sd(x, na.rm=TRUE))\n\nTo look at all of the 29 player statistics in a grand tour.\n\n\nCode\nanimate_xy(aflw_std[,7:35], half_range=0.9)\nrender_gif(aflw_std[,7:35], \n           grand_tour(), \n           display_xy(half_range=0.9),\n           gif_file=\"gifs/aflw_gt.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\nFigure 2.4: Grand tour of the AFLW player statistics\n\n\nNo major surprises! There is a small amount of skewness, and there are no major outliers. Skewness indicates that most players have reasonably similar skills (bunching of points), except for some key players (the moderate outliers). The skewness could be reduced by applying a log or square root transformation to some variables prior to running the PCA. However, we elect not to do this because the moderate outliers are of interest. These correspond to talented players that we’d like to explore further with the analysis.\nBelow we have the conventional summary of the PCA, a scree plot showing the reduction in variance to be explained when each additional PC is considered. It is also conventional to look at a table summarising the proportions of variance explained by PCs, but with 30 variables it is easier to make some decision on the number of PCs needed based on the scree plot.\n\n\nCode\naflw_pca <- prcomp(aflw_std[,7:35], \n               scale = FALSE, \n               retx=TRUE)\n\nggscree(aflw_pca)\n\n\n\n\n\nFigure 2.5: Scree plot showing decay in variance of PCs.\n\n\n\n\nFrom the scree plot in Figure 2.5, we see a sharp drop from one to two, two to three and then smaller drops. After four PCs the variance drops again at six PCs and then gradually decays. We will choose four PCs to examine more closely. This explains 67.2% of the variance.\n\n\nCode\nlibrary(gt)\naflw_pca$rotation[,1:4] %>%\n  as_tibble(rownames=\"Variable\") %>% \n  arrange(desc(PC1), desc(PC2), desc(PC3)) %>%\n  gt() %>%\n  fmt_number(columns = c(PC1, PC2, PC3, PC4),\n             decimals = 2)\n\n\n\n\n\n\nTable 2.4:  Coefficients for the first four PCs. \n  \n  \n    \n      Variable\n      PC1\n      PC2\n      PC3\n      PC4\n    \n  \n  \n    disposals\n0.31\n−0.05\n−0.03\n0.07\n    possessions\n0.31\n−0.03\n−0.07\n0.09\n    kicks\n0.29\n−0.04\n0.09\n−0.12\n    metres\n0.28\n−0.03\n0.10\n−0.15\n    contested\n0.28\n0.01\n−0.12\n0.23\n    uncontested\n0.28\n−0.06\n−0.01\n−0.05\n    turnovers\n0.27\n−0.01\n−0.01\n−0.29\n    clearances\n0.23\n0.00\n−0.29\n0.19\n    clangers\n0.23\n−0.02\n−0.06\n−0.33\n    handballs\n0.23\n−0.04\n−0.19\n0.31\n    frees_for\n0.21\n0.02\n−0.13\n0.18\n    marks\n0.21\n0.03\n0.32\n0.02\n    tackles\n0.20\n0.01\n−0.28\n0.09\n    time_pct\n0.16\n−0.04\n0.35\n−0.02\n    intercepts\n0.13\n−0.28\n0.24\n0.03\n    rebounds_in50\n0.13\n−0.28\n0.24\n−0.06\n    frees_against\n0.13\n0.03\n−0.16\n−0.23\n    assists\n0.09\n0.23\n0.00\n0.05\n    bounces\n0.09\n0.03\n0.02\n−0.28\n    behinds\n0.09\n0.32\n0.08\n−0.02\n    shots\n0.08\n0.38\n0.12\n−0.03\n    tackles_in50\n0.07\n0.27\n−0.18\n0.03\n    marks_in50\n0.06\n0.34\n0.18\n0.04\n    contested_marks\n0.05\n0.16\n0.34\n0.15\n    goals\n0.04\n0.37\n0.16\n0.03\n    accuracy\n0.04\n0.34\n0.10\n0.06\n    one_pct\n0.03\n−0.21\n0.33\n0.08\n    disposal\n0.02\n−0.13\n0.20\n0.50\n    hitouts\n−0.04\n0.00\n−0.03\n0.32\n  \n  \n  \n\n\n\n\n\nWhen there are as many variables as this, it can be hard to digest the combinations of variables most contributing to each PC. Rearranging the table by sorting on a selected PC can help. Table 2.4 has been sorted according to the PC 1 coefficients.\nPC 1 is primarily composed of disposals, possessions, kicks, metres, uncontested, contested, …. Actually almost all variables positively contribute, albeit in different amounts! It is quite common in PCA for the first PC to be a combination of all variables, although it might commonly be a closer to equal contribution, and it tells us that there is one main direction of variation in the data. For PC 1 in the AFLW data, PCA is telling us that the primary variation is through a combination of skills, and this maps to basic football playing skills, where some skills (e.g. disposals, possessions, kicks, …) are more important.\nThus the second PC might be the more interesting. PC 2 is primarily a combination of shots, goals, marks_in50, accuracy, and behinds contrasted against rebounds_in50 and intercepts. The negative coefficients are primary offensive skills and the positive coefficients are defensive skills. This PC is reasonable measure of the offensive vs defensive skills of a player.\nWe would continue to interpret each PC by examining large coefficients to help decide how many PCs are a suitable summary of the information in the data. Briefly, PC 3 is a measure of worth of the player because time_pct has a large coefficient, so players that are on the field longer will contribute strongly to this new variable. It also has large (and opposite) contributions from clearances, tackles, contested_marks. PC 4 appears to be related to aggressive play with clangers, turnovers, bounces and frees_against featuring. So all four PCs have useful information. (Note, if we had continued to examine large coefficients on PC 5 we would find that all variables already have had reasonably large coefficients on PC 1-4, which supports restricting attention to the first four.)\n\nIdeally, when we tour the four PCs, we’d like to be able to stop and identify players. This involves creating a pre-computed animation, with additional mouse-over. This is only feasible with a small number of observations, like the AFLW data, because all of the animation frames are constructed in a single object and passed to plotly. This object gets large very quickly!\n\n\nCode\nlibrary(plotly)\nlibrary(htmlwidgets)\nset.seed(20)\nb <- basis_random(4, 2)\naflw_pct <- tourr::save_history(aflw_pca$x[,1:4], \n                    tour_path = grand_tour(),\n                    start = b,\n                    max_bases = 5)\n# To reconstruct projected data plots, later\nsave(aflw_pct, file=\"data/aflw_pct.rda\") \naflw_pcti <- interpolate(aflw_pct, 0.1)\naflw_anim <- render_anim(aflw_pca$x[,1:4],\n                         frames=aflw_pcti, \n             obs_labels=paste0(aflw$surname,\n                               aflw$given_name))\n\naflw_gp <- ggplot() +\n     geom_path(data=aflw_anim$circle, \n               aes(x=c1, y=c2,\n                   frame=frame), linewidth=0.1) +\n     geom_segment(data=aflw_anim$axes, \n                  aes(x=x1, y=y1, \n                      xend=x2, yend=y2, \n                      frame=frame), \n                  linewidth=0.1) +\n     geom_text(data=aflw_anim$axes, \n               aes(x=x2, y=y2, \n                   frame=frame, \n                   label=axis_labels), \n               size=5) +\n     geom_point(data=aflw_anim$frames, \n                aes(x=P1, y=P2, \n                    frame=frame, \n                    label=obs_labels), \n                alpha=0.8) +\n     xlim(-1,1) + ylim(-1,1) +\n     coord_equal() +\n     theme_bw() +\n     theme(axis.text=element_blank(),\n         axis.title=element_blank(),\n         axis.ticks=element_blank(),\n         panel.grid=element_blank())\naflw_pctour <- ggplotly(aflw_gp,\n                        width=500,\n                        height=550) %>%\n       animation_button(label=\"Go\") %>%\n       animation_slider(len=0.8, x=0.5,\n                        xanchor=\"center\") %>%\n       animation_opts(easing=\"linear\", transition = 0)\n\nhtmlwidgets::saveWidget(aflw_pctour,\n          file=\"html/aflw_pca.html\",\n          selfcontained = TRUE)\n\n\n\n\n\n\nFigure 2.6: Animation of AFLW four PCs with interactive labelling.\n\n\n\n\n\nFrom Figure 2.6 the shape of the four PCs is similar to that of all the variables, bunching of points in the centre with a lot of moderate outliers.\n\n\nCode\nlibrary(plotly)\nload(\"data/aflw_pct.rda\")\naflw_pcti <- interpolate(aflw_pct, 0.1)\nf18 <- matrix(aflw_pcti[,,18], ncol=2)\np18 <- render_proj(aflw_pca$x[,1:4], f18, \n                   obs_labels=paste0(aflw$surname,\n                               aflw$given_name))\npg18 <- ggplot() +\n  geom_path(data=p18$circle, aes(x=c1, y=c2)) +\n  geom_segment(data=p18$axes, aes(x=x1, y=y1, xend=x2, yend=y2)) +\n  geom_text(data=p18$axes, aes(x=x2, y=y2, label=rownames(p18$axes))) +\n  geom_point(data=p18$data_prj, aes(x=P1, y=P2, label=obs_labels)) +\n  xlim(-1,1) + ylim(-1, 1) +\n  ggtitle(\"Frame 18\") +\n  theme_bw() +\n  theme(aspect.ratio=1,\n    axis.text=element_blank(),\n    axis.title=element_blank(),\n    axis.ticks=element_blank(),\n    panel.grid=element_blank())\nggplotly(pg18, width=650, height=650)\n\n\n\n\n\nFigure 2.7: Frame 18 replotted so that players can be identified on mouseover.\n\n\n\nFor any particular frame, like 18 re-plotted in Figure 2.7, we can investigate further. Here there is a branching pattern, where the branch points in the direction of PC 1. Mouseover the players at the tip of this branch and we find players like Alyce Parker, Brittany Bonnici, Dana Hooker, Kiara Bowers. If you look up the bios of these players you’ll find they all have generally good player descriptions like “elite disposals”, “powerful left foot”, “hard-running midfielder”, “best and fairest”.\nIn the direction of PC 2, you’ll find players like Lauren Ahrens, Stacey Livingstone who are star defenders. Players in this end of PC 1, have high scores on intercepts and rebounds_in50.\nAnother interesting frame for inspecting PC 2 is 59. PC 2 at one end has players with high goal scoring skills, and the other good defending skills. So mousing over the other end of PC 2 finds players like Gemma Houghton and Katie Brennan who are known for their goal scoring. The branch pattern is an interesting one, because it tells us there is some combination of skills that are lacking among all players, primarily this appears to be there some distinction between defenders skills and general playing skills. It’s not as simple as this because the branching is only visible when PC 1 and PC 2 are examined with PC 3.\nPCA is useful for getting a sense of the variation in a high-dimensional data set. Interpreting the principal components is often useful, but it can be discombobulating. For the AFLW data it would be good to think about it as a guide to the main directions of variation and to follow with a more direct engineering of variables into interesting player characteristics. For example, calculate offensive skill as an equal combination of goals, accuracy, shots, behinds. A set of new variables specifically computed to measure particular skills would make explaining an analysis easier.\n\nPCA on the aflw data leaves us slightly dizzy, but there are some useful insights. It detects and even ranks outstanding players high on different combinations of skills. Although players tend to have a combination of skills, there appears to be a dichotomy in skill sets for top goal scorers and top defensive players."
  },
  {
    "objectID": "pca.html#when-relationships-are-not-linear",
    "href": "pca.html#when-relationships-are-not-linear",
    "title": "2  Principal component analysis",
    "section": "2.3 When relationships are not linear",
    "text": "2.3 When relationships are not linear\n\n2.3.1 Example: outliers\nFigure 2.11 shows the scree plot for the planar data with noise and outliers. It is very similar to the scree plot on the data without the outliers (Figure 2.2). However, what we see from Figure 2.12 is that PCA loses the outliers. The animation in (a) shows the full data, and the outliers marked by colour and labels 1, 2, are clearly unusual in some projections. When we examine the tour of the first four PCs (as suggested by the scree plot) the outliers are not unusual. They are almost contained in the point cloud. The reason is clear when all the PCs are plotted, and the outliers can be seen to be clearly detected only in PC5, PC6 and PC7.\n\n\n\n\nplane_n_o_pca <- prcomp(plane_noise_outliers)\nggscree(plane_n_o_pca)\n\n\n\n\nFigure 2.11: Scree plot of the planar data with noise and an outlier. It is almost the same as the data without the outliers.\n\n\n\n\n\n\nCode\nclrs <- hcl.colors(12, \"Zissou 1\")\np_col <- c(rep(\"black\", 100), clrs[11], clrs[11])\np_obs_labels <- c(rep(\"\", 100), \"1\", \"2\")\n\nanimate_xy(plane_n_o_pca$x[,1:4],\n           col=p_col,\n           obs_labels=p_obs_labels)\nanimate_xy(plane_noise_outliers,\n           col=p_col,\n           obs_labels=p_obs_labels)\nrender_gif(plane_noise_outliers, \n           grand_tour(), \n           display_xy(half_range=0.8,\n                      col=p_col,\n             obs_labels=p_obs_labels),\n           gif_file=\"gifs/plane_n_o_clr.gif\",\n           frames=500,\n           width=200,\n           height=200,\n           loop=FALSE)\nrender_gif(plane_n_o_pca$x[,1:4], \n           grand_tour(), \n           display_xy(half_range=0.8,\n                      col=p_col,\n             obs_labels=p_obs_labels),\n           gif_file=\"gifs/plane_n_o_pca.gif\",\n           frames=500,\n           width=200,\n           height=200,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n(a) Outliers clearly visible.\n\n\n\n\n\n\n\n(b) Outliers not clearly visible in PC1-4.\n\n\n\n\nFigure 2.12: Examining the handling of outliers in the PCA of the planar data with noise variables and two outliers. PCA has lost these two extreme values.\n\n\n\n\nCode\nlibrary(GGally)\nggscatmat(plane_n_o_pca$x)\n\n\n\n\n\nFigure 2.13: From the scatterplot matrix we can see that the outliers are present in PC5, PC6 and PC7. That means by reducing the dimensionality to the first four PCs the model has missed some important characteristics in the data.\n\n\n\n\n\n\n2.3.2 Example: Non-linear associations\nFigure 2.15 shows the tour of the full 5D data containing non-linear relationships in comparison with a tour of the first three PCs, as recommended by the scree plot (Figure 2.14). The PCs capture some clear and very clean non-linear relationship, but it looks like ti has missed some of the complexities of the relationsips. The scatterplot matrix of all 5 PCs (Figure 2.16) shows that PC4 and PC5 contain interesting features: more non-linearity, and curiously an outlier.\n\ndata(plane_nonlin)\nplane_nonlin_pca <- prcomp(plane_nonlin)\nggscree(plane_nonlin_pca)\n\n\n\n\nFigure 2.14: Scree plot of the non-linear data suggests three PCs.\n\n\n\n\n\n\nCode\nanimate_xy(plane_nonlin_pca$x[,1:3])\nrender_gif(plane_nonlin_pca$x[,1:3], \n           grand_tour(), \n           display_xy(half_range=0.8),\n           gif_file=\"gifs/plane_nonlin_pca.gif\",\n           frames=500,\n           width=200,\n           height=200)\n\n\n\n\n\n\n\n\n\n(a) Non-linear relationship between several variables seen in a tour on all five variables.\n\n\n\n\n\n\n\n(b) The first three principal components reveal a strong non-linear relationship.\n\n\n\n\nFigure 2.15: Comparison of the full data and first three principal components. Some of the non-linearity is clearly visible in the reduced dimension space, but the full data has more complexities.\n\n\n\n\nCode\nggscatmat(plane_nonlin_pca$x)\n\n\n\n\n\nFigure 2.16: From the scatterplot matrix we can see that the there is a non-linear relationship visible in PC1 and PC2, with perhaps a small contribution from PC3. However, we can see that when the data is reduced to three PCs, it misses catching all on the non-linear relationships and also interestingly it seems that there is an unusual observation also.\n\n\n\n\n\nOne of the dangers of PCA is that interesting and curious details of the data only emerge in the lowest PCs, that are usually discarded. The tour, and examining the smaller PCs can help to discover them."
  },
  {
    "objectID": "model-based-clustering.html#examining-the-model-in-2d",
    "href": "model-based-clustering.html#examining-the-model-in-2d",
    "title": "8  Model-based clustering",
    "section": "8.1 Examining the model in 2D",
    "text": "8.1 Examining the model in 2D\nWe start with two of the four real-valued variables (bl, fl) and the three species. The goal is to determine whether model-based methods can discover clusters that closely correspond to the three species. Based on the scatterplot in Figure 8.1 we would expect it to do well, and suggest an elliptical variance-covariance of roughly equal sizes as the model.\n\n\nCode\nload(\"data/penguins_sub.rda\")\nggplot(penguins_sub, aes(x=bl, \n                         y=fl)) + #, \n                         #colour=species)) +\n  geom_point() +\n  geom_density2d(colour=\"#3B99B1\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1)\n\n\n\n\n\nFigure 8.1: Scatterplot of flipper length by bill length of the penguins data.\n\n\n\n\n\npenguins_BIC <- mclustBIC(penguins_sub[,c(1,3)])\nggmc <- ggmcbic(penguins_BIC, cl=2:9, top=4) + \n  scale_color_discrete_divergingx(palette = \"Roma\") +\n  ggtitle(\"(a)\") +\n  theme_minimal() \npenguins_mc <- Mclust(penguins_sub[,c(1,3)], \n                      G=3, \n                      modelNames = \"EVE\")\npenguins_mce <- mc_ellipse(penguins_mc)\npenguins_cl <- penguins_sub[,c(1,3)]\npenguins_cl$cl <- factor(penguins_mc$classification)\nggell <- ggplot() +\n   geom_point(data=penguins_cl, aes(x=bl, y=fl,\n                                    colour=cl),\n              alpha=0.3) +\n   geom_point(data=penguins_mce$ell, aes(x=bl, y=fl,\n                                         colour=cl),\n              shape=16) +\n   geom_point(data=penguins_mce$mn, aes(x=bl, y=fl,\n                                        colour=cl),\n              shape=3, size=2) +\n  scale_color_discrete_divergingx(palette = \"Zissou 1\")  +\n  theme_minimal() +\n  theme(aspect.ratio=1, legend.position=\"none\") +\n  ggtitle(\"(b)\")\nggmc + ggell + plot_layout(ncol=2)\n\n\n\n\nFigure 8.2: Summary plots from model-based clustering: (a) BIC values for clusters 2-9 of top four models, (b) variance-covariance ellipses and cluster means (+) corresponding to the best model. The best model is three-cluster EVE, which has differently shaped variance-covariances albeit the same volume and orientation.\n\n\n\n\nFigure 8.2 summarises the results. All models agree that three clusters is the best. The different variance-covariance models for three clusters have similar BIC values with EVE (different shape, same volume and orientation) being slightly higher. These plots are made from the mclust package output using the ggmcbic and mc_ellipse functions fro the mulgar package."
  },
  {
    "objectID": "model-based-clustering.html#extending-to-higher-dimensions",
    "href": "model-based-clustering.html#extending-to-higher-dimensions",
    "title": "8  Model-based clustering",
    "section": "8.2 Extending to higher dimensions",
    "text": "8.2 Extending to higher dimensions\nNow we will examine how model-based clustering will group the penguins data using all four variables.\n\npenguins_BIC <- mclustBIC(penguins_sub[,1:4])\nggmc <- ggmcbic(penguins_BIC, cl=2:9, top=7) + \n  scale_color_discrete_divergingx(palette = \"Roma\") +\n  theme_minimal() \nggmc\n\n\n\n\nFigure 8.3: BIC values for the top models for 2-9 clusters on the penguins data. The interpretation is mixed: if one were to choose three clusters any of the variance-covariance models would be equally as good, but the very best model is the four-cluster VEE.\n\n\n\n\n\npenguins_mc <- Mclust(penguins_sub[,1:4], \n                      G=4, \n                      modelNames = \"VEE\")\npenguins_mce <- mc_ellipse(penguins_mc)\npenguins_cl <- penguins_sub\npenguins_cl$cl <- factor(penguins_mc$classification)\n\npenguins_mc_data <- penguins_cl %>%\n  select(bl:bm, cl) %>%\n  mutate(type = \"data\") %>%\n  bind_rows(bind_cols(penguins_mce$ell,\n                      type=rep(\"ellipse\",\n                               nrow(penguins_mce$ell)))) %>%\n  mutate(type = factor(type))\n\nanimate_xy(penguins_mc_data[,1:4],\n           col=penguins_mc_data$cl,\n           pch=c(4, 20 )[as.numeric(penguins_mc_data$type)], \n           axes=\"off\")\n\n# \nload(\"data/penguins_tour_path.rda\")\nrender_gif(penguins_mc_data[,1:4], \n           planned_tour(pt1), \n           display_xy(col=penguins_mc_data$cl,\n               pch=c(4, 20)[\n                 as.numeric(penguins_mc_data$type)], \n                      axes=\"off\",\n               half_range = 0.7),\n           gif_file=\"gifs/penguins_best_mc.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\nCode\npenguins_mc <- Mclust(penguins_sub[,1:4], \n                      G=3, \n                      modelNames = \"EEE\")\npenguins_mce <- mc_ellipse(penguins_mc)\npenguins_cl <- penguins_sub\npenguins_cl$cl <- factor(penguins_mc$classification)\n\npenguins_mc_data <- penguins_cl %>%\n  select(bl:bm, cl) %>%\n  mutate(type = \"data\") %>%\n  bind_rows(bind_cols(penguins_mce$ell,\n                      type=rep(\"ellipse\",\n                               nrow(penguins_mce$ell)))) %>%\n  mutate(type = factor(type))\n\nanimate_xy(penguins_mc_data[,1:4],\n           col=penguins_mc_data$cl,\n           pch=c(4, 20)[as.numeric(penguins_mc_data$type)], \n           axes=\"off\")\n\n# Save the animated gif\nload(\"data/penguins_tour_path.rda\")\nrender_gif(penguins_mc_data[,1:4], \n           planned_tour(pt1), \n           display_xy(col=penguins_mc_data$cl,\n               pch=c(4, 20)[\n                 as.numeric(penguins_mc_data$type)], \n                      axes=\"off\",\n               half_range = 0.7),\n           gif_file=\"gifs/penguins_simpler_mc.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n(a) Best model: four-cluster VEE\n\n\n\n\n\n\n\n(b) Three-cluster EEE\n\n\n\n\nFigure 8.4: Examining the model-based clustering results for the penguins data: (a) best model according to BIC value, (b) simpler three-cluster model. Dots are ellipse points, and “x” are data points. It is important to note that the three cluster solution fits the data better, even though it has a lower BIC.\n\n\n\nVisualising the final choices of models with similarly high BIC values helps to choose which best fits the data. It may not be the one with the highest value."
  },
  {
    "objectID": "model-based-clustering.html#exercises",
    "href": "model-based-clustering.html#exercises",
    "title": "8  Model-based clustering",
    "section": "Exercises",
    "text": "Exercises\n\nExamine the three cluster EVE, VVE and VEE models with the tour, and explain whether these are distinguishably different from the EEE three cluster model.\nFit model-based clustering to the the clusters. Does it suggest the data has three clusters? Using the tour examine the best model model. How well does this fit the data?\nFit model-based clustering to the the multicluster. Does it suggest the data has six clusters? Using the tour examine the best model model. How well does this fit the data?\nFit model-based clustering to the fake_trees data. Does it suggest that the data has 10 clusters? If not, why do you think this is? Using the tour examine the best model model. How well does this fit the branching structure?\nTry fitting model-based clustering to the aflw data? What is the best model? Is the solution related to offensive vs defensive vs mid-fielder skills?\nTODO: Provide some challenge data sets\n\n\n\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31."
  },
  {
    "objectID": "data.html#sketches",
    "href": "data.html#sketches",
    "title": "Appendix B — Data",
    "section": "B.5 Sketches",
    "text": "B.5 Sketches\n\nDescription\nThis data is a subset of images from https://quickdraw.withgoogle.com The subset was created using the quickdraw R package at https://huizezhang-sherry.github.io/quickdraw/. It has 6 different groups: banana, boomerang, cactus, flip flops, kangaroo. Each image is 28x28 pixels. The sketches_train data would be used to train a classification model, and the unlabelled sketches_test can be used for prediction.\n\n\nVariables\n\n\n\nName\nDescription\n\n\n\n\nV1-V784\ngrey scale 0-255\n\n\nword\nwhat the person was asked to draw, NA in the test data\n\n\nid\nunique id for each sketch\n\n\n\n\n\nPurpose\nPrimarily this data is useful as an example for supervised classification, and also dimension reduction.\n\n\nSource\nThe full data is available from https://quickdraw.withgoogle.com.\n\n\nPre-processing\nIt is typically useful to pre-process this data into principal components. This code can also be useful for plotting one of the sketches in a recognisable form:\n\nlibrary(mulgar)\nlibrary(ggplot2)\ndata(\"sketches_train\")\nset.seed(77)\nx <- sketches_train[sample(1:nrow(sketches_train), 1), ]\nxm <- data.frame(gry=t(as.matrix(x[,1:784])),\n        x=rep(1:28, 28),\n        y=rep(28:1, rep(28, 28)))\nggplot(xm, aes(x=x, y=y, fill=gry)) +\n  geom_tile() +\n  scale_fill_gradientn(colors = gray.colors(256, start = 0, end = 1, rev = TRUE )) +\n  ggtitle(x$word) +\n  theme_void() + \n    theme(legend.position=\"none\")\n\n\n\n\nFigure B.1: One of the sketches in the subset of training data."
  },
  {
    "objectID": "kmeans-clustering.html",
    "href": "kmeans-clustering.html",
    "title": "7  \\(k\\)-means clustering",
    "section": "",
    "text": "One of the simplest and efficient techniques for clustering data is the \\(k\\)-means algorithm. The algorithm begins with a choice for \\(k\\), the number of clusters to divide the data into. It is seeded with \\(k\\) initial means, and sequentially iterates through the observations, assigning them to the nearest mean, and re-calculating the \\(k\\) means. It stops at a given number of iterations or when points no longer change clusters. The algorithm will tend to segment the data into roughly equal sized, or spherical clusters, and thus will work well if the clusters are separated and equally spherical in shape.\n\nThe key elements to examine in a k-means clustering algorithm result are:\n\nmeans\nboundaries\n\n\nFigure 7.1 shows the results of \\(k\\)-means clustering on the 2D simple_clusters data and two variables of the penguins data. We can see that it works well when the clusters are spherical, but for the penguins data it fails because the shape of the clusters is elliptical. It actually makes a mistake that would not be made if we simply visually clustered: cluster 3 has grouped points across a gap, a divide that visually we would all agree should form a separation.\n\nlibrary(mulgar)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(colorspace)\nlibrary(patchwork)\ndata(\"simple_clusters\")\nload(\"data/penguins_sub.rda\")\n\nset.seed(202305)\nsc_bl_bd_km <- kmeans(simple_clusters[,1:2], centers=2, \n                     iter.max = 50, nstart = 5)\nsc_bl_bd_km_means <- data.frame(sc_bl_bd_km$centers) %>%\n  mutate(cl = factor(rownames(sc_bl_bd_km$centers)))\nsc_bl_bd_km_d <- simple_clusters[,1:2] %>% \n  mutate(cl = factor(sc_bl_bd_km$cluster))\n\nsc_bl_bd_km_p <- ggplot() +\n  geom_point(data=sc_bl_bd_km_d, \n             aes(x=x1, y=x2, colour=cl), \n             shape=16) +\n  geom_point(data=sc_bl_bd_km_means, \n             aes(x=x1, y=x2, colour=cl), \n             shape=3, size=5) +\n    scale_color_discrete_divergingx(\"Zissou 1\") +\n  ggtitle(\"(a)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, \n        legend.position = \"bottom\",\n        legend.title = element_blank()) \n\n\np_bl_bd_km <- kmeans(penguins_sub[,1:2], centers=3, \n                     iter.max = 50, nstart = 5)\np_bl_bd_km_means <- data.frame(p_bl_bd_km$centers) %>%\n  mutate(cl = factor(rownames(p_bl_bd_km$centers)))\np_bl_bd_km_d <- penguins_sub[,1:2] %>% \n  mutate(cl = factor(p_bl_bd_km$cluster))\n\np_bl_bd_km_p <- ggplot() +\n  geom_point(data=p_bl_bd_km_d, \n             aes(x=bl, y=bd, colour=cl), shape=16) +\n  geom_point(data=p_bl_bd_km_means, \n             aes(x=bl, y=bd, colour=cl), shape=3, size=5) +\n    scale_color_discrete_divergingx(\"Zissou 1\") +\n  ggtitle(\"(b)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, \n        legend.position = \"bottom\",\n        legend.title = element_blank()) \n\nsc_bl_bd_km_p + p_bl_bd_km_p + plot_layout(ncol=2)\n\n\n\n\nFigure 7.1: Examining \\(k\\)-means clustering results for simple clusters (a) and two variables of the penguins data (b). The means are indicated by a \\(+\\). The results are perfect for the simple clusters but not for the penguins data. The penguin clusters are elliptically shaped which is not captured by \\(k\\)-means. Cluster 3 has observations grouped across a gap in the data.\n\n\n\n\nThis approach extends to high-dimensions. One colours observations by the cluster label, and overlays the final cluster means. If we see gaps in points in a single cluster it would mean that \\(k\\)-means fails to see important cluster structure.\nGenerally, there is no need to choose \\(k\\) ahead of time. One would re-fit \\(k\\)-means with various choices of \\(k\\), and compare the tot.withinss and examine the clusters visually, to decide on the optimal final value of \\(k\\)."
  },
  {
    "objectID": "LDA.html#exercises",
    "href": "LDA.html#exercises",
    "title": "11  Linear discriminant analysis",
    "section": "Exercises",
    "text": "Exercises\n\nFor the simple_clusters compute the lda model, and make a plot of the data, with points coloured by the class. Overlay variance-covariance ellipses, and a \\(+\\) indicating the sample mean for each class. Is it reasonable to assume that the two classes are sampled from populations with the same variance-covariance?\nExamine the clusters corresponding to the classes in the clusters data set, using a tour. Based on the shape of the data is the assumption of equal variance-coviance reasonable?\nExamine the pooled variance-covariance for the clusters data, overlaid on the data in a tour on the 5D. Does it fit the variance of each cluster nicely?\nFit an LDA model to the simple_clusters data. Examine the boundaries produced by the model, in 2D.\nFit an LDA model to the clusters data. Examine the boundaries produced by the model in 5D.\nAssess the LDA assumptions for the multicluster data. Is LDA an appropriate model?\n\n\n\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nVenables, W. N., and B. Ripley. 2002. Modern Applied Statistics with S. New York: Springer-Verlag."
  },
  {
    "objectID": "LDA.html#about-the-model-and-extracting-the-key-elements",
    "href": "LDA.html#about-the-model-and-extracting-the-key-elements",
    "title": "11  Linear discriminant analysis",
    "section": "11.1 About the model and extracting the key elements",
    "text": "11.1 About the model and extracting the key elements\nFisher’s linear discriminant (Fisher 1936) computes a linear combination of the variables that separates two classes by comparing the differences between class means with the variance of values within each class. It makes no assumptions about the distribution of the data.\nLinear discriminant analysis (LDA), as proposed by Rao (1948), formalizes Fisher’s approach, by recognising that it arises from making the assumption that the data values for each class arise from a \\(p\\)-dimensional multivariate normal distribution, sharing a common variance-covariance matrix with data from other classes. When this assumption holds, Fisher’s linear discriminant gives the optimal separation between the two groups.\nFor two equally weighted groups, where \\(Y\\) is coded as \\(\\{0, 1\\}\\), the LDA rule is:\nAllocate a new observation \\(X_0\\) to group 1 if\n\\[(\\bar{X}_1-\\bar{X}_2)'S^{-1}_{\\rm pooled}X_0 \\geq\n  \\frac{1}{2}(\\bar{X}_1-\\bar{X}_2)'S^{-1}_{\\rm pooled}\n  (\\bar{X}_1+\\bar{X}_2)\\]\nelse allocate it to group 2,\nwhere \\(\\bar{X}_k\\) are the class mean vectors of an \\(n\\times p\\) data matrix \\(X_k ~~(k=1,2)\\),\n\\[S_{\\rm pooled} = \\frac{(n_1-1) S_1}{(n_1-1)+(n_2-1)} + \\frac{(n_2-1) S_2}{(n_1-1)+(n_2-1)}\\]\nis the pooled variance-covariance matrix, and\n\\[S_k = \\frac{1}{n-1}\\sum_{i=1}^{n}\n(X_{ki}-\\bar{X}_k)(X_{ki}-\\bar{X}_k)', ~~k=1,2\\]\nis the class variance–covariance matrix. The linear discriminant part of this rule is \\((\\bar{X}_1-\\bar{X}_2)'S^{-1}_{\\rm pooled}\\), which defines the linear combination of variables that best separates the two groups. To define a classification rule, we compute the value of the new observation \\(X_0\\) on this line and compare it with the value of the average of the two class means \\((\\bar{X}_1+\\bar{X}_2)/2\\) on the same line.\nFor multiple \\((g)\\) classes, the rule and the discriminant space are constructed using the between-group sum-of-squares matrix,\n\\[B=\\sum_{k=1}^g n_k(\\bar{X}_k-\\bar{X})(\\bar{X}_k-\\bar{X})'\\]\nwhich measures the differences between the class means, compared with the overall data mean \\(\\bar{X}\\) and the within-group sum-of-squares matrix,\n\\[W =\n\\sum_{k=1}^g\\sum_{i=1}^{n_k}\n(X_{ki}-\\bar{X}_k)(X_{ki}-\\bar{X}_k)'\\]\nwhich measures the variation of values around each class mean. The linear discriminant space is generated by computing the eigenvectors (canonical coordinates) of \\(W^{-1}B\\), and this is the space where the group means are most separated with respect to the pooled variance–covariance. The resulting classification rule is to allocate a new observation to the class with the highest value of\n\\[\\bar{X}_k'S^{-1}_{\\rm pooled}X_0 -\n\\frac{1}{2}\\bar{X}_k'S^{-1}_{\\rm pooled}\\bar{X}_k ~~~k=1,...,g\\]\nwhich results in allocating the new observation into the class with the closest mean.\n\nBecause LDA is a parametric model it is important to check that the assumptions are reasonable:\n\nshape of clusters are elliptical\ncluster sizes are the same."
  },
  {
    "objectID": "LDA.html#extracting-the-key-elements-of-the-model",
    "href": "LDA.html#extracting-the-key-elements-of-the-model",
    "title": "11  Linear discriminant analysis",
    "section": "11.1 Extracting the key elements of the model",
    "text": "11.1 Extracting the key elements of the model\nLDA builds the model on the between-group sum-of-square matrix\n\\[B=\\sum_{k=1}^g n_k(\\bar{X}_k-\\bar{X})(\\bar{X}_k-\\bar{X})^\\top\\] which measures the differences between the class means, compared with the overall data mean \\(\\bar{X}\\) and the within-group sum-of-squares matrix,\n\\[W =\n\\sum_{k=1}^g\\sum_{i=1}^{n_k}\n(X_{ki}-\\bar{X}_k)(X_{ki}-\\bar{X}_k)^\\top\\]\nwhich measures the variation of values around each class mean. The linear discriminant space is generated by computing the eigenvectors (canonical coordinates) of \\(W^{-1}B\\), and this is the \\((g-1)\\)-D space where the group means are most separated with respect to the pooled variance-covariance.\n\\[\n\\delta_k(x) = (x-\\mu_k)^\\top W^{-1}\\mu_k + \\log \\pi_k\n\\]\nwhere \\(\\pi_k\\) is a prior probability for class \\(k\\) that might be based on unequal sample sizes, or cost of misclassification. The LDA classifier rule is to assign a new observation to the class with the largest value.\nWe can fit an LDA model using the lda() function from the MASS package. Here we have used the penguins data, assuming equal prior probability, to illustrate.\n\nlibrary(dplyr)\nlibrary(mulgar)\nlibrary(MASS)\nload(\"data/penguins_sub.rda\")\n\np_lda <- lda(species~bl+bd+fl+bm, data=penguins_sub, prior=c(1/3, 1/3, 1/3))\noptions(digits=2)\np_lda\n\nCall:\nlda(species ~ bl + bd + fl + bm, data = penguins_sub, prior = c(1/3, \n    1/3, 1/3))\n\nPrior probabilities of groups:\n   Adelie Chinstrap    Gentoo \n     0.33      0.33      0.33 \n\nGroup means:\n             bl    bd    fl    bm\nAdelie    -0.95  0.60 -0.78 -0.62\nChinstrap  0.89  0.64 -0.37 -0.59\nGentoo     0.65 -1.10  1.16  1.10\n\nCoefficients of linear discriminants:\n     LD1   LD2\nbl  0.24 -2.31\nbd -2.04  0.19\nfl  1.20  0.08\nbm  1.22  1.24\n\nProportion of trace:\n LD1  LD2 \n0.83 0.17 \n\n\nBecause there are three classes the dimension of the discriminant space is 2D. We can easily extract the group means from the model.\n\np_lda$means\n\n             bl    bd    fl    bm\nAdelie    -0.95  0.60 -0.78 -0.62\nChinstrap  0.89  0.64 -0.37 -0.59\nGentoo     0.65 -1.10  1.16  1.10\n\n\nThe coefficients to project the data into the discriminant space, that is the eigenvectors of \\(W^{-1}B\\) are:\n\np_lda$scaling\n\n     LD1   LD2\nbl  0.24 -2.31\nbd -2.04  0.19\nfl  1.20  0.08\nbm  1.22  1.24\n\n\nand the predicted values, which include class predictions, and coordinates in the discriminant space are generated as:\n\np_lda_pred <- predict(p_lda, penguins_sub)\n\nThe best separation between classes can be viewed from this object, which can be shown to match the original data projected using the scaling component of the model object.\n\nlibrary(colorspace)\nlibrary(ggplot2)\nlibrary(ggpubr)\np_lda_pred_x1 <- data.frame(p_lda_pred$x)\np_lda_pred_x1$species <- penguins_sub$species\np_lda1 <- ggplot(p_lda_pred_x1, \n                 aes(x=LD1, y=LD2, \n                     colour=species)) + \n  geom_point() +\n  xlim(-6, 8) + ylim(-6.5, 5.5) +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  ggtitle(\"(a)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, legend.title = element_blank()) \n\np_lda_pred_x2 <- data.frame(as.matrix(penguins_sub[,1:4]) %*%\n                              p_lda$scaling)\np_lda_pred_x2$species <- penguins_sub$species\np_lda2 <- ggplot(p_lda_pred_x2, \n                 aes(x=LD1, y=LD2, \n                     colour=species)) + \n  geom_point() +\n  xlim(-6, 8) + ylim(-7, 5.5) +\n  scale_color_discrete_divergingx(\"Zissou 1\") +\n  ggtitle(\"(b)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, legend.title = element_blank()) \nggarrange(p_lda1, p_lda2, ncol=2, \n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\nFigure 11.1: Penguins projected into the 2D discriminant space, done two ways: (a) using the predicted values, (b) directly projecting using the model component. The scale is not quite the same but the projected data is identical in shape.\n\n\n\n\nThe \\(W\\) and \\(B\\) matrices cannot be extracted from the model object, so we need to compute these separately. We only need \\(W\\) actually. It is useful to think of this as the pooled variance-covariance matrix. Because the assumption for LDA is that the population group variance-covariances are identical, we estimate this by computing them for each class and then averaging them to get the pooled variance-covariance matrix. It’s laborious, but easy.\n\np_vc_pool <- mulgar::pooled_vc(penguins_sub[,1:4],\n                               penguins_sub$species)\np_vc_pool\n\n     bl   bd   fl   bm\nbl 0.31 0.18 0.13 0.18\nbd 0.18 0.32 0.14 0.20\nfl 0.13 0.14 0.23 0.16\nbm 0.18 0.20 0.16 0.31\n\n\nThis can be used to draw an ellipse corresponding to the pooled variance-covariance that is used by the LDA model."
  },
  {
    "objectID": "kmeans-clustering.html#exercises",
    "href": "kmeans-clustering.html#exercises",
    "title": "7  \\(k\\)-means clustering",
    "section": "Exercises",
    "text": "Exercises\n\nCompute a \\(k\\)-means clustering for the fake_trees data, varying \\(k\\) to about 20. Choose your best \\(k\\), and examine the solution using the first 10 PCs on the data. It should capture the data quite nicely, although it will break up each branch into multiple clusters.\nCompute a \\(k\\)-means clustering of the first four PCs of the aflw data. Examine the best solution (you choose which \\(k\\)), and describe how it divides the data. By examining the means, can you tell if it extracts clusters of offensive vs defensive vs midfield players? Or does it break the data into high skills vs low skills?\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBoelaert, Julien, Etienne Ollion, and Jan Sodoge. 2022. aweSOM: Interactive Self-Organizing Maps. https://CRAN.R-project.org/package=aweSOM.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nde Vries, Andrie, and Brian D. Ripley. 2022. Ggdendro: Create Dendrograms and Tree Diagrams Using Ggplot2. https://github.com/andrie/ggdendro.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2023. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2023. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIannone, Richard, Joe Cheng, Barret Schloerke, Ellis Hughes, and JooYoung Seo. 2022. Gt: Easily Create Presentation-Ready Display Tables. https://CRAN.R-project.org/package=gt.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2023. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2022. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMock, Thomas. 2022. gtExtras: Extending Gt for Beautiful HTML Tables. https://CRAN.R-project.org/package=gtExtras.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2022. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2023. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2023. Plotly: Create Interactive Web Graphics via Plotly.js.\n\n\nSjoberg, Daniel D., Joseph Larmarange, Michael Curry, Jessica Lavery, Karissa Whiting, and Emily C. Zabor. 2023. Gtsummary: Presentation-Ready Data Summary and Analytic Result Tables. https://CRAN.R-project.org/package=gtsummary.\n\n\nSjoberg, Daniel D., Karissa Whiting, Michael Curry, Jessica A. Lavery, and Joseph Larmarange. 2021. “Reproducible Summary Tables with the Gtsummary Package.” The R Journal 13: 570–80. https://doi.org/10.32614/RJ-2021-053.\n\n\nSlowikowski, Kamil. 2023. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2023. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2023. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "kmeans-clustering.html#examining-k-means-in-2d",
    "href": "kmeans-clustering.html#examining-k-means-in-2d",
    "title": "7  \\(k\\)-means clustering",
    "section": "7.1 Examining \\(k\\)-means in 2D",
    "text": "7.1 Examining \\(k\\)-means in 2D\nFigure 7.1 shows the results of \\(k\\)-means clustering on the 2D simple_clusters data and two variables of the penguins data. We can see that it works well when the clusters are spherical, but for the penguins data it fails because the shape of the clusters is elliptical. It actually makes a mistake that would not be made if we simply visually clustered: cluster 3 has grouped points across a gap, a divide that visually we would all agree should form a separation.\n\nlibrary(mulgar)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(colorspace)\nlibrary(patchwork)\ndata(\"simple_clusters\")\nload(\"data/penguins_sub.rda\")\n\nset.seed(202305)\nsc_bl_bd_km <- kmeans(simple_clusters[,1:2], centers=2, \n                     iter.max = 50, nstart = 5)\nsc_bl_bd_km_means <- data.frame(sc_bl_bd_km$centers) %>%\n  mutate(cl = factor(rownames(sc_bl_bd_km$centers)))\nsc_bl_bd_km_d <- simple_clusters[,1:2] %>% \n  mutate(cl = factor(sc_bl_bd_km$cluster))\n\nsc_bl_bd_km_p <- ggplot() +\n  geom_point(data=sc_bl_bd_km_d, \n             aes(x=x1, y=x2, colour=cl), \n             shape=16) +\n  geom_point(data=sc_bl_bd_km_means, \n             aes(x=x1, y=x2, colour=cl), \n             shape=3, size=5) +\n    scale_color_discrete_divergingx(\"Zissou 1\") +\n  ggtitle(\"(a)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, \n        legend.position = \"bottom\",\n        legend.title = element_blank()) \n\np_bl_bd_km <- kmeans(penguins_sub[,1:2], centers=3, \n                     iter.max = 50, nstart = 5)\np_bl_bd_km_means <- data.frame(p_bl_bd_km$centers) %>%\n  mutate(cl = factor(rownames(p_bl_bd_km$centers)))\np_bl_bd_km_d <- penguins_sub[,1:2] %>% \n  mutate(cl = factor(p_bl_bd_km$cluster))\n\np_bl_bd_km_p <- ggplot() +\n  geom_point(data=p_bl_bd_km_d, \n             aes(x=bl, y=bd, colour=cl), shape=16) +\n  geom_point(data=p_bl_bd_km_means, \n             aes(x=bl, y=bd, colour=cl), shape=3, size=5) +\n    scale_color_discrete_divergingx(\"Zissou 1\") +\n  ggtitle(\"(b)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, \n        legend.position = \"bottom\",\n        legend.title = element_blank()) \n\nsc_bl_bd_km_p + p_bl_bd_km_p + plot_layout(ncol=2)\n\n\n\n\nFigure 7.1: Examining \\(k\\)-means clustering results for simple clusters (a) and two variables of the penguins data (b). The means are indicated by a \\(+\\). The results are perfect for the simple clusters but not for the penguins data. The penguin clusters are elliptically shaped which is not captured by \\(k\\)-means. Cluster 3 has observations grouped across a gap in the data."
  },
  {
    "objectID": "kmeans-clustering.html#k-means-high-dimensions",
    "href": "kmeans-clustering.html#k-means-high-dimensions",
    "title": "7  \\(k\\)-means clustering",
    "section": "7.2 \\(k\\)-means high dimensions",
    "text": "7.2 \\(k\\)-means high dimensions\nThis approach extends to high-dimensions. One colours observations by the cluster label, and overlays the final cluster means. If we see gaps in points in a single cluster it would mean that \\(k\\)-means fails to see important cluster structure. This is what happens with the 4D penguins data as shown in Figure 7.2.\n\np_km <- kmeans(penguins_sub[,1:4], centers=3, \n                     iter.max = 50, nstart = 5)\np_km_means <- data.frame(p_km$centers) %>%\n  mutate(cl = factor(rownames(p_km$centers)))\np_km_d <- penguins_sub[,1:4] %>% \n  mutate(cl = factor(p_km$cluster))\n\n\n\nCode\nlibrary(tourr)\np_km_means <- p_km_means %>%\n  mutate(type = \"mean\")\np_km_d <- p_km_d %>%\n  mutate(type = \"data\")\np_km_all <- bind_rows(p_km_means, p_km_d)\np_km_all$type <- factor(p_km_all$type, levels=c(\"mean\", \"data\"))\np_pch <- c(3, 20)[as.numeric(p_km_all$type)]\np_cex <- c(3, 1)[as.numeric(p_km_all$type)]\nanimate_xy(p_km_all[,1:4], col=p_km_all$cl, \n           pch=p_pch, cex=p_cex, axes=\"bottomleft\")\nrender_gif(p_km_all[,1:4],\n           grand_tour(),\n           display_xy(col=p_km_all$cl, \n                      pch=p_pch, \n                      cex=p_cex, \n                      axes=\"bottomleft\"),\n           gif_file=\"gifs/p_km.gif\",\n           width=400,\n           height=400,\n           frames=500)\n\n\n\n\n\nFigure 7.2: Exploring the k-means clustering result for the 4D penguins data. You can see cluster 2 clearly separated from the other observations. Cluster 3, like in the 2D example, is a mix of observations across a gap. Even the mean of the cluster is almost in the gap.\n\n\nGenerally, there is no need to choose \\(k\\) ahead of time. One would re-fit \\(k\\)-means with various choices of \\(k\\), and compare the tot.withinss and examine the clusters visually, to decide on the optimal final value of \\(k\\). This can be assessed in a similar way to the scree plot for PCA."
  },
  {
    "objectID": "kmeans-clustering.html#examining-results-in-2d",
    "href": "kmeans-clustering.html#examining-results-in-2d",
    "title": "7  \\(k\\)-means clustering",
    "section": "7.1 Examining results in 2D",
    "text": "7.1 Examining results in 2D\nFigure 7.1 shows the results of \\(k\\)-means clustering on the 2D simple_clusters data and two variables of the penguins data. We can see that it works well when the clusters are spherical, but for the penguins data it fails because the shape of the clusters is elliptical. It actually makes a mistake that would not be made if we simply visually clustered: cluster 3 has grouped points across a gap, a divide that visually we would all agree should form a separation.\n\nlibrary(mulgar)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(colorspace)\nlibrary(patchwork)\ndata(\"simple_clusters\")\nload(\"data/penguins_sub.rda\")\n\nset.seed(202305)\nsc_bl_bd_km <- kmeans(simple_clusters[,1:2], centers=2, \n                     iter.max = 50, nstart = 5)\nsc_bl_bd_km_means <- data.frame(sc_bl_bd_km$centers) %>%\n  mutate(cl = factor(rownames(sc_bl_bd_km$centers)))\nsc_bl_bd_km_d <- simple_clusters[,1:2] %>% \n  mutate(cl = factor(sc_bl_bd_km$cluster))\n\nsc_bl_bd_km_p <- ggplot() +\n  geom_point(data=sc_bl_bd_km_d, \n             aes(x=x1, y=x2, colour=cl), \n             shape=16, alpha=0.4) +\n  geom_point(data=sc_bl_bd_km_means, \n             aes(x=x1, y=x2, colour=cl), \n             shape=3, size=5) +\n    scale_color_discrete_divergingx(\"Zissou 1\") +\n  ggtitle(\"(a)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, \n        legend.position = \"bottom\",\n        legend.title = element_blank()) \n\np_bl_bd_km <- kmeans(penguins_sub[,1:2], centers=3, \n                     iter.max = 50, nstart = 5)\np_bl_bd_km_means <- data.frame(p_bl_bd_km$centers) %>%\n  mutate(cl = factor(rownames(p_bl_bd_km$centers)))\np_bl_bd_km_d <- penguins_sub[,1:2] %>% \n  mutate(cl = factor(p_bl_bd_km$cluster))\n\np_bl_bd_km_p <- ggplot() +\n  geom_point(data=p_bl_bd_km_d, \n             aes(x=bl, y=bd, colour=cl), \n             shape=16, alpha=0.4) +\n  geom_point(data=p_bl_bd_km_means, \n             aes(x=bl, y=bd, colour=cl), \n             shape=3, size=5) +\n    scale_color_discrete_divergingx(\"Zissou 1\") +\n  ggtitle(\"(b)\") +\n  theme_minimal() +\n  theme(aspect.ratio = 1, \n        legend.position = \"bottom\",\n        legend.title = element_blank()) \n\nsc_bl_bd_km_p + p_bl_bd_km_p + plot_layout(ncol=2)\n\n\n\n\nFigure 7.1: Examining \\(k\\)-means clustering results for simple clusters (a) and two variables of the penguins data (b). The means are indicated by a \\(+\\). The results are perfect for the simple clusters but not for the penguins data. The penguin clusters are elliptically shaped which is not captured by \\(k\\)-means. Cluster 3 has observations grouped across a gap in the data."
  },
  {
    "objectID": "kmeans-clustering.html#in-high-dimensions",
    "href": "kmeans-clustering.html#in-high-dimensions",
    "title": "7  \\(k\\)-means clustering",
    "section": "7.2 In high dimensions",
    "text": "7.2 In high dimensions\nThis approach extends to high-dimensions. One colours observations by the cluster label, and overlays the final cluster means. If we see gaps in points in a single cluster it would mean that \\(k\\)-means fails to see important cluster structure. This is what happens with the 4D penguins data as shown in Figure 7.2.\n\np_km <- kmeans(penguins_sub[,1:4], centers=3, \n                     iter.max = 50, nstart = 5)\np_km_means <- data.frame(p_km$centers) %>%\n  mutate(cl = factor(rownames(p_km$centers)))\np_km_d <- penguins_sub[,1:4] %>% \n  mutate(cl = factor(p_km$cluster))\n\n\n\nCode\nlibrary(tourr)\np_km_means <- p_km_means %>%\n  mutate(type = \"mean\")\np_km_d <- p_km_d %>%\n  mutate(type = \"data\")\np_km_all <- bind_rows(p_km_means, p_km_d)\np_km_all$type <- factor(p_km_all$type, levels=c(\"mean\", \"data\"))\np_pch <- c(3, 20)[as.numeric(p_km_all$type)]\np_cex <- c(3, 1)[as.numeric(p_km_all$type)]\nanimate_xy(p_km_all[,1:4], col=p_km_all$cl, \n           pch=p_pch, cex=p_cex, axes=\"bottomleft\")\nrender_gif(p_km_all[,1:4],\n           grand_tour(),\n           display_xy(col=p_km_all$cl, \n                      pch=p_pch, \n                      cex=p_cex, \n                      axes=\"bottomleft\"),\n           gif_file=\"gifs/p_km.gif\",\n           width=400,\n           height=400,\n           frames=500)\n\n\n\n\n\nFigure 7.2: Exploring the k-means clustering result for the 4D penguins data. You can see cluster 2 clearly separated from the other observations. Cluster 3, like in the 2D example, is a mix of observations across a gap. Even the mean of the cluster is almost in the gap.\n\n\nGenerally, there is no need to choose \\(k\\) ahead of time. One would re-fit \\(k\\)-means with various choices of \\(k\\), and compare the tot.withinss and examine the clusters visually, to decide on the optimal final value of \\(k\\). This can be assessed in a similar way to the scree plot for PCA."
  },
  {
    "objectID": "kmeans-clustering.html#examining-results-in-high-dimensions",
    "href": "kmeans-clustering.html#examining-results-in-high-dimensions",
    "title": "7  \\(k\\)-means clustering",
    "section": "7.2 Examining results in high dimensions",
    "text": "7.2 Examining results in high dimensions\nThis approach extends to high-dimensions. One colours observations by the cluster label, and overlays the final cluster means. If we see gaps in points in a single cluster it would mean that \\(k\\)-means fails to see important cluster structure. This is what happens with the 4D penguins data as shown in Figure 7.2.\n\np_km <- kmeans(penguins_sub[,1:4], centers=3, \n                     iter.max = 50, nstart = 5)\np_km_means <- data.frame(p_km$centers) %>%\n  mutate(cl = factor(rownames(p_km$centers)))\np_km_d <- penguins_sub[,1:4] %>% \n  mutate(cl = factor(p_km$cluster))\n\n\n\nCode\nlibrary(tourr)\np_km_means <- p_km_means %>%\n  mutate(type = \"mean\")\np_km_d <- p_km_d %>%\n  mutate(type = \"data\")\np_km_all <- bind_rows(p_km_means, p_km_d)\np_km_all$type <- factor(p_km_all$type, levels=c(\"mean\", \"data\"))\np_pch <- c(3, 20)[as.numeric(p_km_all$type)]\np_cex <- c(3, 1)[as.numeric(p_km_all$type)]\nanimate_xy(p_km_all[,1:4], col=p_km_all$cl, \n           pch=p_pch, cex=p_cex, axes=\"bottomleft\")\nrender_gif(p_km_all[,1:4],\n           grand_tour(),\n           display_xy(col=p_km_all$cl, \n                      pch=p_pch, \n                      cex=p_cex, \n                      axes=\"bottomleft\"),\n           gif_file=\"gifs/p_km.gif\",\n           width=400,\n           height=400,\n           frames=500)\n\n\n\n\n\nFigure 7.2: Exploring the k-means clustering result for the 4D penguins data. You can see cluster 2 clearly separated from the other observations. Cluster 3, like in the 2D example, is a mix of observations across a gap. Even the mean of the cluster is almost in the gap.\n\n\nGenerally, there is no need to choose \\(k\\) ahead of time. One would re-fit \\(k\\)-means with various choices of \\(k\\), and compare the tot.withinss and examine the clusters visually, to decide on the optimal final value of \\(k\\). This can be assessed in a similar way to the scree plot for PCA."
  },
  {
    "objectID": "misclassifications.html#exercises",
    "href": "misclassifications.html#exercises",
    "title": "15  Exploring misclassifications",
    "section": "Exercises",
    "text": "Exercises\n\nExamine misclassifications for the fake_trees data between cluster 1 and 0, using the votes matrix instead of the principal components. Describe where these errors fall in the simplex.\nExamine the misclassifications for the sketches data, focusing on cactus sketches that were mistaken for bananas. Follow up by plotting the images of these errors, and describe whether the classifier is correct that these sketches are so poor their true cactus identity cannot be determined.\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create Interactive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Interactive and dynamic graphics for high-dimensional data using R",
    "section": "License",
    "text": "License\nThe online version of this book is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n\n\n\n\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBoelaert, Julien, Etienne Ollion, and Jan Sodoge. 2022. aweSOM: Interactive Self-Organizing Maps. https://CRAN.R-project.org/package=aweSOM.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nde Vries, Andrie, and Brian D. Ripley. 2022. Ggdendro: Create Dendrograms and Tree Diagrams Using Ggplot2. https://github.com/andrie/ggdendro.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2023. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2023. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIannone, Richard, Joe Cheng, Barret Schloerke, Ellis Hughes, and JooYoung Seo. 2022. Gt: Easily Create Presentation-Ready Display Tables. https://CRAN.R-project.org/package=gt.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2023. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2022. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMock, Thomas. 2022. gtExtras: Extending Gt for Beautiful HTML Tables. https://CRAN.R-project.org/package=gtExtras.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2022. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2023. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2023. Plotly: Create Interactive Web Graphics via Plotly.js.\n\n\nSjoberg, Daniel D., Joseph Larmarange, Michael Curry, Jessica Lavery, Karissa Whiting, and Emily C. Zabor. 2023. Gtsummary: Presentation-Ready Data Summary and Analytic Result Tables. https://CRAN.R-project.org/package=gtsummary.\n\n\nSjoberg, Daniel D., Karissa Whiting, Michael Curry, Jessica A. Lavery, and Joseph Larmarange. 2021. “Reproducible Summary Tables with the Gtsummary Package.” The R Journal 13: 570–80. https://doi.org/10.32614/RJ-2021-053.\n\n\nSlowikowski, Kamil. 2023. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2023. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2023. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "som.html#exercises",
    "href": "som.html#exercises",
    "title": "9  Self-organizing maps",
    "section": "Exercises",
    "text": "Exercises\n\nFit an SOM to the first four PCs of the aflw data. Examine the best solution (you choose the size of the net), and describe how the map lays out the data. Does it show offensive vs defensive vs midfield players? Or does it tend to show high skills vs low skills?\nFit an SOM to the first 10 PCs of the fake_trees data, using your choice of net size. How well does the map show the branching structure?\nExamine a range of SOM nets fitted to the first 10 PCs of the fake_trees data in the 10D space using a tour. Set the values of rlen to be 5, 50, 500. How does the net change on this parameter?\nPlot the distances output for the SOM fit to the penguins data. Mark the observations that have the 5 biggest distances, and show these in a tour. These are the observations where the net has fitted least well, and may be outliers.\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create Interactive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "toolbox.html#types-of-tours",
    "href": "toolbox.html#types-of-tours",
    "title": "Appendix A — Toolbox",
    "section": "A.1 Types of tours",
    "text": "A.1 Types of tours\nDescription and explanation of primary methods used throughout the book. Mostly focusing on tour methods.\nWe need a really nice friendly introduction to tour methods:\n\n2D to 1D projections as basic explanation\nmaybe 3D to 2D, or even 4D to 2D illustration\n\nShow examples of what can be gained from looking at combinations as opposed to pairs plots, for example. Clusters is a good situation, but also collinearity and outliers\nExplain data needed for input, what happens if discrete data is included, or time series\nWorking with many dimensions, how to adapt\nGrand tour, and show paths on the space, starting with 1D. How more time gives more coverage of the sphere. Then the torus and paths on torus.\nDifferent types of tours, and when to use them.\nAnd finally how to save tours, and make plot of single projection\nNeed to include - half_range - standardizing variables"
  },
  {
    "objectID": "toolbox.html#software",
    "href": "toolbox.html#software",
    "title": "Appendix A — Toolbox",
    "section": "A.2 Software",
    "text": "A.2 Software\nAlso include other software now available\n\ndetourr\nlangevitour\nwoylier\nspinifex\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBoelaert, Julien, Etienne Ollion, and Jan Sodoge. 2022. aweSOM: Interactive Self-Organizing Maps. https://CRAN.R-project.org/package=aweSOM.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nde Vries, Andrie, and Brian D. Ripley. 2022. Ggdendro: Create Dendrograms and Tree Diagrams Using Ggplot2. https://github.com/andrie/ggdendro.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2023. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2023. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIannone, Richard, Joe Cheng, Barret Schloerke, Ellis Hughes, and JooYoung Seo. 2022. Gt: Easily Create Presentation-Ready Display Tables. https://CRAN.R-project.org/package=gt.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2023. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2022. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMock, Thomas. 2022. gtExtras: Extending Gt for Beautiful HTML Tables. https://CRAN.R-project.org/package=gtExtras.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2022. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2023. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2023. Plotly: Create Interactive Web Graphics via Plotly.js.\n\n\nSjoberg, Daniel D., Joseph Larmarange, Michael Curry, Jessica Lavery, Karissa Whiting, and Emily C. Zabor. 2023. Gtsummary: Presentation-Ready Data Summary and Analytic Result Tables. https://CRAN.R-project.org/package=gtsummary.\n\n\nSjoberg, Daniel D., Karissa Whiting, Michael Curry, Jessica A. Lavery, and Joseph Larmarange. 2021. “Reproducible Summary Tables with the Gtsummary Package.” The R Journal 13: 570–80. https://doi.org/10.32614/RJ-2021-053.\n\n\nSlowikowski, Kamil. 2023. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2023. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2023. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "toolbox.html#types-of-tours-in-the-tourr-package",
    "href": "toolbox.html#types-of-tours-in-the-tourr-package",
    "title": "Appendix A — Toolbox",
    "section": "A.3 Types of tours in the tourr package",
    "text": "A.3 Types of tours in the tourr package\n\ninstall\nstarting a tour\n\nWorking with many dimensions, how to adapt\nGrand tour, and show paths on the space, starting with 1D. How more time gives more coverage of the sphere. Then the torus and paths on torus.\nDifferent types of tours, and when to use them.\nAnd finally how to save tours, and make plot of single projection\nNeed to include - half_range - standardizing variables"
  },
  {
    "objectID": "toolbox.html#tours-in-other-software",
    "href": "toolbox.html#tours-in-other-software",
    "title": "Appendix A — Toolbox",
    "section": "A.3 Tours in other software",
    "text": "A.3 Tours in other software\nAlso include other software now available\n\ndetourr\nlangevitour\nwoylier\nspinifex\nferrn\n\n\n\n\n\nAbbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create Interactive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "toolbox.html#getting-familiar-with-tours",
    "href": "toolbox.html#getting-familiar-with-tours",
    "title": "Appendix A — Toolbox",
    "section": "A.1 Getting familiar with tours",
    "text": "A.1 Getting familiar with tours\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) 2D data\n\n\n\n\n\n\n\n\n(b) 1D grand tour\n\n\n\n\nFigure A.1: To illustrate how a tour can be used to explore high-dimensional data using 2D data (a) and a tour of 1D projections (b). Imagine spinning a line around the centre of the data plot, and at each spot all of the points are projected onto the line. The distribution of points will be different for different angles.\n\n\nFigure A.1 illustrates a tour for 2D data and 1D projections. The (grand) tour will generate all possible 1D projections of the data, and display with a univariate plot like a histogram or density plot. For this data, the simple_clusters data, depending on the projection the distribution might be clustered into two groups, bimodal or unimodal (with no clusters). In this example, all projections are generated by rotating a line around the centre of the plot.\n3D example next"
  },
  {
    "objectID": "toolbox.html#what-can-you-learn",
    "href": "toolbox.html#what-can-you-learn",
    "title": "Appendix A — Toolbox",
    "section": "A.2 What can you learn?",
    "text": "A.2 What can you learn?"
  },
  {
    "objectID": "toolbox.html#what-not-to-do",
    "href": "toolbox.html#what-not-to-do",
    "title": "Appendix A — Toolbox",
    "section": "A.2 What not to do",
    "text": "A.2 What not to do\n\nCategorical data, or discrete data\nWhen time or space is a variable"
  },
  {
    "objectID": "toolbox.html#using-tours-in-the-tourr-package",
    "href": "toolbox.html#using-tours-in-the-tourr-package",
    "title": "Appendix A — Toolbox",
    "section": "A.1 Using tours in the tourr package",
    "text": "A.1 Using tours in the tourr package\n\nA.1.1 Installation\nYou can install the released version of tourr from CRAN with:\ninstall.packages(\"tourr\")\nand the development version from github with:\n# install.packages(\"remotes\")\nremotes::install_github(\"ggobi/tourr\")\n\n\nA.1.2 Getting started\nTo run a tour in R, use one of the animate functions. This code will show a 2D tour displayed as a scatterplot on a 6D data set with three labelled classes.\nanimate_xy(flea[,-7], col=flea$species)\nWickham et al. (2011a) remains a good reference for learning more about this package.\n\n\nA.1.3 Different tours\nThere are two main components of the tour algorithm:\n\nThe dimension of the projection, which will impact the type of display to use.\nThe algorithm that delivers the projections to show.\n\n\nA.1.3.1 Dimension of projection and display\n\ndisplay_dist(): choice of density, histogram or average shifted histogram (ash) display of the 1D projections.\ndisplay_xy(), display_density2d(), display_groupxy(), display_pca(), display_sage(), display_slice(), display_trails(): choices in display of 2D projections.\ndisplay_depth(), display_stereo(): choices to display 3D projections.\ndisplay_pcp(), display_scatmat(), display_stars(), display_faces(): choices for displaying three or more variables.\ndisplay_image(): to use with multispectral images, where different combinations of spectral bands are displayed. See E. J. Wegman, Poston, and Solka (1998) and J. Symanzik (2002) for applications.\ndependence_tour(): displaying two groups of variables as in multiple regression, or multivariate regression or canonical correlation analysis, as two independent 1D projections.\ndisplay_andrews(): 1D projections as Andrews curves.\n\n\n\nA.1.3.2 Algorithms for projection delivery\n\ngrand_tour(): Smooth sequence of random projections to view all possible projections as quickly as possible. Good for getting an overview of the high-dimensional data, especially when you don’t know what you are looking for.\nguided_tour(): Follow a projection pursuit optimisation to find projections that have particular patterns. This is used when you want to learn if the data has particular patterns, such as clustering or outliers. Use the holes() index to find projections with gaps that allow one to see clusters, or lda_pp() or pda_pp() when class labels are known and you want to find the projections where the clusters are separated.\nlittle_tour(): Smoothly interpolate between pairs of variables, to show all the marginal views of the data.\nlocal_tour(): Makes small movements around a chosen projections to explore a small neighbourhood. Very useful to learn if small distances away from a projection change the pattern substantially or not.\nradial_tour(): Interpolates a chosen variable out of the projection, and then back into the projection. This is useful for assessing importance of variables to pattern in a projection. If the pattern changes a lot when the variable is rotated out, then the variable is important for producing it.\ndependendence_tour(): Delivers two sequences of 1D grand tours, to examine associations between two sets of variables.\nfrozen_tour(): This is an interesting one! it allows the coefficient for some variables to be fixed, and others to vary.\n\n\n\n\nA.1.4 The importance of scale\nScaling of multivariate data is really important in many ways. It affects most model fitting, and can affect the perception of patterns when data is visualised. Here we describe a few scaling issues to take control of when using tours.\n\nA.1.4.1 Pre-processing data\nIt is generally useful to standardise your data to have mean 0 and variance-covariance equal to the identity matrix before using the tour. We use the tour to discover associations between variables. Characteristics of single variables should be examined and understood before embarking on looking for high-dimensional structure.\nThe rescale parameter in the animate() function will scale all variables to range between 0 and 1, prior to starting the tour. This will force all to have the same range. It is the default, and without this data with different ranges across variable may have some strange patterns. If you have already scaled the data yourself, even if using a different scaling such as using standardised variables you should set rescale=FALSE.\nA more severe transformation that can be useful prior to starting a tour is to sphere the data. This is also an option in the animate() function, but is FALSE by default. Sphering is the same as conducting a principal component analysis, and using the principal components as the variables. It removes all linear association between variables! This can be especially useful if you want to focus on finding non-linear associations, including clusters, and outliers.\n\n\nA.1.4.2 Scaling to fit into plot region\nThe half_range parameter in most of the display types sets the range used to scale the data into the plot. It is estimated when a tour is started, but you may need to change it if you find that the data keeps escaping the plot window or is not fully using the space. Space expands exponentially as dimension increases, and the estimation takes this into account. However, different distributions of data points lead to different variance of observations in high-dimensional space. A skewed distribution will be more varied than a normal distribution. It is hard to estimate precisely how the data should be scaled so that it fits nicely into the plot space for all projections viewed.\nThe center parameter is used to centre each projection by setting the mean to be at the middle of the plot space. With different distributions the mean of the data can vary around the plot region, and this can be distracting. Fixing the mean of each projection to always be at the center of the plot space makes it easier to focus on other patterns.\n\n\n\nA.1.5 Saving your tour\nThe functions save_history() and planned_tour() allow the tour path to be pre-computed, and re-played in your chosen way. The tour path is saved as a list of projection vectors, which can also be passed to external software for displaying tours easily. Only a minimal set of projections is saved, by default, and a full interpolation path of projections can always be generated from it using the interpolate() function.\nVersions and elements of tours can be saved for publication using a variety of functions:\n\nrender_gif(): Save a tour as an animated gif, using the gifski package.\nrender_proj(): Save an object that can be used to produce a polished rendering of a single projection, possibly with ggplot.\nrender_anim(): Creates an object containing a sequence of projections that can be used with plotly() to produce an HTML animation, with interactive control.\n\n\n\nA.1.6 Understanding your tour path\nGrand tour, and show paths on the space, starting with 1D. How more time gives more coverage of the sphere. Then the torus and paths on torus."
  },
  {
    "objectID": "intro.html#getting-familiar-with-tours",
    "href": "intro.html#getting-familiar-with-tours",
    "title": "Introduction",
    "section": "Getting familiar with tours",
    "text": "Getting familiar with tours\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) 2D data\n\n\n\n\n\n\n\n\n(b) 1D grand tour of the 2D data\n\n\n\n\nFigure 2: How a tour can be used to explore high-dimensional data illustrated using (a) 2D data with two clusters and (b) a tour of 1D projections shown as a density plot. Imagine spinning a line around the centre of the data plot, with points projected orthogonally onto the line. With this data, when the line is at x1=x2 (0.707, 0.707) or (-0.707, -0.707) the clustering is the strongest. When it is at x1=-x2  (0.707, -0.707) there is no clustering.\n\n\nFigure 2 illustrates a tour for 2D data and 1D projections. The (grand) tour will generate all possible 1D projections of the data, and display with a univariate plot like a histogram or density plot. For this data, the simple_clusters data, depending on the projection, the distribution might be clustered into two groups (bimodal), or there might be no clusters (unimodal). In this example, all projections are generated by rotating a line around the centre of the plot. Clustering can be seen in many of the projections, with the strongest being when the contribution of both variables is equal, and the projection is (0.707,  0.707) or (-0.707, -0.707). (If you are curious about the number 0.707, read the last section of this chapter.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) 2D tour of 3D data\n\n\n\n\n\n\n\n\n(b) A projection revealing the hole\n\n\n\n\n\nFigure 3: How a tour can be used to explore high-dimensional data illustrated using a tour of 2D projections of 3D data (a). The data has a donut shape with the hole revealed in a single 2D projection (b). Data usually arrives with a given number of observations, and when we plot it like this using a scatterplot, it is like shadows of a transparent object.\n\n\nFigure 3 illustrates a tour for 3D data using 2D projections. The data are points on the surface of a donut shape. By showing the projections using a scatterplot the donut looks transparent and we can see through the data. The donut shape can be inferred from watching many 2D projections but some are more revealing that others. The projection shown in (b) is where the hole in the donut is clearly visible."
  },
  {
    "objectID": "intro.html#what-can-you-learn",
    "href": "intro.html#what-can-you-learn",
    "title": "Introduction",
    "section": "What can you learn?",
    "text": "What can you learn?\nThere are two ways of detecting structure in tours:\n\npatterns in a single low-dimensional projection\nmovement patterns\n\nwith the latter being especially useful when displaying the projected data as a scatterplot. Figure 6 shows examples of patterns we typically look for when making a scatterplot of data. These include clustering, linear and non-linear association, outliers, barriers where there is a sharp edge beyond which no observations are seen. Not shown, but it also might be possible to observe multiple modes, or density of observations, L-shapes, discreteness or uneven spread of points. The tour is especially useful if these patterns are only visible in combinations of variables.\n\n\n\n\n\nFigure 6: Example structures that might be visible in a 2D projection that imply presence of structure in high dimensions. These include clusters, linear and non-linear association, outliers and barriers.\n\n\n\n\n\n\n\nFigure 7 illustrates how movement patterns of points when using scatterplots to display 2D projections indicate clustering (a, b) and outliers (c, d).\n\n\n\n\n\n\n\n(a) Clustering\n\n\n\n\n\n\n\n(b) Outliers\n\n\n\n\nFigure 7: The movement of points give further clues about the structure of the data in high-dimensions. In the data with clustering, often we can see a group of points moving differently from the others. Because there are three clusters, you should see three distinct movement patterns. It is similar with outliers, except these may be individual points moving alone, and different from all others. This can be seen in the static plot, one point (top left) has a movement pattern upwards whereas most of the other observations near it are moving down towards the right.\n\n\n\nThis type of visualisation is useful for many activities in dealing with high-dimensional data, including:\n\nexploring high-dimensional data.\ndetecting if the data lives in a lower dimensional space than the number of variables.\nchecking assumptions required for multivariate models to be applicable.\ncheck for potential problems in modeling such as multicollinearity among predictors.\nchecking assumptions required for probabilties calculated for statistical hypothesis testing to be valid.\ndiagnosing the fit of multivariate models.\n\n\n\n\nWith a tour we slowly rotate the viewing direction, this allows us to see many individual projections and to track movement patterns. Look for interesting structures such as clusters or outlying points."
  },
  {
    "objectID": "unsupervised-summary.html",
    "href": "unsupervised-summary.html",
    "title": "10  Comparing methods",
    "section": "",
    "text": "Abbott, Edwin. 1884. Flatland: A Romance of Many Dimensions. Dover Publications.\n\n\nAhlberg, C., C. Williamson, and B. Shneiderman. 1991. “Dynamic Queries for Information Exploration: An Implementation and Evaluation.” In ACM CHI ‘92 Conference Proceedings, 619–26. New York: Association of Computing Machinery.\n\n\nAnderson, E. 1957. “A Semigraphical Method for the Analysis of Complex Problems.” In Proceedings of the National Academy of Science, 13, 923–27.\n\n\nAndrews, D. F. 1972. “Plots of High-Dimensional Data.” Biometrics 28: 125–36.\n\n\nAndrews, D. F., R. Gnanadesikan, and J. L. Warner. 1971. “Transformations of Multivariate Data.” Biometrics 27: 825–40.\n\n\nAnselin, L., and S. Bao. 1997. “Exploratory Spatial Data Analysis Linking SpaceStat and ArcView.” In Recent Developments in Spatial Analysis, edited by M. M. Fischer and A. Getis, 35–59. Berlin: Springer.\n\n\nArnold, Jeffrey B. 2021. Ggthemes: Extra Themes, Scales and Geoms for Ggplot2. https://github.com/jrnold/ggthemes.\n\n\nASA Statistical Graphics Section. 2023. “Video Library.” https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. 1985. “The Grand Tour: A Tool for Viewing Multidimensional Data.” SIAM Journal of Scientific and Statistical Computing 6 (1): 128–43.\n\n\nAuguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra.\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. 2018. “Forests of Australia.” https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover.\n\n\nBecker, R. A., and W. S. Cleveland. 1988. “Brushing Scatterplots.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 201–24. Monterey, CA: Wadsworth.\n\n\nBecker, R., W. .S Cleveland, and M-J. Shyu. 1996. “The Visual Design and Control of Trellis Displays.” Journal of Computational and Graphical Statistics 6 (1): 123–55.\n\n\nBecker, Richard A., and John M. Chambers. 1984. S: An Environment for Data Analysis and Graphics. Belmont, CA: Wadsworth.\n\n\nBederson, Benjamin B., and Ben Schneiderman. 2003. The Craft of Information Visualization: Readings and Reflections. San Diego, CA: Morgan Kaufmann.\n\n\nBellman, Richard. 1961. Adaptive Control Processes : A Guided Tour. Princeton Legacy Library.\n\n\nBickel, Peter J., Gil Kur, and Boaz Nadler. 2018. “Projection Pursuit in High Dimensions.” Proceedings of the National Academy of Sciences 115: 9151–56. https://doi.org/10.1073/pnas.1801177115.\n\n\nBishop, C. M. 2006. Pattern Recognition and Machine Learning. New York: Springer.\n\n\nBoehmke, B., and B. M. Greenwell. 2019. Hands-on Machine Learning with r (1st Ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377.\n\n\nBonneau, Georges-Pierre, Thomas Ertl, and Gregory M. Nielson, eds. 2006. Scientific Visualization: The Visual Extraction of Knowledge from Data. New York: Springer.\n\n\nBorg, I., and P. J. F. Groenen. 2005. Modern Multidimensional Scaling. New York: Springer.\n\n\nBreiman, L. 2001. “Random Forests.” Machine Learning 45 (1): 5–32.\n\n\nBreiman, L., and A. Cutler. 2004. “Random Forests.” http://www.math.usu.edu/\\(\\sim\\)adele/forests/cc_home.htm.\n\n\nBreiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2022. randomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://www.stat.berkeley.edu/~breiman/RandomForests/.\n\n\nBreiman, L., J. Friedman, C. Olshen, and C. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth; Brooks/Cole.\n\n\nBuja, A., and D. Asimov. 1986. “Grand Tour Methods: An Outline.” Computing Science and Statistics 17: 63–67.\n\n\nBuja, A., D. Asimov, C. Hurley, and J. A. McDonald. 1988. “Elements of a Viewing Pipeline for Data Analysis.” In Dynamic Graphics for Statistics, edited by W. S. Cleveland and M. E. McGill, 277–308. Monterey, CA: Wadsworth.\n\n\nBuja, A., D. Cook, D. Asimov, and C. Hurley. 1997. “Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods.” Florham Park, NJ: AT&T Labs.\n\n\n———. 2005. “Computational Methods for High-Dimensional Rotations in Data Visualization.” In Handbook of Statistics: Data Mining and Visualization, edited by C. R. Rao, E. J. Wegman, and J. L. Solka, 391–414. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nBuja, A., D. Cook, and D. Swayne. 1996. “Interactive High-Dimensional Data Visualization.” Journal of Computational and Graphical Statistics 5 (1): 78–99.\n\n\nBuja, Andreas. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment.” Journal of Business & Economic Statistics 14 (1): 128–29.\n\n\nBuja, Andreas, Catherine Hurley, and John Alan McDonald. 1986. “A Data Viewer for Multivariate Data.” Computing Science and Statistics 17 (1): 171–74.\n\n\nBuja, Andreas, and Deborah F. Swayne. 2002. “Visualization Methodology for Multidimensional Scaling.” Journal of Classification 19 (1): 7–43.\n\n\nBuja, Andreas, Deborah F Swayne, Michael L Littman, Nathaniel Dean, Heike Hofmann, and Lisha Chen. 2008. “Data Visualization with Multidimensional Scaling.” Journal of Computational and Graphical Statistics 17 (2): 444–72. https://doi.org/10.1198/106186008X318440.\n\n\nBuja, A., and P. Tukey, eds. 1991. Computing and Graphics in Statistics. New York: Springer-Verlag.\n\n\nCard, Stuart K., Jock D. Mackinlay, and Ben Schneiderman. 1999. Readings in Information Visualization. San Francisco, CA: Morgan Kaufmann Publishers.\n\n\nCarr, D. B., E. J. Wegman, and Q. Luo. 1996. “ExplorN: Design Considerations Past and Present.” Technical Report 129. Fairfax, VA: Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. 1995. Problem Solving: A Statistician’s Guide. London: Chapman; Hall/CRC Press.\n\n\nChen, C.-H., W. Härdle, and A. Unwin, eds. 2007. Handbook of Data Visualization. Berlin: Springer.\n\n\nChen, Chun-houh, Wolfgang Härdle, and Antony Unwin, eds. 2006. Handbook of Computational Statistics (Volume III) Data Visualization. Berlin: Springer.\n\n\nCheng, B., and M. Titterington. 1994. “Neural Networks: A Review from a Statistical Perspective.” Statistical Science 9 (1): 2–30.\n\n\nCheng, Joe, and Carson Sievert. 2021. Crosstalk: Inter-Widget Interactivity for HTML Widgets. https://rstudio.github.io/crosstalk/.\n\n\nChernoff, H. 1973. “The Use of Faces to Represent Points in \\(k\\)-Dimensional Space Graphically.” Journal of the American Statistical Association 68: 361–68.\n\n\nCleveland, W. S. 1979. “Robust Localy Weighted Regression and Smoothing Scatterplots.” Journal of American Statistics Association 74: 829–36.\n\n\n———. 1993. Visualizing Data. Summit, NJ: Hobart Press.\n\n\nCleveland, W. S., and M. E. McGill, eds. 1988. Dynamic Graphics for Statistics. Monterey, CA: Wadsworth.\n\n\nCook, D., and A. Buja. 1997. “Manual Controls For High-Dimensional Data Projections.” Journal of Computational and Graphical Statistics 6 (4): 464–80.\n\n\nCook, D., A. Buja, and J. Cabrera. 1993. “Projection Pursuit Indexes Based on Orthonormal Function Expansions.” Journal of Computational and Graphical Statistics 2 (3): 225–50.\n\n\nCook, D., A. Buja, J. Cabrera, and C. Hurley. 1995b. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\n———. 1995a. “Grand Tour and Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (3): 155–72.\n\n\nCook, D., H. Hofmann, E.-K. Lee, H. Yang, B. Nikolau, and E. Wurtele. 2007. “Exploring Gene Expression Data, Using Plots.” Journal of Data Science 5 (2): 151–82.\n\n\nCook, Dianne. 2023. Mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation Using Tours.\n\n\nCook, Dianne, and Deborah F. Swayne. 2007. Interactive and Dynamic Graphics for Data Analysis: With R and GGobi. Use r! New York: Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3.\n\n\nCook, D., E.-K. Lee, A. Buja, and H. Wickham. 2006. “Grand Tours, Projection Pursuit Guided Tours and Manual Controls.” In Handbook of Data Visualization, edited by C.-H. Chen, W. Härdle, and A. Unwin. Berlin: Springer.\n\n\nCook, D., J. J. Majure, J. Symanzik, and N. Cressie. 1996. “Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data Using Linked Software.” Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data 11 (4): 467–80.\n\n\nCortes, Corinna, Daryl Pregibon, and Chris Volinsky. 2003. “Computational Methods for Dynamic Graphs.” Journal of Computational & Graphical Statistics 12 (4): 950–70.\n\n\nCortes, C., and V. N. Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20 (3): 273–97.\n\n\nd’Ocagne, M. 1885. Coordonnées Parallèles Et Axiales: Méthode de Transformation Géométrique Et Procédé Nouveau de Calcul Graphique Déduits de La Considération Des Coordonnées Paralléles. Paris, France: Gauthier-Villars.\n\n\nDalgaard, Peter. 2002. Introductory Statistics with R. New York: Springer.\n\n\nDasu, T., D. F. Swayne, and D. Poole. 2005. “Grouping Multivariate Time Series: A Case Study.” In Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32. IEEE Computer Society.\n\n\nDepartment of Environment, Land, Water & Planning. 2019. “Fire Origins - Current and Historical.” https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical.\n\n\n———. 2020a. “CFA - Fire Station.” https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point.\n\n\n———. 2020b. “Recreation Sites.” https://discover.data.vic.gov.au/dataset/recreation-sites.\n\n\nDiaconis, Persi, and David Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12 (3): 793–815. https://doi.org/10.1214/aos/1176346703.\n\n\nDiaconis, P., and D. Freedman. 1984. “Asymptotics of Graphical Projection Pursuit.” Annals of Statistics 12: 793–815.\n\n\nDykes, J., A. M. MacEachren, and M.-J. Kraak. 2005. Exploring Geovisualization. New York: Elsevier.\n\n\nEveritt, B. S., S. Landau, and M. Leese. 2001. Cluster Analysis (4th Ed). London: Edward Arnold.\n\n\nFienberg, S. E. 1979. “Graphical Methods in Statistics.” Journal of American Statistical Association 33 (4): 165–78.\n\n\nFisher, R. A. 1936a. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7: 179–88.\n\n\n———. 1936b. “The Use of Multiple Measurements in Taxonomic Problems.” Annals of Eugenics 7 (2): 179–88. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\n———. 1938. “The Statistical Utilization of Multiple Measurements.” Annals of Eugenics 8: 376–86.\n\n\nFisherkeller, Mary Anne, Jerome H. Friedman, and John W. Tukey. 1973. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” https://www.youtube.com/watch?v=B7XoW2qiFUA.\n\n\n———. 1974. “PRIM-9, an Interactive Multidimensional Data Display and Analysis System.” In The Collected Works of John w. Tukey: Graphics 1965-1985, Volume v, edited by William S. Cleveland, 340–46.\n\n\nFord, Brian J. 1992. Images of Science: A History of Scientific Illustration. London: The British Library.\n\n\nForgy, E. 1965. “Cluster Analysis of Multivariate Data: Efficiency Versus Interpretability of Classification.” Biometrics 21 (3): 768–69.\n\n\nFraley, Chris, Adrian E. Raftery, and Luca Scrucca. 2022. Mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation. https://mclust-org.github.io/mclust/.\n\n\nFraley, C., and A. E. Raftery. 2002. “Model-Based Clustering, Discriminant Analysis, Density Estimation.” Journal of the American Statistical Association 97: 611–31.\n\n\nFriedman, J. H. 1987. “Exploratory Projection Pursuit.” Journal of American Statistical Association 82: 249–66.\n\n\nFriedman, J. H., and J. W. Tukey. 1974. “A Projection Pursuit Algorithm for Exploratory Data Analysis.” IEEE Transactions on Computing C 23: 881–89.\n\n\nFriendly, M., and D. J. Denis. 2004. “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization.” http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\n———. 2006. “Graphical Milestones.” http://www.math.yorku.ca/SCS/Gallery/milestone.\n\n\nFurnas, George W., and Andreas Buja. 1994. “Prosection Views: Dimensional Inference Through Sections and Projections.” Journal of Computational and Graphical Statistics 3 (4): 323–85.\n\n\nGabriel, K. R. 1971. “The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis.” Biometrika 58: 453–67.\n\n\nGentle, James E., Wolfgang Härdle, and Yuichi Mori, eds. 2004. Handbook of Computational Statistics: Concepts and Methods. New York: Springer.\n\n\nGiordani, Paolo, Maria Brigida Ferraro, and Francesca Martella. 2020. An Introduction to Clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5.\n\n\nGlover, D. M., and P. K. Hopke. 1992. “Exploration of Multivariate Chemical Data by Projection Pursuit.” Chemometrics and Intelligent Laboratory Systems 16: 45–59.\n\n\nGood, Phillip. 2005. Permutation, Parametric, and Bootstrap Tests of Hypotheses. New York: Springer.\n\n\nGower, J. C., and D. J. Hand. 1996. Biplots. London: Chapman; Hall.\n\n\nHansen, Charles, and Chris R. Johnson. 2004. Visualization Handbook. Orlando, FL: Academic Press.\n\n\nHarrison, Paul. 2022. Langevitour: Langevin Tour. https://logarithmic.net/langevitour/.\n\n\nHart, Casper, and Earo Wang. 2022. Detourr: Portable and Performant Tour Animations. https://casperhart.github.io/detourr/.\n\n\nHartigan, J. A., and B. Kleiner. 1981. “Mosaics for Contingency Tables.” In Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–73. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nHartigan, J., and B. Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHaslett, J., R. Bradley, P. Craig, A. Unwin, and G. Wills. 1991. “Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies.” The American Statistician 45 (3): 234–42.\n\n\nHastie, T., R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning. New York: Springer.\n\n\nHennig, Christian, Marina Meila, Fionn Murtagh, and Roberto Rocci, eds. 2015. Handbook of Cluster Analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706.\n\n\nHofmann, H. 2001. Graphical Tools for the Exploration of Multivariate Categorical Data. http://www.bod.de: Books on Demand.\n\n\n———. 2003. “Constructing and Reading Mosaicplots.” Computational Statistics and Data Analysis 43 (4): 565–80.\n\n\nHofmann, H., and M. Theus. 1998. “Selection Sequences in MANET.” Computational Statistics 13 (1): 77–87.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHotelling, H. 1933. “Analysis of a Complex of Statistical Variables into Principal Components.” Journal of Educational Psychology 24 (6): 417--441. https://doi.org/10.1037/h0071325.\n\n\nHuber, P. J. 1985. “Projection Pursuit (with Discussion).” Annals of Statistics 13: 435–525.\n\n\nHurley, Catherine. 1987. “The Data Viewer: An Interactive Program for Data Analysis.” PhD thesis, Seattle: University of Washington.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5: 299–314.\n\n\nIhaka, Ross, Paul Murrell, Kurt Hornik, Jason C. Fisher, Reto Stauffer, Claus O. Wilke, Claire D. McWhite, and Achim Zeileis. 2023. Colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes. https://CRAN.R-project.org/package=colorspace.\n\n\nInselberg, A. 1985. “The Plane with Parallel Coordinates.” The Visual Computer 1: 69–91.\n\n\nIowa State University. 2020. “ASOS-AWOS-METAR Data Download.” https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS.\n\n\nJohnson, Dano, and Jeffrey Travis. 2007. “Flatland: The Movie.” https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., and D. W. Wichern. 2002. Applied Multivariate Statistical Analysis (5th Ed). Englewood Cliffs, NJ: Prentice-Hall.\n\n\nJolliffe, Ian T., and Jorge Cadima. 2016. “Principal Component Analysis: A Review and Recent Developments.” Phil. Trans. R. Soc. A. 374: 20150202. https://doi.org/10.1098/rsta.2015.0202.\n\n\nJones, M. C., and R. Sibson. 1987. “What Is Projection Pursuit? (With Discussion).” Journal of the Royal Statistical Society, Series A 150: 1–36.\n\n\nKassambara, Alboukadel. 2017. Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning. STHDA.\n\n\n———. 2020. Ggpubr: Ggplot2 Based Publication Ready Plots. https://rpkgs.datanovia.com/ggpubr/.\n\n\nKohonen, T. 2001. Self-Organizing Maps (3rd Ed). Berlin: Springer.\n\n\nKoschat, Martin A., and Deborah F. Swayne. 1996. “Interactive Graphical Methods in the Analysis of Customer Panel Data (with Discussion).” Journal of Business and Economic Statistics 14 (1): 113–32.\n\n\nKrijthe, Jesse. 2022. Rtsne: T-Distributed Stochastic Neighbor Embedding Using a Barnes-Hut Implementation. https://github.com/jkrijthe/Rtsne.\n\n\nKruskal, J. B. 1964a. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” Psychometrika 29: 1–27.\n\n\n———. 1964b. “Nonmetric Multidimensional Scaling: A Numerical Method.” Psychometrika 29: 115–29.\n\n\nKruskal, J. B., and M. Wish. 1978. Multidimensional Scaling. London: Sage Publications.\n\n\nLaa, Ursula, Dianne Cook, and German Valencia. 2020a. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\n———. 2020b. “A Slice Tour for Finding Hollowness in High-Dimensional Data.” Journal of Computational and Graphical Statistics 29 (3): 681–87. https://doi.org/10.1080/10618600.2020.1777140.\n\n\nLancaster, H. O. 1965. “The Helmert Matrices.” The American Mathematical Monthly 72 (1): 4–12.\n\n\nLee, E. K., D. Cook, S. Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Eun-Kyung. 2018. “PPtreeViz: An r Package for Visualizing Projection Pursuit Classification Trees.” Journal of Statistical Software 83 (8): 1–30. https://doi.org/10.18637/jss.v083.i08.\n\n\nLee, Eun-Kyung, and Dianne Cook. 2009. “A Projection Pursuit Index for Large \\(p\\) Small \\(n\\) Data.” Statistics and Computing 20: 381–92. https://doi.org/10.1007/s11222-009-9131-1.\n\n\nLee, Eun-Kyung, Dianne Cook, Sigbert Klinke, and T. Lumley. 2005. “Projection Pursuit for Exploratory Supervised Classification.” Journal of Computational and Graphical Statistics 14 (4): 831–46.\n\n\nLee, Stuart. 2021. Liminal: Multivariate Data Visualization with Tours and Embeddings. https://CRAN.R-project.org/package=liminal.\n\n\nLee, Stuart, Dianne Cook, Natalia da Silva, Ursula Laa, Nicholas Spyrison, Earo Wang, and H. Sherry Zhang. 2022. “The State-of-the-Art on Tours for Dynamic Visualization of High-Dimensional Data.” WIREs Computational Statistics 14 (4): e1573. https://doi.org/10.1002/wics.1573.\n\n\nLee, Yoon Dong, Dianne Cook, Ji-won Park, and Eun-Kyung Lee. 2013. “PPtree: Projection pursuit classification tree.” Electronic Journal of Statistics 7 (none): 1369–86. https://doi.org/10.1214/13-EJS810.\n\n\nLeisch, Friedrich, and Bettina Gruen. 2023. “CRAN Task View: Cluster Analysis & Finite Mixture Models.” https://cran.r-project.org/web/views/Cluster.html.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLittman, Michael L, Deborah F Swayne, Nathaniel Dean, and Andreas Buja. 1992. “Visualizing the Embedding of Objects in Euclidean Space.” In Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–17. Fairfax Station, VA: Interface Foundation of North America, Inc.\n\n\nLloyd, S. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37. https://doi.org/10.1109/TIT.1982.1056489.\n\n\nLongley, P. A., D. J. Maguire, M. F. Goodchild, and D. W Rhind. 2005. Geographic Information Systems and Science. New York: John Wiley & Sons.\n\n\nLoperfido, Nicola. 2018. “Skewness-Based Projection Pursuit: A Computational Approach.” Computational Statistics & Data Analysis 120: 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001.\n\n\nMacQueen, J. B. 1967. “Some Methods for Classification and Analysis of Multivariate Observations.” In Proc. Of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, edited by L. M. Le Cam and J. Neyman, 1:281–97. University of California Press.\n\n\nMaindonald, J., and J. Braun. 2003. Data Analysis and Graphics Using r - an Example-Based Approach. Cambridge: Cambridge University Press.\n\n\nMartin, Eric. 1965. “Flatland.” http://www.der.org/films/flatland.html.\n\n\nMcFarlane, M., and F. W. Young. 1994. “Graphical Sensitivity Analysis for Multidimensional Scaling.” Journal of Computational and Graphical Statistics 3: 23–33.\n\n\nMcNeil, D. 1977. Interactive Data Analysis. New York: John Wiley & Sons.\n\n\nMcVicar, Tim. 2011. “Near-Surface Wind Speed. V10. CSIRO. Data Collection.” https://doi.org/10.25919/5c5106acbcb02.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMilborrow, Stephen. 2021. Rpart.plot: Plot Rpart Models: An Enhanced Version of Plot.rpart. http://www.milbo.org/rpart-plot/index.html.\n\n\nMurrell, Paul. 2005. R Graphics. Boca Raton, FL: Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. 2020. “Planet dump retrieved from https://planet.osm.org .” https://www.openstreetmap.org.\n\n\nPearson, Karl. 1901. “LIII. On Lines and Planes of Closest Fit to Systems of Points in Space.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11): 559–72. https://doi.org/10.1080/14786440109462720.\n\n\nPedersen, Thomas Lin. 2020. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPerisic, Igor, and Christian Posse. 2005. “Projection Pursuit Indices Based on the Empirical Distribution Function.” Journal of Computational and Graphical Statistics 14 (3): 700–715. https://doi.org/10.1198/106186005X69440.\n\n\nPolzehl, Jörg. 1995. “Projection Pursuit Discriminant Analysis.” Computational Statistics and Data Analysis 20: 141–57.\n\n\nPosse, C. 1992. “Projection Pursuit Discriminant Analysis for Two Groups.” Communications in Statistics, Part A – Theory and Methods 21: 1–19.\n\n\n———. 1995. “Tools for Two-Dimensional Projection Pursuit.” Journal of Computational and Graphical Statistics 4 (2): 83–100.\n\n\nP-Tree System. 2020. “JAXA Himawari Monitor - User’s Guide.” https://www.eorc.jaxa.jp/ptree/userguide.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRao, C. R. 1948. “The Utilization of Multiple Measurements in Problems of Biological Classification (with Discussion).” Journal of the Royal Statistical Society, Series B 10: 159–203.\n\n\n———, ed. 1993. Handbook of Statistics, Vol. 9. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nRao, C. R., E. J. Wegman, and J. L. Solka, eds. 2006. Handbook of Statistics: Data Mining and Visualization. Amsterdam, The Netherlands: Elsevier/North-Holland.\n\n\nRipley, B. 1996. Pattern Recognition and Neural Networks. Cambridge: Cambridge University Press.\n\n\nRipley, Brian. 2022. MASS: Support Functions and Datasets for Venables and Ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nRothkopf, E. Z. 1957. “A Measure of Stimulus Similarity and Errors in Some Paired-Associate Learning Tasks.” Journal of Experimental Psychology 53: 94–101.\n\n\nSchloerke, Barret. 2016. Geozoo: Zoo of Geometric Objects. https://CRAN.R-project.org/package=geozoo.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to Ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nScrucca, Luca, Michael Fop, T. Brendan Murphy, and Adrian E. Raftery. 2016. “mclust 5: Clustering, Classification and Density Estimation Using Gaussian Finite Mixture Models.” The R Journal 8 (1): 289–317. https://doi.org/10.32614/RJ-2016-021.\n\n\nShepard, R. N. 1962. “The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II.” Psychometrika 27: 125-139 and 219-246.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2021. Plotly: Create Interactive Web Graphics via Plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSlowikowski, Kamil. 2021. Ggrepel: Automatically Position Non-Overlapping Text Labels with Ggplot2. https://github.com/slowkow/ggrepel.\n\n\nSparks, Adam H., Jonathan Carroll, James Goldie, Dean Marchiori, Paul Melloy, Mark Padgham, Hugh Parsonage, and Keith Pembleton. 2020. bomrang: Australian Government Bureau of Meteorology (BOM) Data Client. https://CRAN.R-project.org/package=bomrang.\n\n\nSpence, Robert. 2007. Information Visualization: Design for Interaction. Prentice Hall.\n\n\nStauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1.\n\n\nSutherland, Peter, Anthony Rossini, Thomas Lumley, Nicholas Lewin-Koh, Julie Dickerson, Zach Cox, and Dianne Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29. https://doi.org/10.1080/10618600.2000.10474896.\n\n\nSutherland, P., A. Rossini, T. Lumley, N. Lewin-Koh, J. Dickerson, Z. Cox, and D. Cook. 2000. “Orca: A Visualization Toolkit for High-Dimensional Data.” Journal of Computational and Graphical Statistics 9 (3): 509–29.\n\n\nSwayne, D. F., Andreas Buja, and D. Temple Lang. 2004. “Exploratory Visual Analysis of Graphs in GGobi.” In CompStat: Proceedings in Computational Statistics, 16th Symposium, edited by Jaromir Antoch. Physica-Verlag.\n\n\nSwayne, D. F., and S. Klinke. 1998. “Editorial Commentary.” Computational Statistics: Special Issue on The Use of Interactive Graphics 14 (1).\n\n\nSwayne, D., and A. Buja. 1998. “Missing Data in Interactive High-Dimensional Data Visualization.” Computational Statistics 13 (1): 15–26.\n\n\nSwayne, Deborah F., Dianne Cook, and Andreas Buja. 1992. “XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S.” In American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8. Alexandria, VA: American Statistical Association.\n\n\n———. 1998. “XGobi: Interactive Dynamic Data Visualization in the x Window System.” Journal of Computational and Graphical Statistics 7 (1): 113–30. https://doi.org/10.1080/10618600.1998.10474764.\n\n\nSwayne, Deborah F., Duncan Temple Lang, Andreas Buja, and Dianne Cook. 2003. “GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization.” Computational Statistics & Data Analysis 43: 423–44.\n\n\nSymanzik, J. 2002. “New Applications of the Image Grand Tour.” In Computing Science and Statistics, 34:500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf.\n\n\nSymanzik, Jürgen. 2004. “Interactive and Dynamic Graphics.” In Handbook of Computational Statistics: Concepts and Methods, edited by James E. Gentle, Wolfgang Härdle, and Yuichi Mori, 293–336. New York: Springer.\n\n\nTakatsuka, M., and M. Gahegan. 2002. “GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization.” The Journal of Computers and Geosciences 28 (10): 1131–44.\n\n\nTarpey, T., L. Li, and B. Flury. 1995. “Principal Points and Self–Consistent Points of Elliptical Distributions.” The Annals of Statistics 23: 103–12.\n\n\nTemple Lang, D., D. Swayne, H. Wickham, and M. Lawrence. 2006. “rggobi: An Interface Between R and GGobi.” http://www.R-project.org.\n\n\nTherneau, Terry, and Beth Atkinson. 2022. Rpart: Recursive Partitioning and Regression Trees. https://CRAN.R-project.org/package=rpart.\n\n\nTheus, Martin. 2002. “Interactive Data Visualization Using Mondrian.” Journal of Statistical Software 7 (11): http://www.jstatsoft.org.\n\n\nTheus, M., H. Hofmann, and A. F. X. Wilhelm. 1998. “Selection Sequences – Interactive Analysis of Massive Data Sets.” Computing Science and Statistics 29 (1): 439–44.\n\n\nThompson, Georgia L. 1993. “Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data.” The Annals of Statistics 21: 1401–30.\n\n\nTierney, L. 1991. LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. New York: John Wiley & Sons.\n\n\nTorgerson, W. S. 1952. “Multidimensional Scaling. 1. Theory and Method.” Psychometrika 17: 401–19.\n\n\nTufte, Edward. 1983. The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.\n\n\n———. 1990. Envisioning Information. Cheshire, CT: Graphics Press.\n\n\nTukey, J. W. 1965. “The Technical Tools of Statistics.” The American Statistician 19: 23–28.\n\n\nUnwin, A. R., G. Hawkins, H. Hofmann, and B. Siegl. 1996. “Interactive Graphics for Data Sets with Missing Values - MANET.” Journal of Computational and Graphical Statistics 5 (2): 113–22.\n\n\nUnwin, A., H. Hofmann, and A. Wilhelm. 2002. “Direct Manipulation Graphics for Data Mining.” Journal of Image and Graphics 2 (1): 49–65.\n\n\nUnwin, Antony, Martin Theus, and Heike Hofmann. 2006. Graphics of Large Datasets: Visualizing a Million. Berlin: Springer.\n\n\nUnwin, Antony, Chris Volinsky, and Sylvia Winkler. 2003. “Parallel Coordinates for Exploratory Modelling Analysis.” Comput. Stat. Data Anal. 43 (4): 553–64. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}.\n\n\nUrbanek, Simon, and Martin Theus. 2003. “iPlots: High Interaction Graphics for R.” In Proceedings of the 3rd International Workshop on Distributed Statistical Computing (DSC 2003), edited by Kurt Hornik, Friedrich Leisch, and Achim Zeileis. http://www.ci.tuwien.ac.at/Conferences/DSC-2003.\n\n\nVaidyanathan, Ramnath, Yihui Xie, JJ Allaire, Joe Cheng, Carson Sievert, and Kenton Russell. 2021. Htmlwidgets: HTML Widgets for r. https://github.com/ramnathv/htmlwidgets.\n\n\nvan der Maaten, L. J. P. 2014. “Accelerating t-SNE Using Tree-Based Algorithms.” Journal of Machine Learning Research 15: 3221–45.\n\n\nvan der Maaten, L. J. P., and G. E. Hinton. 2008. “Visualizing High-Dimensional Data Using t-SNE.” Journal of Machine Learning Research 9: 2579–2605.\n\n\nVapnik, V. N. 1999. The Nature of Statistical Learning Theory. New York: Springer.\n\n\nVelleman, Paul F, and A Y Velleman. 1985. Data Desk Handbook. Ithaca, NY: Data Description, Inc.\n\n\nVenables, W. N., and B. Ripley. 2002a. Modern Applied Statistics with S. New York: Springer-Verlag.\n\n\nVenables, W. N., and B. D. Ripley. 2002b. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWainer, H. 2000. Visual Revelations (2nd Ed). Hillsdale, NJ: LEA, Inc.\n\n\nWainer, H., and I. (eds) Spence. 2005a. The Commercial and Political Atlas, Representing, by Means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, During the Whole of the Eighteenth Century, by William Playfair. New York: Cambridge University Press.\n\n\n———. 2005b. The Statistical Breviary; Shewing on a Principle Entirely New, the Resources of Every State and Kingdom in Europe; Illustrated with Stained Copper-Plate Charts, Representing the Physical Powers of Each Distinct Nation with Ease and Perspicuity by William Playfair. New York: Cambridge University Press.\n\n\nWang, P. C. C., ed. 1978. Graphical Representation of Multivariate Data. New York: Academic Press.\n\n\nWegman, E. 1990. “Hyperdimensional Data Analysis Using Parallel Coordinates.” Journal of American Statistics Association 85: 664–75.\n\n\nWegman, E. J. 1991. “The Grand Tour in \\(k\\)-Dimensions.” Technical Report 68. Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., and D. B. Carr. 1993. “Statistical Graphics and Visualization.” In, edited by C. R. Rao, 857–958. Amsterdam, The Netherlands: Elsevier Science Publishers.\n\n\nWegman, E. J., W. L. Poston, and J. L. Solka. 1998. “Image Grand Tour.” In Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–94. Bellingham, WA: SPIE.\n\n\nWehrens, Ron, and Lutgarde M. C. Buydens. 2007. “Self- and Super-Organizing Maps in R: The kohonen Package.” Journal of Statistical Software 21 (5): 1–19. https://doi.org/10.18637/jss.v021.i05.\n\n\nWehrens, Ron, and Johannes Kruisselbrink. 2018. “Flexible Self-Organizing Maps in kohonen 3.0.” Journal of Statistical Software 87 (7): 1–18. https://doi.org/10.18637/jss.v087.i07.\n\n\n———. 2022. Kohonen: Supervised and Unsupervised Self-Organising Maps. https://CRAN.R-project.org/package=kohonen.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2022. Classifly: Explore Classification Models in High Dimensions. http://had.co.nz/classifly.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, and Dianne Cook. 2023. Tourr: Tour Methods for Multivariate Data Visualisation. https://github.com/ggobi/tourr.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2011a. “Tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2). https://doi.org/10.18637/jss.v040.i02.\n\n\n———. 2011b. “tourr: An R Package for Exploring Multivariate Data with Projections.” Journal of Statistical Software 40 (2): 1–18. https://doi.org/10.18637/jss.v040.i02.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWilhelm, A. F. X., E. J. Wegman, and J. Symanzik. 1999. “Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited.” Computational Statistics: Special Issue on Interactive Graphical Data Analysis 14 (1): 109–46.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. New York: Springer.\n\n\nWills, Graham. 1999. “NicheWorks – Interactive Visualization of Very Large Graphs.” Journal of Computational and Graphical Statistics 8 (2): 190–212.\n\n\nXie, Yihui, Heike Hofmann, and Xiaoyue Cheng. 2014. “Reactive Programming for Interactive Graphics.” Statistical Science 29 (2): 201–13. https://doi.org/10.1214/14-STS477.\n\n\nYoung, Forrest W., Pedro M. Valero-Mora, and Michael Friendly. 2006. Visual Statistics: Seeing Data with Dynamic Interactive Graphics. New York: John Wiley & Sons.\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nZeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics & Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033.\n\n\nZhang, Chunming, Jimin Ye, and Xiaomei Wang. 2023. “A Computational Perspective on Projection Pursuit in High Dimensions: Feasible or Infeasible Feature Extraction.” International Statistical Review 91 (1): 140–61. https://doi.org/10.1111/insr.12517.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with Kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  }
]