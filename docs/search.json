[
  {
    "objectID": "4-pca.html",
    "href": "4-pca.html",
    "title": "\n4  Principal component analysis\n",
    "section": "",
    "text": "4.1 Determining how many dimensions\nWe would start by examining the data using a grand tour. The goal is to check whether there might be potential issues for PCA, such as skewness, outliers or clustering, or even non-linear dependencies.\nWe’ll start be showing PCA on the simulated data from Chapter 3. The scree plots show that PCA supports that the data are 2D, 3D and 5D respectively.\n# Conduct PCA and make the scree plot for \n# the 2-, 3- and 5-D planar data\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(mulgar)\ndata(plane)\ndata(box)\nlibrary(geozoo)\ncube5d &lt;- data.frame(cube.solid.random(p=5, n=300)$points)\ncolnames(cube5d) &lt;- paste0(\"x\", 1:5)\ncube5d &lt;- data.frame(apply(cube5d, 2, \n                           function(x) (x-mean(x))/sd(x)))\np_pca &lt;- prcomp(plane)\nb_pca &lt;- prcomp(box)\nc_pca &lt;- prcomp(cube5d)\np_scree &lt;- ggscree(p_pca, q = 5) + theme_minimal()\n\nb_scree &lt;- ggscree(b_pca, q = 5) + theme_minimal()\nc_scree &lt;- ggscree(c_pca, q = 5) + theme_minimal()\nFigure 4.1: Scree plots for the three simulated data sets shown in Figure 3.2. The 2D in 5D is clearly recognised by PCA to be 2D because the variance drops substantially between 2-3 principal components. The 3D in 5D is possibly 3D because the variance drops from 3-4 principal components. The fully 5D data has no drop in variance, and all values are close to the typical value one would observe if the data was fully 5D.\nThe next step is to look at the coefficients for the selected number of PCs. Table 4.1 shows the coefficients for the first two PCs of the plane data. All five variables contribute, with x1, x2, x3 contributing more to PC1, and x4, x5 contributing more to PC2. Table 4.2 shows the coefficients for the first three PCs. Variables x1, x2, x3 contribute strongly to PC1, PC2 has contributions from all variables except x3 and variables x4 and x5 contribute strongly to PC3.\nCode to print PC coefficientslibrary(gt)\np_pca$rotation[,1:2] %&gt;%\n  as_tibble(rownames=\"Variable\") %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = c(PC1, PC2),\n             decimals = 2)\n\n\nTable 4.1: Coefficients for the first two PCs for the plane data.\n\n\n\n\n\n\nVariable\nPC1\nPC2\n\n\n\nx1\n0.58\n−0.06\n\n\nx2\n−0.55\n0.21\n\n\nx3\n0.47\n−0.41\n\n\nx4\n0.25\n0.64\n\n\nx5\n−0.29\n−0.62\nCode to print PC coefficientsb_pca$rotation[,1:3] %&gt;%\n  as_tibble(rownames=\"Variable\") %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = c(PC1, PC2, PC3),\n             decimals = 2)\n\n\nTable 4.2: Coefficients for the first three PCs for the box data.\n\n\n\n\n\n\nVariable\nPC1\nPC2\nPC3\n\n\n\nx1\n−0.51\n0.46\n0.11\n\n\nx2\n0.51\n0.46\n0.00\n\n\nx3\n−0.65\n−0.09\n0.23\n\n\nx4\n−0.22\n0.36\n−0.87\n\n\nx5\n0.02\n0.66\n0.43\nIn each of these simulated data sets, all five variables contributed to the dimension reduction. If we added two purely noise variables to the plane data, as done in Chapter 3, the scree plot would indicate that the data is now 4D, and we would get a different interpretation of the coefficients from the PCA. We see that PC1 and PC2 are approximately the same as before, with main variables being (x1, x2, x3) and (x4, x5) respectively. PC3 and PC4 are both x6 and x7.\nset.seed(5143)\nplane_noise &lt;- plane\nplane_noise$x6 &lt;- rnorm(100)\nplane_noise$x7 &lt;- rnorm(100)\nplane_noise &lt;- data.frame(apply(plane_noise, 2, function(x) (x-mean(x))/sd(x)))\n\npn_pca &lt;- prcomp(plane_noise)\nggscree(pn_pca, q = 7) + theme_minimal()\n\n\n\n\n\n\nFigure 4.2: Additional noise variables expands the data to 4D.\nCode to print PC coefficientspn_pca$rotation[,1:4] %&gt;%\n  as_tibble(rownames=\"Variable\") %&gt;% \n  gt() %&gt;%\n  fmt_number(columns = c(PC1, PC2, PC3, PC4),\n             decimals = 2)\n\n\nTable 4.3: Coefficients for the first four PCs for the box data.\n\n\n\n\n\n\nVariable\nPC1\nPC2\nPC3\nPC4\n\n\n\nx1\n0.58\n0.04\n0.01\n0.00\n\n\nx2\n−0.55\n−0.18\n−0.03\n0.07\n\n\nx3\n0.47\n0.37\n0.05\n−0.20\n\n\nx4\n0.24\n−0.62\n−0.06\n0.17\n\n\nx5\n−0.28\n0.60\n0.07\n−0.14\n\n\nx6\n0.05\n0.29\n−0.58\n0.76\n\n\nx7\n−0.02\n−0.08\n−0.81\n−0.58",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Principal component analysis</span>"
    ]
  },
  {
    "objectID": "4-pca.html#determining-how-many-dimensions",
    "href": "4-pca.html#determining-how-many-dimensions",
    "title": "\n4  Principal component analysis\n",
    "section": "",
    "text": "4.1.1 Example: pisa\n\nThe pisa data contains simulated data from math, reading and science scores, totalling 30 variables. PCA is used here to examine the association. We might expect that it is 3D, but what we see suggests it is primarily 1D. This means that a student that scores well in math, will also score well in reading and science.\n\ndata(pisa)\npisa_std &lt;- pisa %&gt;%\n  filter(CNT == \"Australia\") %&gt;%\n  select(-CNT) %&gt;%\n  mutate_all(mulgar:::scale2)\npisa_pca &lt;- prcomp(pisa_std)\npisa_scree &lt;- ggscree(pisa_pca, q = 15) + theme_minimal()\n\nThe scree plot in Figure 4.3 shows a big drop from one to two PCs in the amount of variance explained. A grand tour on the 30 variables can be run using animate_xy():\n\nanimate_xy(pisa_std, half_range=1)\n\nor rendered as an animated gif using render_gif():\n\nrender_gif(pisa_std, \n           grand_tour(), \n           display_xy(half_range=0.9),\n           gif_file=\"gifs/pisa_gt.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\nand we can see that the data is elliptical in most projections, sometimes shrinking to be a small circle. This pattern strongly indicates that there is one primary direction of variation in the data, with only small variation in any direction away from it. Shrinking to the small circle is analogous to to how a pencil or cigar or water bottle in 3D looks from some angles.\n\n\n\n\n\n\n\n\n\n\n(a) Scree plot\n\n\n\n\n\n\n\n\n\n\n(b) Grand tour\n\n\n\n\n\n\nFigure 4.3: Scree plot and tour of the pisa data, with 30 variables being the plausible scores for Australian students. In combination, these suggest that the data is effectively 1D.\n\n\nThe coefficients of the first PC (first eigenvector) are roughly equal in magnitude (as shown below), which tells us that all variables roughly contribute. Interestingly, they are all negative, which is not actually meaningful. With different software these could easily have been all positive. The sign of the coefficients can be reversed, as long as all are reversed, which is the same as an arrow pointing one way, changing and pointing the other way.\n\nCode to print PC coefficientsround(pisa_pca$rotation[,1], 2)\n\n PV1MATH  PV2MATH  PV3MATH  PV4MATH  PV5MATH  PV6MATH  PV7MATH  PV8MATH \n   -0.18    -0.18    -0.18    -0.18    -0.18    -0.18    -0.18    -0.18 \n PV9MATH PV10MATH  PV1READ  PV2READ  PV3READ  PV4READ  PV5READ  PV6READ \n   -0.18    -0.18    -0.19    -0.18    -0.19    -0.19    -0.19    -0.19 \n PV7READ  PV8READ  PV9READ PV10READ  PV1SCIE  PV2SCIE  PV3SCIE  PV4SCIE \n   -0.19    -0.19    -0.19    -0.19    -0.18    -0.18    -0.19    -0.18 \n PV5SCIE  PV6SCIE  PV7SCIE  PV8SCIE  PV9SCIE PV10SCIE \n   -0.19    -0.18    -0.19    -0.18    -0.19    -0.18 \n\n\n\nThe tour verifies that the pisa data is primarily 1D, indicating that a student who scores well in math, probably scores well in reading and science, too. More interestingly, the regular shape of the data strongly indicates that it is “synthetic”, simulated rather than observed.\n\n\n4.1.2 Example: aflw\n\nThis data has player statistics for all the matches in the 2021 season. We would be interested to know which variables contain similar information, and thus might be combined into single variables. We would expect that many statistics to group into a few small sets, such as offensive and defensive skills. We might also expect that some of the statistics are skewed, most players have low values and just a handful of players are stellar. It is also possible that there are some extreme values. These are interesting features, but they will distract from the main purpose of grouping the statistics. Thus the tour is used to check for potential problems with the data prior to conducting PCA.\n\nlibrary(tourr)\ndata(aflw)\naflw_std &lt;- aflw %&gt;%\n  mutate_if(is.numeric, function(x) (x-\n      mean(x, na.rm=TRUE))/\n      sd(x, na.rm=TRUE))\n\nTo look at all of the 29 player statistics in a grand tour in Figure 4.4.\n\nCode to generate touranimate_xy(aflw_std[,7:35], half_range=0.9)\nrender_gif(aflw_std[,7:35], \n           grand_tour(), \n           display_xy(half_range=0.9),\n           gif_file=\"gifs/aflw_gt.gif\",\n           frames=500,\n           loop=FALSE)\n\n\n\n\n\n\n\nFigure 4.4: Grand tour of the AFLW player statistics. Most player statistics concentrate near the centre, indicating most players are “average”! There are a few outliers appearing in different combinations of the skills, which one would expect to be the star players for particular skill sets.\n\n\nNo major surprises! There is a small amount of skewness, and there are no major outliers. Skewness indicates that most players have reasonably similar skills (bunching of points), except for some key players (the moderate outliers). The skewness could be reduced by applying a log or square root transformation to some variables prior to running the PCA. However, we elect not to do this because the moderate outliers are of interest. These correspond to talented players that we’d like to explore further with the analysis.\nBelow we have the conventional summary of the PCA, a scree plot showing the reduction in variance to be explained when each additional PC is considered. It is also conventional to look at a table summarising the proportions of variance explained by PCs, but with almost 30 variables it is easier to make some decision on the number of PCs needed based on the scree plot.\n\nCode to make screeplotaflw_pca &lt;- prcomp(aflw_std[,7:35], \n               scale = FALSE, \n               retx=TRUE)\n\nggscree(aflw_pca, q = 29) + theme_minimal()\n\n\n\n\n\n\nFigure 4.5: Scree plot showing decay in variance of PCs.\n\n\n\n\n\nFrom the scree plot in Figure 4.5, we see a sharp drop from one to two, two to three and then smaller drops. After four PCs the variance drops again at six PCs and then gradually decays. We will choose four PCs to examine more closely. This explains 67.2% of the variance.\n\nCode to print PC coefficientslibrary(gt)\naflw_pca$rotation[,1:4] %&gt;%\n  as_tibble(rownames=\"Variable\") %&gt;% \n  arrange(desc(PC1), desc(PC2), desc(PC3)) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = c(PC1, PC2, PC3, PC4),\n             decimals = 2)\n\n\nTable 4.4: Coefficients for the first four PCs.\n\n\n\n\n\n\nVariable\nPC1\nPC2\nPC3\nPC4\n\n\n\ndisposals\n0.31\n−0.05\n−0.03\n0.07\n\n\npossessions\n0.31\n−0.03\n−0.07\n0.09\n\n\nkicks\n0.29\n−0.04\n0.09\n−0.12\n\n\nmetres\n0.28\n−0.03\n0.10\n−0.15\n\n\ncontested\n0.28\n0.01\n−0.12\n0.23\n\n\nuncontested\n0.28\n−0.06\n−0.01\n−0.05\n\n\nturnovers\n0.27\n−0.01\n−0.01\n−0.29\n\n\nclearances\n0.23\n0.00\n−0.29\n0.19\n\n\nclangers\n0.23\n−0.02\n−0.06\n−0.33\n\n\nhandballs\n0.23\n−0.04\n−0.19\n0.31\n\n\nfrees_for\n0.21\n0.02\n−0.13\n0.18\n\n\nmarks\n0.21\n0.03\n0.32\n0.02\n\n\ntackles\n0.20\n0.01\n−0.28\n0.09\n\n\ntime_pct\n0.16\n−0.04\n0.35\n−0.02\n\n\nintercepts\n0.13\n−0.28\n0.24\n0.03\n\n\nrebounds_in50\n0.13\n−0.28\n0.24\n−0.06\n\n\nfrees_against\n0.13\n0.03\n−0.16\n−0.23\n\n\nassists\n0.09\n0.23\n0.00\n0.05\n\n\nbounces\n0.09\n0.03\n0.02\n−0.28\n\n\nbehinds\n0.09\n0.32\n0.08\n−0.02\n\n\nshots\n0.08\n0.38\n0.12\n−0.03\n\n\ntackles_in50\n0.07\n0.27\n−0.18\n0.03\n\n\nmarks_in50\n0.06\n0.34\n0.18\n0.04\n\n\ncontested_marks\n0.05\n0.16\n0.34\n0.15\n\n\ngoals\n0.04\n0.37\n0.16\n0.03\n\n\naccuracy\n0.04\n0.34\n0.10\n0.06\n\n\none_pct\n0.03\n−0.21\n0.33\n0.08\n\n\ndisposal\n0.02\n−0.13\n0.20\n0.50\n\n\nhitouts\n−0.04\n0.00\n−0.03\n0.32\n\n\n\n\n\n\n\n\n\nWhen there are as many variables as this, it can be hard to digest the combinations of variables most contributing to each PC. Rearranging the table by sorting on a selected PC can help. Table 4.4 has been sorted according to the PC 1 coefficients.\nPC 1 is primarily composed of disposals, possessions, kicks, metres, uncontested, contested, …. Actually almost all variables positively contribute, albeit in different amounts! It is quite common in PCA for the first PC to be a combination of all variables, although it might commonly be a closer to equal contribution, and it tells us that there is one main direction of variation in the data. For PC 1 in the aflw data, PCA is telling us that the primary variation is through a combination of skills, and this maps to basic football playing skills, where some skills (e.g. disposals, possessions, kicks, …) are more important.\nThus the second PC might be the more interesting. PC 2 is primarily a combination of shots, goals, marks_in50, accuracy, and behinds contrasted against rebounds_in50 and intercepts. The negative coefficients are primary offensive skills and the positive coefficients are defensive skills. This PC is reasonable measure of the offensive vs defensive skills of a player.\n\nWe would continue to interpret each PC by examining large coefficients to help decide how many PCs are a suitable summary of the information in the data. Briefly, PC 3 is a measure of worth of the player because time_pct has a large coefficient, so players that are on the field longer will contribute strongly to this new variable. It also has large (and opposite) contributions from clearances, tackles, contested_marks. PC 4 appears to be related to aggressive play with clangers, turnovers, bounces and frees_against featuring. So all four PCs have useful information. (Note, if we had continued to examine large coefficients on PC 5 we would find that all variables already have had reasonably large coefficients on PC 1-4, which supports restricting attention to the first four.)\nIdeally, when we tour the four PCs, we’d like to be able to stop and identify players. This involves creating a pre-computed animation, with additional mouse-over, made possible by plotly. This is only feasible with a small number of observations, like the aflw data, because all of the animation frames are constructed in a single object. This object gets large very quickly!\nThe result is shown in Figure 4.6. We can see that the shape of the four PCs is similar to that of all the variables, bunching of points in the centre with a lot of moderate outliers.\n\nCode to make tour animationlibrary(plotly)\nlibrary(htmlwidgets)\nset.seed(20)\nb &lt;- basis_random(4, 2)\naflw_pct &lt;- tourr::save_history(aflw_pca$x[,1:4], \n                    tour_path = grand_tour(),\n                    start = b,\n                    max_bases = 5)\n# To reconstruct projected data plots, later\nsave(aflw_pct, file=\"data/aflw_pct.rda\") \naflw_pcti &lt;- interpolate(aflw_pct, 0.1)\naflw_anim &lt;- render_anim(aflw_pca$x[,1:4],\n                         frames=aflw_pcti, \n             obs_labels=paste0(aflw$surname,\n                               aflw$given_name))\n\naflw_gp &lt;- ggplot() +\n     geom_path(data=aflw_anim$circle, \n               aes(x=c1, y=c2,\n                   frame=frame), linewidth=0.1) +\n     geom_segment(data=aflw_anim$axes, \n                  aes(x=x1, y=y1, \n                      xend=x2, yend=y2, \n                      frame=frame), \n                  linewidth=0.1) +\n     geom_text(data=aflw_anim$axes, \n               aes(x=x2, y=y2, \n                   frame=frame, \n                   label=axis_labels), \n               size=5) +\n     geom_point(data=aflw_anim$frames, \n                aes(x=P1, y=P2, \n                    frame=frame, \n                    label=obs_labels), \n                alpha=0.8) +\n     xlim(-1,1) + ylim(-1,1) +\n     coord_equal() +\n     theme_bw() +\n     theme(axis.text=element_blank(),\n         axis.title=element_blank(),\n         axis.ticks=element_blank(),\n         panel.grid=element_blank())\naflw_pctour &lt;- ggplotly(aflw_gp,\n                        width=500,\n                        height=550) %&gt;%\n       animation_button(label=\"Go\") %&gt;%\n       animation_slider(len=0.8, x=0.5,\n                        xanchor=\"center\") %&gt;%\n       animation_opts(easing=\"linear\", transition = 0)\n\nhtmlwidgets::saveWidget(aflw_pctour,\n          file=\"html/aflw_pca.html\",\n          selfcontained = TRUE)\n\n\n\n\n\n\n\n\nFigure 4.6: Animation of four PCs of the aflw data with interactive labelling.\n\n\n\nCode to generate interactive plot of frame 18library(plotly)\nload(\"data/aflw_pct.rda\")\naflw_pcti &lt;- interpolate(aflw_pct, 0.1)\nf18 &lt;- matrix(aflw_pcti[,,18], ncol=2)\np18 &lt;- render_proj(aflw_pca$x[,1:4], f18, \n                   obs_labels=paste0(aflw$surname,\n                               aflw$given_name))\npg18 &lt;- ggplot() +\n  geom_path(data=p18$circle, aes(x=c1, y=c2)) +\n  geom_segment(data=p18$axes, aes(x=x1, y=y1, xend=x2, yend=y2)) +\n  geom_text(data=p18$axes, aes(x=x2, y=y2, label=rownames(p18$axes))) +\n  geom_point(data=p18$data_prj, aes(x=P1, y=P2, label=obs_labels)) +\n  xlim(-1,1) + ylim(-1, 1) +\n  #ggtitle(\"Frame 18\") +\n  theme_bw() +\n  theme(\n    axis.text=element_blank(),\n    axis.title=element_blank(),\n    axis.ticks=element_blank(),\n    panel.grid=element_blank())\n\n\n\nCodeggplotly(pg18, width=500, height=500)\n\n\n\n\n\n\nFigure 4.7: Frame 18 re-plotted so that players can be identified on mouse-over.\n\n\n\nFor any particular frame, like 18 re-plotted in Figure 4.7, we can investigate further. Here there is a branching pattern, where the branch points in the direction of PC 1. Mouse-over the players at the tip of this branch and we find players like Alyce Parker, Brittany Bonnici, Dana Hooker, Kiara Bowers. If you look up the bios of these players you’ll find they all have generally good player descriptions like “elite disposals”, “powerful left foot”, “hard-running midfielder”, “best and fairest”.\nIn the direction of PC 2, you’ll find players like Lauren Ahrens, Stacey Livingstone who are star defenders. Players in this end of PC 1, have high scores on intercepts and rebounds_in50.\nAnother interesting frame for inspecting PC 2 is 59. PC 2 at one end has players with high goal scoring skills, and the other good defending skills. So mousing over the other end of PC 2 finds players like Gemma Houghton and Katie Brennan who are known for their goal scoring. The branch pattern is an interesting one, because it tells us there is some combination of skills that are lacking among all players, primarily this appears to be there some distinction between defenders skills and general playing skills. It’s not as simple as this because the branching is only visible when PC 1 and PC 2 are examined with PC 3.\nPCA is useful for getting a sense of the variation in a high-dimensional data set. Interpreting the principal components is often useful, but it can be discombobulating. For the aflw data it would be good to think about it as a guide to the main directions of variation and to follow with a more direct engineering of variables into interesting player characteristics. For example, calculate offensive skill as an equal combination of goals, accuracy, shots, behinds. A set of new variables specifically computed to measure particular skills would make explaining an analysis easier.\n\nThe tour verifies that PCA on the aflw data is complicated and doesn’t capture all of the variation. However, it does provide useful insights. It detected outstanding players, and indicated the different skills sets of top goal scorers and top defensive players.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Principal component analysis</span>"
    ]
  },
  {
    "objectID": "4-pca.html#examining-the-pca-model-in-the-data-space",
    "href": "4-pca.html#examining-the-pca-model-in-the-data-space",
    "title": "\n4  Principal component analysis\n",
    "section": "\n4.2 Examining the PCA model in the data space",
    "text": "4.2 Examining the PCA model in the data space\n\nWhen you choose a smaller number of PCs \\((k)\\) than the number of original variables, this is essentially producing a model for the data. The model is the lower dimensional \\(k\\)-D space. It is analogous to a linear regression model, except that the residuals from the model are \\((p-k)\\)-D.\nIt is common to show the model, that is the data projected into the \\(k\\)-D model space. When \\(k=2\\) this is called a “biplot”. For the plane and plane_noise data the biplots are shown in Figure 4.8. This is useful for checking which variables contribute most to the new principal component variables, and also to check for any problems that might have affected the fit, such as outliers, clusters or non-linearity. Interestingly, biplots are typically only made in 2D, even if the data should be summarised by more than two PCs. Occasionally you will see the biplot made for PC \\(j\\) vs PC \\(k\\) also. With the pca_tour() function in the tourr package you can view a \\(k\\)-D biplot. This will display the \\(k\\) PCs with the axes displaying the original variables, and thus see their contribution to the PCs.\n\nCode for biplotslibrary(ggfortify)\nlibrary(patchwork)\nplane_pca &lt;- prcomp(plane)\npl1 &lt;- autoplot(plane_pca, loadings = TRUE, \n         loadings.label = TRUE) + \n  ggtitle(\"(a)\") +\n  theme_minimal() + \n  theme(aspect.ratio=1)\nplane_noise_pca &lt;- prcomp(plane_noise)\npl2 &lt;- autoplot(plane_noise_pca, loadings = TRUE, \n         loadings.label = TRUE) + \n  ggtitle(\"(b)\") +\n  theme_minimal() + \n  theme(aspect.ratio=1)\npl1 + pl2\n\n\n\n\n\n\nFigure 4.8: Biplots of the plane (a) and plane + noise (b) data. All five variables contribute strongly to the two principal components in (a): PC1 is primarily x1, x2 and x3 and PC2 is primarily x4 and x5. In (b) the same four variables contribute in almost the same way, with variables x6 and x7 contributing very little. The data was constructed this way, that these two dimensions were purely noise.\n\n\n\n\nIt can be useful to examine this model using the tour. The model is simply a plane in high dimensions. This would be considered to be the model in the data space. The reason to do this is to check how well the model fits the data. The plane corresponding to the model should be oriented along the main direction of the points, and the spread of points around the plane should be small. We should also be able to see if there has been any strong non-linear relationship missed by the model, or outliers and clusters.\nThe function pca_model() from the mulgar package can be used to represent the model as a \\(k\\)-D wire-frame plane. Figure 4.9 shows the models for the plane and box data, 2D and 3D respectively.\n\nWe look at the model in the data space to check how well the model fits the data. If it fits well, the points will cluster tightly around the model representation, with little spread in other directions.\n\n\nCode for model-in-the-dataplane_m &lt;- pca_model(plane_pca)\nplane_m_d &lt;- rbind(plane_m$points, plane)\nanimate_xy(plane_m_d, edges=plane_m$edges,\n           axes=\"bottomleft\",\n           edges.col=\"#E7950F\",\n           edges.width=3)\nrender_gif(plane_m_d, \n           grand_tour(), \n           display_xy(half_range=0.9,\n                      edges=plane_m$edges, \n                      edges.col=\"#E7950F\",\n                      edges.width=3),\n           gif_file=\"gifs/plane_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\nbox_pca &lt;- prcomp(box)\nbox_m &lt;- pca_model(box_pca, d=3)\nbox_m_d &lt;- rbind(box_m$points, box)\nanimate_xy(box_m_d, edges=box_m$edges, \n           axes=\"bottomleft\", edges.col=\"#E7950F\", edges.width=3)\nrender_gif(box_m_d, \n           grand_tour(), \n           display_xy(half_range=0.9,\n                      edges=box_m$edges, \n                      edges.col=\"#E7950F\",\n                      edges.width=3),\n           gif_file=\"gifs/box_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n\n\n(a) Model for the 2D in 5D data.\n\n\n\n\n\n\n\n\n\n(b) Model for the 3D in 5D data.\n\n\n\n\n\n\nFigure 4.9: PCA model overlaid on the data for the 2D in 5D, and 3D in 5D simulated data.\n\n\n\n4.2.1 Example: pisa\n\nThe model for the pisa data is a 1D vector, shown in Figure 4.10.\n\nCode for model-in-the-datapisa_model &lt;- pca_model(pisa_pca, d=1, s=2)\n\npisa_all &lt;- rbind(pisa_model$points, pisa_std)\nanimate_xy(pisa_all, edges=pisa_model$edges,\n           edges.col=\"#E7950F\", edges.width=3)\nrender_gif(pisa_all, \n           grand_tour(), \n           display_xy(half_range=0.9,\n                      edges=pisa_model$edges, \n                      edges.col=\"#E7950F\", \n                      edges.width=5),\n           gif_file=\"gifs/pisa_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\n\n\n\n\n\n\nFigure 4.10: PCA model of the pisa data. The 1D model captures the primary variation in the data and there is a small amount of spread in all directions away from the model.\n\n\n\nThe pisa data fits fairly closely to the 1D PCA model. The variance of points away from the model is symmetric and relatively small. These suggest the 1D model is a reasonably summary of the test scores.\n\n\n4.2.2 Example: aflw\n\nIt is less useful to examine the PCA model for the aflw data, because the main patterns that were of interest were the exceptional players. However, we will do it anyway! Figure 4.11 shows the 4D PCA model overlain on the data. Even though the distribution of points is not as symmetric and balanced as the other examples, we can see that the cube structure mirrors the variation. We can see that the relationships between variables are not strictly linear, because the spread extends unevenly away from the box.\n\nCode for model-in-the-dataaflw_model &lt;- pca_model(aflw_pca, d=4, s=1)\n\naflw_all &lt;- rbind(aflw_model$points, aflw_std[,7:35])\nanimate_xy(aflw_all, edges=aflw_model$edges,\n           edges.col=\"#E7950F\", \n           edges.width=3, \n           half_range=0.8, \n           axes=\"off\")\nrender_gif(aflw_all, \n           grand_tour(), \n           display_xy(half_range=0.8,\n                      edges=aflw_model$edges, \n                      edges.col=\"#E7950F\", \n                      edges.width=3, \n                      axes=\"off\"),\n           gif_file=\"gifs/aflw_model.gif\",\n           frames=500,\n           width=400,\n           height=400,\n           loop=FALSE)\n\n\n\n\n\n\n\nFigure 4.11: PCA model of the aflw data. The linear model is not ideal for this data, which has other patterns like outliers, and some branching. However, the model roughly captures the linear associations, and leaves unexplained and unequal variation in different directions.\n\n\n\nFrom the tour we see that the 4D model leaves substantial variation unexplained. It is also not symmetric, and there is some larger variation away from the model in some combinations of variables than others.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Principal component analysis</span>"
    ]
  },
  {
    "objectID": "4-pca.html#when-relationships-are-not-linear",
    "href": "4-pca.html#when-relationships-are-not-linear",
    "title": "\n4  Principal component analysis\n",
    "section": "\n4.3 When relationships are not linear",
    "text": "4.3 When relationships are not linear\n\n4.3.1 Example: outliers\n\nFigure 4.12 shows the scree plot for the planar data with noise and outliers. It is very similar to the scree plot on the data without the outliers (Figure 4.2). However, what we see from Figure 4.13 is that PCA loses the outliers. The animation in (a) shows the full data, and the outliers marked by colour and labels 1, 2, are clearly unusual in some projections. When we examine the tour of the first four PCs (as suggested by the scree plot) the outliers are not unusual. They are almost contained in the point cloud. The reason is clear when all the PCs are plotted, and the outliers can be seen to be clearly detected only in PC5, PC6 and PC7.\n\nCode for screeplotplane_n_o_pca &lt;- prcomp(plane_noise_outliers)\nggscree(plane_n_o_pca, q = 7) + theme_minimal()\n\n\n\n\n\n\nFigure 4.12: Scree plot of the planar data with noise and an outlier. It is almost the same as the data without the outliers.\n\n\n\n\n\nCode to generate toursclrs &lt;- hcl.colors(12, \"Zissou 1\")\np_col &lt;- c(rep(\"black\", 100), clrs[11], clrs[11])\np_obs_labels &lt;- c(rep(\"\", 100), \"1\", \"2\")\n\nanimate_xy(plane_n_o_pca$x[,1:4],\n           col=p_col,\n           obs_labels=p_obs_labels)\nanimate_xy(plane_noise_outliers,\n           col=p_col,\n           obs_labels=p_obs_labels)\nrender_gif(plane_noise_outliers, \n           grand_tour(), \n           display_xy(half_range=0.8,\n                      col=p_col,\n             obs_labels=p_obs_labels),\n           gif_file=\"gifs/plane_n_o_clr.gif\",\n           frames=500,\n           width=200,\n           height=200,\n           loop=FALSE)\nrender_gif(plane_n_o_pca$x[,1:4], \n           grand_tour(), \n           display_xy(half_range=0.8,\n                      col=p_col,\n             obs_labels=p_obs_labels),\n           gif_file=\"gifs/plane_n_o_pca.gif\",\n           frames=500,\n           width=200,\n           height=200,\n           loop=FALSE)\n\n\n\n\n\n\n\n\n\n\n\n(a) Outliers clearly visible\n\n\n\n\n\n\n\n\n\n(b) Outliers not clearly visible in PC1-4\n\n\n\n\n\n\nFigure 4.13: Examining the handling of outliers in the PCA of the planar data with noise variables and two outliers. PCA has lost these two extreme values.\n\n\n\nCode to make scatterplot matrixlibrary(GGally)\nggscatmat(plane_n_o_pca$x) + theme_minimal() +\n  theme(axis.title = element_blank(),\n        axis.text = element_blank())\n\n\n\n\n\n\nFigure 4.14: From the scatterplot matrix we can see that the outliers are present in PC5, PC6 and PC7. That means by reducing the dimensionality to the first four PCs the model has missed some important characteristics in the data.\n\n\n\n\n\n4.3.2 Example: Non-linear associations\n\nFigure 4.16 shows the tour of the full 5D data containing non-linear relationships in comparison with a tour of the first three PCs, as recommended by the scree plot (Figure 4.15). The PCs capture some clear and very clean non-linear relationship, but it looks like it has missed some of the complexities of the relationships. The scatterplot matrix of all 5 PCs (Figure 4.17) shows that PC4 and PC5 contain interesting features: more non-linearity, and curiously an outlier.\n\nCode for screeplotdata(plane_nonlin)\nplane_nonlin_pca &lt;- prcomp(plane_nonlin)\nggscree(plane_nonlin_pca, q = 5) + theme_minimal()\n\n\n\n\n\n\nFigure 4.15: Scree plot of the non-linear data suggests three PCs.\n\n\n\n\n\nCode to generate touranimate_xy(plane_nonlin_pca$x[,1:3])\nrender_gif(plane_nonlin_pca$x[,1:3], \n           grand_tour(), \n           display_xy(half_range=0.8),\n           gif_file=\"gifs/plane_nonlin_pca.gif\",\n           frames=500,\n           width=200,\n           height=200)\n\n\n\n\n\n\n\n\n\n\n\n(a) All five variables\n\n\n\n\n\n\n\n\n\n(b) First three PCs\n\n\n\n\n\n\nFigure 4.16: Comparison of the full data and first three principal components. Non-linear relationships between several variables can be seen in a tour on all five variables. The first three principal components reveal a strong non-linear relationship. Some of the non-linearity is clearly visible in the reduced dimension space, but the full data has more complexities.\n\n\n\nCode to make scatterplot matrixggscatmat(plane_nonlin_pca$x) +\n  theme_minimal() +\n  theme(axis.title = element_blank(),\n        axis.text = element_blank())\n\n\n\n\n\n\nFigure 4.17: From the scatterplot matrix we can see that the there is a non-linear relationship visible in PC1 and PC2, with perhaps a small contribution from PC3. However, we can see that when the data is reduced to three PCs, it misses catching all on the non-linear relationships and also interestingly it seems that there is an unusual observation also.\n\n\n\n\n\nOne of the dangers of PCA is that interesting and curious details of the data only emerge in the lowest PCs, that are usually discarded. The tour, and examining the smaller PCs, can help to discover them.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Principal component analysis</span>"
    ]
  },
  {
    "objectID": "4-pca.html#exercises",
    "href": "4-pca.html#exercises",
    "title": "\n4  Principal component analysis\n",
    "section": "Exercises",
    "text": "Exercises\n\nMake a scatterplot matrix of the first four PCs of the aflw data. Is the branch pattern visible in any pair?\nConstruct five new variables to measure these skills offense, defense, playing time, ball movement, errors. Using the tour, examine the relationship between these variables. Map out how a few players could be characterised based on these directions of skills.\nSymmetrise any aflw variables that have skewed distributions using a log or square root transformation. Then re-do the PCA. What do we learn that is different about associations between the skill variables?\nExamine the bushfires data using a grand tour on the numeric variables, ignoring the cause (class) variable. Note any issues such as outliers, or skewness that might affect PCA. How many principal components would be recommended by the scree plot? Examine this PCA model with the data, and explain how well it does or doesn’t fit.\nUse the pca_tour to examine the first five PCs of the bushfires data. How do all of the variables contribute to this reduced space?\nReduce the dimension of the sketches data to 12 PCs. How much variation does this explain? Is there any obvious clustering in this lower dimensional space?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Principal component analysis</span>"
    ]
  },
  {
    "objectID": "4-pca.html#project",
    "href": "4-pca.html#project",
    "title": "\n4  Principal component analysis\n",
    "section": "Project",
    "text": "Project\nLinear dimension reduction can optimise for other criteria, and here we will explore one example: the algorithm implemented in the dobin package finds a basis in which the first few directions are optimized for the detection of outliers in the data. We will examine how it performs for the plane_noise_outliers data (the example where outliers were hidden in the first four principal components.)\n\nStart by looking up the documentation of dobin::dobin. How many parameters does the method depend on?\nWe first apply the function to the plane_noise_outliers data using default values for all parameters.\nRecall that the outliers were added in rows 101 and 102 of the data. Make a scatter plots showing the projection onto the first, second and third component, using color to highlight the outliers. Are they visible as outliers with three components?\nAdjust the frac parameter of the dobin function to frac = 0.99 and repeat the graphical evaluation from point 3. How does it compare to the previous solution?\n\n\n\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2021). Ggthemes: Extra themes, scales and geoms for ggplot2. https://github.com/jrnold/ggthemes\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with r (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C., Härdle, W., & Unwin, A. (Eds.). (2006). Handbook of computational statistics (volume III) data visualization. Springer.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer.\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2021). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2023). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer.\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2022). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://github.com/andrie/ggdendro\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEveritt, B. S., Landau, S., & Leese, M. (2001). Cluster Analysis (4th ed). Edward Arnold.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631.\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2022). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHarrison, P. (2023a). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHart, C., & Wang, E. (2022). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2023). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://CRAN.R-project.org/package=palmerpenguins\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2023). Gt: Easily create presentation-ready display tables. https://CRAN.R-project.org/package=gt\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2023). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://CRAN.R-project.org/package=colorspace\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in r: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2022). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2023). Tidymodels: Easily install and load the tidymodels packages. https://CRAN.R-project.org/package=tidymodels\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An r package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://CRAN.R-project.org/package=liminal\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F., & Gruen, B. (2023). CRAN task view: Cluster analysis & finite mixture models. https://cran.r-project.org/web/views/Cluster.html.\n\n\nLeisch, F., & Grün, B. (2020). MSA: Market segmentation analysis.\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using r - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2023). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2022). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2022). gtExtras: Extending gt for beautiful HTML tables. https://CRAN.R-project.org/package=gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2023). Patchwork: The composer of plots. https://CRAN.R-project.org/package=patchwork\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023a). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B. (2023b). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. https://CRAN.R-project.org/package=geozoo\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2023). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nScrucca, L., Fop, M., Murphy, T. B., & Raftery, A. E. (2016). mclust 5: Clustering, classification and density estimation using Gaussian finite mixture models. The R Journal, 8(1), 289–317. https://doi.org/10.32614/RJ-2016-021\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2023). Plotly: Create interactive web graphics via plotly.js. https://CRAN.R-project.org/package=plotly\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2023). Gtsummary: Presentation-ready data summary and analytic result tables. https://CRAN.R-project.org/package=gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2023). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://github.com/slowkow/ggrepel\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://CRAN.R-project.org/package=rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2023). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., & Dunnington, D. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics. https://CRAN.R-project.org/package=ggplot2\n\n\nWickham, H., & Cook, D. (2024). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://CRAN.R-project.org/package=dplyr\n\n\nWickham, H., Hester, J., & Bryan, J. (2023). Readr: Read rectangular text data. https://CRAN.R-project.org/package=readr\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2022). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2021). kableExtra: Construct complex table with kable and pipe syntax. https://CRAN.R-project.org/package=kableExtra",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Principal component analysis</span>"
    ]
  },
  {
    "objectID": "5-nldr.html",
    "href": "5-nldr.html",
    "title": "\n5  Non-linear dimension reduction\n",
    "section": "",
    "text": "5.1 Explanation of NLDR methods\nNon-linear dimension reduction (NLDR) aims to find a low-dimensional representation of the high-dimensional data that shows the main features of the data. In statistics, it dates back to Kruskal (1964a)’s work on multidimensional scaling (MDS). Some techniques only require an interpoint similarity or distance matrix as the main ingredient, rather than the full data. We’ll focus on when the full data is available here, so we can also compare structure perceived using the tour on the high-dimensional space, relative to structure revealed in the low-dimensional embedding.\nThere are many methods available for generating non-linear low dimensional representations of the data. MDS is a classical technique that minimises the difference between two interpoint distance matrices, the distance between points in the high-dimensions, and in the low-dimensional representations. A good resource for learning about MDS is Borg & Groenen (2005).\nCode to generate the 2D non-linear representationlibrary(mulgar)\nlibrary(Rtsne)\nlibrary(uwot)\nlibrary(ggplot2)\nlibrary(patchwork)\nset.seed(42)\ncnl_tsne &lt;- Rtsne(clusters_nonlin)\ncnl_umap &lt;- umap(clusters_nonlin)\nn1 &lt;- ggplot(as.data.frame(cnl_tsne$Y), aes(x=V1, y=V2)) +\n  geom_point() + \n  ggtitle(\"(a) t-SNE\") +\n  theme_minimal() + \n  theme(aspect.ratio=1)\nn2 &lt;- ggplot(as.data.frame(cnl_umap), aes(x=V1, y=V2)) +\n  geom_point() + \n  ggtitle(\"(b) UMAP\") +\n  theme_minimal() + \n  theme(aspect.ratio=1)\nn1 + n2\n\n\n\n\n\n\nFigure 5.1: Two non-linear embeddings of the non-linear clusters data: (a) t-SNE, (b) UMAP. Both suggest four clusters, with two being non-linear in some form.\nFigure 5.1 show two NLDR views of the clusters_nonlin data set from the mulgar package. Both suggest that there are four clusters, and that some clusters are non-linearly shaped. They disagree on the type of non-linear pattern, where t-SNE represents one cluster as a wavy-shape and UMAP both have a simple parabolic shape. Popular methods in current use include t-SNE (Maaten & Hinton, 2008), UMAP (McInnes et al., 2018) and PHATE (Moon et al., 2019).\nCode to create animated giflibrary(tourr)\nrender_gif(clusters_nonlin, \n           grand_tour(),\n           display_xy(),\n           gif_file = \"gifs/clusters_nonlin.gif\",\n           frames = 500,\n           width = 300, \n           height = 300)\nThe full 4D data is shown with a grand tour in Figure 5.2 @. The four clusters suggested by the NLDR methods can be seen. We also get a better sense of the relative size and proximity of the clusters. There are two small spherical clusters, one quite close to the end of the large sine wave cluster. The fourth cluster is relatively small, and has a slight curve, like a bent rod. The t-SNE representation is slightly more accurate than the UMAP representation. We would expect that the wavy cluster is the sine wave seen in the tour.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-linear dimension reduction</span>"
    ]
  },
  {
    "objectID": "5-nldr.html#explanation-of-nldr-methods",
    "href": "5-nldr.html#explanation-of-nldr-methods",
    "title": "\n5  Non-linear dimension reduction\n",
    "section": "",
    "text": "Figure 5.2: Grand tour of the nonlinear clusters data set, shows four clusters. Two are very small and spherical in shape. One is large, and has a sine wave shape, and the other is fairly small with a bent rod shape.\n\n\n\n\nNLDR can provide useful low-dimensional summaries of high-dimensional structure but you need to check whether it is a sensible and accurate representation by comparing with what is perceived from a tour.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-linear dimension reduction</span>"
    ]
  },
  {
    "objectID": "5-nldr.html#assessing-reliability-of-the-nldr-representation",
    "href": "5-nldr.html#assessing-reliability-of-the-nldr-representation",
    "title": "\n5  Non-linear dimension reduction\n",
    "section": "\n5.2 Assessing reliability of the NLDR representation",
    "text": "5.2 Assessing reliability of the NLDR representation\nNLDR can produce useful low-dimensional summaries of structure in high-dimensional data, like those shown in Figure 5.1. However, there are numerous pitfalls. The fitting procedure can produce very different representations depending on the parameter choices, and even the random number seeding the fit. (You can check this by changing the set.seed in the code above, and by changing from the default parameters.) Also, it may not be possible to represent the high-dimensional structures faithfully low dimensions. For these reasons, one needs to connect the NLDR view with a tour of the data, to help assess its usefulness and accuracy. For example, with this data, we would want to know which of the two curved clusters in the UMAP representation correspond to the sine wave cluster.\n\n5.2.1 Using liminal\n\n\nFigure 5.3 shows how the NLDR plot can be linked to a tour view, using the liminal package, to better understand how well the structure of the data is represented. Here we see learn that the smile in the UMAP embedding is the small bent rod cluster, and that the unibrow is the sine wave.\n\nlibrary(liminal)\numap_df &lt;- data.frame(umapX = cnl_umap[, 1],\n                      umapY = cnl_umap[, 2])\nlimn_tour_link(\n  umap_df,\n  clusters_nonlin,\n  cols = x1:x4\n)\n\n\n\n\n\n\n\n\n\n\n(a) Smile matches bent rod.\n\n\n\n\n\n\n\n\n\n\n\n(b) Unibrow matches sine wave.\n\n\n\n\n\n\nFigure 5.3: Two screenshots from liminal showing which clusters match between the UMAP representation and the tour animation. The smile corresponds to the small bent rod cluster. The unibrow matches to the sine wave cluster.\n\n\n\n5.2.2 Using detourr\n\n\nFigure 5.4 shows how the linking is achieved using detourr. It uses a shared data object, as made possible by the crosstalk package, and the UMAP view is made interactive using plotly.\n\nlibrary(detourr)\nlibrary(dplyr)\nlibrary(crosstalk)\nlibrary(plotly)\numap_df &lt;- data.frame(umapX = cnl_umap[, 1],\n                      umapY = cnl_umap[, 2])\ncnl_df &lt;- bind_cols(clusters_nonlin, umap_df)\nshared_cnl &lt;- SharedData$new(cnl_df)\n\ndetour_plot &lt;- detour(shared_cnl, tour_aes(\n  projection = starts_with(\"x\"))) |&gt;\n    tour_path(grand_tour(2), \n                    max_bases=50, fps = 60) |&gt;\n       show_scatter(alpha = 0.7, axes = FALSE,\n                    width = \"100%\", height = \"450px\")\n\numap_plot &lt;- plot_ly(shared_cnl,\n                    x = ~umapX, \n                    y = ~umapY,\n                    color = I(\"black\"),\n                    height = 450) %&gt;%\n    highlight(on = \"plotly_selected\", \n              off = \"plotly_doubleclick\") %&gt;%\n    add_trace(type = \"scatter\", \n              mode = \"markers\")\n\nbscols(\n     detour_plot, umap_plot,\n     widths = c(5, 6)\n )\n\n\n\n\n\n\nFigure 5.4: Screenshot from detourr showing which clusters match between the UMAP representation and the tour animation. The smile corresponds to the small bent rod cluster.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-linear dimension reduction</span>"
    ]
  },
  {
    "objectID": "5-nldr.html#example-fake_trees",
    "href": "5-nldr.html#example-fake_trees",
    "title": "\n5  Non-linear dimension reduction\n",
    "section": "\n5.3 Example: fake_trees\n",
    "text": "5.3 Example: fake_trees\n\n\nFigure 5.5 shows a more complex example, using the fake_trees data. We know that the 10D data has a main branch, and 9 branches (clusters) attached to it, based on our explorations in the earlier chapters. The t-SNE view, where points are coloured by the known branch ids, is very helpful for seeing the linear branch structure.\nWhat we can’t tell is that there is a main branch from which all of the others extend. We also can’t tell which of the clusters corresponds to this branch. Linking the plot with a tour helps with this. Although, not shown in the sequence of snapshots in Figure 5.5, the main branch is actually the dark blue cluster, which is separated into three pieces by t-SNE.\n\nCode to run liminal on the fake trees datalibrary(liminal)\nlibrary(Rtsne)\ndata(fake_trees)\nset.seed(2020)\ntsne &lt;- Rtsne::Rtsne(\n  dplyr::select(fake_trees,\n                dplyr::starts_with(\"dim\")))\ntsne_df &lt;- data.frame(tsneX = tsne$Y[, 1],\n                      tsneY = tsne$Y[, 2])\nlimn_tour_link(\n  tsne_df,\n  fake_trees,\n  cols = dim1:dim10,\n  color = branches\n)\n\n\n\n\n\n\n\n\n\n\n\n(a) Linked views of t-SNE dimension reduction with a tour of the fake trees data. The t-SNE view clearly shows ten 1D non-linear clusters, while the tour of the full 100 variables suggests a lot more variation in the data, and less difference between clusters.\n\n\n\n\n\n\n\n\n\n\n\n(b) Focus on the green cluster which is split by t-SNE. The shape as viewed in many linear projections shown by the tour shows that it is a single curved cluster. The split is an artifact of the t-SNE mapping.\n\n\n\n\n\n\n\n\n\n\n\n(c) Focus on the purple cluster which splits the green cluster in the t-SNE view. The tour shows that these two clusters are distinct, but are close in one neighbourhood of the 100D space. The close proximity in the t-SNE view is reasonable, though.\n\n\n\n\n\n\nFigure 5.5: Three snapshots of using the liminal linked views to explore how t-SNE has summarised the fake_trees data in 2D.\n\n\n\nThe t-SNE representation clearly shows the linear structures of the data, but viewing this 10D data with the tour shows that t-SNE makes several inaccurate breaks of some of the branches.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-linear dimension reduction</span>"
    ]
  },
  {
    "objectID": "5-nldr.html#exercises",
    "href": "5-nldr.html#exercises",
    "title": "\n5  Non-linear dimension reduction\n",
    "section": "Exercises",
    "text": "Exercises\n\nUsing the penguins_sub data generate a 2D representation using t-SNE. Plot the points mapping the colour to species. What is most surprising? (Hint: Are the three species represented by three distinct clusters?)\nRe-do the t-SNE representation with different parameter choices. Are the results different each time, or could they be considered to be equivalent?\nUse liminal or detourr to link the t-SNE representation to a tour of the penguins. Highlight the points that have been placed in an awkward position by t-SNE from others in their species. Watch them relative to the others in their species in the tour view, and think about whether there is any rationale for the awkward placement.\nUse UMAP to make the 2D representation, and use liminal or detourr to link with a tour to explore the result.\nConduct your best t-SNE and UMAP representations of the aflw data. Compare and contrast what is learned relative to a tour on the principal component analysis.\n\n\n\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2021). Ggthemes: Extra themes, scales and geoms for ggplot2. https://github.com/jrnold/ggthemes\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with r (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C., Härdle, W., & Unwin, A. (Eds.). (2006). Handbook of computational statistics (volume III) data visualization. Springer.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer.\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2021). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2023). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer.\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2022). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://github.com/andrie/ggdendro\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEveritt, B. S., Landau, S., & Leese, M. (2001). Cluster Analysis (4th ed). Edward Arnold.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631.\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2022). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHarrison, P. (2023a). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHart, C., & Wang, E. (2022). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2023). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://CRAN.R-project.org/package=palmerpenguins\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2023). Gt: Easily create presentation-ready display tables. https://CRAN.R-project.org/package=gt\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2023). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://CRAN.R-project.org/package=colorspace\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in r: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2022). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2023). Tidymodels: Easily install and load the tidymodels packages. https://CRAN.R-project.org/package=tidymodels\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An r package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://CRAN.R-project.org/package=liminal\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F., & Gruen, B. (2023). CRAN task view: Cluster analysis & finite mixture models. https://cran.r-project.org/web/views/Cluster.html.\n\n\nLeisch, F., & Grün, B. (2020). MSA: Market segmentation analysis.\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using r - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2023). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2022). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2022). gtExtras: Extending gt for beautiful HTML tables. https://CRAN.R-project.org/package=gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2023). Patchwork: The composer of plots. https://CRAN.R-project.org/package=patchwork\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023a). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B. (2023b). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. https://CRAN.R-project.org/package=geozoo\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2023). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nScrucca, L., Fop, M., Murphy, T. B., & Raftery, A. E. (2016). mclust 5: Clustering, classification and density estimation using Gaussian finite mixture models. The R Journal, 8(1), 289–317. https://doi.org/10.32614/RJ-2016-021\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2023). Plotly: Create interactive web graphics via plotly.js. https://CRAN.R-project.org/package=plotly\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2023). Gtsummary: Presentation-ready data summary and analytic result tables. https://CRAN.R-project.org/package=gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2023). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://github.com/slowkow/ggrepel\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://CRAN.R-project.org/package=rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2023). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., & Dunnington, D. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics. https://CRAN.R-project.org/package=ggplot2\n\n\nWickham, H., & Cook, D. (2024). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://CRAN.R-project.org/package=dplyr\n\n\nWickham, H., Hester, J., & Bryan, J. (2023). Readr: Read rectangular text data. https://CRAN.R-project.org/package=readr\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2022). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2021). kableExtra: Construct complex table with kable and pipe syntax. https://CRAN.R-project.org/package=kableExtra",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-linear dimension reduction</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "",
    "text": "Preface\nIt is important to visualise your data because you might discover things that you could never have anticipated. Although there are many resources available for data visualisation, there are few comprehensive resources on high-dimensional data visualisation. High-dimensional (or multivariate) data arises when many different things are measured for each observation. While we can learn many things from plotting with 1D and 2D or 3D methods there are likely more structures hidden in the higher dimensions. This book provides guidance on visualising high-dimensional data and models using linear projections, with R.\nHigh-dimensional data spaces are fascinating places. You may think that there’s a lot of ways to plot one or two variables, and a lot of types of patterns that can be found. You might use a density plot and see skewness or a dot plot to find outliers. A scatterplot of two variables might reveal a non-linear relationship or a barrier beyond which no observations exist. We don’t as yet have so many different choices of plot types for high-dimensions, but these types of patterns are also what we seek in scatterplots of high-dimensional data. The additional dimensions can clarify these patterns, that clusters are likely to be more distinct. Observations that did not appear to be very different can be seen to be lonely anomalies in high-dimensions, that no other observations have quite the same combination of values.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#whats-in-this-book",
    "href": "index.html#whats-in-this-book",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "What’s in this book?",
    "text": "What’s in this book?\nThe book is divided into these parts:\n\n\nIntroduction: Here we introduce you to high-dimensional spaces, how they can be visualised, and notation that is useful for describing methods in later chapters.\n\n\nDimension reduction: This part covers linear and non-linear dimension reduction. It includes ways to help decide on the number of dimensions needed to summarise the high dimensional data, whether linear dimension reduction is appropriate, detecting problems that might affect the dimension reduction, and examining how well or badly a non-linear dimension reduction is representing the data.\n\nCluster analysis: This part described methods for finding groups in data. Although it includes an explanation of a purely graphical approach, it is mostly on using graphics in association with numerical clustering algorithms. There are explanations of assessing the suitability of different numerical techniques for extracting clusters, based on the data shapes, evaluating the clustering result, and showing the solutions in high dimensions.\n\nClassification: This part describes methods for exploring known groups in the data. You’ll learn how to check model assumptions, to help decide if a method is suited to the data, examine classification boundaries and explore where errors arise. \n\n\nIn each of these parts an emphasis is also showing your model with your data in the high dimensional space.\nOur hopes are that you will come away with understanding the importance of plotting your high dimensional data as a regular step in your statistical or machine learning analyses. There are many examples of what you might miss if you don’t plot the data. Effective use of graphics goes hand-in-hand with analytical techniques. With high dimensions visualisation is a challenge but it is fascinating, and leads to many surprising moments.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#audience",
    "href": "index.html#audience",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "Audience",
    "text": "Audience\nHigh-dimensional data arises in many fields such as biology, social sciences, finance, and more. Anyone who is doing exploratory data analysis and model fitting for more than two variables will benefit from learning how to effectively visualise high-dimensions. This book will be useful for students and teachers of multivariate data analysis and machine learning, and researchers, data analysts, and industry professionals who work in these areas.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#how-to-use-the-book",
    "href": "index.html#how-to-use-the-book",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "How to use the book?",
    "text": "How to use the book?\nThe book is written with explanations accompanied by examples with R code. The chapters are organised by types of analysis and focus on how to use the high-dimensional visualisation to complement the commonly used analytical methods. The toolbox chapter in the Appendix provides an overview of the primary high-dimensional visualisation methods discussed in the book and how to get started.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#what-should-i-know-before-reading-this-book",
    "href": "index.html#what-should-i-know-before-reading-this-book",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "What should I know before reading this book?",
    "text": "What should I know before reading this book?\nThe examples assume that you already use R, and have a working knowledge of base R and tidyverse way of thinking about data analysis. It also assumes that you have some knowledge of statistical methods, and some experience with machine learning methods.\nIf you feel like you need build up your skills in these areas in preparation for working through this book, these are our recommended resources:\n\n\nR for Data Science by Wickham and Grolemund for learning about data wrangling and visualisation.\n\nIntroduction to Modern Statistics by Çetinkaya-Rundel and Hardin to learn about introductory statistics.\n\nHands-On Machine Learning with R by Boehmke and Greenwell to learn about machine learning.\n\nWe will assume you know how to plot your data and models in 2D. Our material starts from 2D and beyond.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#setting-up-your-workflow",
    "href": "index.html#setting-up-your-workflow",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "Setting up your workflow",
    "text": "Setting up your workflow\nTo get started set up your computer with the current versions of R and ideally also with Rstudio Desktop.\nIn addition, we have made an R package to share the data and functions used in this book, called mulgar.12\n\ninstall.packages(\"mulgar\", dependencies=TRUE)\n# or the development version\ndevtools::install_github(\"dicook/mulgar\")\n\nTo get a copy of the code and data used and an RStudio project to get started, you can download with this code:\n\nbook_url &lt;- \"https://dicook.github.io/mulgar_book/code_and_data.zip\"\nusethis::use_zip(url=book_url)\n\nYou will be able to click on the mulgar_book.Rproj to get started with the code.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#suggestion-feedback-or-error",
    "href": "index.html#suggestion-feedback-or-error",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "Suggestion, feedback or error?",
    "text": "Suggestion, feedback or error?\nWe welcome suggestions, feedback or details of errors. You can report them as an issue at the Github repo for this book.\nPlease make a small reproducible example and report the error encountered. Reproducible examples have these components:\n\na small amount of data\nsmall amount of code that generates the error\ncopy of the error message that was generated",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "License",
    "text": "License\nThe online version of this book is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n\n\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2021). Ggthemes: Extra themes, scales and geoms for ggplot2. https://github.com/jrnold/ggthemes\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with r (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C., Härdle, W., & Unwin, A. (Eds.). (2006). Handbook of computational statistics (volume III) data visualization. Springer.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer.\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2021). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2023). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer.\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2022). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://github.com/andrie/ggdendro\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEveritt, B. S., Landau, S., & Leese, M. (2001). Cluster Analysis (4th ed). Edward Arnold.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936a). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936b). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631.\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2022). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHarrison, P. (2023a). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHart, C., & Wang, E. (2022). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2023). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://CRAN.R-project.org/package=palmerpenguins\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2023). Gt: Easily create presentation-ready display tables. https://CRAN.R-project.org/package=gt\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2023). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://CRAN.R-project.org/package=colorspace\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in r: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2022). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2023). Tidymodels: Easily install and load the tidymodels packages. https://CRAN.R-project.org/package=tidymodels\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An r package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://CRAN.R-project.org/package=liminal\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F., & Gruen, B. (2023). CRAN task view: Cluster analysis & finite mixture models. https://cran.r-project.org/web/views/Cluster.html.\n\n\nLeisch, F., & Grün, B. (2020). MSA: Market segmentation analysis.\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using r - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2023). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2022). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2022). gtExtras: Extending gt for beautiful HTML tables. https://CRAN.R-project.org/package=gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2023). Patchwork: The composer of plots. https://CRAN.R-project.org/package=patchwork\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023a). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B. (2023b). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. https://CRAN.R-project.org/package=geozoo\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2023). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nScrucca, L., Fop, M., Murphy, T. B., & Raftery, A. E. (2016). mclust 5: Clustering, classification and density estimation using Gaussian finite mixture models. The R Journal, 8(1), 289–317. https://doi.org/10.32614/RJ-2016-021\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2023). Plotly: Create interactive web graphics via plotly.js. https://CRAN.R-project.org/package=plotly\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2023). Gtsummary: Presentation-ready data summary and analytic result tables. https://CRAN.R-project.org/package=gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2023). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://github.com/slowkow/ggrepel\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://CRAN.R-project.org/package=rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2023). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., & Dunnington, D. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics. https://CRAN.R-project.org/package=ggplot2\n\n\nWickham, H., & Cook, D. (2024). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://CRAN.R-project.org/package=dplyr\n\n\nWickham, H., Hester, J., & Bryan, J. (2023). Readr: Read rectangular text data. https://CRAN.R-project.org/package=readr\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2022). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2021). kableExtra: Construct complex table with kable and pipe syntax. https://CRAN.R-project.org/package=kableExtra",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Interactively exploring high-dimensional data and models in R",
    "section": "",
    "text": "Mulga is a type of Australian habitat composed of woodland or open forest dominated by the mulga tree. Massive clearing of mulga led to the vast wheat fields of Western Australia. Here mulgar is an acronym for MULtivariate Graphical Analysis with R.↩︎\nPhoto of mulga tree taken by L. G. Cook.↩︎",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "1-intro.html",
    "href": "1-intro.html",
    "title": "1  Picturing high dimensions",
    "section": "",
    "text": "1.1 Getting familiar with tours\nFigure 1.1 illustrates a tour for 2D data and 1D projections. The (grand) tour will generate all possible 1D projections of the data, and display with a univariate plot like a histogram or density plot. For this data, the simple_clusters data, depending on the projection, the distribution might be clustered into two groups (bimodal), or there might be no clusters (unimodal). In this example, all projections are generated by rotating a line around the centre of the plot. Clustering can be seen in many of the projections, with the strongest being when the contribution of both variables is equal, and the projection is (0.707,  0.707) or (-0.707, -0.707). (If you are curious about the number 0.707, read the last section of this chapter.)\nFigure 1.2 illustrates a tour for 3D data using 2D projections. The data are points on the surface of a donut shape. By showing the projections using a scatterplot the donut looks transparent and we can see through the data. The donut shape can be inferred from watching many 2D projections but some are more revealing that others. The projection shown in (b) is where the hole in the donut is clearly visible.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#getting-familiar-with-tours",
    "href": "1-intro.html#getting-familiar-with-tours",
    "title": "1  Picturing high dimensions",
    "section": "",
    "text": "(a) 2D data\n\n\n\n\n\n\n\n\n\n\n(b) 1D grand tour of the 2D data\n\n\n\n\n\n\nFigure 1.1: How a tour can be used to explore high-dimensional data illustrated using (a) 2D data with two clusters and (b) a tour of 1D projections shown as a density plot. Imagine spinning a line around the centre of the data plot, with points projected orthogonally onto the line. With this data, when the line is at x1=x2 (0.707, 0.707) or (-0.707, -0.707) the clustering is the strongest. When it is at x1=-x2  (0.707, -0.707) there is no clustering.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) 2D tour of 3D data\n\n\n\n\n\n\n\n\n\n\n(b) A projection revealing the hole\n\n\n\n\n\n\n\nFigure 1.2: How a tour can be used to explore high-dimensional data illustrated by showing a sequence of random 2D projections of 3D data (a). The data has a donut shape with the hole revealed in a single 2D projection (b). Data usually arrives with a given number of observations, and when we plot it like this using a scatterplot, it is like shadows of a transparent object.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#whats-different-about-space-beyond-2d",
    "href": "1-intro.html#whats-different-about-space-beyond-2d",
    "title": "1  Picturing high dimensions",
    "section": "\n1.2 What’s different about space beyond 2D?",
    "text": "1.2 What’s different about space beyond 2D?\nThe term “high-dimensional” in this book refers to the dimensionality of the Euclidean space. Figure 1.3 shows a way to imagine this. It shows a sequence of cube wireframes, ranging from one-dimensional (1D) through to five-dimensional (5D), where beyond 2D is a linear projection of the cube. As the dimension increases, a new orthogonal axis is added. For cubes, this is achieved by doubling the cube: a 2D cube consists of two 1D cubes, a 3D cube consists of two 2D cubes, and so forth. This is a great way to think about the space being examined by the visual methods, and also all of the machine learning methods mentioned, in this book.\n\n\n\n\n\n\n\n\nFigure 1.3: Space can be considered to be a high-dimensional cube. Here we have pictured a sequence of increasing dimension cubes, from 1D to 5D, as wireframes, it can be seen that as the dimension increase by one, the cube doubles.\n\n\n\n\nInterestingly, the struggle with imagining high-dimensions this way is described in a novel published in 1884 (Abbott, 1884) 1. Yes, more than 100 years ago! This is a story about characters living in a 2D world, being visited by an alien 3D character. It also is a social satire, serving the reader strong messages about gender inequity, although this provides the means to explain more intricacies in perceiving dimensions. There have been several movies made based on the book in recent decades (e.g. Martin (1965), D. Johnson & Travis (2007)). Although purchasing the movies may be prohibitive, watching the trailers available for free online is sufficient to gain enough geometric intuition on the nature of understanding high-dimensional spaces while living in a low-dimensional world.\nWhen we look at high-dimensional spaces from a low-dimensional space, we meet the “curse of dimensionality”, a term introduced by Bellman (1961) to express the difficulty of doing optimization in high dimensions because of the exponential growth in space as dimension increases. A way to imagine this is look at the cubes in Figure 1.3: As you go from 1D to 2D, 2D to 3D, the space expands a lot, and imagine how vast space might get as more dimensions are added2. The volume of the space grows exponentially with dimension, which makes it infeasible to sample enough points – any sample will be less densely covering the space as dimension increases. The effect is that most points will be far from the sample mean, on the edge of the sample space.\n\nFor visualisation, the curse manifests in an opposite manner. Projecting from high to low dimensions creates a crowding or piling of points near the center of the distribution. This was noted by Diaconis & Freedman (1984a). Figure 1.4 illustrates this phenomenon. As dimension increases, the points crowd the centre, even with as few as ten dimensions. This is something that we may need to correct for when exploring high dimensions with low-dimensional projections.\n\n\n\n\n\n\n\n\nFigure 1.4: Illustration of data crowding in the low-dimensional projection as dimension increases, here from 3, 10, 100. Colour shows the number of points in each hexagon bin (pink is large, navy is small). As dimension increases the points concentrate near the centre.\n\n\n\n\nFigure 1.5 shows 2D tours of two different 5D data sets. One has clusters (a) and the other has two outliers and a plane (b). Can you see these? One difference in the viewing of data with more than three dimensions with 2D projections is that the points seem to shrink towards the centre, and then expand out again. This the effect of dimensionality, with different variance or spread in some directions.\n\n\n\n\n\n\n\n\n\n(a) Clusters\n\n\n\n\n\n\n\n\n\n(b) Outliers\n\n\n\n\n\n\nFigure 1.5: Two 5D datasets shown as tours of 2D projections. Can you see clusters of points in (a) and two outliers with a plane in (b)?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#what-can-you-learn",
    "href": "1-intro.html#what-can-you-learn",
    "title": "1  Picturing high dimensions",
    "section": "\n1.3 What can you learn?",
    "text": "1.3 What can you learn?\nThere are two ways of detecting structure in tours:\n\npatterns in a single low-dimensional projection\nmovement patterns\n\nwith the latter being especially useful when displaying the projected data as a scatterplot. Figure 1.6 shows examples of patterns we typically look for when making a scatterplot of data. These include clustering, linear and non-linear association, outliers, barriers where there is a sharp edge beyond which no observations are seen. Not shown, but it also might be possible to observe multiple modes, or density of observations, L-shapes, discreteness or uneven spread of points. The tour is especially useful if these patterns are only visible in combinations of variables.\n\n\n\n\n\n\n\nFigure 1.6: Example structures that might be visible in a 2D projection that imply presence of structure in high dimensions. These include clusters, linear and non-linear association, outliers and barriers.\n\n\n\n\nFigure 1.7 illustrates how movement patterns of points when using scatterplots to display 2D projections indicate clustering (a, b) and outliers (c, d).\n\n\n\n\n\n\n\n\n\n(a) Clustering\n\n\n\n\n\n\n\n\n\n(b) Outliers\n\n\n\n\n\n\nFigure 1.7: The movement of points give further clues about the structure of the data in high-dimensions. In the data with clustering, often we can see a group of points moving differently from the others. Because there are three clusters, you should see three distinct movement patterns. It is similar with outliers, except these may be individual points moving alone, and different from all others. This can be seen in the static plot, one point (top left) has a movement pattern upwards whereas most of the other observations near it are moving down towards the right.\n\n\n\nThis type of visualisation is useful for many activities in dealing with high-dimensional data, including:\n\nexploring high-dimensional data.\ndetecting if the data lives in a lower dimensional space than the number of variables.\nchecking assumptions required for multivariate models to be applicable.\ncheck for potential problems in modeling such as multicollinearity among predictors.\nchecking assumptions required for probabilities calculated for statistical hypothesis testing to be valid.\ndiagnosing the fit of multivariate models.\n\n\nWith a tour we slowly rotate the viewing direction, this allows us to see many individual projections and to track movement patterns. Look for interesting structures such as clusters or outlying points.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#a-little-history",
    "href": "1-intro.html#a-little-history",
    "title": "1  Picturing high dimensions",
    "section": "\n1.4 A little history",
    "text": "1.4 A little history\nViewing high-dimensional data based on low-dimensional projections can probably be traced back to the early work on principal component analysis by Pearson (1901) and Hotelling (1933), which was extended to known classes as part of discriminant analysis by Fisher (1936a).\nWith computer graphics, the capability of animating plots to show more than a single best projection became possible. The video library (ASA Statistical Graphics Section, 2023) is the best place to experience the earliest work. Kruskal’s 1962 animation of multidimensional scaling showed the process of finding a good 2D representation of high dimensional data, although the views are not projections. Chang’s 1970 video shows her rotating a high dimensional point cloud along coordinate axes to find a special projection where all the numbers align. The classic video that must be watched is PRIM9 (Fisherkeller et al., 1973) where a variety of interactive and dynamic tools are used together to explore high dimensional physics data, documented in Fisherkeller et al. (1974).\nThe methods in this book primarily emerge from Asimov (1985)’s grand tour method. The algorithm provided the first smooth and continuous sequence of low dimensional projections, and guaranteed that all possible low dimensional projections were likely to be shown. The algorithm was refined in Buja & Asimov (1986) (and documented in detail in Buja et al. (2005)) to make it efficiently show all possible projections. Since then there have been numerous varieties of tour algorithms developed to focus on specific tasks in exploring high dimensional data, and these are documented in S. Lee et al. (2022).\nThis book is an evolution from Cook & Swayne (2007). One of the difficulties in working on interactive and dynamic graphics research has been the rapid change in technology. Programming languages have changed a little (FORTRAN to C to java to python) but graphics toolkits and display devices have changed a lot! The tour software used in this book evolved from XGobi, which was written in C and used the X Window System, which was then rewritten in GGobi using gtk. The video library has engaging videos of these software systems There have been several other short-lived implementations, including orca (Sutherland et al., 2000a), written in java, and cranvas (Xie et al., 2014), written in R with a back-end provided by wrapper functions to qt libraries.\nAlthough attempts were made with these ancestor systems to connect the data plots to a statistical analysis system, these were always limited. With the emergence of R, having graphics in the data analysis workflow has been much easier, albeit at the cost of the interactivity with graphics that matches the old systems. We are mostly using the R package, tourr (Wickham et al., 2011a) for examples in this book. It provides the machinery for running a tour, and has the flexibility that it can be ported, modified, and used as a regular element of data analysis.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#exercises",
    "href": "1-intro.html#exercises",
    "title": "1  Picturing high dimensions",
    "section": "Exercises",
    "text": "Exercises\n\nRandomly generate data points that are uniformly distributed in a hyper-cube of 3, 5 and 10 dimensions, with 500 points in each sample, using the cube.solid.random function of the geozoo package. What differences do we expect to see? Now visualise each set in a grand tour and describe how they differ, and whether this matched your expectations?\nUse the geozoo package to generate samples from different shapes and use them to get a better understanding of how shapes appear in a grand tour. You can start with exploring the conic spiral in 3D, a torus in 4D and points along the wire frame of a cube in 5D.\nFor each of the challenge data sets, c1, …, c7 from the mulgar package, use the grand tour to view and try to identify structure (outliers, clusters, non-linear relationships).\n\n\n\n\n\nAbbott, E. (1884). Flatland: A romance of many dimensions. Dover Publications.\n\n\nAhlberg, C., Williamson, C., & Shneiderman, B. (1991). Dynamic Queries for Information Exploration: An Implementation and Evaluation. ACM CHI ‘92 Conference Proceedings, 619–626.\n\n\nAllaire, J., & Chollet, F. (2023). Keras: R interface to ’keras’. https://CRAN.R-project.org/package=keras\n\n\nAnderson, E. (1957). A Semigraphical Method for the Analysis of Complex Problems. Proceedings of the National Academy of Science, 13, 923–927.\n\n\nAndrews, D. F. (1972). Plots of High-dimensional Data. Biometrics, 28, 125–136.\n\n\nAndrews, D. F., Gnanadesikan, R., & Warner, J. L. (1971). Transformations of Multivariate Data. Biometrics, 27, 825–840.\n\n\nAnselin, L., & Bao, S. (1997). Exploratory Spatial Data Analysis Linking SpaceStat and ArcView. In M. M. Fischer & A. Getis (Eds.), Recent Developments in Spatial Analysis (pp. 35–59). Springer.\n\n\nArnold, J. B. (2021). Ggthemes: Extra themes, scales and geoms for ggplot2. https://github.com/jrnold/ggthemes\n\n\nASA Statistical Graphics Section. (2023). Video Library. https://community.amstat.org/jointscsg-section/media/videos.\n\n\nAsimov, D. (1985). The Grand Tour: A Tool for Viewing Multidimensional Data. SIAM Journal of Scientific and Statistical Computing, 6(1), 128–143.\n\n\nAuguie, B. (2017). gridExtra: Miscellaneous functions for \"grid\" graphics. https://CRAN.R-project.org/package=gridExtra\n\n\nAustralian Bureau of Agricultural and Resource Economics and Sciences. (2018). Forests of Australia. https://www.agriculture.gov.au/abares/forestsaustralia/forest-data-maps-and-tools/spatial-data/forest-cover\n\n\nBecker, R. A., & Chambers, J. M. (1984). S: An environment for data analysis and graphics. Wadsworth.\n\n\nBecker, R. A., & Cleveland, W. S. (1988). Brushing Scatterplots. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 201–224). Wadsworth.\n\n\nBecker, R., Cleveland, W. S., & Shyu, M.-J. (1996). The Visual Design and Control of Trellis Displays. Journal of Computational and Graphical Statistics, 6(1), 123–155.\n\n\nBederson, B. B., & Schneiderman, B. (2003). The craft of information visualization: Readings and reflections. Morgan Kaufmann.\n\n\nBellman, R. (1961). Adaptive control processes : A guided tour.\n\n\nBickel, P. J., Kur, G., & Nadler, B. (2018). Projection pursuit in high dimensions. Proceedings of the National Academy of Sciences, 115, 9151–9156. https://doi.org/10.1073/pnas.1801177115\n\n\nBishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n\n\nBoehmke, B., & Greenwell, B. M. (2019). Hands-on machine learning with r (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBoelaert, J., Ollion, E., & Sodoge, J. (2022). aweSOM: Interactive self-organizing maps. https://CRAN.R-project.org/package=aweSOM\n\n\nBonneau, G.-P., Ertl, T., & Nielson, G. M. (Eds.). (2006). Scientific visualization: The visual extraction of knowledge from data. Springer.\n\n\nBorg, I., & Groenen, P. J. F. (2005). Modern Multidimensional Scaling. Springer.\n\n\nBreiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n\n\nBreiman, L., Cutler, A., Liaw, A., & Wiener, M. (2022). randomForest: Breiman and cutler’s random forests for classification and regression. https://www.stat.berkeley.edu/~breiman/RandomForests/\n\n\nBreiman, L., Friedman, J., Olshen, C., & Stone, C. (1984). Classification and Regression Trees. Wadsworth; Brooks/Cole.\n\n\nBuja, A. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data: Comment. Journal of Business & Economic Statistics, 14(1), 128–129.\n\n\nBuja, A., & Asimov, D. (1986). Grand Tour Methods: An Outline. Computing Science and Statistics, 17, 63–67.\n\n\nBuja, A., Asimov, D., Hurley, C., & McDonald, J. A. (1988). Elements of a Viewing Pipeline for Data Analysis. In W. S. Cleveland & M. E. McGill (Eds.), Dynamic graphics for statistics (pp. 277–308). Wadsworth.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (1997). Dynamic Projections in High-Dimensional Visualization: Theory and Computational Methods. AT&T Labs.\n\n\nBuja, A., Cook, D., Asimov, D., & Hurley, C. (2005). Computational Methods for High-Dimensional Rotations in Data Visualization. In C. R. Rao, E. J. Wegman, & J. L. Solka (Eds.), Handbook of statistics: Data mining and visualization (pp. 391–414). Elsevier/North-Holland.\n\n\nBuja, A., Cook, D., & Swayne, D. (1996). Interactive High-Dimensional Data Visualization. Journal of Computational and Graphical Statistics, 5(1), 78–99.\n\n\nBuja, A., Hurley, C., & McDonald, J. A. (1986). A Data Viewer for Multivariate Data. Computing Science and Statistics, 17(1), 171–174.\n\n\nBuja, A., & Swayne, D. F. (2002). Visualization Methodology for Multidimensional Scaling. Journal of Classification, 19(1), 7–43.\n\n\nBuja, A., Swayne, D. F., Littman, M. L., Dean, N., Hofmann, H., & Chen, L. (2008). Data visualization with multidimensional scaling. Journal of Computational and Graphical Statistics, 17(2), 444–472. https://doi.org/10.1198/106186008X318440\n\n\nBuja, A., & Tukey, P. (Eds.). (1991). Computing and Graphics in Statistics. Springer-Verlag.\n\n\nCard, S. K., Mackinlay, J. D., & Schneiderman, B. (1999). Readings in information visualization. Morgan Kaufmann Publishers.\n\n\nCarr, D. B., Wegman, E. J., & Luo, Q. (1996). ExplorN: Design Considerations Past and Present (Technical Report No. 129). Center for Computational Statistics, George Mason University.\n\n\nChatfield, C. (1995). Problem solving: A statistician’s guide. Chapman; Hall/CRC Press.\n\n\nChen, C., Härdle, W., & Unwin, A. (Eds.). (2006). Handbook of computational statistics (volume III) data visualization. Springer.\n\n\nChen, C.-H., Härdle, W., & Unwin, A. (Eds.). (2007). Handbook of Data Visualization. Springer.\n\n\nCheng, B., & Titterington, M. (1994). Neural Networks: A Review from a Statistical Perspective. Statistical Science, 9(1), 2–30.\n\n\nCheng, J., & Sievert, C. (2021). Crosstalk: Inter-widget interactivity for HTML widgets. https://rstudio.github.io/crosstalk/\n\n\nChernoff, H. (1973). The Use of Faces to Represent Points in \\(k\\)-dimensional Space Graphically. Journal of the American Statistical Association, 68, 361–368.\n\n\nCleveland, W. S. (1979). Robust Localy Weighted Regression and Smoothing Scatterplots. Journal of American Statistics Association, 74, 829–836.\n\n\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\n\n\nCleveland, W. S., & McGill, M. E. (Eds.). (1988). Dynamic graphics for statistics. Wadsworth.\n\n\nCook, D., & Buja, A. (1997). Manual Controls For High-Dimensional Data Projections. Journal of Computational and Graphical Statistics, 6(4), 464–480.\n\n\nCook, D., Buja, A., & Cabrera, J. (1993). Projection Pursuit Indexes Based on Orthonormal Function Expansions. Journal of Computational and Graphical Statistics, 2(3), 225–250.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995b). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Buja, A., Cabrera, J., & Hurley, C. (1995a). Grand Tour and Projection Pursuit. Journal of Computational and Graphical Statistics, 4(3), 155–172.\n\n\nCook, D., Hofmann, H., Lee, E.-K., Yang, H., Nikolau, B., & Wurtele, E. (2007). Exploring Gene Expression Data, Using Plots. Journal of Data Science, 5(2), 151–182.\n\n\nCook, D., & Laa, U. (2023). Mulgar: Functions for pre-processing data for multivariate data visualisation using tours. https://dicook.github.io/mulgar/\n\n\nCook, D., Lee, E.-K., Buja, A., & Wickham, H. (2006). Grand Tours, Projection Pursuit Guided Tours and Manual Controls. In C.-H. Chen, W. Härdle, & A. Unwin (Eds.), Handbook of Data Visualization. Springer.\n\n\nCook, D., Majure, J. J., Symanzik, J., & Cressie, N. (1996). Dynamic Graphics in a GIS: Exploring and Analyzing Multivariate Spatial Data using Linked Software. Computational Statistics: Special Issue on Computer Aided Analyses of Spatial Data, 11(4), 467–480.\n\n\nCook, D., & Swayne, D. F. (2007). Interactive and dynamic graphics for data analysis: With R and GGobi. Springer-Verlag. https://doi.org/10.1007/978-0-387-71762-3\n\n\nCortes, C., Pregibon, D., & Volinsky, C. (2003). Computational Methods for Dynamic Graphs. Journal of Computational & Graphical Statistics, 12(4), 950–970.\n\n\nCortes, C., & Vapnik, V. N. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297.\n\n\nd’Ocagne, M. (1885). Coordonnées Parallèles et Axiales: Méthode de transformation géométrique et procédé nouveau de calcul graphique déduits de la considération des coordonnées paralléles. Gauthier-Villars.\n\n\nDalgaard, P. (2002). Introductory statistics with R. Springer.\n\n\nDasu, T., Swayne, D. F., & Poole, D. (2005). Grouping Multivariate Time Series: A Case Study. Proceedings of the IEEE Workshop on Temporal Data Mining: Algorithms, Theory and Applications, in Conjunction with the Conference on Data Mining, Houston, November 27, 2005, 25–32.\n\n\nde Vries, A., & Ripley, B. D. (2022). Ggdendro: Create dendrograms and tree diagrams using ggplot2. https://github.com/andrie/ggdendro\n\n\nDepartment of Environment, Land, Water & Planning. (2019). Fire Origins - Current and Historical. https://discover.data.vic.gov.au/dataset/fire-origins-current-and-historical\n\n\nDepartment of Environment, Land, Water & Planning. (2020a). CFA - Fire Station. https://discover.data.vic.gov.au/dataset/cfa-fire-station-vmfeat-geomark_point\n\n\nDepartment of Environment, Land, Water & Planning. (2020b). Recreation Sites. https://discover.data.vic.gov.au/dataset/recreation-sites\n\n\nDiaconis, P., & Freedman, D. (1984b). Asymptotics of Graphical Projection Pursuit. Annals of Statistics, 12, 793–815.\n\n\nDiaconis, P., & Freedman, D. (1984a). Asymptotics of graphical projection pursuit. Annals of Statistics, 12(3), 793–815. https://doi.org/10.1214/aos/1176346703\n\n\nDykes, J., MacEachren, A. M., & Kraak, M.-J. (2005). Exploring geovisualization. Elsevier.\n\n\nEveritt, B. S., Landau, S., & Leese, M. (2001). Cluster Analysis (4th ed). Edward Arnold.\n\n\nFienberg, S. E. (1979). Graphical Methods in Statistics. Journal of American Statistical Association, 33(4), 165–178.\n\n\nFisher, R. A. (1936b). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7, 179–188.\n\n\nFisher, R. A. (1936a). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179–188. https://doi.org/10.1111/j.1469-1809.1936.tb02137.x\n\n\nFisher, R. A. (1938). The Statistical Utilization of Multiple Measurements. Annals of Eugenics, 8, 376–386.\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1973). PRIM-9, an interactive multidimensional data display and analysis system. https://www.youtube.com/watch?v=B7XoW2qiFUA\n\n\nFisherkeller, M. A., Friedman, J. H., & Tukey, J. W. (1974). PRIM-9, an interactive multidimensional data display and analysis system. In W. S. Cleveland (Ed.), The collected works of john w. Tukey: Graphics 1965-1985, volume v (pp. 340–346).\n\n\nForbes, J., Cook, D., & Hyndman, R. J. (2020). Spatial modelling of the two-party preferred vote in australian federal elections: 2001–2016. Australian & New Zealand Journal of Statistics, 62(2), 168–185. https://doi.org/https://doi.org/10.1111/anzs.12292\n\n\nFord, B. J. (1992). Images of science: A history of scientific illustration. The British Library.\n\n\nForgy, E. (1965). Cluster analysis of multivariate data: Efficiency versus interpretability of classification. Biometrics, 21(3), 768–769.\n\n\nFraley, C., & Raftery, A. E. (2002). Model-based Clustering, Discriminant Analysis, Density Estimation. Journal of the American Statistical Association, 97, 611–631.\n\n\nFraley, C., Raftery, A. E., & Scrucca, L. (2022). Mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation. https://mclust-org.github.io/mclust/\n\n\nFriedman, J. H. (1987). Exploratory Projection Pursuit. Journal of American Statistical Association, 82, 249–266.\n\n\nFriedman, J. H., & Tukey, J. W. (1974). A Projection Pursuit Algorithm for Exploratory Data Analysis. IEEE Transactions on Computing C, 23, 881–889.\n\n\nFriendly, M., & Denis, D. J. (2004). Milestones in the history of thematic cartography, statistical graphics, and data visualization. http://www.math.yorku.ca/SCS/Gallery/milestone/.\n\n\nFritsch, S., Guenther, F., & Wright, M. N. (2019). Neuralnet: Training of neural networks. https://CRAN.R-project.org/package=neuralnet\n\n\nFurnas, G. W., & Buja, A. (1994). Prosection Views: Dimensional Inference Through Sections and Projections. Journal of Computational and Graphical Statistics, 3(4), 323–385.\n\n\nGabriel, K. R. (1971). The Biplot Graphical Display of Matrices with Applications to Principal Component Analysis. Biometrika, 58, 453–467.\n\n\nGentle, J. E., Härdle, W., & Mori, Y. (Eds.). (2004). Handbook of computational statistics: Concepts and methods. Springer.\n\n\nGiordani, P., Ferraro, M. B., & Martella, F. (2020). An introduction to clustering with r. Springer Singapore. https://doi.org/10.1007/978-981-13-0553-5\n\n\nGlover, D. M., & Hopke, P. K. (1992). Exploration of Multivariate Chemical Data by Projection Pursuit. Chemometrics and Intelligent Laboratory Systems, 16, 45–59.\n\n\nGood, P. (2005). Permutation, Parametric, and Bootstrap Tests of Hypotheses. Springer.\n\n\nGower, J. C., & Hand, D. J. (1996). Biplots. Chapman; Hall.\n\n\nHajibaba, H., Karlsson, L., & Dolnicar, S. (2016). Residents open their homes to tourists when disaster strikes. Journal of Travel Research, 56(8), 1065–1078.\n\n\nHansen, C., & Johnson, C. R. (2004). Visualization handbook. Academic Press.\n\n\nHarrison, P. (2023a). Langevitour: Langevin tour. https://logarithmic.net/langevitour/\n\n\nHarrison, P. (2023b). Langevitour: Smooth interactive touring of high dimensions, demonstrated with scRNA-seq data. The R Journal, 15(2), 206–219. https://doi.org/10.32614/RJ-2023-046\n\n\nHart, C., & Wang, E. (2022). Detourr: Portable and performant tour animations. https://casperhart.github.io/detourr/\n\n\nHartigan, J. A., & Kleiner, B. (1981). Mosaics for Contingency Tables. Computer Science and Statistics: Proceedings of the 13th Symposium on the Interface, 268–273.\n\n\nHartigan, J., & Kleiner, B. (1984). A Mosaic of Television Ratings. The American Statistician, 38, 32–35.\n\n\nHaslett, J., Bradley, R., Craig, P., Unwin, A., & Wills, G. (1991). Dynamic Graphics for Exploring Spatial Data with Application to Locating Global and Local Anomalies. The American Statistician, 45(3), 234–242.\n\n\nHastie, T., Tibshirani, R., & Friedman, J. (2001). The Elements of Statistical Learning. Springer.\n\n\nHennig, C., Meila, M., Murtagh, F., & Rocci, R. (Eds.). (2015). Handbook of cluster analysis. Chapman; Hall/CRC. https://doi.org/10.1201/b19706\n\n\nHofmann, H. (2001). Graphical Tools for the Exploration of Multivariate Categorical Data. Books on Demand.\n\n\nHofmann, H. (2003). Constructing and Reading Mosaicplots. Computational Statistics and Data Analysis, 43(4), 565–580.\n\n\nHofmann, H., & Theus, M. (1998). Selection Sequences in MANET. Computational Statistics, 13(1), 77–87.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. https://CRAN.R-project.org/package=ggfortify\n\n\nHorikoshi, M., & Tang, Y. (2023). Ggfortify: Data visualization tools for statistical analysis results. https://github.com/sinhrks/ggfortify\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://CRAN.R-project.org/package=palmerpenguins\n\n\nHotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6), 417--441. https://doi.org/10.1037/h0071325\n\n\nHuber, P. J. (1985). Projection Pursuit (with discussion). Annals of Statistics, 13, 435–525.\n\n\nHurley, C. (1987). The data viewer: An interactive program for data analysis [PhD thesis]. University of Washington.\n\n\nIannone, R., Cheng, J., Schloerke, B., Hughes, E., Lauer, A., & Seo, J. (2023). Gt: Easily create presentation-ready display tables. https://CRAN.R-project.org/package=gt\n\n\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5, 299–314.\n\n\nIhaka, R., Murrell, P., Hornik, K., Fisher, J. C., Stauffer, R., Wilke, C. O., McWhite, C. D., & Zeileis, A. (2023). Colorspace: A toolbox for manipulating and assessing colors and palettes. https://CRAN.R-project.org/package=colorspace\n\n\nInselberg, A. (1985). The Plane with Parallel Coordinates. The Visual Computer, 1, 69–91.\n\n\nIowa State University. (2020). ASOS-AWOS-METAR data download. https://mesonet.agron.iastate.edu/request/download.phtml?network=AU__ASOS\n\n\nJohnson, D., & Travis, J. (2007). Flatland: The movie. https://round-drum-w7xh.squarespace.com/our-story.\n\n\nJohnson, R. A., & Wichern, D. W. (2002). Applied multivariate statistical analysis (5th ed). Prentice-Hall.\n\n\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Phil. Trans. R. Soc. A., 374, 20150202. https://doi.org/10.1098/rsta.2015.0202\n\n\nJones, M. C., & Sibson, R. (1987). What is Projection Pursuit? (With discussion). Journal of the Royal Statistical Society, Series A, 150, 1–36.\n\n\nKassambara, A. (2017). Practical guide to cluster analysis in r: Unsupervised machine learning. STHDA.\n\n\nKassambara, A. (2023). Ggpubr: ggplot2 based publication ready plots. https://rpkgs.datanovia.com/ggpubr/\n\n\nKohonen, T. (2001). Self-Organizing Maps (3rd ed). Springer.\n\n\nKoschat, M. A., & Swayne, D. F. (1996). Interactive Graphical Methods in the Analysis of Customer Panel Data (with discussion). Journal of Business and Economic Statistics, 14(1), 113–132.\n\n\nKrijthe, J. (2022). Rtsne: T-distributed stochastic neighbor embedding using a barnes-hut implementation. https://github.com/jkrijthe/Rtsne\n\n\nKruskal, J. B. (1964a). Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis. Psychometrika, 29, 1–27.\n\n\nKruskal, J. B. (1964b). Nonmetric Multidimensional Scaling: A Numerical Method. Psychometrika, 29, 115–129.\n\n\nKruskal, J. B., & Wish, M. (1978). Multidimensional Scaling. Sage Publications.\n\n\nKuhn, M., & Wickham, H. (2020). Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles. https://www.tidymodels.org\n\n\nKuhn, M., & Wickham, H. (2023). Tidymodels: Easily install and load the tidymodels packages. https://CRAN.R-project.org/package=tidymodels\n\n\nLaa, U., Cook, D., & Lee, S. (2022). Burning sage: Reversing the curse of dimensionality in the visualization of high-dimensional data. Journal of Computational and Graphical Statistics, 31(1), 40–49. https://doi.org/10.1080/10618600.2021.1963264\n\n\nLaa, U., Cook, D., & Valencia, G. (2020a). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLaa, U., Cook, D., & Valencia, G. (2020b). A slice tour for finding hollowness in high-dimensional data. Journal of Computational and Graphical Statistics, 29(3), 681–687. https://doi.org/10.1080/10618600.2020.1777140\n\n\nLancaster, H. O. (1965). The helmert matrices. The American Mathematical Monthly, 72(1), 4–12.\n\n\nLaurent, S. (2023). Cxhull: Convex hull. https://github.com/stla/cxhull\n\n\nLee, E.-K. (2018). PPtreeViz: An r package for visualizing projection pursuit classification trees. Journal of Statistical Software, 83(8), 1–30. https://doi.org/10.18637/jss.v083.i08\n\n\nLee, E.-K., & Cook, D. (2009). A projection pursuit index for large \\(p\\) small \\(n\\) data. Statistics and Computing, 20, 381–392. https://doi.org/10.1007/s11222-009-9131-1\n\n\nLee, E.-K., Cook, D., Klinke, S., & Lumley, T. (2005). Projection Pursuit for Exploratory Supervised Classification. Journal of Computational and Graphical Statistics, 14(4), 831–846.\n\n\nLee, S. (2021). Liminal: Multivariate data visualization with tours and embeddings. https://CRAN.R-project.org/package=liminal\n\n\nLee, S., Cook, D., Silva, N. da, Laa, U., Spyrison, N., Wang, E., & Zhang, H. S. (2022). The state-of-the-art on tours for dynamic visualization of high-dimensional data. WIREs Computational Statistics, 14(4), e1573. https://doi.org/10.1002/wics.1573\n\n\nLee, Y. D., Cook, D., Park, J., & Lee, E.-K. (2013). PPtree: Projection pursuit classification tree. Electronic Journal of Statistics, 7(none), 1369–1386. https://doi.org/10.1214/13-EJS810\n\n\nLeisch, F., & Gruen, B. (2023). CRAN task view: Cluster analysis & finite mixture models. https://cran.r-project.org/web/views/Cluster.html.\n\n\nLeisch, F., & Grün, B. (2020). MSA: Market segmentation analysis.\n\n\nLi, M., Zhao, Z., & Scheidegger, C. (2020). Visualizing neural networks with the grand tour. Distill. https://doi.org/10.23915/distill.00025\n\n\nLiaw, A., & Wiener, M. (2002). Classification and regression by randomForest. R News, 2(3), 18–22. https://CRAN.R-project.org/doc/Rnews/\n\n\nLittman, M. L., Swayne, D. F., Dean, N., & Buja, A. (1992). Visualizing the Embedding of Objects in Euclidean Space. Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 208–217.\n\n\nLloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2), 129–137. https://doi.org/10.1109/TIT.1982.1056489\n\n\nLongley, P. A., Maguire, D. J., Goodchild, M. F., & Rhind, D. W. (2005). Geographic information systems and science. John Wiley & Sons.\n\n\nLoperfido, N. (2018). Skewness-based projection pursuit: A computational approach. Computational Statistics & Data Analysis, 120, 42–57. https://doi.org/https://doi.org/10.1016/j.csda.2017.11.001\n\n\nMaaten, L. van der, & Hinton, G. (2008). Visualizing data using t-SNE. J. Mach. Learn. Res., 9(Nov), 2579–2605. http://www.jmlr.org/papers/v9/vandermaaten08a.html\n\n\nMacQueen, J. B. (1967). Some methods for classification and analysis of multivariate observations. In L. M. L. Cam & J. Neyman (Eds.), Proc. Of the fifth berkeley symposium on mathematical statistics and probability (Vol. 1, pp. 281–297). University of California Press.\n\n\nMaindonald, J., & Braun, J. (2003). Data analysis and graphics using r - an example-based approach. Cambridge University Press.\n\n\nMartin, E. (1965). Flatland. http://www.der.org/films/flatland.html.\n\n\nMayer, M., & Watson, D. (2023). Kernelshap: Kernel SHAP. https://CRAN.R-project.org/package=kernelshap\n\n\nMcFarlane, M., & Young, F. W. (1994). Graphical Sensitivity Analysis for Multidimensional Scaling. Journal of Computational and Graphical Statistics, 3, 23–33.\n\n\nMcInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform manifold approximation and projection for dimension reduction. http://arxiv.org/abs/1802.03426\n\n\nMcNeil, D. (1977). Interactive Data Analysis. John Wiley & Sons.\n\n\nMcVicar, T. (2011). Near-surface wind speed. v10. CSIRO. Data collection. https://doi.org/10.25919/5c5106acbcb02\n\n\nMeyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2023). e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien. https://CRAN.R-project.org/package=e1071\n\n\nMilborrow, S. (2022). Rpart.plot: Plot rpart models: An enhanced version of plot.rpart. http://www.milbo.org/rpart-plot/index.html\n\n\nMock, T. (2022). gtExtras: Extending gt for beautiful HTML tables. https://CRAN.R-project.org/package=gtExtras\n\n\nMolnar, C. (2022). Interpretable machine learning: A guide for making black box models explainable (2nd ed). https://christophm.github.io/interpretable-ml-book/.\n\n\nMoon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., Yim, K., Elzen, A. van den, Hirn, M. J., Coifman, R. R., Ivanova, N. B., Wolf, G., & Krishnaswamy, S. (2019). Visualizing structure and transitions for biological data exploration. Nature Biotechnology, 37, 1482–1492. https://doi.org/10.1038/s41587-019-0336-3\n\n\nMurrell, P. (2005). R graphics. Chapman & Hall/CRC.\n\n\nOpenStreetMap contributors. (2020). Planet dump retrieved from https://planet.osm.org . https://www.openstreetmap.org.\n\n\nPearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11), 559–572. https://doi.org/10.1080/14786440109462720\n\n\nPedersen, T. L. (2023). Patchwork: The composer of plots. https://CRAN.R-project.org/package=patchwork\n\n\nPerisic, I., & Posse, C. (2005). Projection pursuit indices based on the empirical distribution function. Journal of Computational and Graphical Statistics, 14(3), 700–715. https://doi.org/10.1198/106186005X69440\n\n\nPolzehl, J. (1995). Projection Pursuit Discriminant Analysis. Computational Statistics and Data Analysis, 20, 141–157.\n\n\nPosse, C. (1992). Projection Pursuit Discriminant Analysis for Two Groups. Communications in Statistics, Part A – Theory and Methods, 21, 1–19.\n\n\nPosse, C. (1995). Tools for Two-dimensional Projection Pursuit. Journal of Computational and Graphical Statistics, 4(2), 83–100.\n\n\nP-Tree System. (2020). JAXA Himawari Monitor - User’s Guide. https://www.eorc.jaxa.jp/ptree/userguide.html\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRao, C. R. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification (with discussion). Journal of the Royal Statistical Society, Series B, 10, 159–203.\n\n\nRao, C. R. (Ed.). (1993). Handbook of Statistics, Vol. 9. Elsevier Science Publishers.\n\n\nRao, C. R., Wegman, E. J., & Solka, J. L. (Eds.). (2006). Handbook of Statistics: Data Mining and Visualization. Elsevier/North-Holland.\n\n\nRipley, B. (1996). Pattern Recognition and Neural Networks. Cambridge University Press.\n\n\nRipley, B. (2023a). MASS: Support functions and datasets for venables and ripley’s MASS. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRipley, B. (2023b). Nnet: Feed-forward neural networks and multinomial log-linear models. http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nRothkopf, E. Z. (1957). A Measure of Stimulus Similarity and Errors in Some Paired-associate Learning Tasks. Journal of Experimental Psychology, 53, 94–101.\n\n\nSchloerke, B. (2016). Geozoo: Zoo of geometric objects. https://CRAN.R-project.org/package=geozoo\n\n\nSchloerke, B., Cook, D., Larmarange, J., Briatte, F., Marbach, M., Thoen, E., Elberg, A., & Crowley, J. (2023). GGally: Extension to ggplot2. https://ggobi.github.io/ggally/\n\n\nScrucca, L., Fop, M., Murphy, T. B., & Raftery, A. E. (2016). mclust 5: Clustering, classification and density estimation using Gaussian finite mixture models. The R Journal, 8(1), 289–317. https://doi.org/10.32614/RJ-2016-021\n\n\nShepard, R. N. (1962). The Analysis of Proximities: Multidimensional Scaling with an Unknown Distance Function, I and II. Psychometrika, 27, 125-139 and 219-246.\n\n\nSievert, C. (2020). Interactive web-based data visualization with r, plotly, and shiny. Chapman; Hall/CRC. https://plotly-r.com\n\n\nSievert, C., Parmer, C., Hocking, T., Chamberlain, S., Ram, K., Corvellec, M., & Despouy, P. (2023). Plotly: Create interactive web graphics via plotly.js. https://CRAN.R-project.org/package=plotly\n\n\nSjoberg, D. D., Larmarange, J., Curry, M., Lavery, J., Whiting, K., & Zabor, E. C. (2023). Gtsummary: Presentation-ready data summary and analytic result tables. https://CRAN.R-project.org/package=gtsummary\n\n\nSjoberg, D. D., Whiting, K., Curry, M., Lavery, J. A., & Larmarange, J. (2021). Reproducible summary tables with the gtsummary package. The R Journal, 13, 570–580. https://doi.org/10.32614/RJ-2021-053\n\n\nSlowikowski, K. (2023). Ggrepel: Automatically position non-overlapping text labels with ggplot2. https://github.com/slowkow/ggrepel\n\n\nSparks, A. H., Carroll, J., Goldie, J., Marchiori, D., Melloy, P., Padgham, M., Parsonage, H., & Pembleton, K. (2020). bomrang: Australian government bureau of meteorology (BOM) data client. https://CRAN.R-project.org/package=bomrang\n\n\nSpence, R. (2007). Information visualization: Design for interaction. Prentice Hall.\n\n\nStauffer, R., Mayr, G. J., Dabernig, M., & Zeileis, A. (2009). Somewhere over the rainbow: How to make effective use of colors in meteorological visualizations. Bulletin of the American Meteorological Society, 96(2), 203–216. https://doi.org/10.1175/BAMS-D-13-00155.1\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000b). Orca: A Visualization Toolkit for High-Dimensional Data. Journal of Computational and Graphical Statistics, 9(3), 509–529.\n\n\nSutherland, P., Rossini, A., Lumley, T., Lewin-Koh, N., Dickerson, J., Cox, Z., & Cook, D. (2000a). Orca: A visualization toolkit for high-dimensional data. Journal of Computational and Graphical Statistics, 9(3), 509–529. https://doi.org/10.1080/10618600.2000.10474896\n\n\nSwayne, D. F., Buja, A., & Temple Lang, D. (2004). Exploratory visual analysis of graphs in GGobi. In J. Antoch (Ed.), CompStat: Proceedings in computational statistics, 16th symposium. Physica-Verlag.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1992). XGobi: Interactive Dynamic Graphics in the X Window System with a Link to S. American Statistical Association 1991 Proceedings of the Section on Statistical Graphics, 1–8.\n\n\nSwayne, D. F., Cook, D., & Buja, A. (1998). XGobi: Interactive dynamic data visualization in the x window system. Journal of Computational and Graphical Statistics, 7(1), 113–130. https://doi.org/10.1080/10618600.1998.10474764\n\n\nSwayne, D. F., & Klinke, S. (1998). Editorial commentary. Computational Statistics: Special Issue on The Use of Interactive Graphics, 14(1).\n\n\nSwayne, D. F., Temple Lang, D., Buja, A., & Cook, D. (2003). GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization. Computational Statistics & Data Analysis, 43, 423–444.\n\n\nSwayne, D., & Buja, A. (1998). Missing Data in Interactive High-Dimensional Data Visualization. Computational Statistics, 13(1), 15–26.\n\n\nSymanzik, J. (2002). New applications of the image grand tour. Computing Science and Statistics, 34, 500--512. https://math.usu.edu/symanzik/papers/2002_interface.pdf\n\n\nSymanzik, J. (2004). Interactive and Dynamic Graphics. In J. E. Gentle, W. Härdle, & Y. Mori (Eds.), Handbook of computational statistics: Concepts and methods (pp. 293–336). Springer.\n\n\nTakatsuka, M., & Gahegan, M. (2002). GeoVISTA Studio: A Codeless Visual Programming Environment for Geoscientific Data Analysis and Visualization. The Journal of Computers and Geosciences, 28(10), 1131–1144.\n\n\nTang, Y., Horikoshi, M., & Li, W. (2016). Ggfortify: Unified interface to visualize statistical result of popular r packages. The R Journal, 8(2), 474–485. https://doi.org/10.32614/RJ-2016-060\n\n\nTarpey, T., Li, L., & Flury, B. (1995). Principal points and self–consistent points of elliptical distributions. The Annals of Statistics, 23, 103–112.\n\n\nTemple Lang, D., Swayne, D., Wickham, H., & Lawrence, M. (2006). rggobi: An Interface between R and GGobi. http://www.R-project.org.\n\n\nTherneau, T., & Atkinson, B. (2023). Rpart: Recursive partitioning and regression trees. https://CRAN.R-project.org/package=rpart\n\n\nTheus, M. (2002). Interactive Data Visualization Using Mondrian. Journal of Statistical Software, 7(11), http://www.jstatsoft.org.\n\n\nTheus, M., Hofmann, H., & Wilhelm, A. F. X. (1998). Selection Sequences – Interactive Analysis of Massive Data Sets. Computing Science and Statistics, 29(1), 439–444.\n\n\nThompson, G. L. (1993). Generalized Permutation Polytopes and Exploratory Graphical Methods for Ranked Data. The Annals of Statistics, 21, 1401–1430.\n\n\nTierney, L. (1991). LispStat: An Object-Orientated Environment for Statistical Computing and Dynamic Graphics. John Wiley & Sons.\n\n\nTierney, N., & Cook, D. (2023a). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., & Cook, D. (2023b). Expanding tidy data principles to facilitate missing data exploration, visualization and assessment of imputations. Journal of Statistical Software, 105(7), 1–31. https://doi.org/10.18637/jss.v105.i07\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2023). Naniar: Data structures, summaries, and visualisations for missing data. https://github.com/njtierney/naniar\n\n\nTorgerson, W. S. (1952). Multidimensional Scaling. 1. Theory and Method. Psychometrika, 17, 401–419.\n\n\nTufte, E. (1983). The visual display of quantitative information. Graphics Press.\n\n\nTufte, E. (1990). Envisioning information. Graphics Press.\n\n\nTukey, J. W. (1965). The Technical Tools of Statistics. The American Statistician, 19, 23–28.\n\n\nUnwin, A. R., Hawkins, G., Hofmann, H., & Siegl, B. (1996). Interactive Graphics for Data Sets with Missing Values - MANET. Journal of Computational and Graphical Statistics, 5(2), 113–122.\n\n\nUnwin, A., Hofmann, H., & Wilhelm, A. (2002). Direct Manipulation Graphics for Data Mining. Journal of Image and Graphics, 2(1), 49–65.\n\n\nUnwin, A., Theus, M., & Hofmann, H. (2006). Graphics of Large Datasets: Visualizing a Million. Springer.\n\n\nUnwin, A., Volinsky, C., & Winkler, S. (2003). Parallel Coordinates for Exploratory Modelling Analysis. Comput. Stat. Data Anal., 43(4), 553–564. https://doi.org/{\\tt http://dx.doi.org/10.1016/S0167-9473(02)00292-X}\n\n\nUrbanek, S., & Theus, M. (2003). iPlots: High Interaction Graphics for R. In K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of the 3rd international workshop on distributed statistical computing (DSC 2003).\n\n\nVaidyanathan, R., Xie, Y., Allaire, J., Cheng, J., Sievert, C., & Russell, K. (2023). Htmlwidgets: HTML widgets for r. https://github.com/ramnathv/htmlwidgets\n\n\nvan der Maaten, L. J. P. (2014). Accelerating t-SNE using tree-based algorithms. Journal of Machine Learning Research, 15, 3221–3245.\n\n\nvan der Maaten, L. J. P., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research, 9, 2579–2605.\n\n\nVapnik, V. N. (1999). The Nature of Statistical Learning Theory. Springer.\n\n\nVelleman, P. F., & Velleman, A. Y. (1985). Data desk handbook. Data Description, Inc.\n\n\nVenables, W. N., & Ripley, B. (2002a). Modern Applied Statistics with S. Springer-Verlag.\n\n\nVenables, W. N., & Ripley, B. D. (2002b). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nVenables, W. N., & Ripley, B. D. (2002c). Modern applied statistics with s (Fourth). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWainer, H. (2000). Visual Revelations (2nd ed). LEA, Inc.\n\n\nWainer, H., & Spence, I. (eds). (2005a). The Commercial and Political Atlas, Representing, by means of Stained Copper-Plate Charts, The Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the whole of the Eighteenth Century, by William Playfair. Cambridge University Press.\n\n\nWainer, H., & Spence, I. (eds). (2005b). The Statistical Breviary; Shewing on a Principle entirely new, the resources of every state and kingdom in Europe; illustrated with Stained Copper-Plate Charts, representing the physical powers of each distinct nation with ease and perspicuity by William Playfair. Cambridge University Press.\n\n\nWang, P. C. C. (Ed.). (1978). Graphical Representation of Multivariate Data. Academic Press.\n\n\nWegman, E. (1990). Hyperdimensional Data Analysis Using Parallel Coordinates. Journal of American Statistics Association, 85, 664–675.\n\n\nWegman, E. J. (1991). The Grand Tour in \\(k\\)-Dimensions (Technical Report No. 68). Center for Computational Statistics, George Mason University.\n\n\nWegman, E. J., & Carr, D. B. (1993). Statistical Graphics and Visualization (C. R. Rao, Ed.; pp. 857–958). Elsevier Science Publishers.\n\n\nWegman, E. J., Poston, W. L., & Solka, J. L. (1998). Image Grand Tour. Automatic Target Recognition VIII - Proceedings of SPIE, 3371, 286–294.\n\n\nWehrens, R., & Buydens, L. M. C. (2007). Self- and super-organizing maps in R: The kohonen package. Journal of Statistical Software, 21(5), 1–19. https://doi.org/10.18637/jss.v021.i05\n\n\nWehrens, R., & Kruisselbrink, J. (2018). Flexible self-organizing maps in kohonen 3.0. Journal of Statistical Software, 87(7), 1–18. https://doi.org/10.18637/jss.v087.i07\n\n\nWehrens, R., & Kruisselbrink, J. (2023). Kohonen: Supervised and unsupervised self-organising maps. https://CRAN.R-project.org/package=kohonen\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2022). Classifly: Explore classification models in high dimensions. http://had.co.nz/classifly\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., & Dunnington, D. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics. https://CRAN.R-project.org/package=ggplot2\n\n\nWickham, H., & Cook, D. (2024). Tourr: Tour methods for multivariate data visualisation. https://github.com/ggobi/tourr\n\n\nWickham, H., Cook, D., & Hofmann, H. (2015). Visualizing statistical models: Removing the blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal, 8(4), 203–225. https://doi.org/10.1002/sam.11271\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011a). Tourr: An R Package for Exploring Multivariate Data with Projections. Journal of Statistical Software, 40(2). https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., Cook, D., Hofmann, H., & Buja, A. (2011b). tourr: An R package for exploring multivariate data with projections. Journal of Statistical Software, 40(2), 1–18. https://doi.org/10.18637/jss.v040.i02\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://CRAN.R-project.org/package=dplyr\n\n\nWickham, H., Hester, J., & Bryan, J. (2023). Readr: Read rectangular text data. https://CRAN.R-project.org/package=readr\n\n\nWilhelm, A. F. X., Wegman, E. J., & Symanzik, J. (1999). Visual Clustering and Classification: The Oronsay Particle Size Data Set Revisited. Computational Statistics: Special Issue on Interactive Graphical Data Analysis, 14(1), 109–146.\n\n\nWilkinson, L. (2005). The grammar of graphics. Springer.\n\n\nWills, G. (1999). NicheWorks – Interactive Visualization of Very Large Graphs. Journal of Computational and Graphical Statistics, 8(2), 190–212.\n\n\nXie, Y., Hofmann, H., & Cheng, X. (2014). Reactive Programming for Interactive Graphics. Statistical Science, 29(2), 201–213. https://doi.org/10.1214/14-STS477\n\n\nYoung, F. W., Valero-Mora, P. M., & Friendly, M. (2006). Visual Statistics: Seeing Data with Dynamic Interactive Graphics. John Wiley & Sons.\n\n\nZeileis, A., Fisher, J. C., Hornik, K., Ihaka, R., McWhite, C. D., Murrell, P., Stauffer, R., & Wilke, C. O. (2020). colorspace: A toolbox for manipulating and assessing colors and palettes. Journal of Statistical Software, 96(1), 1–49. https://doi.org/10.18637/jss.v096.i01\n\n\nZeileis, A., Hornik, K., & Murrell, P. (2009). Escaping RGBland: Selecting colors for statistical graphics. Computational Statistics & Data Analysis, 53(9), 3259–3270. https://doi.org/10.1016/j.csda.2008.11.033\n\n\nZhang, C., Ye, J., & Wang, X. (2023). A computational perspective on projection pursuit in high dimensions: Feasible or infeasible feature extraction. International Statistical Review, 91(1), 140–161. https://doi.org/10.1111/insr.12517\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2021). Visual diagnostics for constrained optimisation with application to guided tours. The R Journal, 13(2), 624–641. https://doi.org/10.32614/RJ-2021-105\n\n\nZhang, H. S., Cook, D., Laa, U., Langrené, N., & Menéndez, P. (2022). Ferrn: Facilitate exploration of touRR optimisatioN. https://github.com/huizezhang-sherry/ferrn/\n\n\nZhu, H. (2021). kableExtra: Construct complex table with kable and pipe syntax. https://CRAN.R-project.org/package=kableExtra",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  },
  {
    "objectID": "1-intro.html#footnotes",
    "href": "1-intro.html#footnotes",
    "title": "1  Picturing high dimensions",
    "section": "",
    "text": "Thanks to Barret Schloerke for directing co-author Cook to this history when he was an undergraduate student and we were starting the geozoo project.↩︎\n“Space is big. Really big. You might think it’s a long way to the pharmacy, but that’s peanuts to space.” from Douglas Adams’ Hitchhiker’s Guide to the Galaxy always springs to mind when thinking about high dimensions!↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Picturing high dimensions</span>"
    ]
  }
]