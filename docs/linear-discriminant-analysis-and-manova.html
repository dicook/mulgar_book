<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Linear discriminant analysis and MANOVA | Interactive and dynamic graphics for multivariate data using R</title>
  <meta name="description" content="This is a book about exploring multivariate data." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Linear discriminant analysis and MANOVA | Interactive and dynamic graphics for multivariate data using R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a book about exploring multivariate data." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Linear discriminant analysis and MANOVA | Interactive and dynamic graphics for multivariate data using R" />
  
  <meta name="twitter:description" content="This is a book about exploring multivariate data." />
  

<meta name="author" content="Di Cook, Ursula Laa, Stuart Lee, Earo Wang" />


<meta name="date" content="2021-02-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression-methods.html"/>
<link rel="next" href="trees-and-forests.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interactive and dynamic graphics for multivariate data using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#audience"><i class="fa fa-check"></i><b>0.1</b> Audience</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#how-to-use-the-book"><i class="fa fa-check"></i><b>0.2</b> How to use the book?</a><ul>
<li class="chapter" data-level="0.2.1" data-path="index.html"><a href="index.html#what-do-we-assume-about-you"><i class="fa fa-check"></i><b>0.2.1</b> What do we assume about you?</a></li>
</ul></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#setting-up-your-workflow"><i class="fa fa-check"></i><b>0.3</b> Setting up your workflow</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#whats-different-about-space-beyond-2d"><i class="fa fa-check"></i><b>1.1</b> Whatâ€™s different about space beyond 2D</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#interactive-and-dynamic-graphics-literature"><i class="fa fa-check"></i><b>1.2</b> Interactive and dynamic graphics literature</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#an-opening-case-study"><i class="fa fa-check"></i><b>1.3</b> An opening case study</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#the-big-picture-of-the-book"><i class="fa fa-check"></i><b>1.4</b> The big picture of the book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="toolbox.html"><a href="toolbox.html"><i class="fa fa-check"></i><b>2</b> Toolbox</a></li>
<li class="chapter" data-level="3" data-path="dimension-reduction.html"><a href="dimension-reduction.html"><i class="fa fa-check"></i><b>3</b> Dimension reduction</a></li>
<li class="chapter" data-level="4" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>4</b> Data</a><ul>
<li class="chapter" data-level="4.0.1" data-path="data.html"><a href="data.html#other-possible-sources-for-data"><i class="fa fa-check"></i><b>4.0.1</b> Other possible sources for data</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="regression-methods.html"><a href="regression-methods.html"><i class="fa fa-check"></i><b>5</b> Regression methods</a><ul>
<li class="chapter" data-level="5.1" data-path="regression-methods.html"><a href="regression-methods.html#support-vector-machine"><i class="fa fa-check"></i><b>5.1</b> Support vector machine</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-discriminant-analysis-and-manova.html"><a href="linear-discriminant-analysis-and-manova.html"><i class="fa fa-check"></i><b>6</b> Linear discriminant analysis and MANOVA</a></li>
<li class="chapter" data-level="7" data-path="trees-and-forests.html"><a href="trees-and-forests.html"><i class="fa fa-check"></i><b>7</b> Trees and forests</a><ul>
<li class="chapter" data-level="7.1" data-path="trees-and-forests.html"><a href="trees-and-forests.html#trees"><i class="fa fa-check"></i><b>7.1</b> Trees</a></li>
<li class="chapter" data-level="7.2" data-path="trees-and-forests.html"><a href="trees-and-forests.html#random-forests"><i class="fa fa-check"></i><b>7.2</b> Random forests</a></li>
<li class="chapter" data-level="" data-path="trees-and-forests.html"><a href="trees-and-forests.html#exercises"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="neural-networks-and-deep-learning.html"><a href="neural-networks-and-deep-learning.html"><i class="fa fa-check"></i><b>8</b> Neural networks and deep learning</a></li>
<li class="chapter" data-level="9" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html"><i class="fa fa-check"></i><b>9</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="10" data-path="k-means-clustering.html"><a href="k-means-clustering.html"><i class="fa fa-check"></i><b>10</b> k-means clustering</a></li>
<li class="chapter" data-level="11" data-path="model-based-clustering.html"><a href="model-based-clustering.html"><i class="fa fa-check"></i><b>11</b> model-based clustering</a></li>
<li class="chapter" data-level="12" data-path="multivariate-time-series.html"><a href="multivariate-time-series.html"><i class="fa fa-check"></i><b>12</b> Multivariate time series</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interactive and dynamic graphics for multivariate data using R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-discriminant-analysis-and-manova" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Linear discriminant analysis and MANOVA</h1>
<p>Discriminant analysis dates to the early 1900s. Fisherâ€™s linear
discriminant  determines a linear combination of the
variables that separates two classes by comparing the differences
between class means with the variance of values within each class. It
makes no assumptions about the distribution of the data. Linear
discriminant analysis (LDA), as proposed by ,
formalizes Fisherâ€™s approach by imposing the assumption that the data
values for each class arise from a <span class="math inline">\(p\)</span>-dimensional multivariate normal
distribution, which shares a common varianceâ€“covariance matrix with data
from other classes. Under this assumption, Fisherâ€™s linear
discriminant gives the optimal separation between the two groups.</p>
<p>For two equally weighted groups, where <span class="math inline">\(Y\)</span> is coded as <span class="math inline">\(\{0, 1\}\)</span>, the LDA rule is:</p>

<p>where ${}_k $ are the class mean vectors of an
<span class="math inline">\(n\times p\)</span> data matrix <span class="math inline">\(\blX_k ~~(k=1,2)\)</span>,</p>
<p><span class="math display">\[
\blS_{\rm pooled} = \frac{(n_1-1)
\blS_1}{(n_1-1)+(n_2-1)} + \frac{(n_2-1) \blS_2}{(n_1-1)+(n_2-1)}
\]</span></p>
<p>is the pooled varianceâ€“covariance matrix, and</p>
<p><span class="math display">\[ 
\blS_k = \frac{1}{n-1}\sum_{i=1}^{n}
(\blX_{ki}-\bar{\blX}_k)(\blX_{ki}-\bar{\blX}_k)&#39;, ~~k=1,2
\]</span></p>
<p>is the class varianceâ€“covariance matrix. The linear
discriminant part of this rule is
<span class="math inline">\((\bar{\blX}_1-\bar{\blX}_2)&#39;\blS^{-1}_{\rm pooled}\)</span>, which defines
the linear combination of variables that best separates the two
groups. To define a classification rule, we compute the value of the
new observation <span class="math inline">\(\blX_0\)</span> on this line and compare it with the value of
the average of the two class means <span class="math inline">\((\bar{\blX}_1+\bar{\blX}_2)/2\)</span> on
the same line.
%Computing the value of the new observation <span class="math inline">\(\blX_0\)</span> on this
%line and comparing it with the value of the average of the two class
%means <span class="math inline">\((\bar{\blX}_1+\bar{\blX}_2)/2\)</span> on this line gives the
%classification rule.</p>
<p>For multiple <span class="math inline">\((g)\)</span> classes, the rule and the discriminant space are
constructed using the between-group sum-of-squares matrix,</p>
<p><span class="math display">\[
\blB =
\sum_{k=1}^g n_k(\bar{\blX}_k-\bar{\blX})(\bar{\blX}_k-\bar{\blX})&#39; 
\]</span></p>
<p>which measures the differences between the class means,
compared with the overall data mean <span class="math inline">\(\bar{\blX}\)</span> and the within-group
sum-of-squares matrix,</p>
<p><span class="math display">\[
\blW =
\sum_{k=1}^g\sum_{i=1}^{n_k}
(\blX_{ki}-\bar{\blX}_k)(\blX_{ki}-\bar{\blX}_k)&#39;
\]</span></p>
<p>which measures the variation of values around each class mean.
The linear discriminant space is generated by computing the
eigenvectors (canonical coordinates) of <span class="math inline">\(\blW^{-1}\blB\)</span>, and this is
the space where the group means are most separated with respect to the
pooled varianceâ€“covariance. The resulting classification rule is to
allocate a new observation to the class with the highest value of</p>
<p><span class="math display">\[\begin{eqnarray}
\bar{\blX}_k&#39;\blS^{-1}_{\rm pooled}\blX_0 - 
\frac{1}{2}\bar{\blX}_k&#39;\blS^{-1}_{\rm pooled}\bar{\blX}_k ~~~k=1,...,g \label{lda-rule}
\end{eqnarray}\]</span></p>
<p>which results in allocating the new observation into the
class with the closest mean.</p>
<p>This LDA approach is widely applicable, but it is useful
to check the underlying assumptions on which it depends: (1)
that the cluster structure corresponding to each class forms an
ellipse, showing that the class is consistent with a sample from a
multivariate normal distribution, and (2) that the variance of values
around each mean is nearly the same. Figure~
illustrates two datasets, of which only one is consistent with these
assumptions. Other parametric models, such as quadratic discriminant
analysis or logistic regression, also depend on assumptions
about the data which should be validated.  </p>
<p>% Figure 1</p>
<p>Our description is derived from <span class="citation">(<span class="citeproc-not-found" data-reference-id="VR02"><strong>???</strong></span>)</span> and
<span class="citation">(<span class="citeproc-not-found" data-reference-id="Ri96"><strong>???</strong></span>)</span>. A good general treatment of parametric methods for
supervised classification can be found in <span class="citation">(<span class="citeproc-not-found" data-reference-id="JW02"><strong>???</strong></span>)</span> or another
similar multivariate analysis textbook. Missing from multivariate
textbooks is a good explanation of the use of interactive graphics
both to check the assumptions underlying the methods and to explore
the results. This chapter fills this gap.</p>
<p>Algorithmic methods have overtaken parametric methods in the practice
of supervised classification. A parametric method such as linear
discriminant analysis yields a set of interpretable output parameters, so
it leaves a clear trail helping us to understand what was done to
produce the results. An algorithmic method, on the other hand, is
more or less a black box, with various input parameters that are
adjusted to tune the algorithm. The algorithmâ€™s input and output
parameters do not always correspond in any obvious way to the
interpretation of the results. All the same, these methods can be
very powerful and their use is not limited by requirements about
variable distributions as is the case with parametric methods.</p>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression-methods.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="trees-and-forests.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["mulgar.pdf", "mulgar.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
